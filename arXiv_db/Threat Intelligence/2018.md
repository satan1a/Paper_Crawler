# 2018

## TOC

- [2018-09](#2018-09)
- [2018-10](#2018-10)
- [2018-11](#2018-11)
- [2018-12](#2018-12)

## 2018-09

<details>

<summary>2018-09-06 11:21:18 - Fixed set search applied to the traveling salesman problem</summary>

- *Raka Jovanovic, Milan Tuba, Stefan Voss*

- `1809.04942v1` - [abs](http://arxiv.org/abs/1809.04942v1) - [pdf](http://arxiv.org/pdf/1809.04942v1)

> In this paper we present a new population based metaheuristic called the fixed set search (FSS). The proposed approach represents a method of adding a learning mechanism to the greedy randomized adaptive search procedure (GRASP). The basic concept of FSS is to avoid focusing on specific high quality solutions but on parts or elements that such solutions have. This is done through fixing a set of elements that exist in such solutions and dedicating computational effort to finding near optimal solutions for the underlying subproblem. The simplicity of implementing the proposed method is illustrated on the traveling salesman problem. Our computational experiments show that the FSS manages to find significantly better solutions than the GRASP it is based on and also the dynamic convexized method.

</details>

<details>

<summary>2018-09-06 12:16:17 - Imitation Learning with Concurrent Actions in 3D Games</summary>

- *Jack Harmer, Linus Gisslén, Jorge del Val, Henrik Holst, Joakim Bergdahl, Tom Olsson, Kristoffer Sjöö, Magnus Nordin*

- `1803.05402v5` - [abs](http://arxiv.org/abs/1803.05402v5) - [pdf](http://arxiv.org/pdf/1803.05402v5)

> In this work we describe a novel deep reinforcement learning architecture that allows multiple actions to be selected at every time-step in an efficient manner. Multi-action policies allow complex behaviours to be learnt that would otherwise be hard to achieve when using single action selection techniques. We use both imitation learning and temporal difference (TD) reinforcement learning (RL) to provide a 4x improvement in training time and 2.5x improvement in performance over single action selection TD RL. We demonstrate the capabilities of this network using a complex in-house 3D game. Mimicking the behavior of the expert teacher significantly improves world state exploration and allows the agents vision system to be trained more rapidly than TD RL alone. This initial training technique kick-starts TD learning and the agent quickly learns to surpass the capabilities of the expert.

</details>

<details>

<summary>2018-09-06 12:24:04 - Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots</summary>

- *Shaojie Jiang, Maarten de Rijke*

- `1809.01941v1` - [abs](http://arxiv.org/abs/1809.01941v1) - [pdf](http://arxiv.org/pdf/1809.01941v1)

> Diversity is a long-studied topic in information retrieval that usually refers to the requirement that retrieved results should be non-repetitive and cover different aspects. In a conversational setting, an additional dimension of diversity matters: an engaging response generation system should be able to output responses that are diverse and interesting. Sequence-to-sequence (Seq2Seq) models have been shown to be very effective for response generation. However, dialogue responses generated by Seq2Seq models tend to have low diversity. In this paper, we review known sources and existing approaches to this low-diversity problem. We also identify a source of low diversity that has been little studied so far, namely model over-confidence. We sketch several directions for tackling model over-confidence and, hence, the low-diversity problem, including confidence penalties and label smoothing.

</details>

<details>

<summary>2018-09-06 12:24:44 - A tutorial on Particle Swarm Optimization Clustering</summary>

- *Augusto Luis Ballardini*

- `1809.01942v1` - [abs](http://arxiv.org/abs/1809.01942v1) - [pdf](http://arxiv.org/pdf/1809.01942v1)

> This paper proposes a tutorial on the Data Clustering technique using the Particle Swarm Optimization approach. Following the work proposed by Merwe et al. here we present an in-deep analysis of the algorithm together with a Matlab implementation and a short tutorial that explains how to modify the proposed implementation and the effect of the parameters of the original algorithm. Moreover, we provide a comparison against the results obtained using the well known K-Means approach. All the source code presented in this paper is publicly available under the GPL-v2 license.

</details>

<details>

<summary>2018-09-06 12:26:24 - Cascaded Mutual Modulation for Visual Reasoning</summary>

- *Yiqun Yao, Jiaming Xu, Feng Wang, Bo Xu*

- `1809.01943v1` - [abs](http://arxiv.org/abs/1809.01943v1) - [pdf](http://arxiv.org/pdf/1809.01943v1)

> Visual reasoning is a special visual question answering problem that is multi-step and compositional by nature, and also requires intensive text-vision interactions. We propose CMM: Cascaded Mutual Modulation as a novel end-to-end visual reasoning model. CMM includes a multi-step comprehension process for both question and image. In each step, we use a Feature-wise Linear Modulation (FiLM) technique to enable textual/visual pipeline to mutually control each other. Experiments show that CMM significantly outperforms most related models, and reach state-of-the-arts on two visual reasoning benchmarks: CLEVR and NLVR, collected from both synthetic and natural languages. Ablation studies confirm that both our multistep framework and our visual-guided language modulation are critical to the task. Our code is available at https://github.com/FlamingHorizon/CMM-VR.

</details>

<details>

<summary>2018-09-06 13:47:53 - Evaluation Measures for Quantification: An Axiomatic Approach</summary>

- *Fabrizio Sebastiani*

- `1809.01991v1` - [abs](http://arxiv.org/abs/1809.01991v1) - [pdf](http://arxiv.org/pdf/1809.01991v1)

> Quantification is the task of estimating, given a set $\sigma$ of unlabelled items and a set of classes $\mathcal{C}=\{c_{1}, \ldots, c_{|\mathcal{C}|}\}$, the prevalence (or `relative frequency') in $\sigma$ of each class $c_{i}\in \mathcal{C}$. While quantification may in principle be solved by classifying each item in $\sigma$ and counting how many such items have been labelled with $c_{i}$, it has long been shown that this `classify and count' (CC) method yields suboptimal quantification accuracy. As a result, quantification is no longer considered a mere byproduct of classification, and has evolved as a task of its own. While the scientific community has devoted a lot of attention to devising more accurate quantification methods, it has not devoted much to discussing what properties an \emph{evaluation measure for quantification} (EMQ) should enjoy, and which EMQs should be adopted as a result. This paper lies down a number of interesting properties that an EMQ may or may not enjoy, discusses if (and when) each of these properties is desirable, surveys the EMQs that have been used so far, and discusses whether they enjoy or not the above properties. As a result of this investigation, some of the EMQs that have been used in the literature turn out to be severely unfit, while others emerge as closer to what the quantification community actually needs. However, a significant result is that no existing EMQ satisfies all the properties identified as desirable, thus indicating that more research is needed in order to identify (or synthesize) a truly adequate EMQ.

</details>

<details>

<summary>2018-09-06 15:03:13 - Planning with Arithmetic and Geometric Attributes</summary>

- *David Folqué, Sainbayar Sukhbaatar, Arthur Szlam, Joan Bruna*

- `1809.02031v1` - [abs](http://arxiv.org/abs/1809.02031v1) - [pdf](http://arxiv.org/pdf/1809.02031v1)

> A desirable property of an intelligent agent is its ability to understand its environment to quickly generalize to novel tasks and compose simpler tasks into more complex ones. If the environment has geometric or arithmetic structure, the agent should exploit these for faster generalization. Building on recent work that augments the environment with user-specified attributes, we show that further equipping these attributes with the appropriate geometric and arithmetic structure brings substantial gains in sample complexity.

</details>

<details>

<summary>2018-09-06 15:18:14 - Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks</summary>

- *Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian, Daniel Gildea*

- `1809.02040v1` - [abs](http://arxiv.org/abs/1809.02040v1) - [pdf](http://arxiv.org/pdf/1809.02040v1)

> Multi-hop reading comprehension focuses on one type of factoid question, where a system needs to properly integrate multiple pieces of evidence to correctly answer a question. Previous work approximates global evidence with local coreference information, encoding coreference chains with DAG-styled GRU layers within a gated-attention reader. However, coreference is limited in providing information for rich inference. We introduce a new method for better connecting global evidence, which forms more complex graphs compared to DAGs. To perform evidence integration on our graphs, we investigate two recent graph neural networks, namely graph convolutional network (GCN) and graph recurrent network (GRN). Experiments on two standard datasets show that richer global information leads to better answers. Our method performs better than all published results on these datasets.

</details>

<details>

<summary>2018-09-06 16:03:18 - Deep learning for in vitro prediction of pharmaceutical formulations</summary>

- *Yilong Yang, Zhuyifan Ye, Yan Su, Qianqian Zhao, Xiaoshan Li, Defang Ouyang*

- `1809.02069v1` - [abs](http://arxiv.org/abs/1809.02069v1) - [pdf](http://arxiv.org/pdf/1809.02069v1)

> Current pharmaceutical formulation development still strongly relies on the traditional trial-and-error approach by individual experiences of pharmaceutical scientists, which is laborious, time-consuming and costly. Recently, deep learning has been widely applied in many challenging domains because of its important capability of automatic feature extraction. The aim of this research is to use deep learning to predict pharmaceutical formulations. In this paper, two different types of dosage forms were chosen as model systems. Evaluation criteria suitable for pharmaceutics were applied to assessing the performance of the models. Moreover, an automatic dataset selection algorithm was developed for selecting the representative data as validation and test datasets. Six machine learning methods were compared with deep learning. The result shows the accuracies of both two deep neural networks were above 80% and higher than other machine learning models, which showed good prediction in pharmaceutical formulations. In summary, deep learning with the automatic data splitting algorithm and the evaluation criteria suitable for pharmaceutical formulation data was firstly developed for the prediction of pharmaceutical formulations. The cross-disciplinary integration of pharmaceutics and artificial intelligence may shift the paradigm of pharmaceutical researches from experience-dependent studies to data-driven methodologies.

</details>

<details>

<summary>2018-09-06 16:27:32 - Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models</summary>

- *Tong Niu, Mohit Bansal*

- `1809.02079v1` - [abs](http://arxiv.org/abs/1809.02079v1) - [pdf](http://arxiv.org/pdf/1809.02079v1)

> We present two categories of model-agnostic adversarial strategies that reveal the weaknesses of several generative, task-oriented dialogue models: Should-Not-Change strategies that evaluate over-sensitivity to small and semantics-preserving edits, as well as Should-Change strategies that test if a model is over-stable against subtle yet semantics-changing modifications. We next perform adversarial training with each strategy, employing a max-margin approach for negative generative examples. This not only makes the target dialogue model more robust to the adversarial inputs, but also helps it perform significantly better on the original inputs. Moreover, training on all strategies combined achieves further improvements, achieving a new state-of-the-art performance on the original task (also verified via human evaluation). In addition to adversarial training, we also address the robustness task at the model-level, by feeding it subword units as both inputs and outputs, and show that the resulting model is equally competitive, requires only 1/4 of the original vocabulary size, and is robust to one of the adversarial strategies (to which the original model is vulnerable) even without adversarial training.

</details>

<details>

<summary>2018-09-06 16:56:32 - Object Ordering with Bidirectional Matchings for Visual Reasoning</summary>

- *Hao Tan, Mohit Bansal*

- `1804.06870v2` - [abs](http://arxiv.org/abs/1804.06870v2) - [pdf](http://arxiv.org/pdf/1804.06870v2)

> Visual reasoning with compositional natural language instructions, e.g., based on the newly-released Cornell Natural Language Visual Reasoning (NLVR) dataset, is a challenging task, where the model needs to have the ability to create an accurate mapping between the diverse phrases and the several objects placed in complex arrangements in the image. Further, this mapping needs to be processed to answer the question in the statement given the ordering and relationship of the objects across three similar images. In this paper, we propose a novel end-to-end neural model for the NLVR task, where we first use joint bidirectional attention to build a two-way conditioning between the visual information and the language phrases. Next, we use an RL-based pointer network to sort and process the varying number of unordered objects (so as to match the order of the statement phrases) in each of the three images and then pool over the three decisions. Our model achieves strong improvements (of 4-6% absolute) over the state-of-the-art on both the structured representation and raw image versions of the dataset.

</details>

<details>

<summary>2018-09-06 17:08:21 - Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation</summary>

- *Mikel Artetxe, Gorka Labaka, Iñigo Lopez-Gazpio, Eneko Agirre*

- `1809.02094v1` - [abs](http://arxiv.org/abs/1809.02094v1) - [pdf](http://arxiv.org/pdf/1809.02094v1)

> Following the recent success of word embeddings, it has been argued that there is no such thing as an ideal representation for words, as different models tend to capture divergent and often mutually incompatible aspects like semantics/syntax and similarity/relatedness. In this paper, we show that each embedding model captures more information than directly apparent. A linear transformation that adjusts the similarity order of the model without any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones.

</details>

<details>

<summary>2018-09-06 17:50:22 - Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning</summary>

- *Shang-Yu Su, Xiujun Li, Jianfeng Gao, Jingjing Liu, Yun-Nung Chen*

- `1808.09442v2` - [abs](http://arxiv.org/abs/1808.09442v2) - [pdf](http://arxiv.org/pdf/1808.09442v2)

> This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving the effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed framework that extends the Dyna-Q algorithm to integrate planning for task-completion dialogue policy learning. To obviate DDQ's high dependency on the quality of simulated experiences, we incorporate an RNN-based discriminator in D3Q to differentiate simulated experience from real user experience in order to control the quality of training data. Experiments show that D3Q significantly outperforms DDQ by controlling the quality of simulated experience used for planning. The effectiveness and robustness of D3Q is further demonstrated in a domain extension setting, where the agent's capability of adapting to a changing environment is tested.

</details>

<details>

<summary>2018-09-06 18:00:26 - GANs beyond divergence minimization</summary>

- *Alexia Jolicoeur-Martineau*

- `1809.02145v1` - [abs](http://arxiv.org/abs/1809.02145v1) - [pdf](http://arxiv.org/pdf/1809.02145v1)

> Generative adversarial networks (GANs) can be interpreted as an adversarial game between two players, a discriminator D and a generator G, in which D learns to classify real from fake data and G learns to generate realistic data by "fooling" D into thinking that fake data is actually real data. Currently, a dominating view is that G actually learns by minimizing a divergence given that the general objective function is a divergence when D is optimal. However, this view has been challenged due to inconsistencies between theory and practice. In this paper, we discuss of the properties associated with most loss functions for G (e.g., saturating/non-saturating f-GAN, LSGAN, WGAN, etc.). We show that these loss functions are not divergences and do not have the same equilibrium as expected of divergences. This suggests that G does not need to minimize the same objective function as D maximize, nor maximize the objective of D after swapping real data with fake data (non-saturating GAN) but can instead use a wide range of possible loss functions to learn to generate realistic data. We define GANs through two separate and independent D maximization and G minimization steps. We generalize the generator step to four new classes of loss functions, most of which are actual divergences (while traditional G loss functions are not). We test a wide variety of loss functions from these four classes on a synthetic dataset and on CIFAR-10. We observe that most loss functions converge well and provide comparable data generation quality to non-saturating GAN, LSGAN, and WGAN-GP generator loss functions, whether we use divergences or non-divergences. These results suggest that GANs do not conform well to the divergence minimization theory and form a much broader range of models than previously assumed.

</details>

<details>

<summary>2018-09-06 20:01:29 - Community Regularization of Visually-Grounded Dialog</summary>

- *Akshat Agarwal, Swaminathan Gurumurthy, Vasu Sharma, Mike Lewis, Katia Sycara*

- `1808.04359v2` - [abs](http://arxiv.org/abs/1808.04359v2) - [pdf](http://arxiv.org/pdf/1808.04359v2)

> The task of conducting visually grounded dialog involves learning goal-oriented cooperative dialog between autonomous agents who exchange information about a scene through several rounds of questions and answers in natural language. We posit that requiring artificial agents to adhere to the rules of human language, while also requiring them to maximize information exchange through dialog is an ill-posed problem. We observe that humans do not stray from a common language because they are social creatures who live in communities, and have to communicate with many people everyday, so it is far easier to stick to a common language even at the cost of some efficiency loss. Using this as inspiration, we propose and evaluate a multi-agent community-based dialog framework where each agent interacts with, and learns from, multiple agents, and show that this community-enforced regularization results in more relevant and coherent dialog (as judged by human evaluators) without sacrificing task performance (as judged by quantitative metrics).

</details>

<details>

<summary>2018-09-06 20:17:44 - Challenges of Context and Time in Reinforcement Learning: Introducing Space Fortress as a Benchmark</summary>

- *Akshat Agarwal, Ryan Hope, Katia Sycara*

- `1809.02206v1` - [abs](http://arxiv.org/abs/1809.02206v1) - [pdf](http://arxiv.org/pdf/1809.02206v1)

> Research in deep reinforcement learning (RL) has coalesced around improving performance on benchmarks like the Arcade Learning Environment. However, these benchmarks conspicuously miss important characteristics like abrupt context-dependent shifts in strategy and temporal sensitivity that are often present in real-world domains. As a result, RL research has not focused on these challenges, resulting in algorithms which do not understand critical changes in context, and have little notion of real world time. To tackle this issue, this paper introduces the game of Space Fortress as a RL benchmark which incorporates these characteristics. We show that existing state-of-the-art RL algorithms are unable to learn to play the Space Fortress game. We then confirm that this poor performance is due to the RL algorithms' context insensitivity and reward sparsity. We also identify independent axes along which to vary context and temporal sensitivity, allowing Space Fortress to be used as a testbed for understanding both characteristics in combination and also in isolation. We release Space Fortress as an open-source Gym environment.

</details>

<details>

<summary>2018-09-06 21:09:44 - Two geometric input transformation methods for fast online reinforcement learning with neural nets</summary>

- *Sina Ghiassian, Huizhen Yu, Banafsheh Rafiee, Richard S. Sutton*

- `1805.07476v2` - [abs](http://arxiv.org/abs/1805.07476v2) - [pdf](http://arxiv.org/pdf/1805.07476v2)

> We apply neural nets with ReLU gates in online reinforcement learning. Our goal is to train these networks in an incremental manner, without the computationally expensive experience replay. By studying how individual neural nodes behave in online training, we recognize that the global nature of ReLU gates can cause undesirable learning interference in each node's learning behavior. We propose reducing such interferences with two efficient input transformation methods that are geometric in nature and match well the geometric property of ReLU gates. The first one is tile coding, a classic binary encoding scheme originally designed for local generalization based on the topological structure of the input space. The second one (EmECS) is a new method we introduce; it is based on geometric properties of convex sets and topological embedding of the input space into the boundary of a convex set. We discuss the behavior of the network when it operates on the transformed inputs. We also compare it experimentally with some neural nets that do not use the same input transformations, and with the classic algorithm of tile coding plus a linear function approximator, and on several online reinforcement learning tasks, we show that the neural net with tile coding or EmECS can achieve not only faster learning but also more accurate approximations. Our results strongly suggest that geometric input transformation of this type can be effective for interference reduction and takes us a step closer to fully incremental reinforcement learning with neural nets.

</details>

<details>

<summary>2018-09-06 21:53:39 - Automated Game Design via Conceptual Expansion</summary>

- *Matthew Guzdial, Mark Riedl*

- `1809.02232v1` - [abs](http://arxiv.org/abs/1809.02232v1) - [pdf](http://arxiv.org/pdf/1809.02232v1)

> Automated game design has remained a key challenge within the field of Game AI. In this paper, we introduce a method for recombining existing games to create new games through a process called conceptual expansion. Prior automated game design approaches have relied on hand-authored or crowd-sourced knowledge, which limits the scope and applications of such systems. Our approach instead relies on machine learning to learn approximate representations of games. Our approach recombines knowledge from these learned representations to create new games via conceptual expansion. We evaluate this approach by demonstrating the ability for the system to recreate existing games. To the best of our knowledge, this represents the first machine learning-based automated game design system.

</details>

<details>

<summary>2018-09-06 22:00:46 - Player Experience Extraction from Gameplay Video</summary>

- *Zijin Luo, Matthew Guzdial, Nicholas Liao, Mark Riedl*

- `1809.06201v1` - [abs](http://arxiv.org/abs/1809.06201v1) - [pdf](http://arxiv.org/pdf/1809.06201v1)

> The ability to extract the sequence of game events for a given player's play-through has traditionally required access to the game's engine or source code. This serves as a barrier to researchers, developers, and hobbyists who might otherwise benefit from these game logs. In this paper we present two approaches to derive game logs from game video via convolutional neural networks and transfer learning. We evaluate the approaches in a Super Mario Bros. clone, Mega Man and Skyrim. Our results demonstrate our approach outperforms random forest and other transfer baselines.

</details>

<details>

<summary>2018-09-06 23:58:53 - Global-Locally Self-Attentive Dialogue State Tracker</summary>

- *Victor Zhong, Caiming Xiong, Richard Socher*

- `1805.09655v3` - [abs](http://arxiv.org/abs/1805.09655v3) - [pdf](http://arxiv.org/pdf/1805.09655v3)

> Dialogue state tracking, which estimates user goals and requests given the dialogue context, is an essential part of task-oriented dialogue systems. In this paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker (GLAD), which learns representations of the user utterance and previous system actions with global-local modules. Our model uses global modules to share parameters between estimators for different types (called slots) of dialogue states, and uses local modules to learn slot-specific features. We show that this significantly improves tracking of rare states and achieves state-of-the-art performance on the WoZ and DSTC2 state tracking tasks. GLAD obtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ, outperforming prior work by 3.7% and 5.5%. On DSTC2, our model obtains 74.5% joint goal accuracy and 97.5% request accuracy, outperforming prior work by 1.1% and 1.0%.

</details>

<details>

<summary>2018-09-07 00:24:29 - The Force of Proof by Which Any Argument Prevails</summary>

- *Brian Shay, Patrick Brazil*

- `1809.02260v1` - [abs](http://arxiv.org/abs/1809.02260v1) - [pdf](http://arxiv.org/pdf/1809.02260v1)

> Jakob Bernoulli, working in the late 17th century, identified a gap in contemporary probability theory. He cautioned that it was inadequate to specify force of proof (probability of provability) for some kinds of uncertain arguments. After 300 years, this gap remains in present-day probability theory. We present axioms analogous to Kolmogorov's axioms for probability, specifying uncertainty that lies in an argument's inference/implication itself rather than in its premise and conclusion. The axioms focus on arguments spanning two Boolean algebras, but generalize the obligatory: "force of proof of A implies B is the probability of B or not A" in the case that the Boolean algebras are identical. We propose a categorical framework that relies on generalized probabilities (objects) to express uncertainty in premises, to mix with arguments (morphisms) to express uncertainty embedded directly in inference/implication. There is a direct application to Shafer's evidence theory (Dempster-Shafer theory), greatly expanding its scope for applications. Therefore, we can offer this framework not only as an optimal solution to a difficult historical puzzle, but also to advance the frontiers of contemporary artificial intelligence.   Keywords: force of proof, probability of provability, Ars Conjectandi, non additive probabilities, evidence theory.

</details>

<details>

<summary>2018-09-07 00:31:16 - ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience Replay</summary>

- *Sameera Lanka, Tianfu Wu*

- `1809.02070v2` - [abs](http://arxiv.org/abs/1809.02070v2) - [pdf](http://arxiv.org/pdf/1809.02070v2)

> Experience replay is an important technique for addressing sample-inefficiency in deep reinforcement learning (RL), but faces difficulty in learning from binary and sparse rewards due to disproportionately few successful experiences in the replay buffer. Hindsight experience replay (HER) was recently proposed to tackle this difficulty by manipulating unsuccessful transitions, but in doing so, HER introduces a significant bias in the replay buffer experiences and therefore achieves a suboptimal improvement in sample-efficiency. In this paper, we present an analysis on the source of bias in HER, and propose a simple and effective method to counter the bias, to most effectively harness the sample-efficiency provided by HER. Our method, motivated by counter-factual reasoning and called ARCHER, extends HER with a trade-off to make rewards calculated for hindsight experiences numerically greater than real rewards. We validate our algorithm on two continuous control environments from DeepMind Control Suite - Reacher and Finger, which simulate manipulation tasks with a robotic arm - in combination with various reward functions, task complexities and goal sampling strategies. Our experiments consistently demonstrate that countering bias using more aggressive hindsight rewards increases sample efficiency, thus establishing the greater benefit of ARCHER in RL applications with limited computing budget.

</details>

<details>

<summary>2018-09-07 04:17:40 - Unsupervised Cross-lingual Word Embedding by Multilingual Neural Language Models</summary>

- *Takashi Wada, Tomoharu Iwata*

- `1809.02306v1` - [abs](http://arxiv.org/abs/1809.02306v1) - [pdf](http://arxiv.org/pdf/1809.02306v1)

> We propose an unsupervised method to obtain cross-lingual embeddings without any parallel data or pre-trained word embeddings. The proposed model, which we call multilingual neural language models, takes sentences of multiple languages as an input. The proposed model contains bidirectional LSTMs that perform as forward and backward language models, and these networks are shared among all the languages. The other parameters, i.e. word embeddings and linear transformation between hidden states and outputs, are specific to each language. The shared LSTMs can capture the common sentence structure among all languages. Accordingly, word embeddings of each language are mapped into a common latent space, making it possible to measure the similarity of words across multiple languages. We evaluate the quality of the cross-lingual word embeddings on a word alignment task. Our experiments demonstrate that our model can obtain cross-lingual embeddings of much higher quality than existing unsupervised models when only a small amount of monolingual data (i.e. 50k sentences) are available, or the domains of monolingual data are different across languages.

</details>

<details>

<summary>2018-09-07 04:57:15 - Generating Sentences by Editing Prototypes</summary>

- *Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, Percy Liang*

- `1709.08878v2` - [abs](http://arxiv.org/abs/1709.08878v2) - [pdf](http://arxiv.org/pdf/1709.08878v2)

> We propose a new generative model of sentences that first samples a prototype sentence from the training corpus and then edits it into a new sentence. Compared to traditional models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation. Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.

</details>

<details>

<summary>2018-09-07 05:14:37 - Geology prediction based on operation data of TBM: comparison between deep neural network and statistical learning methods</summary>

- *Maolin Shi, Xueguan Song, Wei Sun*

- `1809.06688v1` - [abs](http://arxiv.org/abs/1809.06688v1) - [pdf](http://arxiv.org/pdf/1809.06688v1)

> Tunnel boring machine (TBM) is a complex engineering system widely used for tunnel construction. In view of the complicated construction environments, it is necessary to predict geology conditions prior to excavation. In recent years, massive operation data of TBM has been recorded, and mining these data can provide important references and useful information for designers and operators of TBM. In this work, a geology prediction approach is proposed based on deep neural network and operation data. It can provide relatively accurate geology prediction results ahead of the tunnel face compared with the other prediction models based on statistical learning methods. The application case study on a tunnel in China shows that the proposed approach can accurately estimate the geological conditions prior to excavation, especially for the short range ahead of training data. This work can be regarded as a good complement to the geophysical prospecting approach during the construction of tunnels, and also highlights the applicability and potential of deep neural networks for other data mining tasks of TBMs.

</details>

<details>

<summary>2018-09-07 05:47:39 - QoS aware Automatic Web Service Composition with Multiple objectives</summary>

- *Soumi Chattopadhyay, Ansuman Banerjee*

- `1809.02317v1` - [abs](http://arxiv.org/abs/1809.02317v1) - [pdf](http://arxiv.org/pdf/1809.02317v1)

> With an increasing number of web services, providing an end-to-end Quality of Service (QoS) guarantee in responding to user queries is becoming an important concern. Multiple QoS parameters (e.g., response time, latency, throughput, reliability, availability, success rate) are associated with a service, thereby, service composition with a large number of candidate services is a challenging multi-objective optimization problem. In this paper, we study the multi-constrained multi-objective QoS aware web service composition problem and propose three different approaches to solve the same, one optimal, based on Pareto front construction and two other based on heuristically traversing the solution space. We compare the performance of the heuristics against the optimal, and show the effectiveness of our proposals over other classical approaches for the same problem setting, with experiments on WSC-2009 and ICEBE-2005 datasets.

</details>

<details>

<summary>2018-09-07 08:01:55 - Weighted Abstract Dialectical Frameworks: Extended and Revised Report</summary>

- *Gerhard Brewka, Jörg Pührer, Hannes Strass, Johannes P. Wallner, Stefan Woltran*

- `1806.07717v2` - [abs](http://arxiv.org/abs/1806.07717v2) - [pdf](http://arxiv.org/pdf/1806.07717v2)

> Abstract Dialectical Frameworks (ADFs) generalize Dung's argumentation frameworks allowing various relationships among arguments to be expressed in a systematic way. We further generalize ADFs so as to accommodate arbitrary acceptance degrees for the arguments. This makes ADFs applicable in domains where both the initial status of arguments and their relationship are only insufficiently specified by Boolean functions. We define all standard ADF semantics for the weighted case, including grounded, preferred and stable semantics. We illustrate our approach using acceptance degrees from the unit interval and show how other valuation structures can be integrated. In each case it is sufficient to specify how the generalized acceptance conditions are represented by formulas, and to specify the information ordering underlying the characteristic ADF operator. We also present complexity results for problems related to weighted ADFs.

</details>

<details>

<summary>2018-09-07 08:18:01 - Exploiting local and global performance of candidate systems for aggregation of summarization techniques</summary>

- *Parth Mehta, Prasenjit Majumder*

- `1809.02343v1` - [abs](http://arxiv.org/abs/1809.02343v1) - [pdf](http://arxiv.org/pdf/1809.02343v1)

> With an ever growing number of extractive summarization techniques being proposed, there is less clarity then ever about how good each system is compared to the rest. Several studies highlight the variance in performance of these systems with change in datasets or even across documents within the same corpus. An effective way to counter this variance and to make the systems more robust could be to use inputs from multiple systems when generating a summary. In the present work, we define a novel way of creating such ensemble by exploiting similarity between the content of candidate summaries to estimate their reliability. We define GlobalRank which captures the performance of a candidate system on an overall corpus and LocalRank which estimates its performance on a given document cluster. We then use these two scores to assign a weight to each individual systems, which is then used to generate the new aggregate ranking. Experiments on DUC2003 and DUC 2004 datasets show a significant improvement in terms of ROUGE score, over existing sate-of-art techniques.

</details>

<details>

<summary>2018-09-07 09:03:55 - A proof that artificial neural networks overcome the curse of dimensionality in the numerical approximation of Black-Scholes partial differential equations</summary>

- *Philipp Grohs, Fabian Hornung, Arnulf Jentzen, Philippe von Wurstemberger*

- `1809.02362v1` - [abs](http://arxiv.org/abs/1809.02362v1) - [pdf](http://arxiv.org/pdf/1809.02362v1)

> Artificial neural networks (ANNs) have very successfully been used in numerical simulations for a series of computational problems ranging from image classification/image recognition, speech recognition, time series analysis, game intelligence, and computational advertising to numerical approximations of partial differential equations (PDEs). Such numerical simulations suggest that ANNs have the capacity to very efficiently approximate high-dimensional functions and, especially, such numerical simulations indicate that ANNs seem to admit the fundamental power to overcome the curse of dimensionality when approximating the high-dimensional functions appearing in the above named computational problems. There are also a series of rigorous mathematical approximation results for ANNs in the scientific literature. Some of these mathematical results prove convergence without convergence rates and some of these mathematical results even rigorously establish convergence rates but there are only a few special cases where mathematical results can rigorously explain the empirical success of ANNs when approximating high-dimensional functions. The key contribution of this article is to disclose that ANNs can efficiently approximate high-dimensional functions in the case of numerical approximations of Black-Scholes PDEs. More precisely, this work reveals that the number of required parameters of an ANN to approximate the solution of the Black-Scholes PDE grows at most polynomially in both the reciprocal of the prescribed approximation accuracy $\varepsilon > 0$ and the PDE dimension $d \in \mathbb{N}$ and we thereby prove, for the first time, that ANNs do indeed overcome the curse of dimensionality in the numerical approximation of Black-Scholes PDEs.

</details>

<details>

<summary>2018-09-07 09:56:21 - Monte Carlo Tree Search with Scalable Simulation Periods for Continuously Running Tasks</summary>

- *Seydou Ba, Takuya Hiraoka, Takashi Onishi, Toru Nakata, Yoshimasa Tsuruoka*

- `1809.02378v1` - [abs](http://arxiv.org/abs/1809.02378v1) - [pdf](http://arxiv.org/pdf/1809.02378v1)

> Monte Carlo Tree Search (MCTS) is particularly adapted to domains where the potential actions can be represented as a tree of sequential decisions. For an effective action selection, MCTS performs many simulations to build a reliable tree representation of the decision space. As such, a bottleneck to MCTS appears when enough simulations cannot be performed between action selections. This is particularly highlighted in continuously running tasks, for which the time available to perform simulations between actions tends to be limited due to the environment's state constantly changing. In this paper, we present an approach that takes advantage of the anytime characteristic of MCTS to increase the simulation time when allowed. Our approach is to effectively balance the prospect of selecting an action with the time that can be spared to perform MCTS simulations before the next action selection. For that, we considered the simulation time as a decision variable to be selected alongside an action. We extended the Hierarchical Optimistic Optimization applied to Tree (HOOT) method to adapt our approach to environments with a continuous decision space. We evaluated our approach for environments with a continuous decision space through OpenAI gym's Pendulum and Continuous Mountain Car environments and for environments with discrete action space through the arcade learning environment (ALE) platform. The evaluation results show that, with variable simulation times, the proposed approach outperforms the conventional MCTS in the evaluated continuous decision space tasks and improves the performance of MCTS in most of the ALE tasks.

</details>

<details>

<summary>2018-09-07 10:00:53 - On2Vec: Embedding-based Relation Prediction for Ontology Population</summary>

- *Muhao Chen, Yingtao Tian, Xuelu Chen, Zijun Xue, Carlo Zaniolo*

- `1809.02382v1` - [abs](http://arxiv.org/abs/1809.02382v1) - [pdf](http://arxiv.org/pdf/1809.02382v1)

> Populating ontology graphs represents a long-standing problem for the Semantic Web community. Recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. However, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. These comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. Hence, we propose On2Vec, a novel translation-based graph embedding method for ontology population. On2Vec integrates two model components that effectively characterize comprehensive relation facts in ontology graphs. The first is the Component-specific Model that encodes concepts and relations into low-dimensional embedding spaces without a loss of relational properties; the second is the Hierarchy Model that performs focused learning of hierarchical relation facts. Experiments on several well-known ontology graphs demonstrate the promising capabilities of On2Vec in predicting and verifying new relation facts. These promising results also make possible significant improvements in related methods.

</details>

<details>

<summary>2018-09-07 10:10:12 - Improving On-policy Learning with Statistical Reward Accumulation</summary>

- *Yubin Deng, Ke Yu, Dahua Lin, Xiaoou Tang, Chen Change Loy*

- `1809.02387v1` - [abs](http://arxiv.org/abs/1809.02387v1) - [pdf](http://arxiv.org/pdf/1809.02387v1)

> Deep reinforcement learning has obtained significant breakthroughs in recent years. Most methods in deep-RL achieve good results via the maximization of the reward signal provided by the environment, typically in the form of discounted cumulative returns. Such reward signals represent the immediate feedback of a particular action performed by an agent. However, tasks with sparse reward signals are still challenging to on-policy methods. In this paper, we introduce an effective characterization of past reward statistics (which can be seen as long-term feedback signals) to supplement this immediate reward feedback. In particular, value functions are learned with multi-critics supervision, enabling complex value functions to be more easily approximated in on-policy learning, even when the reward signals are sparse. We also introduce a novel exploration mechanism called "hot-wiring" that can give a boost to seemingly trapped agents. We demonstrate the effectiveness of our advantage actor multi-critic (A2MC) method across the discrete domains in Atari games as well as continuous domains in the MuJoCo environments. A video demo is provided at https://youtu.be/zBmpf3Yz8tc.

</details>

<details>

<summary>2018-09-07 10:36:22 - Deep Feature Learning of Multi-Network Topology for Node Classification</summary>

- *Hansheng Xue, Jiajie Peng, Xuequn Shang*

- `1809.02394v1` - [abs](http://arxiv.org/abs/1809.02394v1) - [pdf](http://arxiv.org/pdf/1809.02394v1)

> Networks are ubiquitous structure that describes complex relationships between different entities in the real world. As a critical component of prediction task over nodes in networks, learning the feature representation of nodes has become one of the most active areas recently. Network Embedding, aiming to learn non-linear and low-dimensional feature representation based on network topology, has been proved to be helpful on tasks of network analysis, especially node classification. For many real-world systems, multiple types of relations are naturally represented by multiple networks. However, existing network embedding methods mainly focus on single network embedding and neglect the information shared among different networks. In this paper, we propose a novel multiple network embedding method based on semisupervised autoencoder, named DeepMNE, which captures complex topological structures of multi-networks and takes the correlation among multi-networks into account. We evaluate DeepMNE on the task of node classification with two real-world datasets. The experimental results demonstrate the superior performance of our method over four state-of-the-art algorithms.

</details>

<details>

<summary>2018-09-07 10:37:22 - Reductive property of new fuzzy reasoning method based on distance measure</summary>

- *Son-il Kwak, Gum-ju Kim, Michio Sugeno, Gwang-chol Li, Myong-suk Son, Hyok-chol Kim, Un-ha Kim*

- `1809.05001v1` - [abs](http://arxiv.org/abs/1809.05001v1) - [pdf](http://arxiv.org/pdf/1809.05001v1)

> Firstly in this paper we propose a new criterion function for evaluation of the reductive property about the fuzzy reasoning result for fuzzy modus ponens and fuzzy modus tollens. Secondly unlike fuzzy reasoning methods based on the similarity measure, we propose a new fuzzy reasoning method based on distance measure. Thirdly the reductive property for 5 fuzzy reasoning methods are checked with respect to fuzzy modus ponens and fuzzy modus tollens. Through the experiment, we show that proposed method is better than the previous methods in accordance with human thinking.

</details>

<details>

<summary>2018-09-07 12:37:50 - Optimizing deep video representation to match brain activity</summary>

- *Hugo Richard, Ana Pinho, Bertrand Thirion, Guillaume Charpiat*

- `1809.02440v1` - [abs](http://arxiv.org/abs/1809.02440v1) - [pdf](http://arxiv.org/pdf/1809.02440v1)

> The comparison of observed brain activity with the statistics generated by artificial intelligence systems is useful to probe brain functional organization under ecological conditions. Here we study fMRI activity in ten subjects watching color natural movies and compute deep representations of these movies with an architecture that relies on optical flow and image content. The association of activity in visual areas with the different layers of the deep architecture displays complexity-related contrasts across visual areas and reveals a striking foveal/peripheral dichotomy.

</details>

<details>

<summary>2018-09-07 13:41:55 - Rank Pruning for Dominance Queries in CP-Nets</summary>

- *Kathryn Laing, Peter Adam Thwaites, John Paul Gosling*

- `1712.08588v2` - [abs](http://arxiv.org/abs/1712.08588v2) - [pdf](http://arxiv.org/pdf/1712.08588v2)

> Conditional preference networks (CP-nets) are a graphical representation of a person's (conditional) preferences over a set of discrete variables. In this paper, we introduce a novel method of quantifying preference for any given outcome based on a CP-net representation of a user's preferences. We demonstrate that these values are useful for reasoning about user preferences. In particular, they allow us to order (any subset of) the possible outcomes in accordance with the user's preferences. Further, these values can be used to improve the efficiency of outcome dominance testing. That is, given a pair of outcomes, we can determine which the user prefers more efficiently. Through experimental results, we show that this method is more effective than existing techniques for improving dominance testing efficiency. We show that the above results also hold for CP-nets that express indifference between variable values.

</details>

<details>

<summary>2018-09-07 13:51:39 - Under the Hood: Using Diagnostic Classifiers to Investigate and Improve how Language Models Track Agreement Information</summary>

- *Mario Giulianelli, Jack Harding, Florian Mohnert, Dieuwke Hupkes, Willem Zuidema*

- `1808.08079v2` - [abs](http://arxiv.org/abs/1808.08079v2) - [pdf](http://arxiv.org/pdf/1808.08079v2)

> How do neural language models keep track of number agreement between subject and verb? We show that `diagnostic classifiers', trained to predict number from the internal states of a language model, provide a detailed understanding of how, when, and where this information is represented. Moreover, they give us insight into when and where number information is corrupted in cases where the language model ends up making agreement errors. To demonstrate the causal role played by the representations we find, we then use agreement information to influence the course of the LSTM during the processing of difficult sentences. Results from such an intervention reveal a large increase in the language model's accuracy. Together, these results show that diagnostic classifiers give us an unrivalled detailed look into the representation of linguistic information in neural models, and demonstrate that this knowledge can be used to improve their performance.

</details>

<details>

<summary>2018-09-07 14:20:32 - Meteorologists and Students: A resource for language grounding of geographical descriptors</summary>

- *Alejandro Ramos-Soto, Ehud Reiter, Kees van Deemter, Jose M. Alonso, Albert Gatt*

- `1809.02494v1` - [abs](http://arxiv.org/abs/1809.02494v1) - [pdf](http://arxiv.org/pdf/1809.02494v1)

> We present a data resource which can be useful for research purposes on language grounding tasks in the context of geographical referring expression generation. The resource is composed of two data sets that encompass 25 different geographical descriptors and a set of associated graphical representations, drawn as polygons on a map by two groups of human subjects: teenage students and expert meteorologists.

</details>

<details>

<summary>2018-09-07 15:32:28 - Revisiting Inaccuracies of Time Series Averaging under Dynamic Time Warping</summary>

- *Brijnesh Jain*

- `1809.03371v1` - [abs](http://arxiv.org/abs/1809.03371v1) - [pdf](http://arxiv.org/pdf/1809.03371v1)

> This article revisits an analysis on inaccuracies of time series averaging under dynamic time warping conducted by \cite{Niennattrakul2007}. The authors presented a correctness-criterion and introduced drift-outs of averages from clusters. They claimed that averages are inaccurate if they are incorrect or drift-outs. Furthermore, they conjectured that such inaccuracies are caused by the lack of triangle inequality. We show that a rectified version of the correctness-criterion is unsatisfiable and that the concept of drift-out is geometrically and operationally inconclusive. Satisfying the triangle inequality is insufficient to achieve correctness and unnecessary to overcome the drift-out phenomenon. We place the concept of drift-out on a principled basis and show that sample means as global minimizers of a Fr\'echet function never drift out. The adjusted drift-out is a way to test to which extent an approximation is coherent. Empirical results show that solutions obtained by the state-of-the-art methods SSG and DBA are incoherent approximations of a sample mean in over a third of all trials.

</details>

<details>

<summary>2018-09-07 18:03:47 - SECS: Efficient Deep Stream Processing via Class Skew Dichotomy</summary>

- *Boyuan Feng, Kun Wan, Shu Yang, Yufei Ding*

- `1809.06691v1` - [abs](http://arxiv.org/abs/1809.06691v1) - [pdf](http://arxiv.org/pdf/1809.06691v1)

> Despite that accelerating convolutional neural network (CNN) receives an increasing research focus, the save on resource consumption always comes with a decrease in accuracy. To both increase accuracy and decrease resource consumption, we explore an environment information, called class skew, which is easily available and exists widely in daily life. Since the class skew may switch as time goes, we bring up probability layer to utilize class skew without any overhead during the runtime. Further, we observe class skew dichotomy that some class skew may appear frequently in the future, called hot class skew, and others will never appear again or appear seldom, called cold class skew. Inspired by techniques from source code optimization, two modes, i.e., interpretation and compilation, are proposed. The interpretation mode pursues efficient adaption during runtime for cold class skew and the compilation mode aggressively optimize on hot ones for more efficient deployment in the future. Aggressive optimization is processed by class-specific pruning and provides extra benefit. Finally, we design a systematic framework, SECS, to dynamically detect class skew, processing interpretation and compilation, as well as select the most accurate architectures under the runtime resource budget. Extensive evaluations show that SECS can realize end-to-end classification speedups by a factor of 3x to 11x relative to state-of-the-art convolutional neural networks, at a higher accuracy.

</details>

<details>

<summary>2018-09-07 18:13:10 - Embedding Multimodal Relational Data for Knowledge Base Completion</summary>

- *Pouya Pezeshkpour, Liyan Chen, Sameer Singh*

- `1809.01341v2` - [abs](http://arxiv.org/abs/1809.01341v2) - [pdf](http://arxiv.org/pdf/1809.01341v2)

> Representing entities and relations in an embedding space is a well-studied approach for machine learning on relational data. Existing approaches, however, primarily focus on simple link structure between a finite set of entities, ignoring the variety of data types that are often used in knowledge bases, such as text, images, and numerical values. In this paper, we propose multimodal knowledge base embeddings (MKBE) that use different neural encoders for this variety of observed data, and combine them with existing relational models to learn embeddings of the entities and multimodal data. Further, using these learned embedings and different neural decoders, we introduce a novel multimodal imputation model to generate missing multimodal values, like text and images, from information in the knowledge base. We enrich existing relational datasets to create two novel benchmarks that contain additional information such as textual descriptions and images of the original entities. We demonstrate that our models utilize this additional information effectively to provide more accurate link prediction, achieving state-of-the-art results with a considerable gap of 5-7% over existing methods. Further, we evaluate the quality of our generated multimodal values via a user study. We have release the datasets and the open-source implementation of our models at https://github.com/pouyapez/mkbe

</details>

<details>

<summary>2018-09-07 19:38:51 - A Transfer-Learnable Natural Language Interface for Databases</summary>

- *Wenlu Wang, Yingtao Tian, Hongyu Xiong, Haixun Wang, Wei-Shinn Ku*

- `1809.02649v1` - [abs](http://arxiv.org/abs/1809.02649v1) - [pdf](http://arxiv.org/pdf/1809.02649v1)

> Relational database management systems (RDBMSs) are powerful because they are able to optimize and answer queries against any relational database. A natural language interface (NLI) for a database, on the other hand, is tailored to support that specific database. In this work, we introduce a general purpose transfer-learnable NLI with the goal of learning one model that can be used as NLI for any relational database. We adopt the data management principle of separating data and its schema, but with the additional support for the idiosyncrasy and complexity of natural languages. Specifically, we introduce an automatic annotation mechanism that separates the schema and the data, where the schema also covers knowledge about natural language. Furthermore, we propose a customized sequence model that translates annotated natural language queries to SQL statements. We show in experiments that our approach outperforms previous NLI methods on the WikiSQL dataset and the model we learned can be applied to another benchmark dataset OVERNIGHT without retraining.

</details>

<details>

<summary>2018-09-07 21:12:14 - How morphological development can guide evolution</summary>

- *Sam Kriegman, Nick Cheney, Josh Bongard*

- `1711.07387v5` - [abs](http://arxiv.org/abs/1711.07387v5) - [pdf](http://arxiv.org/pdf/1711.07387v5)

> Organisms result from adaptive processes interacting across different time scales. One such interaction is that between development and evolution. Models have shown that development sweeps over several traits in a single agent, sometimes exposing promising static traits. Subsequent evolution can then canalize these rare traits. Thus, development can, under the right conditions, increase evolvability. Here, we report on a previously unknown phenomenon when embodied agents are allowed to develop and evolve: Evolution discovers body plans robust to control changes, these body plans become genetically assimilated, yet controllers for these agents are not assimilated. This allows evolution to continue climbing fitness gradients by tinkering with the developmental programs for controllers within these permissive body plans. This exposes a previously unknown detail about the Baldwin effect: instead of all useful traits becoming genetically assimilated, only traits that render the agent robust to changes in other traits become assimilated. We refer to this as differential canalization. This finding also has implications for the evolutionary design of artificial and embodied agents such as robots: robots robust to internal changes in their controllers may also be robust to external changes in their environment, such as transferal from simulation to reality or deployment in novel environments.

</details>

<details>

<summary>2018-09-08 01:49:03 - Operations Guided Neural Networks for High Fidelity Data-To-Text Generation</summary>

- *Feng Nie, Jinpeng Wang, Jin-Ge Yao, Rong Pan, Chin-Yew Lin*

- `1809.02735v1` - [abs](http://arxiv.org/abs/1809.02735v1) - [pdf](http://arxiv.org/pdf/1809.02735v1)

> Recent neural models for data-to-text generation are mostly based on data-driven end-to-end training over encoder-decoder networks. Even though the generated texts are mostly fluent and informative, they often generate descriptions that are not consistent with the input structured data. This is a critical issue especially in domains that require inference or calculations over raw data. In this paper, we attempt to improve the fidelity of neural data-to-text generation by utilizing pre-executed symbolic operations. We propose a framework called Operation-guided Attention-based sequence-to-sequence network (OpAtt), with a specifically designed gating mechanism as well as a quantization module for operation results to utilize information from pre-executed operations. Experiments on two sports datasets show our proposed method clearly improves the fidelity of the generated texts to the input structured data.

</details>

<details>

<summary>2018-09-08 02:57:14 - Clustrophile 2: Guided Visual Clustering Analysis</summary>

- *Marco Cavallo, Çağatay Demiralp*

- `1804.03048v3` - [abs](http://arxiv.org/abs/1804.03048v3) - [pdf](http://arxiv.org/pdf/1804.03048v3)

> Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce \textit{Clustrophile~2}, a new interactive tool for guided clustering analysis. \textit{Clustrophile~2} guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, \textit{Clustrophile~2} contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate \textit{Clustrophile~2} through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson's disease patients. Results suggest that \textit{Clustrophile~2} improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.

</details>

<details>

<summary>2018-09-08 04:01:58 - Optimal and Low-Complexity Dynamic Spectrum Access for RF-Powered Ambient Backscatter System with Online Reinforcement Learning</summary>

- *Nguyen Van Huynh, Dinh Thai Hoang, Diep N. Nguyen, Eryk Dutkiewicz, Dusit Niyato, Ping Wang*

- `1809.02753v1` - [abs](http://arxiv.org/abs/1809.02753v1) - [pdf](http://arxiv.org/pdf/1809.02753v1)

> Ambient backscatter has been introduced with a wide range of applications for low power wireless communications. In this article, we propose an optimal and low-complexity dynamic spectrum access framework for RF-powered ambient backscatter system. In this system, the secondary transmitter not only harvests energy from ambient signals (from incumbent users), but also backscatters these signals to its receiver for data transmission. Under the dynamics of the ambient signals, we first adopt the Markov decision process (MDP) framework to obtain the optimal policy for the secondary transmitter, aiming to maximize the system throughput. However, the MDP-based optimization requires complete knowledge of environment parameters, e.g., the probability of a channel to be idle and the probability of a successful packet transmission, that may not be practical to obtain. To cope with such incomplete knowledge of the environment, we develop a low-complexity online reinforcement learning algorithm that allows the secondary transmitter to "learn" from its decisions and then attain the optimal policy. Simulation results show that the proposed learning algorithm not only efficiently deals with the dynamics of the environment, but also improves the average throughput up to 50% and reduces the blocking probability and delay up to 80% compared with conventional methods.

</details>

<details>

<summary>2018-09-08 07:39:40 - Travel Speed Prediction with a Hierarchical Convolutional Neural Network and Long Short-Term Memory Model Framework</summary>

- *Wei Wang, Xucheng Li*

- `1809.01887v2` - [abs](http://arxiv.org/abs/1809.01887v2) - [pdf](http://arxiv.org/pdf/1809.01887v2)

> Advanced travel information and warning, if provided accurately, can help road users avoid traffic congestion through dynamic route planning and behavior change. It also enables traffic control centres mitigate the impact of congestion by activating Intelligent Transport System (ITS) proactively. Deep learning has become increasingly popular in recent years, following a surge of innovative GPU technology, high-resolution, big datasets and thriving machine learning algorithms. However, there are few examples exploiting this emerging technology to develop applications for traffic prediction. This is largely due to the difficulty in capturing random, seasonal, non-linear, and spatio-temporal correlated nature of traffic data. In this paper, we propose a data-driven modelling approach with a novel hierarchical D-CLSTM-t deep learning model for short-term traffic speed prediction, a framework combined with convolutional neural network (CNN) and long short-term memory (LSTM) models. A deep CNN model is employed to learn the spatio-temporal traffic patterns of the input graphs, which are then fed into a deep LSTM model for sequence learning. To capture traffic seasonal variations, time of the day and day of the week indicators are fused with trained features. The model is trained end-to-end to predict travel speed in 15 to 90 minutes in the future. We compare the model performance against other baseline models including CNN, LGBM, LSTM, and traditional speed-flow curves. Experiment results show that the D-CLSTM-t outperforms other models considerably. Model tests show that speed upstream also responds sensibly to a sudden accident occurring downstream. Our D-CLSTM-t model framework is also highly scalable for future extension such as for network-wide traffic prediction, which can also be improved by including additional features such as weather, long term seasonality and accident information.

</details>

<details>

<summary>2018-09-08 10:58:31 - An adaptive prefix-assignment technique for symmetry reduction</summary>

- *Tommi Junttila, Matti Karppa, Petteri Kaski, Jukka Kohonen*

- `1706.08325v2` - [abs](http://arxiv.org/abs/1706.08325v2) - [pdf](http://arxiv.org/pdf/1706.08325v2)

> This paper presents a technique for symmetry reduction that adaptively assigns a prefix of variables in a system of constraints so that the generated prefix-assignments are pairwise nonisomorphic under the action of the symmetry group of the system. The technique is based on McKay's canonical extension framework [J.~Algorithms 26 (1998), no.~2, 306--324]. Among key features of the technique are (i) adaptability---the prefix sequence can be user-prescribed and truncated for compatibility with the group of symmetries; (ii) parallelizability---prefix-assignments can be processed in parallel independently of each other; (iii) versatility---the method is applicable whenever the group of symmetries can be concisely represented as the automorphism group of a vertex-colored graph; and (iv) implementability---the method can be implemented relying on a canonical labeling map for vertex-colored graphs as the only nontrivial subroutine. To demonstrate the practical applicability of our technique, we have prepared an experimental open-source implementation of the technique and carry out a set of experiments that demonstrate ability to reduce symmetry on hard instances. Furthermore, we demonstrate that the implementation effectively parallelizes to compute clusters with multiple nodes via a message-passing interface.

</details>

<details>

<summary>2018-09-08 14:13:46 - Handling Concept Drift via Model Reuse</summary>

- *Peng Zhao, Le-Wen Cai, Zhi-Hua Zhou*

- `1809.02804v1` - [abs](http://arxiv.org/abs/1809.02804v1) - [pdf](http://arxiv.org/pdf/1809.02804v1)

> In many real-world applications, data are often collected in the form of stream, and thus the distribution usually changes in nature, which is referred as concept drift in literature. We propose a novel and effective approach to handle concept drift via model reuse, leveraging previous knowledge by reusing models. Each model is associated with a weight representing its reusability towards current data, and the weight is adaptively adjusted according to the model performance. We provide generalization and regret analysis. Experimental results also validate the superiority of our approach on both synthetic and real-world datasets.

</details>

<details>

<summary>2018-09-08 17:20:45 - Non-Parametric Variational Inference with Graph Convolutional Networks for Gaussian Processes</summary>

- *Linfeng Liu, Liping Liu*

- `1809.02838v1` - [abs](http://arxiv.org/abs/1809.02838v1) - [pdf](http://arxiv.org/pdf/1809.02838v1)

> Inference for GP models with non-Gaussian noises is computationally expensive when dealing with large datasets. Many recent inference methods approximate the posterior distribution with a simpler distribution defined on a small number of inducing points. The inference is accurate only when data points have strong correlation with these inducing points. In this paper, we consider the inference problem in a different direction: GP function values in the posterior are mostly correlated in short distance. We construct a variational distribution such that the inference for a data point considers only its neighborhood. With this construction, the variational lower bound is highly decomposible, hence we can run stochastic optimization with very small batches. We then train Graph Convolutional Networks as a reusable model to identify variational parameters for each data point. Model reuse greatly reduces the number of parameters and the number of iterations needed in optimization. The proposed method significantly speeds up the inference and often gets more accurate results than previous methods.

</details>

<details>

<summary>2018-09-08 19:21:09 - iDriveSense: Dynamic Route Planning Involving Roads Quality Information</summary>

- *Amr S. El-Wakeel, Aboelmagd Noureldin, Hossam S. Hassanein, Nizar Zorba*

- `1809.02855v1` - [abs](http://arxiv.org/abs/1809.02855v1) - [pdf](http://arxiv.org/pdf/1809.02855v1)

> Owing to the expeditious growth in the information and communication technologies, smart cities have raised the expectations in terms of efficient functioning and management. One key aspect of residents' daily comfort is assured through affording reliable traffic management and route planning. Comprehensively, the majority of the present trip planning applications and service providers are enabling their trip planning recommendations relying on shortest paths and/or fastest routes. However, such suggestions may discount drivers' preferences with respect to safe and less disturbing trips. Road anomalies such as cracks, potholes, and manholes induce risky driving scenarios and can lead to vehicles damages and costly repairs. Accordingly, in this paper, we propose a crowdsensing based dynamic route planning system. Leveraging both the vehicle motion sensors and the inertial sensors within the smart devices, road surface types and anomalies have been detected and categorized. In addition, the monitored events are geo-referenced utilizing GPS receivers on both vehicles and smart devices. Consequently, road segments assessments are conducted using fuzzy system models based on aspects such as the number of anomalies and their severity levels in each road segment. Afterward, another fuzzy model is adopted to recommend the best trip routes based on the road segments quality in each potential route. Extensive road experiments are held to build and show the potential of the proposed system.

</details>

<details>

<summary>2018-09-08 20:44:43 - AI Safety and Reproducibility: Establishing Robust Foundations for the Neuropsychology of Human Values</summary>

- *Gopal P. Sarma, Nick J. Hay, Adam Safron*

- `1712.04307v3` - [abs](http://arxiv.org/abs/1712.04307v3) - [pdf](http://arxiv.org/pdf/1712.04307v3)

> We propose the creation of a systematic effort to identify and replicate key findings in neuropsychology and allied fields related to understanding human values. Our aim is to ensure that research underpinning the value alignment problem of artificial intelligence has been sufficiently validated to play a role in the design of AI systems.

</details>

<details>

<summary>2018-09-08 21:06:57 - Towards a Deep Unified Framework for Nuclear Reactor Perturbation Analysis</summary>

- *Fabio De Sousa Ribeiro, Francesco Caliva, Dionysios Chionis, Abdelhamid Dokhane, Antonios Mylonakis, Christophe Demaziere, Georgios Leontidis, Stefanos Kollias*

- `1807.10096v2` - [abs](http://arxiv.org/abs/1807.10096v2) - [pdf](http://arxiv.org/pdf/1807.10096v2)

> In this paper, we take the first steps towards a novel unified framework for the analysis of perturbations in both the Time and Frequency domains. The identification of type and source of such perturbations is fundamental for monitoring reactor cores and guarantee safety while running at nominal conditions. A 3D Convolutional Neural Network (3D-CNN) was employed to analyse perturbations happening in the frequency domain, such as an absorber of variable strength or propagating perturbation. Recurrent neural networks (RNN), specifically Long Short-Term Memory (LSTM) networks were used to study signal sequences related to perturbations induced in the time domain, including the vibrations of fuel assemblies and the fluctuations of thermal-hydraulic parameters at the inlet of the reactor coolant loops. 512 dimensional representations were extracted from the 3D-CNN and LSTM architectures, and used as input to a fused multi-sigmoid classification layer to recognise the perturbation type. If the perturbation is in the frequency domain, a separate fully-connected layer utilises said representations to regress the coordinates of its source. The results showed that the perturbation type can be recognised with high accuracy in all cases, and frequency domain scenario sources can be localised with high precision.

</details>

<details>

<summary>2018-09-08 22:45:23 - Non-Parametric Transformation Networks</summary>

- *Dipan K. Pal, Marios Savvides*

- `1801.04520v6` - [abs](http://arxiv.org/abs/1801.04520v6) - [pdf](http://arxiv.org/pdf/1801.04520v6)

> ConvNets, through their architecture, only enforce invariance to translation. In this paper, we introduce a new class of deep convolutional architectures called Non-Parametric Transformation Networks (NPTNs) which can learn \textit{general} invariances and symmetries directly from data. NPTNs are a natural generalization of ConvNets and can be optimized directly using gradient descent. Unlike almost all previous works in deep architectures, they make no assumption regarding the structure of the invariances present in the data and in that aspect are flexible and powerful. We also model ConvNets and NPTNs under a unified framework called Transformation Networks (TN), which yields a better understanding of the connection between the two. We demonstrate the efficacy of NPTNs on data such as MNIST with extreme transformations and CIFAR10 where they outperform baselines, and further outperform several recent algorithms on ETH-80. They do so while having the same number of parameters. We also show that they are more effective than ConvNets in modelling symmetries and invariances from data, without the explicit knowledge of the added arbitrary nuisance transformations. Finally, we replace ConvNets with NPTNs within Capsule Networks and show that this enables Capsule Nets to perform even better.

</details>

<details>

<summary>2018-09-09 01:07:11 - End-to-end Language Identification using NetFV and NetVLAD</summary>

- *Jinkun Chen, Weicheng Cai, Danwei Cai, Zexin Cai, Haibin Zhong, Ming Li*

- `1809.02906v1` - [abs](http://arxiv.org/abs/1809.02906v1) - [pdf](http://arxiv.org/pdf/1809.02906v1)

> In this paper, we apply the NetFV and NetVLAD layers for the end-to-end language identification task. NetFV and NetVLAD layers are the differentiable implementations of the standard Fisher Vector and Vector of Locally Aggregated Descriptors (VLAD) methods, respectively. Both of them can encode a sequence of feature vectors into a fixed dimensional vector which is very important to process those variable-length utterances. We first present the relevances and differences between the classical i-vector and the aforementioned encoding schemes. Then, we construct a flexible end-to-end framework including a convolutional neural network (CNN) architecture and an encoding layer (NetFV or NetVLAD) for the language identification task. Experimental results on the NIST LRE 2007 close-set task show that the proposed system achieves significant EER reductions against the conventional i-vector baseline and the CNN temporal average pooling system, respectively.

</details>

<details>

<summary>2018-09-09 01:40:45 - Elliptical Distributions-Based Weights-Determining Method for OWA Operators</summary>

- *Xiuyan Sha, Zeshui Xu, Chuancun Yin*

- `1809.02909v1` - [abs](http://arxiv.org/abs/1809.02909v1) - [pdf](http://arxiv.org/pdf/1809.02909v1)

> The ordered weighted averaging (OWA) operators play a crucial role in aggregating multiple criteria evaluations into an overall assessment supporting the decision makers' choice. One key point steps is to determine the associated weights. In this paper, we first briefly review some main methods for determining the weights by using distribution functions. Then we propose a new approach for determining OWA weights by using the RIM quantifier. Motivated by the idea of normal distribution-based method to determine the OWA weights, we develop a method based on elliptical distributions for determining the OWA weights, and some of its desirable properties have been investigated.

</details>

<details>

<summary>2018-09-09 02:02:51 - An Accelerated Approach to Safely and Efficiently Test Pre-Production Autonomous Vehicles on Public Streets</summary>

- *Mansur Arief, Peter Glynn, Ding Zhao*

- `1805.02114v2` - [abs](http://arxiv.org/abs/1805.02114v2) - [pdf](http://arxiv.org/pdf/1805.02114v2)

> Various automobile and mobility companies, for instance Ford, Uber and Waymo, are currently testing their pre-produced autonomous vehicle (AV) fleets on the public roads. However, due to rareness of the safety-critical cases and, effectively, unlimited number of possible traffic scenarios, these on-road testing efforts have been acknowledged as tedious, costly, and risky. In this study, we propose Accelerated De- ployment framework to safely and efficiently estimate the AVs performance on public streets. We showed that by appropriately addressing the gradual accuracy improvement and adaptively selecting meaningful and safe environment under which the AV is deployed, the proposed framework yield to highly accurate estimation with much faster evaluation time, and more importantly, lower deployment risk. Our findings provide an answer to the currently heated and active discussions on how to properly test AV performance on public roads so as to achieve safe, efficient, and statistically-reliable testing framework for AV technologies.

</details>

<details>

<summary>2018-09-09 03:49:06 - Towards Query Efficient Black-box Attacks: An Input-free Perspective</summary>

- *Yali Du, Meng Fang, Jinfeng Yi, Jun Cheng, Dacheng Tao*

- `1809.02918v1` - [abs](http://arxiv.org/abs/1809.02918v1) - [pdf](http://arxiv.org/pdf/1809.02918v1)

> Recent studies have highlighted that deep neural networks (DNNs) are vulnerable to adversarial attacks, even in a black-box scenario. However, most of the existing black-box attack algorithms need to make a huge amount of queries to perform attacks, which is not practical in the real world. We note one of the main reasons for the massive queries is that the adversarial example is required to be visually similar to the original image, but in many cases, how adversarial examples look like does not matter much. It inspires us to introduce a new attack called \emph{input-free} attack, under which an adversary can choose an arbitrary image to start with and is allowed to add perceptible perturbations on it. Following this approach, we propose two techniques to significantly reduce the query complexity. First, we initialize an adversarial example with a gray color image on which every pixel has roughly the same importance for the target model. Then we shrink the dimension of the attack space by perturbing a small region and tiling it to cover the input image. To make our algorithm more effective, we stabilize a projected gradient ascent algorithm with momentum, and also propose a heuristic approach for region size selection. Through extensive experiments, we show that with only 1,701 queries on average, we can perturb a gray image to any target class of ImageNet with a 100\% success rate on InceptionV3. Besides, our algorithm has successfully defeated two real-world systems, the Clarifai food detection API and the Baidu Animal Identification API.

</details>

<details>

<summary>2018-09-09 05:44:16 - Probabilistic Prediction of Interactive Driving Behavior via Hierarchical Inverse Reinforcement Learning</summary>

- *Liting Sun, Wei Zhan, Masayoshi Tomizuka*

- `1809.02926v1` - [abs](http://arxiv.org/abs/1809.02926v1) - [pdf](http://arxiv.org/pdf/1809.02926v1)

> Autonomous vehicles (AVs) are on the road. To safely and efficiently interact with other road participants, AVs have to accurately predict the behavior of surrounding vehicles and plan accordingly. Such prediction should be probabilistic, to address the uncertainties in human behavior. Such prediction should also be interactive, since the distribution over all possible trajectories of the predicted vehicle depends not only on historical information, but also on future plans of other vehicles that interact with it. To achieve such interaction-aware predictions, we propose a probabilistic prediction approach based on hierarchical inverse reinforcement learning (IRL). First, we explicitly consider the hierarchical trajectory-generation process of human drivers involving both discrete and continuous driving decisions. Based on this, the distribution over all future trajectories of the predicted vehicle is formulated as a mixture of distributions partitioned by the discrete decisions. Then we apply IRL hierarchically to learn the distributions from real human demonstrations. A case study for the ramp-merging driving scenario is provided. The quantitative results show that the proposed approach can accurately predict both the discrete driving decisions such as yield or pass as well as the continuous trajectories.

</details>

<details>

<summary>2018-09-09 06:02:50 - Generic Probabilistic Interactive Situation Recognition and Prediction: From Virtual to Real</summary>

- *Jiachen Li, Hengbo Ma, Wei Zhan, Masayoshi Tomizuka*

- `1809.02927v1` - [abs](http://arxiv.org/abs/1809.02927v1) - [pdf](http://arxiv.org/pdf/1809.02927v1)

> Accurate and robust recognition and prediction of traffic situation plays an important role in autonomous driving, which is a prerequisite for risk assessment and effective decision making. Although there exist a lot of works dealing with modeling driver behavior of a single object, it remains a challenge to make predictions for multiple highly interactive agents that react to each other simultaneously. In this work, we propose a generic probabilistic hierarchical recognition and prediction framework which employs a two-layer Hidden Markov Model (TLHMM) to obtain the distribution of potential situations and a learning-based dynamic scene evolution model to sample a group of future trajectories. Instead of predicting motions of a single entity, we propose to get the joint distribution by modeling multiple interactive agents as a whole system. Moreover, due to the decoupling property of the layered structure, our model is suitable for knowledge transfer from simulation to real world applications as well as among different traffic scenarios, which can reduce the computational efforts of training and the demand for a large data amount. A case study of highway ramp merging scenario is demonstrated to verify the effectiveness and accuracy of the proposed framework.

</details>

<details>

<summary>2018-09-09 15:45:25 - Speeding Up Neural Machine Translation Decoding by Cube Pruning</summary>

- *Wen Zhang, Liang Huang, Yang Feng, Lei Shen, Qun Liu*

- `1809.02992v1` - [abs](http://arxiv.org/abs/1809.02992v1) - [pdf](http://arxiv.org/pdf/1809.02992v1)

> Although neural machine translation has achieved promising results, it suffers from slow translation speed. The direct consequence is that a trade-off has to be made between translation quality and speed, thus its performance can not come into full play. We apply cube pruning, a popular technique to speed up dynamic programming, into neural machine translation to speed up the translation. To construct the equivalence class, similar target hidden states are combined, leading to less RNN expansion operations on the target side and less \$\mathrm{softmax}\$ operations over the large target vocabulary. The experiments show that, at the same or even better translation quality, our method can translate faster compared with naive beam search by \$3.3\times\$ on GPUs and \$3.5\times\$ on CPUs.

</details>

<details>

<summary>2018-09-09 16:26:43 - Refining Source Representations with Relation Networks for Neural Machine Translation</summary>

- *Wen Zhang, Jiawei Hu, Yang Feng, Qun Liu*

- `1805.11154v2` - [abs](http://arxiv.org/abs/1805.11154v2) - [pdf](http://arxiv.org/pdf/1805.11154v2)

> Although neural machine translation with the encoder-decoder framework has achieved great success recently, it still suffers drawbacks of forgetting distant information, which is an inherent disadvantage of recurrent neural network structure, and disregarding relationship between source words during encoding step. Whereas in practice, the former information and relationship are often useful in current step. We target on solving these problems and thus introduce relation networks to learn better representations of the source. The relation networks are able to facilitate memorization capability of recurrent neural network via associating source words with each other, this would also help retain their relationships. Then the source representations and all the relations are fed into the attention component together while decoding, with the main encoder-decoder framework unchanged. Experiments on several datasets show that our method can improve the translation performance significantly over the conventional encoder-decoder model and even outperform the approach involving supervised syntactic knowledge.

</details>

<details>

<summary>2018-09-09 21:08:57 - How clever is the FiLM model, and how clever can it be?</summary>

- *Alexander Kuhnle, Huiyuan Xie, Ann Copestake*

- `1809.03044v1` - [abs](http://arxiv.org/abs/1809.03044v1) - [pdf](http://arxiv.org/pdf/1809.03044v1)

> The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR dataset and is distinguished from other such models by having a comparatively simple and easily transferable architecture. In this paper, we investigate in more detail the ability of FiLM to learn various linguistic constructions. Our main results show that (a) FiLM is not able to learn relational statements straight away except for very simple instances, (b) training on a broader set of instances as well as pretraining on simpler instance types can help alleviate these learning difficulties, (c) mixing is less robust than pretraining and very sensitive to the compositional structure of the dataset. Overall, our results suggest that the approach of big all-encompassing datasets and the paradigm of "the effectiveness of data" may have fundamental limitations.

</details>

<details>

<summary>2018-09-09 21:32:49 - Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples</summary>

- *Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra, Prateek Jain, Sumit Gulwani*

- `1804.01186v2` - [abs](http://arxiv.org/abs/1804.01186v2) - [pdf](http://arxiv.org/pdf/1804.01186v2)

> Synthesizing user-intended programs from a small number of input-output examples is a challenging problem with several important applications like spreadsheet manipulation, data wrangling and code refactoring. Existing synthesis systems either completely rely on deductive logic techniques that are extensively hand-engineered or on purely statistical models that need massive amounts of data, and in general fail to provide real-time synthesis on challenging benchmarks. In this work, we propose Neural Guided Deductive Search (NGDS), a hybrid synthesis technique that combines the best of both symbolic logic techniques and statistical models. Thus, it produces programs that satisfy the provided specifications by construction and generalize well on unseen examples, similar to data-driven systems. Our technique effectively utilizes the deductive search framework to reduce the learning problem of the neural component to a simple supervised learning setup. Further, this allows us to both train on sparingly available real-world data and still leverage powerful recurrent neural network encoders. We demonstrate the effectiveness of our method by evaluating on real-world customer scenarios by synthesizing accurate programs with up to 12x speed-up compared to state-of-the-art systems.

</details>

<details>

<summary>2018-09-09 22:33:20 - Attentional Multi-Reading Sarcasm Detection</summary>

- *Reza Ghaeini, Xiaoli Z. Fern, Prasad Tadepalli*

- `1809.03051v1` - [abs](http://arxiv.org/abs/1809.03051v1) - [pdf](http://arxiv.org/pdf/1809.03051v1)

> Recognizing sarcasm often requires a deep understanding of multiple sources of information, including the utterance, the conversational context, and real world facts. Most of the current sarcasm detection systems consider only the utterance in isolation. There are some limited attempts toward taking into account the conversational context. In this paper, we propose an interpretable end-to-end model that combines information from both the utterance and the conversational context to detect sarcasm, and demonstrate its effectiveness through empirical evaluations. We also study the behavior of the proposed model to provide explanations for the model's decisions. Importantly, our model is capable of determining the impact of utterance and conversational context on the model's decisions. Finally, we provide an ablation study to illustrate the impact of different components of the proposed model.

</details>

<details>

<summary>2018-09-09 23:03:54 - Variance Reduction in Monte Carlo Counterfactual Regret Minimization (VR-MCCFR) for Extensive Form Games using Baselines</summary>

- *Martin Schmid, Neil Burch, Marc Lanctot, Matej Moravcik, Rudolf Kadlec, Michael Bowling*

- `1809.03057v1` - [abs](http://arxiv.org/abs/1809.03057v1) - [pdf](http://arxiv.org/pdf/1809.03057v1)

> Learning strategies for imperfect information games from samples of interaction is a challenging problem. A common method for this setting, Monte Carlo Counterfactual Regret Minimization (MCCFR), can have slow long-term convergence rates due to high variance. In this paper, we introduce a variance reduction technique (VR-MCCFR) that applies to any sampling variant of MCCFR. Using this technique, per-iteration estimated values and updates are reformulated as a function of sampled values and state-action baselines, similar to their use in policy gradient reinforcement learning. The new formulation allows estimates to be bootstrapped from other estimates within the same episode, propagating the benefits of baselines along the sampled trajectory; the estimates remain unbiased even when bootstrapping from other estimates. Finally, we show that given a perfect baseline, the variance of the value estimates can be reduced to zero. Experimental evaluation shows that VR-MCCFR brings an order of magnitude speedup, while the empirical variance decreases by three orders of magnitude. The decreased variance allows for the first time CFR+ to be used with sampling, increasing the speedup to two orders of magnitude.

</details>

<details>

<summary>2018-09-10 01:12:26 - Sample Complexity of Nonparametric Semi-Supervised Learning</summary>

- *Chen Dan, Liu Leqi, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing*

- `1809.03073v1` - [abs](http://arxiv.org/abs/1809.03073v1) - [pdf](http://arxiv.org/pdf/1809.03073v1)

> We study the sample complexity of semi-supervised learning (SSL) and introduce new assumptions based on the mismatch between a mixture model learned from unlabeled data and the true mixture model induced by the (unknown) class conditional distributions. Under these assumptions, we establish an $\Omega(K\log K)$ labeled sample complexity bound without imposing parametric assumptions, where $K$ is the number of classes. Our results suggest that even in nonparametric settings it is possible to learn a near-optimal classifier using only a few labeled samples. Unlike previous theoretical work which focuses on binary classification, we consider general multiclass classification ($K>2$), which requires solving a difficult permutation learning problem. This permutation defines a classifier whose classification error is controlled by the Wasserstein distance between mixing measures, and we provide finite-sample results characterizing the behaviour of the excess risk of this classifier. Finally, we describe three algorithms for computing these estimators based on a connection to bipartite graph matching, and perform experiments to illustrate the superiority of the MLE over the majority vote estimator.

</details>

<details>

<summary>2018-09-10 01:28:24 - Online Convex Optimization for Sequential Decision Processes and Extensive-Form Games</summary>

- *Gabriele Farina, Christian Kroer, Tuomas Sandholm*

- `1809.03075v1` - [abs](http://arxiv.org/abs/1809.03075v1) - [pdf](http://arxiv.org/pdf/1809.03075v1)

> Regret minimization is a powerful tool for solving large-scale extensive-form games. State-of-the-art methods rely on minimizing regret locally at each decision point. In this work we derive a new framework for regret minimization on sequential decision problems and extensive-form games with general compact convex sets at each decision point and general convex losses, as opposed to prior work which has been for simplex decision points and linear losses. We call our framework laminar regret decomposition. It generalizes the CFR algorithm to this more general setting. Furthermore, our framework enables a new proof of CFR even in the known setting, which is derived from a perspective of decomposing polytope regret, thereby leading to an arguably simpler interpretation of the algorithm. Our generalization to convex compact sets and convex losses allows us to develop new algorithms for several problems: regularized sequential decision making, regularized Nash equilibria in extensive-form games, and computing approximate extensive-form perfect equilibria. Our generalization also leads to the first regret-minimization algorithm for computing reduced-normal-form quantal response equilibria based on minimizing local regrets. Experiments show that our framework leads to algorithms that scale at a rate comparable to the fastest variants of counterfactual regret minimization for computing Nash equilibrium, and therefore our approach leads to the first algorithm for computing quantal response equilibria in extremely large games. Finally we show that our framework enables a new kind of scalable opponent exploitation approach.

</details>

<details>

<summary>2018-09-10 01:45:24 - Can machine learning identify interesting mathematics? An exploration using empirically observed laws</summary>

- *Chai Wah Wu*

- `1805.07431v3` - [abs](http://arxiv.org/abs/1805.07431v3) - [pdf](http://arxiv.org/pdf/1805.07431v3)

> We explore the possibility of using machine learning to identify interesting mathematical structures by using certain quantities that serve as fingerprints. In particular, we extract features from integer sequences using two empirical laws: Benford's law and Taylor's law and experiment with various classifiers to identify whether a sequence is, for example, nice, important, multiplicative, easy to compute or related to primes or palindromes.

</details>

<details>

<summary>2018-09-10 03:35:33 - Memristive LSTM network hardware architecture for time-series predictive modeling problem</summary>

- *Kazybek Adam, Kamilya Smagulova, Alex Pappachen James*

- `1809.03119v1` - [abs](http://arxiv.org/abs/1809.03119v1) - [pdf](http://arxiv.org/pdf/1809.03119v1)

> Analysis of time-series data allows to identify long-term trends and make predictions that can help to improve our lives. With the rapid development of artificial neural networks, long short-term memory (LSTM) recurrent neural network (RNN) configuration is found to be capable in dealing with time-series forecasting problems where data points are time-dependent and possess seasonality trends. Gated structure of LSTM cell and flexibility in network topology (one-to-many, many-to-one, etc.) allows to model systems with multiple input variables and control several parameters such as the size of the look-back window to make a prediction and number of time steps to be predicted. These make LSTM attractive tool over conventional methods such as autoregression models, the simple average, moving average, naive approach, ARIMA, Holt's linear trend method, Holt's Winter seasonal method, and others. In this paper, we propose a hardware implementation of LSTM network architecture for time-series forecasting problem. All simulations were performed using TSMC 0.18um CMOS technology and HP memristor model.

</details>

<details>

<summary>2018-09-10 04:59:19 - A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents</summary>

- *Yueh-Hua Wu, Shou-De Lin*

- `1712.04172v2` - [abs](http://arxiv.org/abs/1712.04172v2) - [pdf](http://arxiv.org/pdf/1712.04172v2)

> This paper proposes a low-cost, easily realizable strategy to equip a reinforcement learning (RL) agent the capability of behaving ethically. Our model allows the designers of RL agents to solely focus on the task to achieve, without having to worry about the implementation of multiple trivial ethical patterns to follow. Based on the assumption that the majority of human behavior, regardless which goals they are achieving, is ethical, our design integrates human policy with the RL policy to achieve the target objective with less chance of violating the ethical code that human beings normally obey.

</details>

<details>

<summary>2018-09-10 06:38:22 - A Multi-Agent Reinforcement Learning Method for Impression Allocation in Online Display Advertising</summary>

- *Di Wu, Cheng Chen, Xun Yang, Xiujun Chen, Qing Tan, Jian Xu, Kun Gai*

- `1809.03152v1` - [abs](http://arxiv.org/abs/1809.03152v1) - [pdf](http://arxiv.org/pdf/1809.03152v1)

> In online display advertising, guaranteed contracts and real-time bidding (RTB) are two major ways to sell impressions for a publisher. Despite the increasing popularity of RTB, there is still half of online display advertising revenue generated from guaranteed contracts. Therefore, simultaneously selling impressions through both guaranteed contracts and RTB is a straightforward choice for a publisher to maximize its yield. However, deriving the optimal strategy to allocate impressions is not a trivial task, especially when the environment is unstable in real-world applications. In this paper, we formulate the impression allocation problem as an auction problem where each contract can submit virtual bids for individual impressions. With this formulation, we derive the optimal impression allocation strategy by solving the optimal bidding functions for contracts. Since the bids from contracts are decided by the publisher, we propose a multi-agent reinforcement learning (MARL) approach to derive cooperative policies for the publisher to maximize its yield in an unstable environment. The proposed approach also resolves the common challenges in MARL such as input dimension explosion, reward credit assignment, and non-stationary environment. Experimental evaluations on large-scale real datasets demonstrate the effectiveness of our approach.

</details>

<details>

<summary>2018-09-10 09:16:26 - Decentralized Cooperative Planning for Automated Vehicles with Continuous Monte Carlo Tree Search</summary>

- *Karl Kurzer, Florian Engelhorn, J. Marius Zöllner*

- `1809.03200v1` - [abs](http://arxiv.org/abs/1809.03200v1) - [pdf](http://arxiv.org/pdf/1809.03200v1)

> Urban traffic scenarios often require a high degree of cooperation between traffic participants to ensure safety and efficiency. Observing the behavior of others, humans infer whether or not others are cooperating. This work aims to extend the capabilities of automated vehicles, enabling them to cooperate implicitly in heterogeneous environments. Continuous actions allow for arbitrary trajectories and hence are applicable to a much wider class of problems than existing cooperative approaches with discrete action spaces. Based on cooperative modeling of other agents, Monte Carlo Tree Search (MCTS) in conjunction with Decoupled-UCT evaluates the action-values of each agent in a cooperative and decentralized way, respecting the interdependence of actions among traffic participants. The extension to continuous action spaces is addressed by incorporating novel MCTS-specific enhancements for efficient search space exploration. The proposed algorithm is evaluated under different scenarios, showing that the algorithm is able to achieve effective cooperative planning and generate solutions egocentric planning fails to identify.

</details>

<details>

<summary>2018-09-10 09:17:04 - Learning Sequence Encoders for Temporal Knowledge Graph Completion</summary>

- *Alberto García-Durán, Sebastijan Dumančić, Mathias Niepert*

- `1809.03202v1` - [abs](http://arxiv.org/abs/1809.03202v1) - [pdf](http://arxiv.org/pdf/1809.03202v1)

> Research on link prediction in knowledge graphs has mainly focused on static multi-relational data. In this work we consider temporal knowledge graphs where relations between entities may only hold for a time interval or a specific point in time. In line with previous work on static knowledge graphs, we propose to address this problem by learning latent entity and relation type representations. To incorporate temporal information, we utilize recurrent neural networks to learn time-aware representations of relation types which can be used in conjunction with existing latent factorization methods. The proposed approach is shown to be robust to common challenges in real-world KGs: the sparsity and heterogeneity of temporal expressions. Experiments show the benefits of our approach on four temporal KGs. The data sets are available under a permissive BSD-3 license 1.

</details>

<details>

<summary>2018-09-10 10:00:46 - Gait learning for soft microrobots controlled by light fields</summary>

- *Alexander von Rohr, Sebastian Trimpe, Alonso Marco, Peer Fischer, Stefano Palagi*

- `1809.03225v1` - [abs](http://arxiv.org/abs/1809.03225v1) - [pdf](http://arxiv.org/pdf/1809.03225v1)

> Soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. This inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. Albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. Common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. Here we propose a probabilistic learning approach for light-controlled soft microrobots based on Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. These features are obtained by designing the learning scheme through the comparison of different GP priors and BO settings on a semi-synthetic data set. The developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. These encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control.

</details>

<details>

<summary>2018-09-10 10:55:43 - Dual Ask-Answer Network for Machine Reading Comprehension</summary>

- *Han Xiao, Feng Wang, Jianfeng Yan, Jingyao Zheng*

- `1809.01997v2` - [abs](http://arxiv.org/abs/1809.01997v2) - [pdf](http://arxiv.org/pdf/1809.01997v2)

> There are three modalities in the reading comprehension setting: question, answer and context. The task of question answering or question generation aims to infer an answer or a question when given the counterpart based on context. We present a novel two-way neural sequence transduction model that connects three modalities, allowing it to learn two tasks simultaneously and mutually benefit one another. During training, the model receives question-context-answer triplets as input and captures the cross-modal interaction via a hierarchical attention process. Unlike previous joint learning paradigms that leverage the duality of question generation and question answering at data level, we solve such dual tasks at the architecture level by mirroring the network structure and partially sharing components at different layers. This enables the knowledge to be transferred from one task to another, helping the model to find a general representation for each modality. The evaluation on four public datasets shows that our dual-learning model outperforms the mono-learning counterpart as well as the state-of-the-art joint models on both question answering and question generation tasks.

</details>

<details>

<summary>2018-09-10 12:11:21 - Automated Test Generation to Detect Individual Discrimination in AI Models</summary>

- *Aniya Agarwal, Pranay Lohia, Seema Nagar, Kuntal Dey, Diptikalyan Saha*

- `1809.03260v1` - [abs](http://arxiv.org/abs/1809.03260v1) - [pdf](http://arxiv.org/pdf/1809.03260v1)

> Dependability on AI models is of utmost importance to ensure full acceptance of the AI systems. One of the key aspects of the dependable AI system is to ensure that all its decisions are fair and not biased towards any individual. In this paper, we address the problem of detecting whether a model has an individual discrimination. Such a discrimination exists when two individuals who differ only in the values of their protected attributes (such as, gender/race) while the values of their non-protected ones are exactly the same, get different decisions. Measuring individual discrimination requires an exhaustive testing, which is infeasible for a non-trivial system. In this paper, we present an automated technique to generate test inputs, which is geared towards finding individual discrimination. Our technique combines the well-known technique called symbolic execution along with the local explainability for generation of effective test cases. Our experimental results clearly demonstrate that our technique produces 3.72 times more successful test cases than the existing state-of-the-art across all our chosen benchmarks.

</details>

<details>

<summary>2018-09-10 14:09:10 - Assessing and Addressing Algorithmic Bias - But Before We Get There</summary>

- *Jean Garcia-Gathright, Aaron Springer, Henriette Cramer*

- `1809.03332v1` - [abs](http://arxiv.org/abs/1809.03332v1) - [pdf](http://arxiv.org/pdf/1809.03332v1)

> Algorithmic and data bias are gaining attention as a pressing issue in popular press - and rightly so. However, beyond these calls to action, standard processes and tools for practitioners do not readily exist to assess and address unfair algorithmic and data biases. The literature is relatively scattered and the needed interdisciplinary approach means that very different communities are working on the topic. We here provide a number of challenges encountered in assessing and addressing algorithmic and data bias in practice. We describe an early approach that attempts to translate the literature into processes for (production) teams wanting to assess both intended data and algorithm characteristics and unintended, unfair biases.

</details>

<details>

<summary>2018-09-10 14:38:47 - Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference</summary>

- *Yi Tay, Luu Anh Tuan, Siu Cheung Hui*

- `1801.00102v2` - [abs](http://arxiv.org/abs/1801.00102v2) - [pdf](http://arxiv.org/pdf/1801.00102v2)

> This paper presents a new deep learning architecture for Natural Language Inference (NLI). Firstly, we introduce a new architecture where alignment pairs are compared, compressed and then propagated to upper layers for enhanced representation learning. Secondly, we adopt factorization layers for efficient and expressive compression of alignment vectors into scalar features, which are then used to augment the base word representations. The design of our approach is aimed to be conceptually simple, compact and yet powerful. We conduct experiments on three popular benchmarks, SNLI, MultiNLI and SciTail, achieving competitive performance on all. A lightweight parameterization of our model also enjoys a $\approx 3$ times reduction in parameter size compared to the existing state-of-the-art models, e.g., ESIM and DIIN, while maintaining competitive performance. Additionally, visual analysis shows that our propagated features are highly interpretable.

</details>

<details>

<summary>2018-09-10 14:46:35 - Torchbearer: A Model Fitting Library for PyTorch</summary>

- *Ethan Harris, Matthew Painter, Jonathon Hare*

- `1809.03363v1` - [abs](http://arxiv.org/abs/1809.03363v1) - [pdf](http://arxiv.org/pdf/1809.03363v1)

> We introduce torchbearer, a model fitting library for pytorch aimed at researchers working on deep learning or differentiable programming. The torchbearer library provides a high level metric and callback API that can be used for a wide range of applications. We also include a series of built in callbacks that can be used for: model persistence, learning rate decay, logging, data visualization and more. The extensive documentation includes an example library for deep learning and dynamic programming problems and can be found at http://torchbearer.readthedocs.io. The code is licensed under the MIT License and available at https://github.com/ecs-vlc/torchbearer.

</details>

<details>

<summary>2018-09-10 17:11:59 - The relativistic discriminator: a key element missing from standard GAN</summary>

- *Alexia Jolicoeur-Martineau*

- `1807.00734v3` - [abs](http://arxiv.org/abs/1807.00734v3) - [pdf](http://arxiv.org/pdf/1807.00734v3)

> In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs.   We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function.   Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.

</details>

<details>

<summary>2018-09-10 17:41:39 - ViZDoom Competitions: Playing Doom from Pixels</summary>

- *Marek Wydmuch, Michał Kempka, Wojciech Jaśkowski*

- `1809.03470v1` - [abs](http://arxiv.org/abs/1809.03470v1) - [pdf](http://arxiv.org/pdf/1809.03470v1)

> This paper presents the first two editions of Visual Doom AI Competition, held in 2016 and 2017. The challenge was to create bots that compete in a multi-player deathmatch in a first-person shooter (FPS) game, Doom. The bots had to make their decisions based solely on visual information, i.e., a raw screen buffer. To play well, the bots needed to understand their surroundings, navigate, explore, and handle the opponents at the same time. These aspects, together with the competitive multi-agent aspect of the game, make the competition a unique platform for evaluating the state of the art reinforcement learning algorithms. The paper discusses the rules, solutions, results, and statistics that give insight into the agents' behaviors. Best-performing agents are described in more detail. The results of the competition lead to the conclusion that, although reinforcement learning can produce capable Doom bots, they still are not yet able to successfully compete against humans in this game. The paper also revisits the ViZDoom environment, which is a flexible, easy to use, and efficient 3D platform for research for vision-based reinforcement learning, based on a well-recognized first-person perspective game Doom.

</details>

<details>

<summary>2018-09-10 17:48:58 - Towards a Fatality-Aware Benchmark of Probabilistic Reaction Prediction in Highly Interactive Driving Scenarios</summary>

- *Wei Zhan, Liting Sun, Yeping Hu, Jiachen Li, Masayoshi Tomizuka*

- `1809.03478v1` - [abs](http://arxiv.org/abs/1809.03478v1) - [pdf](http://arxiv.org/pdf/1809.03478v1)

> Autonomous vehicles should be able to generate accurate probabilistic predictions for uncertain behavior of other road users. Moreover, reactive predictions are necessary in highly interactive driving scenarios to answer "what if I take this action in the future" for autonomous vehicles. There is no existing unified framework to homogenize the problem formulation, representation simplification, and evaluation metric for various prediction methods, such as probabilistic graphical models (PGM), neural networks (NN) and inverse reinforcement learning (IRL). In this paper, we formulate a probabilistic reaction prediction problem, and reveal the relationship between reaction and situation prediction problems. We employ prototype trajectories with designated motion patterns other than "intention" to homogenize the representation so that probabilities corresponding to each trajectory generated by different methods can be evaluated. We also discuss the reasons why "intention" is not suitable to serve as a motion indicator in highly interactive scenarios. We propose to use Brier score as the baseline metric for evaluation. In order to reveal the fatality of the consequences when the predictions are adopted by decision-making and planning, we propose a fatality-aware metric, which is a weighted Brier score based on the criticality of the trajectory pairs of the interacting entities. Conservatism and non-defensiveness are defined from the weighted Brier score to indicate the consequences caused by inaccurate predictions. Modified methods based on PGM, NN and IRL are provided to generate probabilistic reaction predictions in an exemplar scenario of nudging from a highway ramp. The results are evaluated by the baseline and proposed metrics to construct a mini benchmark. Analysis on the properties of each method is also provided by comparing the baseline and proposed metric scores.

</details>

<details>

<summary>2018-09-10 18:40:46 - Bayesian Patchworks: An Approach to Case-Based Reasoning</summary>

- *Ramin Moghaddass, Cynthia Rudin*

- `1809.03541v1` - [abs](http://arxiv.org/abs/1809.03541v1) - [pdf](http://arxiv.org/pdf/1809.03541v1)

> Doctors often rely on their past experience in order to diagnose patients. For a doctor with enough experience, almost every patient would have similarities to key cases seen in the past, and each new patient could be viewed as a mixture of these key past cases. Because doctors often tend to reason this way, an efficient computationally aided diagnostic tool that thinks in the same way might be helpful in locating key past cases of interest that could assist with diagnosis. This article develops a novel mathematical model to mimic the type of logical thinking that physicians use when considering past cases. The proposed model can also provide physicians with explanations that would be similar to the way they would naturally reason about cases. The proposed method is designed to yield predictive accuracy, computational efficiency, and insight into medical data; the key element is the insight into medical data, in some sense we are automating a complicated process that physicians might perform manually. We finally implemented the result of this work on two publicly available healthcare datasets, for heart disease prediction and breast cancer prediction.

</details>

<details>

<summary>2018-09-10 18:42:40 - Visualizing and Understanding Atari Agents</summary>

- *Sam Greydanus, Anurag Koul, Jonathan Dodge, Alan Fern*

- `1711.00138v5` - [abs](http://arxiv.org/abs/1711.00138v5) - [pdf](http://arxiv.org/pdf/1711.00138v5)

> While deep reinforcement learning (deep RL) agents are effective at maximizing rewards, it is often unclear what strategies they use to do so. In this paper, we take a step toward explaining deep RL agents through a case study using Atari 2600 environments. In particular, we focus on using saliency maps to understand how an agent learns and executes a policy. We introduce a method for generating useful saliency maps and use it to show 1) what strong agents attend to, 2) whether agents are making decisions for the right or wrong reasons, and 3) how agents evolve during learning. We also test our method on non-expert human subjects and find that it improves their ability to reason about these agents. Overall, our results show that saliency information can provide significant insight into an RL agent's decisions and learning behavior.

</details>

<details>

<summary>2018-09-10 19:28:57 - Deep Learning Towards Mobile Applications</summary>

- *Ji Wang, Bokai Cao, Philip S. Yu, Lichao Sun, Weidong Bao, Xiaomin Zhu*

- `1809.03559v1` - [abs](http://arxiv.org/abs/1809.03559v1) - [pdf](http://arxiv.org/pdf/1809.03559v1)

> Recent years have witnessed an explosive growth of mobile devices. Mobile devices are permeating every aspect of our daily lives. With the increasing usage of mobile devices and intelligent applications, there is a soaring demand for mobile applications with machine learning services. Inspired by the tremendous success achieved by deep learning in many machine learning tasks, it becomes a natural trend to push deep learning towards mobile applications. However, there exist many challenges to realize deep learning in mobile applications, including the contradiction between the miniature nature of mobile devices and the resource requirement of deep neural networks, the privacy and security concerns about individuals' data, and so on. To resolve these challenges, during the past few years, great leaps have been made in this area. In this paper, we provide an overview of the current challenges and representative achievements about pushing deep learning on mobile devices from three aspects: training with mobile data, efficient inference on mobile devices, and applications of mobile deep learning. The former two aspects cover the primary tasks of deep learning. Then, we go through our two recent applications that apply the data collected by mobile devices to inferring mood disturbance and user identification. Finally, we conclude this paper with the discussion of the future of this area.

</details>

<details>

<summary>2018-09-10 21:49:38 - URBAN-i: From urban scenes to mapping slums, transport modes, and pedestrians in cities using deep learning and computer vision</summary>

- *Mohamed R. Ibrahim, James Haworth, Tao Cheng*

- `1809.03609v1` - [abs](http://arxiv.org/abs/1809.03609v1) - [pdf](http://arxiv.org/pdf/1809.03609v1)

> Within the burgeoning expansion of deep learning and computer vision across the different fields of science, when it comes to urban development, deep learning and computer vision applications are still limited towards the notions of smart cities and autonomous vehicles. Indeed, a wide gap of knowledge appears when it comes to cities and urban regions in less developed countries where the chaos of informality is the dominant scheme. How can deep learning and Artificial Intelligence (AI) untangle the complexities of informality to advance urban modelling and our understanding of cities? Various questions and debates can be raised concerning the future of cities of the North and the South in the paradigm of AI and computer vision. In this paper, we introduce a new method for multipurpose realistic-dynamic urban modelling relying on deep learning and computer vision, using deep Convolutional Neural Networks (CNN), to sense and detect informality and slums in urban scenes from aerial and street view images in addition to detection of pedestrian and transport modes. The model has been trained on images of urban scenes in cities across the globe. The model shows a good validation of understanding a wide spectrum of nuances among the planned and the unplanned regions, including informal and slum areas. We attempt to advance urban modelling for better understanding the dynamics of city developments. We also aim to exemplify the significant impacts of AI in cities beyond how smart cities are discussed and perceived in the mainstream. The algorithms of the URBAN-i model are fully-coded in Python programming with the pre-trained deep learning models to be used as a tool for mapping and city modelling in the various corner of the globe, including informal settlements and slum regions.

</details>

<details>

<summary>2018-09-10 22:12:53 - REGMAPR - Text Matching Made Easy</summary>

- *Siddhartha Brahma*

- `1808.04343v3` - [abs](http://arxiv.org/abs/1808.04343v3) - [pdf](http://arxiv.org/pdf/1808.04343v3)

> Text matching is a fundamental problem in natural language processing. Neural models using bidirectional LSTMs for sentence encoding and inter-sentence attention mechanisms perform remarkably well on several benchmark datasets. We propose REGMAPR - a simple and general architecture for text matching that does not use inter-sentence attention. Starting from a Siamese architecture, we augment the embeddings of the words with two features based on exact and para- phrase match between words in the two sentences. We train the model using three types of regularization on datasets for textual entailment, paraphrase detection and semantic related- ness. REGMAPR performs comparably or better than more complex neural models or models using a large number of handcrafted features. REGMAPR achieves state-of-the-art results for paraphrase detection on the SICK dataset and for textual entailment on the SNLI dataset among models that do not use inter-sentence attention.

</details>

<details>

<summary>2018-09-10 22:16:36 - Improved Sentence Modeling using Suffix Bidirectional LSTM</summary>

- *Siddhartha Brahma*

- `1805.07340v2` - [abs](http://arxiv.org/abs/1805.07340v2) - [pdf](http://arxiv.org/pdf/1805.07340v2)

> Recurrent neural networks have become ubiquitous in computing representations of sequential data, especially textual data in natural language processing. In particular, Bidirectional LSTMs are at the heart of several neural models achieving state-of-the-art performance in a wide variety of tasks in NLP. However, BiLSTMs are known to suffer from sequential bias - the contextual representation of a token is heavily influenced by tokens close to it in a sentence. We propose a general and effective improvement to the BiLSTM model which encodes each suffix and prefix of a sequence of tokens in both forward and reverse directions. We call our model Suffix Bidirectional LSTM or SuBiLSTM. This introduces an alternate bias that favors long range dependencies. We apply SuBiLSTMs to several tasks that require sentence modeling. We demonstrate that using SuBiLSTM instead of a BiLSTM in existing models leads to improvements in performance in learning general sentence representations, text classification, textual entailment and paraphrase detection. Using SuBiLSTM we achieve new state-of-the-art results for fine-grained sentiment classification and question classification.

</details>

<details>

<summary>2018-09-11 01:44:51 - Teaching Meaningful Explanations</summary>

- *Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy, Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra Mojsilovic*

- `1805.11648v2` - [abs](http://arxiv.org/abs/1805.11648v2) - [pdf](http://arxiv.org/pdf/1805.11648v2)

> The adoption of machine learning in high-stakes applications such as healthcare and law has lagged in part because predictions are not accompanied by explanations comprehensible to the domain user, who often holds the ultimate responsibility for decisions and outcomes. In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users. A joint model is then learned to produce both labels and explanations from the input features. This simple idea ensures that explanations are tailored to the complexity expectations and domain knowledge of the consumer. Evaluation spans multiple modeling techniques on a game dataset, a (visual) aesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that our approach is generalizable across domains and algorithms. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, also improve modeling accuracy.

</details>

<details>

<summary>2018-09-11 01:49:04 - Counting and Sampling from Markov Equivalent DAGs Using Clique Trees</summary>

- *AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Kun Zhang*

- `1802.01239v2` - [abs](http://arxiv.org/abs/1802.01239v2) - [pdf](http://arxiv.org/pdf/1802.01239v2)

> A directed acyclic graph (DAG) is the most common graphical model for representing causal relationships among a set of variables. When restricted to using only observational data, the structure of the ground truth DAG is identifiable only up to Markov equivalence, based on conditional independence relations among the variables. Therefore, the number of DAGs equivalent to the ground truth DAG is an indicator of the causal complexity of the underlying structure--roughly speaking, it shows how many interventions or how much additional information is further needed to recover the underlying DAG. In this paper, we propose a new technique for counting the number of DAGs in a Markov equivalence class. Our approach is based on the clique tree representation of chordal graphs. We show that in the case of bounded degree graphs, the proposed algorithm is polynomial time. We further demonstrate that this technique can be utilized for uniform sampling from a Markov equivalence class, which provides a stochastic way to enumerate DAGs in the equivalence class and may be needed for finding the best DAG or for causal inference given the equivalence class as input. We also extend our counting and sampling method to the case where prior knowledge about the underlying DAG is available, and present applications of this extension in causal experiment design and estimating the causal effect of joint interventions.

</details>

<details>

<summary>2018-09-11 02:09:03 - Resource-driven Substructural Defeasible Logic</summary>

- *Francesco Olivieri, Guido Governatori, Matteo Cristani, Nick van Beest, Silvano Colombo-Tosatto*

- `1809.03656v1` - [abs](http://arxiv.org/abs/1809.03656v1) - [pdf](http://arxiv.org/pdf/1809.03656v1)

> Linear Logic and Defeasible Logic have been adopted to formalise different features relevant to agents: consumption of resources, and reasoning with exceptions. We propose a framework to combine sub-structural features, corresponding to the consumption of resources, with defeasibility aspects, and we discuss the design choices for the framework.

</details>

<details>

<summary>2018-09-11 06:40:36 - Evaluating Multimodal Representations on Sentence Similarity: vSTS, Visual Semantic Textual Similarity Dataset</summary>

- *Oier Lopez de Lacalle, Aitor Soroa, Eneko Agirre*

- `1809.03695v1` - [abs](http://arxiv.org/abs/1809.03695v1) - [pdf](http://arxiv.org/pdf/1809.03695v1)

> In this paper we introduce vSTS, a new dataset for measuring textual similarity of sentences using multimodal information. The dataset is comprised by images along with its respectively textual captions. We describe the dataset both quantitatively and qualitatively, and claim that it is a valid gold standard for measuring automatic multimodal textual similarity systems. We also describe the initial experiments combining the multimodal information.

</details>

<details>

<summary>2018-09-11 11:11:15 - CNN features are also great at unsupervised classification</summary>

- *Joris Guérin, Olivier Gibaru, Stéphane Thiery, Eric Nyiri*

- `1707.01700v2` - [abs](http://arxiv.org/abs/1707.01700v2) - [pdf](http://arxiv.org/pdf/1707.01700v2)

> This paper aims at providing insight on the transferability of deep CNN features to unsupervised problems. We study the impact of different pretrained CNN feature extractors on the problem of image set clustering for object classification as well as fine-grained classification. We propose a rather straightforward pipeline combining deep-feature extraction using a CNN pretrained on ImageNet and a classic clustering algorithm to classify sets of images. This approach is compared to state-of-the-art algorithms in image-clustering and provides better results. These results strengthen the belief that supervised training of deep CNN on large datasets, with a large variability of classes, extracts better features than most carefully designed engineering approaches, even for unsupervised tasks. We also validate our approach on a robotic application, consisting in sorting and storing objects smartly based on clustering.

</details>

<details>

<summary>2018-09-11 13:17:38 - Visualizing Convolutional Neural Networks to Improve Decision Support for Skin Lesion Classification</summary>

- *Pieter Van Molle, Miguel De Strooper, Tim Verbelen, Bert Vankeirsbilck, Pieter Simoens, Bart Dhoedt*

- `1809.03851v1` - [abs](http://arxiv.org/abs/1809.03851v1) - [pdf](http://arxiv.org/pdf/1809.03851v1)

> Because of their state-of-the-art performance in computer vision, CNNs are becoming increasingly popular in a variety of fields, including medicine. However, as neural networks are black box function approximators, it is difficult, if not impossible, for a medical expert to reason about their output. This could potentially result in the expert distrusting the network when he or she does not agree with its output. In such a case, explaining why the CNN makes a certain decision becomes valuable information. In this paper, we try to open the black box of the CNN by inspecting and visualizing the learned feature maps, in the field of dermatology. We show that, to some extent, CNNs focus on features similar to those used by dermatologists to make a diagnosis. However, more research is required for fully explaining their output.

</details>

<details>

<summary>2018-09-11 13:27:36 - Response Characterization for Auditing Cell Dynamics in Long Short-term Memory Networks</summary>

- *Ramin M. Hasani, Alexander Amini, Mathias Lechner, Felix Naser, Radu Grosu, Daniela Rus*

- `1809.03864v1` - [abs](http://arxiv.org/abs/1809.03864v1) - [pdf](http://arxiv.org/pdf/1809.03864v1)

> In this paper, we introduce a novel method to interpret recurrent neural networks (RNNs), particularly long short-term memory networks (LSTMs) at the cellular level. We propose a systematic pipeline for interpreting individual hidden state dynamics within the network using response characterization methods. The ranked contribution of individual cells to the network's output is computed by analyzing a set of interpretable metrics of their decoupled step and sinusoidal responses. As a result, our method is able to uniquely identify neurons with insightful dynamics, quantify relationships between dynamical properties and test accuracy through ablation analysis, and interpret the impact of network capacity on a network's dynamical distribution. Finally, we demonstrate generalizability and scalability of our method by evaluating a series of different benchmark sequential datasets.

</details>

<details>

<summary>2018-09-11 13:53:10 - Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising</summary>

- *Junqi Jin, Chengru Song, Han Li, Kun Gai, Jun Wang, Weinan Zhang*

- `1802.09756v2` - [abs](http://arxiv.org/abs/1802.09756v2) - [pdf](http://arxiv.org/pdf/1802.09756v2)

> Real-time advertising allows advertisers to bid for each impression for a visiting user. To optimize specific goals such as maximizing revenue and return on investment (ROI) led by ad placements, advertisers not only need to estimate the relevance between the ads and user's interests, but most importantly require a strategic response with respect to other advertisers bidding in the market. In this paper, we formulate bidding optimization with multi-agent reinforcement learning. To deal with a large number of advertisers, we propose a clustering method and assign each cluster with a strategic bidding agent. A practical Distributed Coordinated Multi-Agent Bidding (DCMAB) has been proposed and implemented to balance the tradeoff between the competition and cooperation among advertisers. The empirical study on our industry-scaled real-world data has demonstrated the effectiveness of our methods. Our results show cluster-based bidding would largely outperform single-agent and bandit approaches, and the coordinated bidding achieves better overall objectives than purely self-interested bidding agents.

</details>

<details>

<summary>2018-09-11 13:56:13 - Learning to Drive in a Day</summary>

- *Alex Kendall, Jeffrey Hawke, David Janz, Przemyslaw Mazur, Daniele Reda, John-Mark Allen, Vinh-Dieu Lam, Alex Bewley, Amar Shah*

- `1807.00412v2` - [abs](http://arxiv.org/abs/1807.00412v2) - [pdf](http://arxiv.org/pdf/1807.00412v2)

> We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.

</details>

<details>

<summary>2018-09-11 14:18:49 - Detecting Intentions of Vulnerable Road Users Based on Collective Intelligence</summary>

- *Maarten Bieshaar, Günther Reitberger, Stefan Zernetsch, Bernhard Sick, Erich Fuchs, Konrad Doll*

- `1809.03916v1` - [abs](http://arxiv.org/abs/1809.03916v1) - [pdf](http://arxiv.org/pdf/1809.03916v1)

> Vulnerable road users (VRUs, i.e. cyclists and pedestrians) will play an important role in future traffic. To avoid accidents and achieve a highly efficient traffic flow, it is important to detect VRUs and to predict their intentions. In this article a holistic approach for detecting intentions of VRUs by cooperative methods is presented. The intention detection consists of basic movement primitive prediction, e.g. standing, moving, turning, and a forecast of the future trajectory. Vehicles equipped with sensors, data processing systems and communication abilities, referred to as intelligent vehicles, acquire and maintain a local model of their surrounding traffic environment, e.g. crossing cyclists. Heterogeneous, open sets of agents (cooperating and interacting vehicles, infrastructure, e.g. cameras and laser scanners, and VRUs equipped with smart devices and body-worn sensors) exchange information forming a multi-modal sensor system with the goal to reliably and robustly detect VRUs and their intentions under consideration of real time requirements and uncertainties. The resulting model allows to extend the perceptual horizon of the individual agent beyond their own sensory capabilities, enabling a longer forecast horizon. Concealments, implausibilities and inconsistencies are resolved by the collective intelligence of cooperating agents. Novel techniques of signal processing and modelling in combination with analytical and learning based approaches of pattern and activity recognition are used for detection, as well as intention prediction of VRUs. Cooperation, by means of probabilistic sensor and knowledge fusion, takes place on the level of perception and intention recognition. Based on the requirements of the cooperative approach for the communication a new strategy for an ad hoc network is proposed.

</details>

<details>

<summary>2018-09-11 15:02:24 - Abstraction Learning</summary>

- *Fei Deng, Jinsheng Ren, Feng Chen*

- `1809.03956v1` - [abs](http://arxiv.org/abs/1809.03956v1) - [pdf](http://arxiv.org/pdf/1809.03956v1)

> There has been a gap between artificial intelligence and human intelligence. In this paper, we identify three key elements forming human intelligence, and suggest that abstraction learning combines these elements and is thus a way to bridge the gap. Prior researches in artificial intelligence either specify abstraction by human experts, or take abstraction as a qualitative explanation for the model. This paper aims to learn abstraction directly. We tackle three main challenges: representation, objective function, and learning algorithm. Specifically, we propose a partition structure that contains pre-allocated abstraction neurons; we formulate abstraction learning as a constrained optimization problem, which integrates abstraction properties; we develop a network evolution algorithm to solve this problem. This complete framework is named ONE (Optimization via Network Evolution). In our experiments on MNIST, ONE shows elementary human-like intelligence, including low energy consumption, knowledge sharing, and lifelong learning.

</details>

<details>

<summary>2018-09-11 15:37:25 - Endowing Robots with Longer-term Autonomy by Recovering from External Disturbances in Manipulation through Grounded Anomaly Classification and Recovery Policies</summary>

- *Hongmin Wu, Shuangqi Luo, Longxin Chen, Shuangda Duan, Sakmongkon Chumkamon, Dong Liu, Yisheng Guan, Juan Rojas*

- `1809.03979v1` - [abs](http://arxiv.org/abs/1809.03979v1) - [pdf](http://arxiv.org/pdf/1809.03979v1)

> Robot manipulation is increasingly poised to interact with humans in co-shared workspaces. Despite increasingly robust manipulation and control algorithms, failure modes continue to exist whenever models do not capture the dynamics of the unstructured environment. To obtain longer-term horizons in robot automation, robots must develop introspection and recovery abilities. We contribute a set of recovery policies to deal with anomalies produced by external disturbances as well as anomaly classification through the use of non-parametric statistics with memoized variational inference with scalable adaptation. A recovery critic stands atop of a tightly-integrated, graph-based online motion-generation and introspection system that resolves a wide range of anomalous situations. Policies, skills, and introspection models are learned incrementally and contextually in a task. Two task-level recovery policies: re-enactment and adaptation resolve accidental and persistent anomalies respectively. The introspection system uses non-parametric priors along with Markov jump linear systems and memoized variational inference with scalable adaptation to learn a model from the data. Extensive real-robot experimentation with various strenuous anomalous conditions is induced and resolved at different phases of a task and in different combinations. The system executes around-the-clock introspection and recovery and even elicited self-recovery when misclassifications occurred.

</details>

<details>

<summary>2018-09-11 18:19:09 - Learning Graph-Level Representations with Recurrent Neural Networks</summary>

- *Yu Jin, Joseph F. JaJa*

- `1805.07683v4` - [abs](http://arxiv.org/abs/1805.07683v4) - [pdf](http://arxiv.org/pdf/1805.07683v4)

> Recently a variety of methods have been developed to encode graphs into low-dimensional vectors that can be easily exploited by machine learning algorithms. The majority of these methods start by embedding the graph nodes into a low-dimensional vector space, followed by using some scheme to aggregate the node embeddings. In this work, we develop a new approach to learn graph-level representations, which includes a combination of unsupervised and supervised learning components. We start by learning a set of node representations in an unsupervised fashion. Graph nodes are mapped into node sequences sampled from random walk approaches approximated by the Gumbel-Softmax distribution. Recurrent neural network (RNN) units are modified to accommodate both the node representations as well as their neighborhood information. Experiments on standard graph classification benchmarks demonstrate that our proposed approach achieves superior or comparable performance relative to the state-of-the-art algorithms in terms of convergence speed and classification accuracy. We further illustrate the effectiveness of the different components used by our approach.

</details>

<details>

<summary>2018-09-11 18:52:56 - ACM RecSys 2018 Late-Breaking Results Proceedings</summary>

- *Christoph Trattner, Vanessa Murdock, Steven Chang*

- `1809.04106v1` - [abs](http://arxiv.org/abs/1809.04106v1) - [pdf](http://arxiv.org/pdf/1809.04106v1)

> The ACM RecSys'18 Late-Breaking Results track (previously known as the Poster track) is part of the main program of the 2018 ACM Conference on Recommender Systems in Vancouver, Canada. The track attracted 48 submissions this year out of which 18 papers could be accepted resulting in an acceptance rated of 37.5%.

</details>

<details>

<summary>2018-09-11 22:00:49 - Multi-Hop Knowledge Graph Reasoning with Reward Shaping</summary>

- *Xi Victoria Lin, Richard Socher, Caiming Xiong*

- `1808.10568v2` - [abs](http://arxiv.org/abs/1808.10568v2) - [pdf](http://arxiv.org/pdf/1808.10568v2)

> Multi-hop reasoning is an effective approach for query answering (QA) over incomplete knowledge graphs (KGs). The problem can be formulated in a reinforcement learning (RL) setup, where a policy-based agent sequentially extends its inference path until it reaches a target. However, in an incomplete KG environment, the agent receives low-quality rewards corrupted by false negatives in the training data, which harms generalization at test time. Furthermore, since no golden action sequence is used for training, the agent can be misled by spurious search trajectories that incidentally lead to the correct answer. We propose two modeling advances to address both issues: (1) we reduce the impact of false negative supervision by adopting a pretrained one-hop embedding model to estimate the reward of unobserved facts; (2) we counter the sensitivity to spurious paths of on-policy RL by forcing the agent to explore a diverse set of paths using randomly generated edge masks. Our approach significantly improves over existing path-based KGQA models on several benchmark datasets and is comparable or better than embedding-based models.

</details>

<details>

<summary>2018-09-11 23:41:47 - Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals</summary>

- *Andrew Cotter, Heinrich Jiang, Serena Wang, Taman Narayan, Maya Gupta, Seungil You, Karthik Sridharan*

- `1809.04198v1` - [abs](http://arxiv.org/abs/1809.04198v1) - [pdf](http://arxiv.org/pdf/1809.04198v1)

> We show that many machine learning goals, such as improved fairness metrics, can be expressed as constraints on the model's predictions, which we call rate constraints. We study the problem of training non-convex models subject to these rate constraints (or any non-convex and non-differentiable constraints). In the non-convex setting, the standard approach of Lagrange multipliers may fail. Furthermore, if the constraints are non-differentiable, then one cannot optimize the Lagrangian with gradient-based methods. To solve these issues, we introduce the proxy-Lagrangian formulation. This new formulation leads to an algorithm that produces a stochastic classifier by playing a two-player non-zero-sum game solving for what we call a semi-coarse correlated equilibrium, which in turn corresponds to an approximately optimal and feasible solution to the constrained optimization problem. We then give a procedure which shrinks the randomized solution down to one that is a mixture of at most $m+1$ deterministic solutions, given $m$ constraints. This culminates in algorithms that can solve non-convex constrained optimization problems with possibly non-differentiable and non-convex constraints with theoretical guarantees. We provide extensive experimental results enforcing a wide range of policy goals including different fairness metrics, and other goals on accuracy, coverage, recall, and churn.

</details>

<details>

<summary>2018-09-12 02:43:19 - Safe Exploration in Markov Decision Processes with Time-Variant Safety using Spatio-Temporal Gaussian Process</summary>

- *Akifumi Wachi, Hiroshi Kajino, Asim Munawar*

- `1809.04232v1` - [abs](http://arxiv.org/abs/1809.04232v1) - [pdf](http://arxiv.org/pdf/1809.04232v1)

> In many real-world applications (e.g., planetary exploration, robot navigation), an autonomous agent must be able to explore a space with guaranteed safety. Most safe exploration algorithms in the field of reinforcement learning and robotics have been based on the assumption that the safety features are a priori known and time-invariant. This paper presents a learning algorithm called ST-SafeMDP for exploring Markov decision processes (MDPs) that is based on the assumption that the safety features are a priori unknown and time-variant. In this setting, the agent explores MDPs while constraining the probability of entering unsafe states defined by a safety function being below a threshold. The unknown and time-variant safety values are modeled using a spatio-temporal Gaussian process. However, there remains an issue that an agent may have no viable action in a shrinking true safe space. To address this issue, we formulate a problem maximizing the cumulative number of safe states in the worst case scenario with respect to future observations. The effectiveness of this approach was demonstrated in two simulation settings, including one using real lunar terrain data.

</details>

<details>

<summary>2018-09-12 07:09:08 - Safe Navigation with Human Instructions in Complex Scenes</summary>

- *Zhe Hu, Jia Pan, Tingxiang Fan, Ruigang Yang, Dinesh Manocha*

- `1809.04280v1` - [abs](http://arxiv.org/abs/1809.04280v1) - [pdf](http://arxiv.org/pdf/1809.04280v1)

> In this paper, we present a robotic navigation algorithm with natural language interfaces, which enables a robot to safely walk through a changing environment with moving persons by following human instructions such as "go to the restaurant and keep away from people". We first classify human instructions into three types: the goal, the constraints, and uninformative phrases. Next, we provide grounding for the extracted goal and constraint items in a dynamic manner along with the navigation process, to deal with the target objects that are too far away for sensor observation and the appearance of moving obstacles like humans. In particular, for a goal phrase (e.g., "go to the restaurant"), we ground it to a location in a predefined semantic map and treat it as a goal for a global motion planner, which plans a collision-free path in the workspace for the robot to follow. For a constraint phrase (e.g., "keep away from people"), we dynamically add the corresponding constraint into a local planner by adjusting the values of a local costmap according to the results returned by the object detection module. The updated costmap is then used to compute a local collision avoidance control for the safe navigation of the robot. By combining natural language processing, motion planning, and computer vision, our developed system is demonstrated to be able to successfully follow natural language navigation instructions to achieve navigation tasks in both simulated and real-world scenarios. Videos are available at https://sites.google.com/view/snhi

</details>

<details>

<summary>2018-09-12 07:30:52 - Predicting Hurricane Trajectories using a Recurrent Neural Network</summary>

- *Sheila Alemany, Jonathan Beltran, Adrian Perez, Sam Ganzfried*

- `1802.02548v3` - [abs](http://arxiv.org/abs/1802.02548v3) - [pdf](http://arxiv.org/pdf/1802.02548v3)

> Hurricanes are cyclones circulating about a defined center whose closed wind speeds exceed 75 mph originating over tropical and subtropical waters. At landfall, hurricanes can result in severe disasters. The accuracy of predicting their trajectory paths is critical to reduce economic loss and save human lives. Given the complexity and nonlinearity of weather data, a recurrent neural network (RNN) could be beneficial in modeling hurricane behavior. We propose the application of a fully connected RNN to predict the trajectory of hurricanes. We employed the RNN over a fine grid to reduce typical truncation errors. We utilized their latitude, longitude, wind speed, and pressure publicly provided by the National Hurricane Center (NHC) to predict the trajectory of a hurricane at 6-hour intervals. Results show that this proposed technique is competitive to methods currently employed by the NHC and can predict up to approximately 120 hours of hurricane path.

</details>

<details>

<summary>2018-09-12 07:43:23 - Deep Learning Based Multi-modal Addressee Recognition in Visual Scenes with Utterances</summary>

- *Thao Minh Le, Nobuyuki Shimizu, Takashi Miyazaki, Koichi Shinoda*

- `1809.04288v1` - [abs](http://arxiv.org/abs/1809.04288v1) - [pdf](http://arxiv.org/pdf/1809.04288v1)

> With the widespread use of intelligent systems, such as smart speakers, addressee recognition has become a concern in human-computer interaction, as more and more people expect such systems to understand complicated social scenes, including those outdoors, in cafeterias, and hospitals. Because previous studies typically focused only on pre-specified tasks with limited conversational situations such as controlling smart homes, we created a mock dataset called Addressee Recognition in Visual Scenes with Utterances (ARVSU) that contains a vast body of image variations in visual scenes with an annotated utterance and a corresponding addressee for each scenario. We also propose a multi-modal deep-learning-based model that takes different human cues, specifically eye gazes and transcripts of an utterance corpus, into account to predict the conversational addressee from a specific speaker's view in various real-life conversational scenarios. To the best of our knowledge, we are the first to introduce an end-to-end deep learning model that combines vision and transcripts of utterance for addressee recognition. As a result, our study suggests that future addressee recognition can reach the ability to understand human intention in many social situations previously unexplored, and our modality dataset is a first step in promoting research in this field.

</details>

<details>

<summary>2018-09-12 08:31:20 - Chinese Poetry Generation with a Working Memory Model</summary>

- *Xiaoyuan Yi, Maosong Sun, Ruoyu Li, Zonghan Yang*

- `1809.04306v1` - [abs](http://arxiv.org/abs/1809.04306v1) - [pdf](http://arxiv.org/pdf/1809.04306v1)

> As an exquisite and concise literary form, poetry is a gem of human culture. Automatic poetry generation is an essential step towards computer creativity. In recent years, several neural models have been designed for this task. However, among lines of a whole poem, the coherence in meaning and topics still remains a big challenge. In this paper, inspired by the theoretical concept in cognitive psychology, we propose a novel Working Memory model for poetry generation. Different from previous methods, our model explicitly maintains topics and informative limited history in a neural memory. During the generation process, our model reads the most relevant parts from memory slots to generate the current line. After each line is generated, it writes the most salient parts of the previous line into memory slots. By dynamic manipulation of the memory, our model keeps a coherent information flow and learns to express each topic flexibly and naturally. We experiment on three different genres of Chinese poetry: quatrain, iambic and chinoiserie lyric. Both automatic and human evaluation results show that our model outperforms current state-of-the-art methods.

</details>

<details>

<summary>2018-09-12 08:50:30 - Chinese Poetry Generation with a Salient-Clue Mechanism</summary>

- *Xiaoyuan Yi, Ruoyu Li, Maosong Sun*

- `1809.04313v1` - [abs](http://arxiv.org/abs/1809.04313v1) - [pdf](http://arxiv.org/pdf/1809.04313v1)

> As a precious part of the human cultural heritage, Chinese poetry has influenced people for generations. Automatic poetry composition is a challenge for AI. In recent years, significant progress has been made in this area benefiting from the development of neural networks. However, the coherence in meaning, theme or even artistic conception for a generated poem as a whole still remains a big problem. In this paper, we propose a novel Salient-Clue mechanism for Chinese poetry generation. Different from previous work which tried to exploit all the context information, our model selects the most salient characters automatically from each so-far generated line to gradually form a salient clue, which is utilized to guide successive poem generation process so as to eliminate interruptions and improve coherence. Besides, our model can be flexibly extended to control the generated poem in different aspects, for example, poetry style, which further enhances the coherence. Experimental results show that our model is very effective, outperforming three strong baselines.

</details>

<details>

<summary>2018-09-12 09:03:20 - Neural Melody Composition from Lyrics</summary>

- *Hangbo Bao, Shaohan Huang, Furu Wei, Lei Cui, Yu Wu, Chuanqi Tan, Songhao Piao, Ming Zhou*

- `1809.04318v1` - [abs](http://arxiv.org/abs/1809.04318v1) - [pdf](http://arxiv.org/pdf/1809.04318v1)

> In this paper, we study a novel task that learns to compose music from natural language. Given the lyrics as input, we propose a melody composition model that generates lyrics-conditional melody as well as the exact alignment between the generated melody and the given lyrics simultaneously. More specifically, we develop the melody composition model based on the sequence-to-sequence framework. It consists of two neural encoders to encode the current lyrics and the context melody respectively, and a hierarchical decoder to jointly produce musical notes and the corresponding alignment. Experimental results on lyrics-melody pairs of 18,451 pop songs demonstrate the effectiveness of our proposed methods. In addition, we apply a singing voice synthesizer software to synthesize the "singing" of the lyrics and melodies for human evaluation. Results indicate that our generated melodies are more melodious and tuneful compared with the baseline method.

</details>

<details>

<summary>2018-09-12 09:17:48 - Reinforcement Learning in Topology-based Representation for Human Body Movement with Whole Arm Manipulation</summary>

- *Weihao Yuan, Kaiyu Hang, Haoran Song, Danica Kragic, Michael Y. Wang, Johannes A. Stork*

- `1809.04322v1` - [abs](http://arxiv.org/abs/1809.04322v1) - [pdf](http://arxiv.org/pdf/1809.04322v1)

> Moving a human body or a large and bulky object can require the strength of whole arm manipulation (WAM). This type of manipulation places the load on the robot's arms and relies on global properties of the interaction to succeed---rather than local contacts such as grasping or non-prehensile pushing. In this paper, we learn to generate motions that enable WAM for holding and transporting of humans in certain rescue or patient care scenarios. We model the task as a reinforcement learning problem in order to provide a behavior that can directly respond to external perturbation and human motion. For this, we represent global properties of the robot-human interaction with topology-based coordinates that are computed from arm and torso positions. These coordinates also allow transferring the learned policy to other body shapes and sizes. For training and evaluation, we simulate a dynamic sea rescue scenario and show in quantitative experiments that the policy can solve unseen scenarios with differently-shaped humans, floating humans, or with perception noise. Our qualitative experiments show the subsequent transporting after holding is achieved and we demonstrate that the policy can be directly transferred to a real world setting.

</details>

<details>

<summary>2018-09-12 10:11:39 - The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA</summary>

- *Shailza Jolly, Sandro Pezzelle, Tassilo Klein, Andreas Dengel, Moin Nabi*

- `1809.04344v1` - [abs](http://arxiv.org/abs/1809.04344v1) - [pdf](http://arxiv.org/pdf/1809.04344v1)

> We introduce MASSES, a simple evaluation metric for the task of Visual Question Answering (VQA). In its standard form, the VQA task is operationalized as follows: Given an image and an open-ended question in natural language, systems are required to provide a suitable answer. Currently, model performance is evaluated by means of a somehow simplistic metric: If the predicted answer is chosen by at least 3 human annotators out of 10, then it is 100% correct. Though intuitively valuable, this metric has some important limitations. First, it ignores whether the predicted answer is the one selected by the Majority (MA) of annotators. Second, it does not account for the quantitative Subjectivity (S) of the answers in the sample (and dataset). Third, information about the Semantic Similarity (SES) of the responses is completely neglected. Based on such limitations, we propose a multi-component metric that accounts for all these issues. We show that our metric is effective in providing a more fine-grained evaluation both on the quantitative and qualitative level.

</details>

<details>

<summary>2018-09-12 11:16:31 - Training Deep Neural Networks with Different Datasets In-the-wild: The Emotion Recognition Paradigm</summary>

- *Dimitrios Kollias, Stefanos Zafeiriou*

- `1809.04359v1` - [abs](http://arxiv.org/abs/1809.04359v1) - [pdf](http://arxiv.org/pdf/1809.04359v1)

> A novel procedure is presented in this paper, for training a deep convolutional and recurrent neural network, taking into account both the available training data set and some information extracted from similar networks trained with other relevant data sets. This information is included in an extended loss function used for the network training, so that the network can have an improved performance when applied to the other data sets, without forgetting the learned knowledge from the original data set. Facial expression and emotion recognition in-the-wild is the test bed application that is used to demonstrate the improved performance achieved using the proposed approach. In this framework, we provide an experimental study on categorical emotion recognition using datasets from a very recent related emotion recognition challenge.

</details>

<details>

<summary>2018-09-12 12:34:30 - A Framework for Approval-based Budgeting Methods</summary>

- *Piotr Faliszewski, Nimrod Talmon*

- `1809.04382v1` - [abs](http://arxiv.org/abs/1809.04382v1) - [pdf](http://arxiv.org/pdf/1809.04382v1)

> We define and study a general framework for approval-based budgeting methods and compare certain methods within this framework by their axiomatic and computational properties. Furthermore, we visualize their behavior on certain Euclidean distributions and analyze them experimentally.

</details>

<details>

<summary>2018-09-12 13:12:07 - Artificial Intelligence for the Public Sector: Opportunities and challenges of cross-sector collaboration</summary>

- *Slava Jankin Mikhaylov, Marc Esteve, Averill Campion*

- `1809.04399v1` - [abs](http://arxiv.org/abs/1809.04399v1) - [pdf](http://arxiv.org/pdf/1809.04399v1)

> Public sector organisations are increasingly interested in using data science and artificial intelligence capabilities to deliver policy and generate efficiencies in high uncertainty environments. The long-term success of data science and AI in the public sector relies on effectively embedding it into delivery solutions for policy implementation. However, governments cannot do this integration of AI into public service delivery on their own. The UK Government Industrial Strategy is clear that delivering on the AI grand challenge requires collaboration between universities and public and private sectors. This cross-sectoral collaborative approach is the norm in applied AI centres of excellence around the world. Despite their popularity, cross-sector collaborations entail serious management challenges that hinder their success. In this article we discuss the opportunities and challenges from AI for public sector. Finally, we propose a series of strategies to successfully manage these cross-sectoral collaborations.

</details>

<details>

<summary>2018-09-12 16:50:39 - Coordinated Heterogeneous Distributed Perception based on Latent Space Representation</summary>

- *Timo Korthals, Jürgen Leitner, Ulrich Rückert*

- `1809.04558v1` - [abs](http://arxiv.org/abs/1809.04558v1) - [pdf](http://arxiv.org/pdf/1809.04558v1)

> We investigate a reinforcement approach for distributed sensing based on the latent space derived from multi-modal deep generative models. Our contribution provides insights to the following benefits: Detections can be exchanged effectively between robots equipped with uni-modal sensors due to a shared latent representation of information that is trained by a Variational Auto Encoder (VAE). Sensor-fusion can be applied asynchronously due to the generative feature of the VAE. Deep Q-Networks (DQNs) are trained to minimize uncertainty in latent space by coordinating robots to a Point-of-Interest (PoI) where their sensor modality can provide beneficial information about the PoI. Additionally, we show that the decrease in uncertainty can be defined as the direct reward signal for training the DQN.

</details>

<details>

<summary>2018-09-12 17:40:58 - Monocular Depth Estimation by Learning from Heterogeneous Datasets</summary>

- *Akhil Gurram, Onay Urfalioglu, Ibrahim Halfaoui, Fahd Bouzaraa, Antonio M. Lopez*

- `1803.08018v2` - [abs](http://arxiv.org/abs/1803.08018v2) - [pdf](http://arxiv.org/pdf/1803.08018v2)

> Depth estimation provides essential information to perform autonomous driving and driver assistance. Especially, Monocular Depth Estimation is interesting from a practical point of view, since using a single camera is cheaper than many other options and avoids the need for continuous calibration strategies as required by stereo-vision approaches. State-of-the-art methods for Monocular Depth Estimation are based on Convolutional Neural Networks (CNNs). A promising line of work consists of introducing additional semantic information about the traffic scene when training CNNs for depth estimation. In practice, this means that the depth data used for CNN training is complemented with images having pixel-wise semantic labels, which usually are difficult to annotate (e.g. crowded urban images). Moreover, so far it is common practice to assume that the same raw training data is associated with both types of ground truth, i.e., depth and semantic labels. The main contribution of this paper is to show that this hard constraint can be circumvented, i.e., that we can train CNNs for depth estimation by leveraging the depth and semantic information coming from heterogeneous datasets. In order to illustrate the benefits of our approach, we combine KITTI depth and Cityscapes semantic segmentation datasets, outperforming state-of-the-art results on Monocular Depth Estimation.

</details>

<details>

<summary>2018-09-12 17:50:07 - Closed-Book Training to Improve Summarization Encoder Memory</summary>

- *Yichen Jiang, Mohit Bansal*

- `1809.04585v1` - [abs](http://arxiv.org/abs/1809.04585v1) - [pdf](http://arxiv.org/pdf/1809.04585v1)

> A good neural sequence-to-sequence summarization model should have a strong encoder that can distill and memorize the important information from long input texts so that the decoder can generate salient summaries based on the encoder's memory. In this paper, we aim to improve the memorization capabilities of the encoder of a pointer-generator model by adding an additional 'closed-book' decoder without attention and pointer mechanisms. Such a decoder forces the encoder to be more selective in the information encoded in its memory state because the decoder can't rely on the extra information provided by the attention and possibly copy modules, and hence improves the entire model. On the CNN/Daily Mail dataset, our 2-decoder model outperforms the baseline significantly in terms of ROUGE and METEOR metrics, for both cross-entropy and reinforced setups (and on human evaluation). Moreover, our model also achieves higher scores in a test-only DUC-2002 generalizability setup. We further present a memory ability test, two saliency metrics, as well as several sanity-check ablations (based on fixed-encoder, gradient-flow cut, and model capacity) to prove that the encoder of our 2-decoder model does in fact learn stronger memory representations than the baseline encoder.

</details>

<details>

<summary>2018-09-12 21:01:55 - A Unified Batch Online Learning Framework for Click Prediction</summary>

- *Rishabh Iyer, Nimit Acharya, Tanuja Bompada, Denis Charles, Eren Manavoglu*

- `1809.04673v1` - [abs](http://arxiv.org/abs/1809.04673v1) - [pdf](http://arxiv.org/pdf/1809.04673v1)

> We present a unified framework for Batch Online Learning (OL) for Click Prediction in Search Advertisement. Machine Learning models once deployed, show non-trivial accuracy and calibration degradation over time due to model staleness. It is therefore necessary to regularly update models, and do so automatically. This paper presents two paradigms of Batch Online Learning, one which incrementally updates the model parameters via an early stopping mechanism, and another which does so through a proximal regularization. We argue how both these schemes naturally trade-off between old and new data. We then theoretically and empirically show that these two seemingly different schemes are closely related. Through extensive experiments, we demonstrate the utility of of our OL framework; how the two OL schemes relate to each other and how they trade-off between the new and historical data. We then compare batch OL to full model retrains, and show how online learning is more robust to data issues. We also demonstrate the long term impact of Online Learning, the role of the initial Models in OL, the impact of delays in the update, and finally conclude with some implementation details and challenges in deploying a real world online learning system in production. While this paper mostly focuses on application of click prediction for search advertisement, we hope that the lessons learned here can be carried over to other problem domains.

</details>

<details>

<summary>2018-09-12 21:29:20 - Fair lending needs explainable models for responsible recommendation</summary>

- *Jiahao Chen*

- `1809.04684v1` - [abs](http://arxiv.org/abs/1809.04684v1) - [pdf](http://arxiv.org/pdf/1809.04684v1)

> The financial services industry has unique explainability and fairness challenges arising from compliance and ethical considerations in credit decisioning. These challenges complicate the use of model machine learning and artificial intelligence methods in business decision processes.

</details>

<details>

<summary>2018-09-12 21:34:03 - Zero-Shot Cross-lingual Classification Using Multilingual Neural Machine Translation</summary>

- *Akiko Eriguchi, Melvin Johnson, Orhan Firat, Hideto Kazawa, Wolfgang Macherey*

- `1809.04686v1` - [abs](http://arxiv.org/abs/1809.04686v1) - [pdf](http://arxiv.org/pdf/1809.04686v1)

> Transferring representations from large supervised tasks to downstream tasks has shown promising results in AI fields such as Computer Vision and Natural Language Processing (NLP). In parallel, the recent progress in Machine Translation (MT) has enabled one to train multilingual Neural MT (NMT) systems that can translate between multiple languages and are also capable of performing zero-shot translation. However, little attention has been paid to leveraging representations learned by a multilingual NMT system to enable zero-shot multilinguality in other NLP tasks. In this paper, we demonstrate a simple framework, a multilingual Encoder-Classifier, for cross-lingual transfer learning by reusing the encoder from a multilingual NMT system and stitching it with a task-specific classifier component. Our proposed model achieves significant improvements in the English setup on three benchmark tasks - Amazon Reviews, SST and SNLI. Further, our system can perform classification in a new language for which no classification data was seen during training, showing that zero-shot classification is possible and remarkably competitive. In order to understand the underlying factors contributing to this finding, we conducted a series of analyses on the effect of the shared vocabulary, the training data type for NMT, classifier complexity, encoder representation power, and model generalization on zero-shot performance. Our results provide strong evidence that the representations learned from multilingual NMT systems are widely applicable across languages and tasks.

</details>

<details>

<summary>2018-09-12 21:34:59 - Logical Rule Induction and Theory Learning Using Neural Theorem Proving</summary>

- *Andres Campero, Aldo Pareja, Tim Klinger, Josh Tenenbaum, Sebastian Riedel*

- `1809.02193v3` - [abs](http://arxiv.org/abs/1809.02193v3) - [pdf](http://arxiv.org/pdf/1809.02193v3)

> A hallmark of human cognition is the ability to continually acquire and distill observations of the world into meaningful, predictive theories. In this paper we present a new mechanism for logical theory acquisition which takes a set of observed facts and learns to extract from them a set of logical rules and a small set of core facts which together entail the observations. Our approach is neuro-symbolic in the sense that the rule pred- icates and core facts are given dense vector representations. The rules are applied to the core facts using a soft unification procedure to infer additional facts. After k steps of forward inference, the consequences are compared to the initial observations and the rules and core facts are then encouraged towards representations that more faithfully generate the observations through inference. Our approach is based on a novel neural forward-chaining differentiable rule induction network. The rules are interpretable and learned compositionally from their predicates, which may be invented. We demonstrate the efficacy of our approach on a variety of ILP rule induction and domain theory learning datasets.

</details>

<details>

<summary>2018-09-12 23:26:16 - Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism</summary>

- *Hector Zenil, Narsis A. Kiani, Allan A. Zea, Jesper Tegnér*

- `1802.09904v8` - [abs](http://arxiv.org/abs/1802.09904v8) - [pdf](http://arxiv.org/pdf/1802.09904v8)

> Complex data usually results from the interaction of objects produced by different generating mechanisms. Here we introduce a universal, unsupervised and parameter-free model-oriented approach, based upon the seminal concept of algorithmic probability, that decomposes an observation into its most likely algorithmic generative sources. Our approach uses a causal calculus to infer model representations. We demonstrate its ability to deconvolve interacting mechanisms regardless of whether the resultant objects are strings, space-time evolution diagrams, images or networks. While this is mostly a conceptual contribution and a novel framework, we provide numerical evidence evaluating the ability of our methods to separate data from observations produced by discrete dynamical systems such as cellular automata and complex networks. We think that these separating techniques can contribute to tackling the challenge of causation, thus complementing other statistically oriented approaches.

</details>

<details>

<summary>2018-09-13 00:29:17 - Robust Text-to-SQL Generation with Execution-Guided Decoding</summary>

- *Chenglong Wang, Kedar Tatwawadi, Marc Brockschmidt, Po-Sen Huang, Yi Mao, Oleksandr Polozov, Rishabh Singh*

- `1807.03100v3` - [abs](http://arxiv.org/abs/1807.03100v3) - [pdf](http://arxiv.org/pdf/1807.03100v3)

> We consider the problem of neural semantic parsing, which translates natural language questions into executable SQL queries. We introduce a new mechanism, execution guidance, to leverage the semantics of SQL. It detects and excludes faulty programs during the decoding procedure by conditioning on the execution of partially generated program. The mechanism can be used with any autoregressive generative model, which we demonstrate on four state-of-the-art recurrent or template-based semantic parsing models. We demonstrate that execution guidance universally improves model performance on various text-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS, and GeoQuery. As a result, we achieve new state-of-the-art execution accuracy of 83.8% on WikiSQL.

</details>

<details>

<summary>2018-09-13 01:56:57 - Fairness-aware Classification: Criterion, Convexity, and Bounds</summary>

- *Yongkai Wu, Lu Zhang, Xintao Wu*

- `1809.04737v1` - [abs](http://arxiv.org/abs/1809.04737v1) - [pdf](http://arxiv.org/pdf/1809.04737v1)

> Fairness-aware classification is receiving increasing attention in the machine learning fields. Recently research proposes to formulate the fairness-aware classification as constrained optimization problems. However, several limitations exist in previous works due to the lack of a theoretical framework for guiding the formulation. In this paper, we propose a general framework for learning fair classifiers which addresses previous limitations. The framework formulates various commonly-used fairness metrics as convex constraints that can be directly incorporated into classic classification models. Within the framework, we propose a constraint-free criterion on the training data which ensures that any classifier learned from the data is fair. We also derive the constraints which ensure that the real fairness metric is satisfied when surrogate functions are used to achieve convexity. Our framework can be used to for formulating fairness-aware classification with fairness guarantee and computational efficiency. The experiments using real-world datasets demonstrate our theoretical results and show the effectiveness of proposed framework and methods.

</details>

<details>

<summary>2018-09-13 02:16:40 - Toward Controlled Generation of Text</summary>

- *Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P. Xing*

- `1703.00955v4` - [abs](http://arxiv.org/abs/1703.00955v4) - [pdf](http://arxiv.org/pdf/1703.00955v4)

> Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.

</details>

<details>

<summary>2018-09-13 03:03:58 - Your 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in Ratings</summary>

- *Jingyan Wang, Nihar B. Shah*

- `1806.05085v2` - [abs](http://arxiv.org/abs/1806.05085v2) - [pdf](http://arxiv.org/pdf/1806.05085v2)

> Cardinal scores (numeric ratings) collected from people are well known to suffer from miscalibrations. A popular approach to address this issue is to assume simplistic models of miscalibration (such as linear biases) to de-bias the scores. This approach, however, often fares poorly because people's miscalibrations are typically far more complex and not well understood. In the absence of simplifying assumptions on the miscalibration, it is widely believed by the crowdsourcing community that the only useful information in the cardinal scores is the induced ranking. In this paper, inspired by the framework of Stein's shrinkage, empirical Bayes, and the classic two-envelope problem, we contest this widespread belief. Specifically, we consider cardinal scores with arbitrary (or even adversarially chosen) miscalibrations which are only required to be consistent with the induced ranking. We design estimators which despite making no assumptions on the miscalibration, strictly and uniformly outperform all possible estimators that rely on only the ranking. Our estimators are flexible in that they can be used as a plug-in for a variety of applications, and we provide a proof-of-concept for A/B testing and ranking. Our results thus provide novel insights in the eternal debate between cardinal and ordinal data.

</details>

<details>

<summary>2018-09-13 04:48:51 - Towards Coinductive Theory Exploration in Horn Clause Logic: Position Paper</summary>

- *Ekaterina Komendantskaya Dr, Yue Li*

- `1809.04771v1` - [abs](http://arxiv.org/abs/1809.04771v1) - [pdf](http://arxiv.org/pdf/1809.04771v1)

> Coinduction occurs in two guises in Horn clause logic: in proofs of self-referencing properties and relations, and in proofs involving construction of (possibly irregular) infinite data. Both instances of coinductive reasoning appeared in the literature before, but a systematic analysis of these two kinds of proofs and of their relation was lacking. We propose a general proof-theoretic framework for handling both kinds of coinduction arising in Horn clause logic. To this aim, we propose a coinductive extension of Miller et al's framework of uniform proofs and prove its soundness relative to coinductive models of Horn clause logic.

</details>

<details>

<summary>2018-09-13 06:46:34 - Focus Group on Artificial Intelligence for Health</summary>

- *Marcel Salathé, Thomas Wiegand, Markus Wenzel*

- `1809.04797v1` - [abs](http://arxiv.org/abs/1809.04797v1) - [pdf](http://arxiv.org/pdf/1809.04797v1)

> Artificial Intelligence (AI) - the phenomenon of machines being able to solve problems that require human intelligence - has in the past decade seen an enormous rise of interest due to significant advances in effectiveness and use. The health sector, one of the most important sectors for societies and economies worldwide, is particularly interesting for AI applications, given the ongoing digitalisation of all types of health information. The potential for AI assistance in the health domain is immense, because AI can support medical decision making at reduced costs, everywhere. However, due to the complexity of AI algorithms, it is difficult to distinguish good from bad AI-based solutions and to understand their strengths and weaknesses, which is crucial for clarifying responsibilities and for building trust. For this reason, the International Telecommunication Union (ITU) has established a new Focus Group on "Artificial Intelligence for Health" (FG-AI4H) in partnership with the World Health Organization (WHO). Health and care services are usually the responsibility of a government - even when provided through private insurance systems - and thus under the responsibility of WHO/ITU member states. FG-AI4H will identify opportunities for international standardization, which will foster the application of AI to health issues on a global scale. In particular, it will establish a standardized assessment framework with open benchmarks for the evaluation of AI-based methods for health, such as AI-based diagnosis, triage or treatment decisions.

</details>

<details>

<summary>2018-09-13 08:56:25 - Investigation of Multimodal Features, Classifiers and Fusion Methods for Emotion Recognition</summary>

- *Zheng Lian, Ya Li, Jianhua Tao, Jian Huang*

- `1809.06225v1` - [abs](http://arxiv.org/abs/1809.06225v1) - [pdf](http://arxiv.org/pdf/1809.06225v1)

> Automatic emotion recognition is a challenging task. In this paper, we present our effort for the audio-video based sub-challenge of the Emotion Recognition in the Wild (EmotiW) 2018 challenge, which requires participants to assign a single emotion label to the video clip from the six universal emotions (Anger, Disgust, Fear, Happiness, Sad and Surprise) and Neutral. The proposed multimodal emotion recognition system takes audio, video and text information into account. Except for handcraft features, we also extract bottleneck features from deep neutral networks (DNNs) via transfer learning. Both temporal classifiers and non-temporal classifiers are evaluated to obtain the best unimodal emotion classification result. Then possibilities are extracted and passed into the Beam Search Fusion (BS-Fusion). We test our method in the EmotiW 2018 challenge and we gain promising results. Compared with the baseline system, there is a significant improvement. We achieve 60.34% accuracy on the testing dataset, which is only 1.5% lower than the winner. It shows that our method is very competitive.

</details>

<details>

<summary>2018-09-13 09:29:55 - Three Factors Influencing Minima in SGD</summary>

- *Stanisław Jastrzębski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, Amos Storkey*

- `1711.04623v3` - [abs](http://arxiv.org/abs/1711.04623v3) - [pdf](http://arxiv.org/pdf/1711.04623v3)

> We investigate the dynamical and convergent properties of stochastic gradient descent (SGD) applied to Deep Neural Networks (DNNs). Characterizing the relation between learning rate, batch size and the properties of the final minima, such as width or generalization, remains an open question. In order to tackle this problem we investigate the previously proposed approximation of SGD by a stochastic differential equation (SDE). We theoretically argue that three factors - learning rate, batch size and gradient covariance - influence the minima found by SGD. In particular we find that the ratio of learning rate to batch size is a key determinant of SGD dynamics and of the width of the final minima, and that higher values of the ratio lead to wider minima and often better generalization. We confirm these findings experimentally. Further, we include experiments which show that learning rate schedules can be replaced with batch size schedules and that the ratio of learning rate to batch size is an important factor influencing the memorization process.

</details>

<details>

<summary>2018-09-13 12:44:48 - Coordination-driven learning in multi-agent problem spaces</summary>

- *Sean L. Barton, Nicholas R. Waytowich, Derrik E. Asher*

- `1809.04918v1` - [abs](http://arxiv.org/abs/1809.04918v1) - [pdf](http://arxiv.org/pdf/1809.04918v1)

> We discuss the role of coordination as a direct learning objective in multi-agent reinforcement learning (MARL) domains. To this end, we present a novel means of quantifying coordination in multi-agent systems, and discuss the implications of using such a measure to optimize coordinated agent policies. This concept has important implications for adversary-aware RL, which we take to be a sub-domain of multi-agent learning.

</details>

<details>

<summary>2018-09-13 13:53:01 - Real-Time Lightweight Chaotic Encryption for 5G IoT Enabled Lip-Reading Driven Secure Hearing-Aid</summary>

- *Ahsan Adeel, Jawad Ahmad, Amir Hussain*

- `1809.04966v1` - [abs](http://arxiv.org/abs/1809.04966v1) - [pdf](http://arxiv.org/pdf/1809.04966v1)

> Existing audio-only hearing-aids are known to perform poorly in noisy situations where overwhelming noise is present. Next-generation audio-visual (lip-reading driven) hearing-aids stand as a major enabler to realise more intelligible audio. However, high data rate, low latency, low computational complexity, and privacy are some of the major bottlenecks to the successful deployment of such advanced hearing aids. To address these challenges, we envision an integration of 5G Cloud-Radio Access Network, Internet of Things (IoT), and strong privacy algorithms to fully benefit from the possibilities these technologies have to offer. The envisioned 5G IoT enabled secure audio-visual (AV) hearing-aid transmits the encrypted compressed AV information and receives encrypted enhanced reconstructed speech in real-time which fully addresses cybersecurity attacks such as location privacy and eavesdropping. For security implementation, a real-time lightweight AV encryption is utilized. For speech enhancement, the received AV information in the cloud is used to filter noisy audio using both deep learning and analytical acoustic modelling (filtering based approach). To offload the computational complexity and real-time optimization issues, the framework runs deep learning and big data optimization processes in the background on the cloud. Specifically, in this work, three key contributions are reported: (1) 5G IoT enabled secure audio-visual hearing-aid framework that aims to achieve a round-trip latency up to 5ms with 100 Mbps datarate (2) Real-time lightweight audio-visual encryption (3) Lip-reading driven deep learning approach for speech enhancement in the cloud. The critical analysis in terms of both speech enhancement and AV encryption demonstrate the potential of the envisioned technology in acquiring high-quality speech reconstruction and secure mobile AV hearing aid communication.

</details>

<details>

<summary>2018-09-13 13:54:50 - Analytical Formulations for the Level Based Weighted Average Value of Discrete Trapezoidal Fuzzy Numbers</summary>

- *Resmiye Nasiboglu, Rahila Abdullayeva*

- `1810.05110v1` - [abs](http://arxiv.org/abs/1810.05110v1) - [pdf](http://arxiv.org/pdf/1810.05110v1)

> In fuzzy decision-making processes based on linguistic information, operations on discrete fuzzy numbers are commonly performed. Aggregation and defuzzification operations are some of these often used operations. Many aggregation and defuzzification operators produce results independent to the decision makers strategy. On the other hand, the Weighted Average Based on Levels (WABL) approach can take into account the level weights and the decision makers optimism strategy. This gives flexibility to the WABL operator and, through machine learning, can be trained in the direction of the decision makers strategy, producing more satisfactory results for the decision maker. However, in order to determine the WABL value, it is necessary to calculate some integrals. In this study, the concept of WABL for discrete trapezoidal fuzzy numbers is investigated, and analytical formulas have been proven to facilitate the calculation of WABL value for these fuzzy numbers. Trapezoidal and their special form, triangular fuzzy numbers, are the most commonly used fuzzy number types in fuzzy modeling, so in this study, such numbers have been studied. Computational examples explaining the theoretical results have been performed.

</details>

<details>

<summary>2018-09-13 14:22:58 - Part-based Graph Convolutional Network for Action Recognition</summary>

- *Kalpit Thakkar, P J Narayanan*

- `1809.04983v1` - [abs](http://arxiv.org/abs/1809.04983v1) - [pdf](http://arxiv.org/pdf/1809.04983v1)

> Human actions comprise of joint motion of articulated body parts or `gestures'. Human skeleton is intuitively represented as a sparse graph with joints as nodes and natural connections between them as edges. Graph convolutional networks have been used to recognize actions from skeletal videos. We introduce a part-based graph convolutional network (PB-GCN) for this task, inspired by Deformable Part-based Models (DPMs). We divide the skeleton graph into four subgraphs with joints shared across them and learn a recognition model using a part-based graph convolutional network. We show that such a model improves performance of recognition, compared to a model using entire skeleton graph. Instead of using 3D joint coordinates as node features, we show that using relative coordinates and temporal displacements boosts performance. Our model achieves state-of-the-art performance on two challenging benchmark datasets NTURGB+D and HDM05, for skeletal action recognition.

</details>

<details>

<summary>2018-09-13 14:27:25 - Sequential Coordination of Deep Models for Learning Visual Arithmetic</summary>

- *Eric Crawford, Guillaume Rabusseau, Joelle Pineau*

- `1809.04988v1` - [abs](http://arxiv.org/abs/1809.04988v1) - [pdf](http://arxiv.org/pdf/1809.04988v1)

> Achieving machine intelligence requires a smooth integration of perception and reasoning, yet models developed to date tend to specialize in one or the other; sophisticated manipulation of symbols acquired from rich perceptual spaces has so far proved elusive. Consider a visual arithmetic task, where the goal is to carry out simple arithmetical algorithms on digits presented under natural conditions (e.g. hand-written, placed randomly). We propose a two-tiered architecture for tackling this problem. The lower tier consists of a heterogeneous collection of information processing modules, which can include pre-trained deep neural networks for locating and extracting characters from the image, as well as modules performing symbolic transformations on the representations extracted by perception. The higher tier consists of a controller, trained using reinforcement learning, which coordinates the modules in order to solve the high-level task. For instance, the controller may learn in what contexts to execute the perceptual networks and what symbolic transformations to apply to their outputs. The resulting model is able to solve a variety of tasks in the visual arithmetic domain, and has several advantages over standard, architecturally homogeneous feedforward networks including improved sample efficiency.

</details>

<details>

<summary>2018-09-13 16:39:53 - XNLI: Evaluating Cross-lingual Sentence Representations</summary>

- *Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R. Bowman, Holger Schwenk, Veselin Stoyanov*

- `1809.05053v1` - [abs](http://arxiv.org/abs/1809.05053v1) - [pdf](http://arxiv.org/pdf/1809.05053v1)

> State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.

</details>

<details>

<summary>2018-09-13 17:23:13 - Learning Shape Priors for Single-View 3D Completion and Reconstruction</summary>

- *Jiajun Wu, Chengkai Zhang, Xiuming Zhang, Zhoutong Zhang, William T. Freeman, Joshua B. Tenenbaum*

- `1809.05068v1` - [abs](http://arxiv.org/abs/1809.05068v1) - [pdf](http://arxiv.org/pdf/1809.05068v1)

> The problem of single-view 3D shape completion or reconstruction is challenging, because among the many possible shapes that explain an observation, most are implausible and do not correspond to natural objects. Recent research in the field has tackled this problem by exploiting the expressiveness of deep convolutional networks. In fact, there is another level of ambiguity that is often overlooked: among plausible shapes, there are still multiple shapes that fit the 2D image equally well; i.e., the ground truth shape is non-deterministic given a single-view input. Existing fully supervised approaches fail to address this issue, and often produce blurry mean shapes with smooth surfaces but no fine details.   In this paper, we propose ShapeHD, pushing the limit of single-view shape completion and reconstruction by integrating deep generative models with adversarially learned shape priors. The learned priors serve as a regularizer, penalizing the model only if its output is unrealistic, not if it deviates from the ground truth. Our design thus overcomes both levels of ambiguity aforementioned. Experiments demonstrate that ShapeHD outperforms state of the art by a large margin in both shape completion and shape reconstruction on multiple real datasets.

</details>

<details>

<summary>2018-09-13 17:23:20 - Physical Primitive Decomposition</summary>

- *Zhijian Liu, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu*

- `1809.05070v1` - [abs](http://arxiv.org/abs/1809.05070v1) - [pdf](http://arxiv.org/pdf/1809.05070v1)

> Objects are made of parts, each with distinct geometry, physics, functionality, and affordances. Developing such a distributed, physical, interpretable representation of objects will facilitate intelligent agents to better explore and interact with the world. In this paper, we study physical primitive decomposition---understanding an object through its components, each with physical and geometric attributes. As annotated data for object parts and physics are rare, we propose a novel formulation that learns physical primitives by explaining both an object's appearance and its behaviors in physical events. Our model performs well on block towers and tools in both synthetic and real scenarios; we also demonstrate that visual and physical observations often provide complementary signals. We further present ablation and behavioral studies to better understand our model and contrast it with human performance.

</details>

<details>

<summary>2018-09-13 18:22:04 - IL-Net: Using Expert Knowledge to Guide the Design of Furcated Neural Networks</summary>

- *Khushmeen Sakloth, Wesley Beckner, Jim Pfaendtner, Garrett B. Goh*

- `1809.05127v1` - [abs](http://arxiv.org/abs/1809.05127v1) - [pdf](http://arxiv.org/pdf/1809.05127v1)

> Deep neural networks (DNN) excel at extracting patterns. Through representation learning and automated feature engineering on large datasets, such models have been highly successful in computer vision and natural language applications. Designing optimal network architectures from a principled or rational approach however has been less than successful, with the best successful approaches utilizing an additional machine learning algorithm to tune the network hyperparameters. However, in many technical fields, there exist established domain knowledge and understanding about the subject matter. In this work, we develop a novel furcated neural network architecture that utilizes domain knowledge as high-level design principles of the network. We demonstrate proof-of-concept by developing IL-Net, a furcated network for predicting the properties of ionic liquids, which is a class of complex multi-chemicals entities. Compared to existing state-of-the-art approaches, we show that furcated networks can improve model accuracy by approximately 20-35%, without using additional labeled data. Lastly, we distill two key design principles for furcated networks that can be adapted to other domains.

</details>

<details>

<summary>2018-09-13 18:27:08 - Multimodal Deep Neural Networks using Both Engineered and Learned Representations for Biodegradability Prediction</summary>

- *Garrett B. Goh, Khushmeen Sakloth, Charles Siegel, Abhinav Vishnu, Jim Pfaendtner*

- `1808.04456v2` - [abs](http://arxiv.org/abs/1808.04456v2) - [pdf](http://arxiv.org/pdf/1808.04456v2)

> Deep learning algorithms excel at extracting patterns from raw data, and with large datasets, they have been very successful in computer vision and natural language applications. However, in other domains, large datasets on which to learn representations from may not exist. In this work, we develop a novel multimodal CNN-MLP neural network architecture that utilizes both domain-specific feature engineering as well as learned representations from raw data. We illustrate the effectiveness of such network designs in the chemical sciences, for predicting biodegradability. DeepBioD, a multimodal CNN-MLP network is more accurate than either standalone network designs, and achieves an error classification rate of 0.125 that is 27% lower than the current state-of-the-art. Thus, our work indicates that combining traditional feature engineering with representation learning can be effective, particularly in situations where labeled data is limited.

</details>

<details>

<summary>2018-09-13 19:41:22 - Clustering with Deep Learning: Taxonomy and New Methods</summary>

- *Elie Aljalbout, Vladimir Golkov, Yawar Siddiqui, Maximilian Strobel, Daniel Cremers*

- `1801.07648v2` - [abs](http://arxiv.org/abs/1801.07648v2) - [pdf](http://arxiv.org/pdf/1801.07648v2)

> Clustering methods based on deep neural networks have proven promising for clustering real-world data because of their high representational power. In this paper, we propose a systematic taxonomy of clustering methods that utilize deep neural networks. We base our taxonomy on a comprehensive review of recent work and validate the taxonomy in a case study. In this case study, we show that the taxonomy enables researchers and practitioners to systematically create new clustering methods by selectively recombining and replacing distinct aspects of previous methods with the goal of overcoming their individual limitations. The experimental evaluation confirms this and shows that the method created for the case study achieves state-of-the-art clustering quality and surpasses it in some cases.

</details>

<details>

<summary>2018-09-13 22:08:17 - Learning Time-Sensitive Strategies in Space Fortress</summary>

- *Akshat Agarwal, Ryan Hope, Katia Sycara*

- `1805.06824v4` - [abs](http://arxiv.org/abs/1805.06824v4) - [pdf](http://arxiv.org/pdf/1805.06824v4)

> Although there has been remarkable progress and impressive performance on reinforcement learning (RL) on Atari games, there are many problems with challenging characteristics that have not yet been explored in Deep Learning for RL. These include reward sparsity, abrupt context-dependent reversals of strategy and time-sensitive game play. In this paper, we present Space Fortress, a game that incorporates all these characteristics and experimentally show that the presence of any of these renders state of the art Deep RL algorithms incapable of learning. Then, we present our enhancements to an existing algorithm and show big performance increases through each enhancement through an ablation study. We discuss how each of these enhancements was able to help and also argue that appropriate transfer learning boosts performance.

</details>

<details>

<summary>2018-09-14 01:15:28 - Model-Based Reinforcement Learning via Meta-Policy Optimization</summary>

- *Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim Asfour, Pieter Abbeel*

- `1809.05214v1` - [abs](http://arxiv.org/abs/1809.05214v1) - [pdf](http://arxiv.org/pdf/1809.05214v1)

> Model-based reinforcement learning approaches carry the promise of being data efficient. However, due to challenges in learning dynamics models that sufficiently match the real-world dynamics, they struggle to achieve the same asymptotic performance as model-free methods. We propose Model-Based Meta-Policy-Optimization (MB-MPO), an approach that foregoes the strong reliance on accurate learned dynamics models. Using an ensemble of learned dynamic models, MB-MPO meta-learns a policy that can quickly adapt to any model in the ensemble with one policy gradient step. This steers the meta-policy towards internalizing consistent dynamics predictions among the ensemble while shifting the burden of behaving optimally w.r.t. the model discrepancies towards the adaptation step. Our experiments show that MB-MPO is more robust to model imperfections than previous model-based approaches. Finally, we demonstrate that our approach is able to match the asymptotic performance of model-free methods while requiring significantly less experience.

</details>

<details>

<summary>2018-09-14 02:01:22 - SafeCity: Understanding Diverse Forms of Sexual Harassment Personal Stories</summary>

- *Sweta Karlekar, Mohit Bansal*

- `1809.04739v2` - [abs](http://arxiv.org/abs/1809.04739v2) - [pdf](http://arxiv.org/pdf/1809.04739v2)

> With the recent rise of #MeToo, an increasing number of personal stories about sexual harassment and sexual abuse have been shared online. In order to push forward the fight against such harassment and abuse, we present the task of automatically categorizing and analyzing various forms of sexual harassment, based on stories shared on the online forum SafeCity. For the labels of groping, ogling, and commenting, our single-label CNN-RNN model achieves an accuracy of 86.5%, and our multi-label model achieves a Hamming score of 82.5%. Furthermore, we present analysis using LIME, first-derivative saliency heatmaps, activation clustering, and embedding visualization to interpret neural model predictions and demonstrate how this extracts features that can help automatically fill out incident reports, identify unsafe areas, avoid unsafe practices, and 'pin the creeps'.

</details>

<details>

<summary>2018-09-14 02:31:25 - Leveraging Intra-User and Inter-User Representation Learning for Automated Hate Speech Detection</summary>

- *Jing Qian, Mai ElSherief, Elizabeth M. Belding, William Yang Wang*

- `1804.03124v2` - [abs](http://arxiv.org/abs/1804.03124v2) - [pdf](http://arxiv.org/pdf/1804.03124v2)

> Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP). Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the accuracy is still poor. The central problem is that social media posts are short and noisy, and most existing hate speech detection solutions take each post as an isolated input instance, which is likely to yield high false positive and negative rates. In this paper, we radically improve automated hate speech detection by presenting a novel model that leverages intra-user and inter-user representation learning for robust hate speech detection on Twitter. In addition to the target Tweet, we collect and analyze the user's historical posts to model intra-user Tweet representations. To suppress the noise in a single Tweet, we also model the similar Tweets posted by all other users with reinforced inter-user representation learning techniques. Experimentally, we show that leveraging these two representations can significantly improve the f-score of a strong bidirectional LSTM baseline model by 10.1%.

</details>

<details>

<summary>2018-09-14 03:07:40 - Follow Me at the Edge: Mobility-Aware Dynamic Service Placement for Mobile Edge Computing</summary>

- *Tao Ouyang, Zhi Zhou, Xu Chen*

- `1809.05239v1` - [abs](http://arxiv.org/abs/1809.05239v1) - [pdf](http://arxiv.org/pdf/1809.05239v1)

> Mobile edge computing is a new computing paradigm, which pushes cloud computing capabilities away from the centralized cloud to the network edge. However, with the sinking of computing capabilities, the new challenge incurred by user mobility arises: since end-users typically move erratically, the services should be dynamically migrated among multiple edges to maintain the service performance, i.e., user-perceived latency. Tackling this problem is non-trivial since frequent service migration would greatly increase the operational cost. To address this challenge in terms of the performance-cost trade-off, in this paper we study the mobile edge service performance optimization problem under long-term cost budget constraint. To address user mobility which is typically unpredictable, we apply Lyapunov optimization to decompose the long-term optimization problem into a series of real-time optimization problems which do not require a priori knowledge such as user mobility. As the decomposed problem is NP-hard, we first design an approximation algorithm based on Markov approximation to seek a near-optimal solution. To make our solution scalable and amenable to future 5G application scenario with large-scale user devices, we further propose a distributed approximation scheme with greatly reduced time complexity, based on the technique of best response update. Rigorous theoretical analysis and extensive evaluations demonstrate the efficacy of the proposed centralized and distributed schemes.

</details>

<details>

<summary>2018-09-14 06:51:01 - Learning to Fingerprint the Latent Structure in Question Articulation</summary>

- *Kumar Mrityunjay, Guntur Ravindra*

- `1809.05275v1` - [abs](http://arxiv.org/abs/1809.05275v1) - [pdf](http://arxiv.org/pdf/1809.05275v1)

> Abstract Machine understanding of questions is tightly related to recognition of articulation in the context of the computational capabilities of an underlying processing algorithm. In this paper a mathematical model to capture and distinguish the latent structure in the articulation of questions is presented. We propose an objective-driven approach to represent this latent structure and show that such an approach is beneficial when examples of complementary objectives are not available. We show that the latent structure can be represented as a system that maximizes a cost function related to the underlying objective. Further, we show that the optimization formulation can be approximated to building a memory of patterns represented as a trained neural auto-encoder. Experimental evaluation using many clusters of questions, each related to an objective, shows 80% recognition accuracy and negligible false positive across these clusters of questions. We then extend the same memory to a related task where the goal is to iteratively refine a dataset of questions based on the latent articulation. We also demonstrate a refinement scheme called K-fingerprints, that achieves nearly 100% recognition with negligible false positive across the different clusters of questions.

</details>

<details>

<summary>2018-09-14 08:58:49 - On Plans With Loops and Noise</summary>

- *Vaishak Belle*

- `1809.05309v1` - [abs](http://arxiv.org/abs/1809.05309v1) - [pdf](http://arxiv.org/pdf/1809.05309v1)

> In an influential paper, Levesque proposed a formal specification for analysing the correctness of program-like plans, such as conditional plans, iterative plans, and knowledge-based plans. He motivated a logical characterisation within the situation calculus that included binary sensing actions. While the characterisation does not immediately yield a practical algorithm, the specification serves as a general skeleton to explore the synthesis of program-like plans for reasonable, tractable fragments.   Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications. This raises the question as to what the specification for correctness should look like, since Levesque's account makes the assumption that sensing is exact and actions are deterministic. Building on a situation calculus theory for reasoning about degrees of belief and noise, we revisit the execution semantics of generalised plans. The specification is then used to analyse the correctness of example plans.

</details>

<details>

<summary>2018-09-14 09:09:04 - Reasoning about Discrete and Continuous Noisy Sensors and Effectors in Dynamical Systems</summary>

- *Vaishak Belle, Hector J. Levesque*

- `1809.05314v1` - [abs](http://arxiv.org/abs/1809.05314v1) - [pdf](http://arxiv.org/pdf/1809.05314v1)

> Among the many approaches for reasoning about degrees of belief in the presence of noisy sensing and acting, the logical account proposed by Bacchus, Halpern, and Levesque is perhaps the most expressive. While their formalism is quite general, it is restricted to fluents whose values are drawn from discrete finite domains, as opposed to the continuous domains seen in many robotic applications. In this work, we show how this limitation in that approach can be lifted. By dealing seamlessly with both discrete distributions and continuous densities within a rich theory of action, we provide a very general logical specification of how belief should change after acting and sensing in complex noisy domains.

</details>

<details>

<summary>2018-09-14 15:33:06 - Discovering Reliable Dependencies from Data: Hardness and Improved Algorithms</summary>

- *Panagiotis Mandros, Mario Boley, Jilles Vreeken*

- `1809.05467v1` - [abs](http://arxiv.org/abs/1809.05467v1) - [pdf](http://arxiv.org/pdf/1809.05467v1)

> The reliable fraction of information is an attractive score for quantifying (functional) dependencies in high-dimensional data. In this paper, we systematically explore the algorithmic implications of using this measure for optimization. We show that the problem is NP-hard, which justifies the usage of worst-case exponential-time as well as heuristic search methods. We then substantially improve the practical performance for both optimization styles by deriving a novel admissible bounding function that has an unbounded potential for additional pruning over the previously proposed one. Finally, we empirically investigate the approximation ratio of the greedy algorithm and show that it produces highly competitive results in a fraction of time needed for complete branch-and-bound style search.

</details>

<details>

<summary>2018-09-14 16:09:50 - Blameworthiness in Strategic Games</summary>

- *Pavel Naumov, Jia Tao*

- `1809.05485v1` - [abs](http://arxiv.org/abs/1809.05485v1) - [pdf](http://arxiv.org/pdf/1809.05485v1)

> There are multiple notions of coalitional responsibility. The focus of this paper is on the blameworthiness defined through the principle of alternative possibilities: a coalition is blamable for a statement if the statement is true, but the coalition had a strategy to prevent it. The main technical result is a sound and complete bimodal logical system that describes properties of blameworthiness in one-shot games.

</details>

<details>

<summary>2018-09-14 16:34:35 - Towards Blended Reactive Planning and Acting using Behavior Trees</summary>

- *Michele Colledanchise, Diogo Almeida, Petter Ögren*

- `1611.00230v2` - [abs](http://arxiv.org/abs/1611.00230v2) - [pdf](http://arxiv.org/pdf/1611.00230v2)

> In this paper, we show how a planning algorithm can be used to automatically create and update a Behavior Tree (BT), controlling a robot in a dynamic environment. The planning part of the algorithm is based on the idea of back chaining. Starting from a goal condition we iteratively select actions to achieve that goal, and if those actions have unmet preconditions, they are extended with actions to achieve them in the same way. The fact that BTs are inherently modular and reactive makes the proposed solution blend acting and planning in a way that enables the robot to efficiently react to external disturbances. If an external agent undoes an action the robot reexecutes it without re-planning, and if an external agent helps the robot, it skips the corresponding actions, again without replanning. We illustrate our approach in two different robotics scenarios.

</details>

<details>

<summary>2018-09-14 17:53:53 - Extending Neural Generative Conversational Model using External Knowledge Sources</summary>

- *Prasanna Parthasarathi, Joelle Pineau*

- `1809.05524v1` - [abs](http://arxiv.org/abs/1809.05524v1) - [pdf](http://arxiv.org/pdf/1809.05524v1)

> The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.

</details>

<details>

<summary>2018-09-14 17:59:34 - Semantic Analysis of (Reflectional) Visual Symmetry: A Human-Centred Computational Model for Declarative Explainability</summary>

- *Jakob Suchan, Mehul Bhatt, Srikrishna Vardarajan, Seyed Ali Amirshahi, Stella Yu*

- `1806.07376v2` - [abs](http://arxiv.org/abs/1806.07376v2) - [pdf](http://arxiv.org/pdf/1806.07376v2)

> We present a computational model for the semantic interpretation of symmetry in naturalistic scenes. Key features include a human-centred representation, and a declarative, explainable interpretation model supporting deep semantic question-answering founded on an integration of methods in knowledge representation and deep learning based computer vision. In the backdrop of the visual arts, we showcase the framework's capability to generate human-centred, queryable, relational structures, also evaluating the framework with an empirical study on the human perception of visual symmetry. Our framework represents and is driven by the application of foundational, integrated Vision and Knowledge Representation and Reasoning methods for applications in the arts, and the psychological and social sciences.

</details>

<details>

<summary>2018-09-14 22:34:40 - Semantic DMN: Formalizing and Reasoning About Decisions in the Presence of Background Knowledge</summary>

- *Diego Calvanese, Marlon Dumas, Fabrizio Maria Maggi, Marco Montali*

- `1807.11615v3` - [abs](http://arxiv.org/abs/1807.11615v3) - [pdf](http://arxiv.org/pdf/1807.11615v3)

> The Decision Model and Notation (DMN) is a recent OMG standard for the elicitation and representation of decision models, and for managing their interconnection with business processes. DMN builds on the notion of decision tables, and their combination into more complex decision requirements graphs (DRGs), which bridge between business process models and decision logic models. DRGs may rely on additional, external business knowledge models, whose functioning is not part of the standard. In this work, we consider one of the most important types of business knowledge, namely background knowledge that conceptually accounts for the structural aspects of the domain of interest, and propose decision knowledge bases (DKBs), which semantically combine DRGs modeled in DMN, and domain knowledge captured by means of first-order logic with datatypes. We provide a logic-based semantics for such an integration, and formalize different DMN reasoning tasks for DKBs. We then consider background knowledge formulated as a description logic ontology with datatypes, and show how the main verification tasks for DMN in this enriched setting can be formalized as standard DL reasoning services, and actually carried out in ExpTime. We discuss the effectiveness of our framework on a case study in maritime security.

</details>

<details>

<summary>2018-09-14 23:47:59 - Microsoft Dialogue Challenge: Building End-to-End Task-Completion Dialogue Systems</summary>

- *Xiujun Li, Yu Wang, Siqi Sun, Sarah Panda, Jingjing Liu, Jianfeng Gao*

- `1807.11125v2` - [abs](http://arxiv.org/abs/1807.11125v2) - [pdf](http://arxiv.org/pdf/1807.11125v2)

> This proposal introduces a Dialogue Challenge for building end-to-end task-completion dialogue systems, with the goal of encouraging the dialogue research community to collaborate and benchmark on standard datasets and unified experimental environment. In this special session, we will release human-annotated conversational data in three domains (movie-ticket booking, restaurant reservation, and taxi booking), as well as an experiment platform with built-in simulators in each domain, for training and evaluation purposes. The final submitted systems will be evaluated both in simulated setting and by human judges.

</details>

<details>

<summary>2018-09-15 01:20:06 - DLO: Direct LiDAR Odometry for 2.5D Outdoor Environment</summary>

- *Lu Sun, Junqiao Zhao, Xudong He, Chen Ye*

- `1809.10199v1` - [abs](http://arxiv.org/abs/1809.10199v1) - [pdf](http://arxiv.org/pdf/1809.10199v1)

> For autonomous vehicles, high-precision real-time localization is the guarantee of stable driving. Compared with the visual odometry (VO), the LiDAR odometry (LO) has the advantages of higher accuracy and better stability. However, 2D LO is only suitable for the indoor environment, and 3D LO has less efficiency in general. Both are not suitable for the online localization of an autonomous vehicle in an outdoor driving environment. In this paper, a direct LO method based on the 2.5D grid map is proposed. The fast semi-dense direct method proposed for VO is employed to register two 2.5D maps. Experiments show that this method is superior to both the 3D-NDT and LOAM in the outdoor environment.

</details>

<details>

<summary>2018-09-15 14:24:37 - Incorporating Behavioral Constraints in Online AI Systems</summary>

- *Avinash Balakrishnan, Djallel Bouneffouf, Nicholas Mattei, Francesca Rossi*

- `1809.05720v1` - [abs](http://arxiv.org/abs/1809.05720v1) - [pdf](http://arxiv.org/pdf/1809.05720v1)

> AI systems that learn through reward feedback about the actions they take are increasingly deployed in domains that have significant impact on our daily life. However, in many cases the online rewards should not be the only guiding criteria, as there are additional constraints and/or priorities imposed by regulations, values, preferences, or ethical principles. We detail a novel online agent that learns a set of behavioral constraints by observation and uses these learned constraints as a guide when making decisions in an online setting while still being reactive to reward feedback. To define this agent, we propose to adopt a novel extension to the classical contextual multi-armed bandit setting and we provide a new algorithm called Behavior Constrained Thompson Sampling (BCTS) that allows for online learning while obeying exogenous constraints. Our agent learns a constrained policy that implements the observed behavioral constraints demonstrated by a teacher agent, and then uses this constrained policy to guide the reward-based online exploration and exploitation. We characterize the upper bound on the expected regret of the contextual bandit algorithm that underlies our agent and provide a case study with real world data in two application domains. Our experiments show that the designed agent is able to act within the set of behavior constraints without significantly degrading its overall reward performance.

</details>

<details>

<summary>2018-09-15 19:57:02 - Using Artificial Intelligence to Support Compliance with the General Data Protection Regulation</summary>

- *John KC Kingston*

- `1809.05762v1` - [abs](http://arxiv.org/abs/1809.05762v1) - [pdf](http://arxiv.org/pdf/1809.05762v1)

> The General Data Protection Regulation (GDPR) is a European Union regulation that will replace the existing Data Protection Directive on 25 May 2018. The most significant change is a huge increase in the maximum fine that can be levied for breaches of the regulation. Yet fewer than half of UK companies are fully aware of GDPR - and a number of those who were preparing for it stopped doing so when the Brexit vote was announced. A last-minute rush to become compliant is therefore expected, and numerous companies are starting to offer advice, checklists and consultancy on how to comply with GDPR. In such an environment, artificial intelligence technologies ought to be able to assist by providing best advice; asking all and only the relevant questions; monitoring activities; and carrying out assessments. The paper considers four areas of GDPR compliance where rule based technologies and/or machine learning techniques may be relevant: * Following compliance checklists and codes of conduct; * Supporting risk assessments; * Complying with the new regulations regarding technologies that perform automatic profiling; * Complying with the new regulations concerning recognising and reporting breaches of security. It concludes that AI technology can support each of these four areas. The requirements that GDPR (or organisations that need to comply with GDPR) state for explanation and justification of reasoning imply that rule-based approaches are likely to be more helpful than machine learning approaches. However, there may be good business reasons to take a different approach in some circumstances.

</details>

<details>

<summary>2018-09-15 20:01:06 - Sampled Policy Gradient for Learning to Play the Game Agar.io</summary>

- *Anton Orell Wiehe, Nil Stolt Ansó, Madalina M. Drugan, Marco A. Wiering*

- `1809.05763v1` - [abs](http://arxiv.org/abs/1809.05763v1) - [pdf](http://arxiv.org/pdf/1809.05763v1)

> In this paper, a new offline actor-critic learning algorithm is introduced: Sampled Policy Gradient (SPG). SPG samples in the action space to calculate an approximated policy gradient by using the critic to evaluate the samples. This sampling allows SPG to search the action-Q-value space more globally than deterministic policy gradient (DPG), enabling it to theoretically avoid more local optima. SPG is compared to Q-learning and the actor-critic algorithms CACLA and DPG in a pellet collection task and a self play environment in the game Agar.io. The online game Agar.io has become massively popular on the internet due to intuitive game design and the ability to instantly compete against players around the world. From the point of view of artificial intelligence this game is also very intriguing: The game has a continuous input and action space and allows to have diverse agents with complex strategies compete against each other. The experimental results show that Q-Learning and CACLA outperform a pre-programmed greedy bot in the pellet collection task, but all algorithms fail to outperform this bot in a fighting scenario. The SPG algorithm is analyzed to have great extendability through offline exploration and it matches DPG in performance even in its basic form without extensive sampling.

</details>

<details>

<summary>2018-09-15 23:57:34 - Modelling Latent Travel Behaviour Characteristics with Generative Machine Learning</summary>

- *Melvin Wong, Bilal Farooq*

- `1809.05781v1` - [abs](http://arxiv.org/abs/1809.05781v1) - [pdf](http://arxiv.org/pdf/1809.05781v1)

> In this paper, we implement an information-theoretic approach to travel behaviour analysis by introducing a generative modelling framework to identify informative latent characteristics in travel decision making. It involves developing a joint tri-partite Bayesian graphical network model using a Restricted Boltzmann Machine (RBM) generative modelling framework. We apply this framework on a mode choice survey data to identify abstract latent variables and compare the performance with a traditional latent variable model with specific latent preferences -- safety, comfort, and environmental. Data collected from a joint stated and revealed preference mode choice survey in Quebec, Canada were used to calibrate the RBM model. Results show that a signficant impact on model likelihood statistics and suggests that machine learning tools are highly suitable for modelling complex networks of conditional independent behaviour interactions.

</details>

<details>

<summary>2018-09-16 01:36:41 - Bounding and Counting Linear Regions of Deep Neural Networks</summary>

- *Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam*

- `1711.02114v4` - [abs](http://arxiv.org/abs/1711.02114v4) - [pdf](http://arxiv.org/pdf/1711.02114v4)

> We investigate the complexity of deep neural networks (DNN) that represent piecewise linear (PWL) functions. In particular, we study the number of linear regions, i.e. pieces, that a PWL function represented by a DNN can attain, both theoretically and empirically. We present (i) tighter upper and lower bounds for the maximum number of linear regions on rectifier networks, which are exact for inputs of dimension one; (ii) a first upper bound for multi-layer maxout networks; and (iii) a first method to perform exact enumeration or counting of the number of regions by modeling the DNN with a mixed-integer linear formulation. These bounds come from leveraging the dimension of the space defining each linear region. The results also indicate that a deep rectifier network can only have more linear regions than every shallow counterpart with same number of neurons if that number exceeds the dimension of the input.

</details>

<details>

<summary>2018-09-16 03:56:21 - Dual Memory Network Model for Biased Product Review Classification</summary>

- *Yunfei Long, Mingyu Ma, Qin Lu, Rong Xiang, Chu-Ren Huang*

- `1809.05807v1` - [abs](http://arxiv.org/abs/1809.05807v1) - [pdf](http://arxiv.org/pdf/1809.05807v1)

> In sentiment analysis (SA) of product reviews, both user and product information are proven to be useful. Current tasks handle user profile and product information in a unified model which may not be able to learn salient features of users and products effectively. In this work, we propose a dual user and product memory network (DUPMN) model to learn user profiles and product reviews using separate memory networks. Then, the two representations are used jointly for sentiment prediction. The use of separate models aims to capture user profiles and product information more effectively. Compared to state-of-the-art unified prediction models, the evaluations on three benchmark datasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives performance gain of 0.6%, 1.2%, and 0.9%, respectively. The improvements are also deemed very significant measured by p-values.

</details>

<details>

<summary>2018-09-16 07:38:31 - Testing SensoGraph, a geometric approach for fast sensory evaluation</summary>

- *David Orden, Encarnación Fernández-Fernández, José M. Rodríguez-Nogales, Josefina Vila-Crespo*

- `1809.06911v1` - [abs](http://arxiv.org/abs/1809.06911v1) - [pdf](http://arxiv.org/pdf/1809.06911v1)

> This paper introduces SensoGraph, a novel approach for fast sensory evaluation using two-dimensional geometric techniques. In the tasting sessions, the assessors follow their own criteria to place samples on a tablecloth, according to the similarity between samples. In order to analyse the data collected, first a geometric clustering is performed to each tablecloth, extracting connections between the samples. Then, these connections are used to construct a global similarity matrix. Finally, a graph drawing algorithm is used to obtain a 2D consensus graphic, which reflects the global opinion of the panel by (1) positioning closer those samples that have been globally perceived as similar and (2) showing the strength of the connections between samples. The proposal is validated by performing four tasting sessions, with three types of panels tasting different wines, and by developing a new software to implement the proposed techniques. The results obtained show that the graphics provide similar positionings of the samples as the consensus maps obtained by multiple factor analysis (MFA), further providing extra information about connections between samples, not present in any previous method. The main conclusion is that the use of geometric techniques provides information complementary to MFA, and of a different type. Finally, the method proposed is computationally able to manage a significantly larger number of assessors than MFA, which can be useful for the comparison of pictures by a huge number of consumers, via the Internet.

</details>

<details>

<summary>2018-09-16 07:58:09 - A Fog Robotic System for Dynamic Visual Servoing</summary>

- *Nan Tian, Jinfa Chen, Mas Ma, Robert Zhang, Bill Huang, Ken Goldberg, Somayeh Sojoudi*

- `1809.06716v1` - [abs](http://arxiv.org/abs/1809.06716v1) - [pdf](http://arxiv.org/pdf/1809.06716v1)

> Cloud Robotics is a paradigm where distributed robots are connected to cloud services via networks to access unlimited computation power, at the cost of network communication. However, due to limitations such as network latency and variability, it is difficult to control dynamic, human compliant service robots directly from the cloud. In this work, by leveraging asynchronous protocol with a heartbeat signal, we combine cloud robotics with a smart edge device to build a Fog Robotic system. We use the system to enable robust teleoperation of a dynamic self-balancing robot from the cloud. We first use the system to pick up boxes from static locations, a task commonly performed in warehouse logistics. To make cloud teleoperation more efficient, we deploy image based visual servoing (IBVS) to perform box pickups automatically. Visual feedbacks, including apriltag recognition and tracking, are performed in the cloud to emulate a Fog Robotic object recognition system for IBVS. We demonstrate the feasibility of real-time dynamic automation system using this cloud-edge hybrid, which opens up possibilities of deploying dynamic robotic control with deep-learning recognition systems in Fog Robotics. Finally, we show that Fog Robotics enables the self-balancing service robot to pick up a box automatically from a person under unstructured environments.

</details>

<details>

<summary>2018-09-16 08:51:05 - A Generic Multi-modal Dynamic Gesture Recognition System using Machine Learning</summary>

- *Gautham Krishna G, Karthik Subramanian Nathan, Yogesh Kumar B, Ankith A Prabhu, Ajay Kannan, Vineeth Vijayaraghavan*

- `1809.05839v1` - [abs](http://arxiv.org/abs/1809.05839v1) - [pdf](http://arxiv.org/pdf/1809.05839v1)

> Human computer interaction facilitates intelligent communication between humans and computers, in which gesture recognition plays a prominent role. This paper proposes a machine learning system to identify dynamic gestures using tri-axial acceleration data acquired from two public datasets. These datasets, uWave and Sony, were acquired using accelerometers embedded in Wii remotes and smartwatches, respectively. A dynamic gesture signed by the user is characterized by a generic set of features extracted across time and frequency domains. The system was analyzed from an end-user perspective and was modelled to operate in three modes. The modes of operation determine the subsets of data to be used for training and testing the system. From an initial set of seven classifiers, three were chosen to evaluate each dataset across all modes rendering the system towards mode-neutrality and dataset-independence. The proposed system is able to classify gestures performed at varying speeds with minimum preprocessing, making it computationally efficient. Moreover, this system was found to run on a low-cost embedded platform - Raspberry Pi Zero (USD 5), making it economically viable.

</details>

<details>

<summary>2018-09-16 13:21:49 - On-Line Learning of Linear Dynamical Systems: Exponential Forgetting in Kalman Filters</summary>

- *Mark Kozdoba, Jakub Marecek, Tigran Tchrakian, Shie Mannor*

- `1809.05870v1` - [abs](http://arxiv.org/abs/1809.05870v1) - [pdf](http://arxiv.org/pdf/1809.05870v1)

> Kalman filter is a key tool for time-series forecasting and analysis. We show that the dependence of a prediction of Kalman filter on the past is decaying exponentially, whenever the process noise is non-degenerate. Therefore, Kalman filter may be approximated by regression on a few recent observations. Surprisingly, we also show that having some process noise is essential for the exponential decay. With no process noise, it may happen that the forecast depends on all of the past uniformly, which makes forecasting more difficult.   Based on this insight, we devise an on-line algorithm for improper learning of a linear dynamical system (LDS), which considers only a few most recent observations. We use our decay results to provide the first regret bounds w.r.t. to Kalman filters within learning an LDS. That is, we compare the results of our algorithm to the best, in hindsight, Kalman filter for a given signal. Also, the algorithm is practical: its per-update run-time is linear in the regression depth.

</details>

<details>

<summary>2018-09-16 14:39:28 - An investigation of a deep learning based malware detection system</summary>

- *Mohit Sewak, Sanjay K. Sahay, Hemant Rathore*

- `1809.05888v1` - [abs](http://arxiv.org/abs/1809.05888v1) - [pdf](http://arxiv.org/pdf/1809.05888v1)

> We investigate a Deep Learning based system for malware detection. In the investigation, we experiment with different combination of Deep Learning architectures including Auto-Encoders, and Deep Neural Networks with varying layers over Malicia malware dataset on which earlier studies have obtained an accuracy of (98%) with an acceptable False Positive Rates (1.07%). But these results were done using extensive man-made custom domain features and investing corresponding feature engineering and design efforts. In our proposed approach, besides improving the previous best results (99.21% accuracy and a False Positive Rate of 0.19%) indicates that Deep Learning based systems could deliver an effective defense against malware. Since it is good in automatically extracting higher conceptual features from the data, Deep Learning based systems could provide an effective, general and scalable mechanism for detection of existing and unknown malware.

</details>

<details>

<summary>2018-09-16 14:40:16 - Comparison of Deep Learning and the Classical Machine Learning Algorithm for the Malware Detection</summary>

- *Mohit Sewak, Sanjay K. Sahay, Hemant Rathore*

- `1809.05889v1` - [abs](http://arxiv.org/abs/1809.05889v1) - [pdf](http://arxiv.org/pdf/1809.05889v1)

> Recently, Deep Learning has been showing promising results in various Artificial Intelligence applications like image recognition, natural language processing, language modeling, neural machine translation, etc. Although, in general, it is computationally more expensive as compared to classical machine learning techniques, their results are found to be more effective in some cases. Therefore, in this paper, we investigated and compared one of the Deep Learning Architecture called Deep Neural Network (DNN) with the classical Random Forest (RF) machine learning algorithm for the malware classification. We studied the performance of the classical RF and DNN with 2, 4 & 7 layers architectures with the four different feature sets, and found that irrespective of the features inputs, the classical RF accuracy outperforms the DNN.

</details>

<details>

<summary>2018-09-16 14:48:45 - Semantic Interoperability Middleware Architecture for Heterogeneous Environmental Data Sources</summary>

- *A. K. Akanbi, M. Masinde*

- `1809.05890v1` - [abs](http://arxiv.org/abs/1809.05890v1) - [pdf](http://arxiv.org/pdf/1809.05890v1)

> Data heterogeneity hampers the effort to integrate and infer knowledge from vast heterogeneous data sources. An application case study is described, in which the objective was to semantically represent and integrate structured data from sensor devices with unstructured data in the form of local indigenous knowledge. However, the semantic representation of these heterogeneous data sources for environmental monitoring systems is not well supported yet. To combat the incompatibility issues, a dedicated semantic middleware solution is required. In this paper, we describe and evaluate a cross-domain middleware architecture that semantically integrates and generate inference from heterogeneous data sources. These use of semantic technology for predicting and forecasting complex environmental phenomenon will increase the degree of accuracy of environmental monitoring systems.

</details>

<details>

<summary>2018-09-16 15:43:11 - Systems of bounded rational agents with information-theoretic constraints</summary>

- *Sebastian Gottwald, Daniel A. Braun*

- `1809.05897v1` - [abs](http://arxiv.org/abs/1809.05897v1) - [pdf](http://arxiv.org/pdf/1809.05897v1)

> Specialization and hierarchical organization are important features of efficient collaboration in economical, artificial, and biological systems. Here, we investigate the hypothesis that both features can be explained by the fact that each entity of such a system is limited in a certain way. We propose an information-theoretic approach based on a Free Energy principle, in order to computationally analyze systems of bounded rational agents that deal with such limitations optimally. We find that specialization allows to focus on fewer tasks, thus leading to a more efficient execution, but in turn requires coordination in hierarchical structures of specialized experts and coordinating units. Our results suggest that hierarchical architectures of specialized units at lower levels that are coordinated by units at higher levels are optimal, given that each unit's information-processing capability is limited and conforms to constraints on complexity costs.

</details>

<details>

<summary>2018-09-16 20:33:45 - The Space-Efficient Core of Vadalog</summary>

- *Gerald Berger, Georg Gottlob, Andreas Pieris, Emanuel Sallinger*

- `1809.05951v1` - [abs](http://arxiv.org/abs/1809.05951v1) - [pdf](http://arxiv.org/pdf/1809.05951v1)

> Vadalog is a system for performing complex reasoning tasks such as those required in advanced knowledge graphs. The logical core of the underlying Vadalog language is the warded fragment of tuple-generating dependencies (TGDs). This formalism ensures tractable reasoning in data complexity, while a recent analysis focusing on a practical implementation led to the reasoning algorithm around which the Vadalog system is built. A fundamental question that has emerged in the context of Vadalog is the following: can we limit the recursion allowed by wardedness in order to obtain a formalism that provides a convenient syntax for expressing useful recursive statements, and at the same time achieves space-efficiency? After analyzing several real-life examples of warded sets of TGDs provided by our industrial partners, as well as recent benchmarks, we observed that recursion is often used in a restricted way: the body of a TGD contains at most one atom whose predicate is mutually recursive with a predicate in the head. We show that this type of recursion, known as piece-wise linear in the Datalog literature, is the answer to our main question. We further show that piece-wise linear recursion alone, without the wardedness condition, is not enough as it leads to the undecidability of reasoning. We finally study the relative expressiveness of the query languages based on (piece-wise linear) warded sets of TGDs.

</details>

<details>

<summary>2018-09-16 21:19:35 - Lazy Modeling of Variants of Token Swapping Problem and Multi-agent Path Finding through Combination of Satisfiability Modulo Theories and Conflict-based Search</summary>

- *Pavel Surynek*

- `1809.05959v1` - [abs](http://arxiv.org/abs/1809.05959v1) - [pdf](http://arxiv.org/pdf/1809.05959v1)

> We address item relocation problems in graphs in this paper. We assume items placed in vertices of an undirected graph with at most one item per vertex. Items can be moved across edges while various constraints depending on the type of relocation problem must be satisfied. We introduce a general problem formulation that encompasses known types of item relocation problems such as multi-agent path finding (MAPF) and token swapping (TSWAP). In this formulation we express two new types of relocation problems derived from token swapping that we call token rotation (TROT) and token permutation (TPERM). Our solving approach for item relocation combines satisfiability modulo theory (SMT) with conflict-based search (CBS). We interpret CBS in the SMT framework where we start with the basic model and refine the model with a collision resolution constraint whenever a collision between items occurs in the current solution. The key difference between the standard CBS and our SMT-based modification of CBS (SMT-CBS) is that the standard CBS branches the search to resolve the collision while in SMT-CBS we iteratively add a single disjunctive collision resolution constraint. Experimental evaluation on several benchmarks shows that the SMT-CBS algorithm significantly outperforms the standard CBS. We also compared SMT-CBS with a modification of the SAT-based MDD-SAT solver that uses an eager modeling of item relocation in which all potential collisions are eliminated by constrains in advance. Experiments show that lazy approach in SMT-CBS produce fewer constraint than MDD-SAT and also achieves faster solving run-times.

</details>

<details>

<summary>2018-09-17 00:25:48 - Deep Compressive Autoencoder for Action Potential Compression in Large-Scale Neural Recording</summary>

- *Tong Wu, Wenfeng Zhao, Edward Keefer, Zhi Yang*

- `1809.05522v2` - [abs](http://arxiv.org/abs/1809.05522v2) - [pdf](http://arxiv.org/pdf/1809.05522v2)

> Understanding the coordinated activity underlying brain computations requires large-scale, simultaneous recordings from distributed neuronal structures at a cellular-level resolution. One major hurdle to design high-bandwidth, high-precision, large-scale neural interfaces lies in the formidable data streams that are generated by the recorder chip and need to be online transferred to a remote computer. The data rates can require hundreds to thousands of I/O pads on the recorder chip and power consumption on the order of Watts for data streaming alone. We developed a deep learning-based compression model to reduce the data rate of multichannel action potentials. The proposed model is built upon a deep compressive autoencoder (CAE) with discrete latent embeddings. The encoder is equipped with residual transformations to extract representative features from spikes, which are mapped into the latent embedding space and updated via vector quantization (VQ). The decoder network reconstructs spike waveforms from the quantized latent embeddings. Experimental results show that the proposed model consistently outperforms conventional methods by achieving much higher compression ratios (20-500x) and better or comparable reconstruction accuracies. Testing results also indicate that CAE is robust against a diverse range of imperfections, such as waveform variation and spike misalignment, and has minor influence on spike sorting accuracy. Furthermore, we have estimated the hardware cost and real-time performance of CAE and shown that it could support thousands of recording channels simultaneously without excessive power/heat dissipation. The proposed model can reduce the required data transmission bandwidth in large-scale recording experiments and maintain good signal qualities. The code of this work has been made available at https://github.com/tong-wu-umn/spike-compression-autoencoder

</details>

<details>

<summary>2018-09-17 03:09:58 - News Session-Based Recommendations using Deep Neural Networks</summary>

- *Gabriel de Souza P. Moreira, Felipe Ferreira, Adilson Marques da Cunha*

- `1808.00076v3` - [abs](http://arxiv.org/abs/1808.00076v3) - [pdf](http://arxiv.org/pdf/1808.00076v3)

> News recommender systems are aimed to personalize users experiences and help them to discover relevant articles from a large and dynamic search space. Therefore, news domain is a challenging scenario for recommendations, due to its sparse user profiling, fast growing number of items, accelerated item's value decay, and users preferences dynamic shift. Some promising results have been recently achieved by the usage of Deep Learning techniques on Recommender Systems, specially for item's feature extraction and for session-based recommendations with Recurrent Neural Networks. In this paper, it is proposed an instantiation of the CHAMELEON -- a Deep Learning Meta-Architecture for News Recommender Systems. This architecture is composed of two modules, the first responsible to learn news articles representations, based on their text and metadata, and the second module aimed to provide session-based recommendations using Recurrent Neural Networks. The recommendation task addressed in this work is next-item prediction for users sessions: "what is the next most likely article a user might read in a session?" Users sessions context is leveraged by the architecture to provide additional information in such extreme cold-start scenario of news recommendation. Users' behavior and item features are both merged in an hybrid recommendation approach. A temporal offline evaluation method is also proposed as a complementary contribution, for a more realistic evaluation of such task, considering dynamic factors that affect global readership interests like popularity, recency, and seasonality. Experiments with an extensive number of session-based recommendation methods were performed and the proposed instantiation of CHAMELEON meta-architecture obtained a significant relative improvement in top-n accuracy and ranking metrics (10% on Hit Rate and 13% on MRR) over the best benchmark methods.

</details>

<details>

<summary>2018-09-17 06:27:40 - Scattering Networks for Hybrid Representation Learning</summary>

- *Edouard Oyallon, Sergey Zagoruyko, Gabriel Huang, Nikos Komodakis, Simon Lacoste-Julien, Matthew Blaschko, Eugene Belilovsky*

- `1809.06367v1` - [abs](http://arxiv.org/abs/1809.06367v1) - [pdf](http://arxiv.org/pdf/1809.06367v1)

> Scattering networks are a class of designed Convolutional Neural Networks (CNNs) with fixed weights. We argue they can serve as generic representations for modelling images. In particular, by working in scattering space, we achieve competitive results both for supervised and unsupervised learning tasks, while making progress towards constructing more interpretable CNNs. For supervised learning, we demonstrate that the early layers of CNNs do not necessarily need to be learned, and can be replaced with a scattering network instead. Indeed, using hybrid architectures, we achieve the best results with predefined representations to-date, while being competitive with end-to-end learned CNNs. Specifically, even applying a shallow cascade of small-windowed scattering coefficients followed by 1$\times$1-convolutions results in AlexNet accuracy on the ILSVRC2012 classification task. Moreover, by combining scattering networks with deep residual networks, we achieve a single-crop top-5 error of 11.4% on ILSVRC2012. Also, we show they can yield excellent performance in the small sample regime on CIFAR-10 and STL-10 datasets, exceeding their end-to-end counterparts, through their ability to incorporate geometrical priors. For unsupervised learning, scattering coefficients can be a competitive representation that permits image recovery. We use this fact to train hybrid GANs to generate images. Finally, we empirically analyze several properties related to stability and reconstruction of images from scattering coefficients.

</details>

<details>

<summary>2018-09-17 07:13:46 - Multi-target Unsupervised Domain Adaptation without Exactly Shared Categories</summary>

- *Huanhuan Yu, Menglei Hu, Songcan Chen*

- `1809.00852v2` - [abs](http://arxiv.org/abs/1809.00852v2) - [pdf](http://arxiv.org/pdf/1809.00852v2)

> Unsupervised domain adaptation (UDA) aims to learn the unlabeled target domain by transferring the knowledge of the labeled source domain. To date, most of the existing works focus on the scenario of one source domain and one target domain (1S1T), and just a few works concern the scenario of multiple source domains and one target domain (mS1T). While, to the best of our knowledge, almost no work concerns the scenario of one source domain and multiple target domains (1SmT), in which these unlabeled target domains may not necessarily share the same categories, therefore, contrasting to mS1T, 1SmT is more challenging. Accordingly, for such a new UDA scenario, we propose a UDA framework through the model parameter adaptation (PA-1SmT). A key ingredient of PA-1SmT is to transfer knowledge through adaptive learning of a common model parameter dictionary, which is completely different from existing popular methods for UDA, such as subspace alignment, distribution matching etc., and can also be directly used for DA of privacy protection due to the fact that the knowledge is transferred just via the model parameters rather than data itself. Finally, our experimental results on three domain adaptation benchmark datasets demonstrate the superiority of our framework.

</details>

<details>

<summary>2018-09-17 07:59:36 - Object-sensitive Deep Reinforcement Learning</summary>

- *Yuezhang Li, Katia Sycara, Rahul Iyer*

- `1809.06064v1` - [abs](http://arxiv.org/abs/1809.06064v1) - [pdf](http://arxiv.org/pdf/1809.06064v1)

> Deep reinforcement learning has become popular over recent years, showing superiority on different visual-input tasks such as playing Atari games and robot navigation. Although objects are important image elements, few work considers enhancing deep reinforcement learning with object characteristics. In this paper, we propose a novel method that can incorporate object recognition processing to deep reinforcement learning models. This approach can be adapted to any existing deep reinforcement learning frameworks. State-of-the-art results are shown in experiments on Atari games. We also propose a new approach called "object saliency maps" to visually explain the actions made by deep reinforcement learning agents.

</details>

<details>

<summary>2018-09-17 12:05:28 - Neural Allocentric Intuitive Physics Prediction from Real Videos</summary>

- *Zhihua Wang, Stefano Rosa, Yishu Miao, Zihang Lai, Linhai Xie, Andrew Markham, Niki Trigoni*

- `1809.03330v2` - [abs](http://arxiv.org/abs/1809.03330v2) - [pdf](http://arxiv.org/pdf/1809.03330v2)

> Humans are able to make rich predictions about the future dynamics of physical objects from a glance. On the other hand, most existing computer vision approaches require strong assumptions about the underlying system, ad-hoc modeling, or annotated datasets, to carry out even simple predictions. To tackle this gap, we propose a new perspective on the problem of learning intuitive physics that is inspired by the spatial memory representation of objects and spaces in human brains, in particular the co-existence of egocentric and allocentric spatial representations. We present a generic framework that learns a layered representation of the physical world, using a cascade of invertible modules. In this framework, real images are first converted to a synthetic domain representation that reduces complexity arising from lighting and texture. Then, an allocentric viewpoint transformer removes viewpoint complexity by projecting images to a canonical view. Finally, a novel Recurrent Latent Variation Network (RLVN) architecture learns the dynamics of the objects interacting with the environment and predicts future motion, leveraging the availability of unlimited synthetic simulations. Predicted frames are then projected back to the original camera view and translated back to the real world domain. Experimental results show the ability of the framework to consistently and accurately predict several frames in the future and the ability to adapt to real images.

</details>

<details>

<summary>2018-09-17 13:38:41 - Intermediate Deep Feature Compression: the Next Battlefield of Intelligent Sensing</summary>

- *Zhuo Chen, Weisi Lin, Shiqi Wang, Lingyu Duan, Alex C. Kot*

- `1809.06196v1` - [abs](http://arxiv.org/abs/1809.06196v1) - [pdf](http://arxiv.org/pdf/1809.06196v1)

> The recent advances of hardware technology have made the intelligent analysis equipped at the front-end with deep learning more prevailing and practical. To better enable the intelligent sensing at the front-end, instead of compressing and transmitting visual signals or the ultimately utilized top-layer deep learning features, we propose to compactly represent and convey the intermediate-layer deep learning features of high generalization capability, to facilitate the collaborating approach between front and cloud ends. This strategy enables a good balance among the computational load, transmission load and the generalization ability for cloud servers when deploying the deep neural networks for large scale cloud based visual analysis. Moreover, the presented strategy also makes the standardization of deep feature coding more feasible and promising, as a series of tasks can simultaneously benefit from the transmitted intermediate layers. We also present the results for evaluation of lossless deep feature compression with four benchmark data compression methods, which provides meaningful investigations and baselines for future research and standardization activities.

</details>

<details>

<summary>2018-09-17 14:45:21 - Learning to Collaborate: Multi-Scenario Ranking via Multi-Agent Reinforcement Learning</summary>

- *Jun Feng, Heng Li, Minlie Huang, Shichen Liu, Wenwu Ou, Zhirong Wang, Xiaoyan Zhu*

- `1809.06260v1` - [abs](http://arxiv.org/abs/1809.06260v1) - [pdf](http://arxiv.org/pdf/1809.06260v1)

> Ranking is a fundamental and widely studied problem in scenarios such as search, advertising, and recommendation. However, joint optimization for multi-scenario ranking, which aims to improve the overall performance of several ranking strategies in different scenarios, is rather untouched. Separately optimizing each individual strategy has two limitations. The first one is lack of collaboration between scenarios meaning that each strategy maximizes its own objective but ignores the goals of other strategies, leading to a sub-optimal overall performance. The second limitation is the inability of modeling the correlation between scenarios meaning that independent optimization in one scenario only uses its own user data but ignores the context in other scenarios.   In this paper, we formulate multi-scenario ranking as a fully cooperative, partially observable, multi-agent sequential decision problem. We propose a novel model named Multi-Agent Recurrent Deterministic Policy Gradient (MA-RDPG) which has a communication component for passing messages, several private actors (agents) for making actions for ranking, and a centralized critic for evaluating the overall performance of the co-working actors. Each scenario is treated as an agent (actor). Agents collaborate with each other by sharing a global action-value function (the critic) and passing messages that encodes historical information across scenarios. The model is evaluated with online settings on a large E-commerce platform. Results show that the proposed model exhibits significant improvements against baselines in terms of the overall performance.

</details>

<details>

<summary>2018-09-17 16:27:13 - Guess who? Multilingual approach for the automated generation of author-stylized poetry</summary>

- *Alexey Tikhonov, Ivan P. Yamshchikov*

- `1807.07147v3` - [abs](http://arxiv.org/abs/1807.07147v3) - [pdf](http://arxiv.org/pdf/1807.07147v3)

> This paper addresses the problem of stylized text generation in a multilingual setup. A version of a language model based on a long short-term memory (LSTM) artificial neural network with extended phonetic and semantic embeddings is used for stylized poetry generation. The quality of the resulting poems generated by the network is estimated through bilingual evaluation understudy (BLEU), a survey and a new cross-entropy based metric that is suggested for the problems of such type. The experiments show that the proposed model consistently outperforms random sample and vanilla-LSTM baselines, humans also tend to associate machine generated texts with the target author.

</details>

<details>

<summary>2018-09-17 17:06:06 - Powerful, transferable representations for molecules through intelligent task selection in deep multitask networks</summary>

- *Clyde Fare, Lukas Turcani, Edward O. Pyzer-Knapp*

- `1809.06334v1` - [abs](http://arxiv.org/abs/1809.06334v1) - [pdf](http://arxiv.org/pdf/1809.06334v1)

> Chemical representations derived from deep learning are emerging as a powerful tool in areas such as drug discovery and materials innovation. Currently, this methodology has three major limitations - the cost of representation generation, risk of inherited bias, and the requirement for large amounts of data. We propose the use of multi-task learning in tandem with transfer learning to address these limitations directly. In order to avoid introducing unknown bias into multi-task learning through the task selection itself, we calculate task similarity through pairwise task affinity, and use this measure to programmatically select tasks. We test this methodology on several real-world data sets to demonstrate its potential for execution in complex and low-data environments. Finally, we utilise the task similarity to further probe the expressiveness of the learned representation through a comparison to a commonly used cheminformatics fingerprint, and show that the deep representation is able to capture more expressive task-based information.

</details>

<details>

<summary>2018-09-17 21:51:57 - Holarchic Structures for Decentralized Deep Learning - A Performance Analysis</summary>

- *Evangelos Pournaras, Srivatsan Yadhunathan, Ada Diaconescu*

- `1805.02686v2` - [abs](http://arxiv.org/abs/1805.02686v2) - [pdf](http://arxiv.org/pdf/1805.02686v2)

> Structure plays a key role in learning performance. In centralized computational systems, hyperparameter optimization and regularization techniques such as dropout are computational means to enhance learning performance by adjusting the deep hierarchical structure. However, in decentralized deep learning by the Internet of Things, the structure is an actual network of autonomous interconnected devices such as smart phones that interact via complex network protocols. Self-adaptation of the learning structure is a challenge. Uncertainties such as network latency, node and link failures or even bottlenecks by limited processing capacity and energy availability can signif- icantly downgrade learning performance. Network self-organization and self-management is complex, while it requires additional computational and network resources that hinder the feasibility of decentralized deep learning. In contrast, this paper introduces a self-adaptive learning approach based on holarchic learning structures for exploring, mitigating and boosting learning performance in distributed environments with uncertainties. A large-scale performance analysis with 864000 experiments fed with synthetic and real-world data from smart grid and smart city pilot projects confirm the cost-effectiveness of holarchic structures for decentralized deep learning.

</details>

<details>

<summary>2018-09-17 21:54:25 - AtDelfi: Automatically Designing Legible, Full Instructions For Games</summary>

- *Michael Cerny Green, Ahmed Khalifa, Gabriella A. B. Barros, Tiago Machado, Andy Nealen, Julian Togelius*

- `1807.04375v2` - [abs](http://arxiv.org/abs/1807.04375v2) - [pdf](http://arxiv.org/pdf/1807.04375v2)

> This paper introduces a fully automatic method for generating video game tutorials. The AtDELFI system (AuTomatically DEsigning Legible, Full Instructions for games) was created to investigate procedural generation of instructions that teach players how to play video games. We present a representation of game rules and mechanics using a graph system as well as a tutorial generation method that uses said graph representation. We demonstrate the concept by testing it on games within the General Video Game Artificial Intelligence (GVG-AI) framework; the paper discusses tutorials generated for eight different games. Our findings suggest that a graph representation scheme works well for simple arcade style games such as Space Invaders and Pacman, but it appears that tutorials for more complex games might require higher-level understanding of the game than just single mechanics.

</details>

<details>

<summary>2018-09-17 23:11:50 - Towards Deep and Representation Learning for Talent Search at LinkedIn</summary>

- *Rohan Ramanath, Hakan Inan, Gungor Polatkan, Bo Hu, Qi Guo, Cagri Ozcaglar, Xianren Wu, Krishnaram Kenthapadi, Sahin Cem Geyik*

- `1809.06473v1` - [abs](http://arxiv.org/abs/1809.06473v1) - [pdf](http://arxiv.org/pdf/1809.06473v1)

> Talent search and recommendation systems at LinkedIn strive to match the potential candidates to the hiring needs of a recruiter or a hiring manager expressed in terms of a search query or a job posting. Recent work in this domain has mainly focused on linear models, which do not take complex relationships between features into account, as well as ensemble tree models, which introduce non-linearity but are still insufficient for exploring all the potential feature interactions, and strictly separate feature generation from modeling. In this paper, we present the results of our application of deep and representation learning models on LinkedIn Recruiter. Our key contributions include: (i) Learning semantic representations of sparse entities within the talent search domain, such as recruiter ids, candidate ids, and skill entity ids, for which we utilize neural network models that take advantage of LinkedIn Economic Graph, and (ii) Deep models for learning recruiter engagement and candidate response in talent search applications. We also explore learning to rank approaches applied to deep models, and show the benefits for the talent search use case. Finally, we present offline and online evaluation results for LinkedIn talent search and recommendation systems, and discuss potential challenges along the path to a fully deep model architecture. The challenges and approaches discussed generalize to any multi-faceted search engine.

</details>

<details>

<summary>2018-09-18 00:03:15 - Talent Search and Recommendation Systems at LinkedIn: Practical Challenges and Lessons Learned</summary>

- *Sahin Cem Geyik, Qi Guo, Bo Hu, Cagri Ozcaglar, Ketan Thakkar, Xianren Wu, Krishnaram Kenthapadi*

- `1809.06481v1` - [abs](http://arxiv.org/abs/1809.06481v1) - [pdf](http://arxiv.org/pdf/1809.06481v1)

> LinkedIn Talent Solutions business contributes to around 65% of LinkedIn's annual revenue, and provides tools for job providers to reach out to potential candidates and for job seekers to find suitable career opportunities. LinkedIn's job ecosystem has been designed as a platform to connect job providers and job seekers, and to serve as a marketplace for efficient matching between potential candidates and job openings. A key mechanism to help achieve these goals is the LinkedIn Recruiter product, which enables recruiters to search for relevant candidates and obtain candidate recommendations for their job postings. In this work, we highlight a set of unique information retrieval, system, and modeling challenges associated with talent search and recommendation systems.

</details>

<details>

<summary>2018-09-18 00:24:23 - In-Session Personalization for Talent Search</summary>

- *Sahin Cem Geyik, Vijay Dialani, Meng Meng, Ryan Smith*

- `1809.06488v1` - [abs](http://arxiv.org/abs/1809.06488v1) - [pdf](http://arxiv.org/pdf/1809.06488v1)

> Previous efforts in recommendation of candidates for talent search followed the general pattern of receiving an initial search criteria and generating a set of candidates utilizing a pre-trained model. Traditionally, the generated recommendations are final, that is, the list of potential candidates is not modified unless the user explicitly changes his/her search criteria. In this paper, we are proposing a candidate recommendation model which takes into account the immediate feedback of the user, and updates the candidate recommendations at each step. This setting also allows for very uninformative initial search queries, since we pinpoint the user's intent due to the feedback during the search session. To achieve our goal, we employ an intent clustering method based on topic modeling which separates the candidate space into meaningful, possibly overlapping, subsets (which we call intent clusters) for each position. On top of the candidate segments, we apply a multi-armed bandit approach to choose which intent cluster is more appropriate for the current session. We also present an online learning scheme which updates the intent clusters within the session, due to user feedback, to achieve further personalization. Our offline experiments as well as the results from the online deployment of our solution demonstrate the benefits of our proposed methodology.

</details>

<details>

<summary>2018-09-18 02:44:57 - Learning Discrete Bayesian Networks from Continuous Data</summary>

- *Yi-Chun Chen, Tim Allan Wheeler, Mykel John Kochenderfer*

- `1512.02406v3` - [abs](http://arxiv.org/abs/1512.02406v3) - [pdf](http://arxiv.org/pdf/1512.02406v3)

> Learning Bayesian networks from raw data can help provide insights into the relationships between variables. While real data often contains a mixture of discrete and continuous-valued variables, many Bayesian network structure learning algorithms assume all random variables are discrete. Thus, continuous variables are often discretized when learning a Bayesian network. However, the choice of discretization policy has significant impact on the accuracy, speed, and interpretability of the resulting models. This paper introduces a principled Bayesian discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques. Empirical demonstrations show that the proposed method is superior to the established minimum description length algorithm. In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and simultaneously learn Bayesian network structures.

</details>

<details>

<summary>2018-09-18 03:14:31 - An Efficient Approximation Algorithm for Multi-criteria Indoor Route Planning Queries</summary>

- *Chaluka Salgado, Muhammad Aamir Cheema, David Taniar*

- `1809.07614v1` - [abs](http://arxiv.org/abs/1809.07614v1) - [pdf](http://arxiv.org/pdf/1809.07614v1)

> A route planning query has many real-world applications and has been studied extensively in outdoor spaces such as road networks or Euclidean space. Despite its many applications in indoor venues (e.g., shopping centres, libraries, airports), almost all existing studies are specifically designed for outdoor spaces and do not take into account unique properties of the indoor spaces such as hallways, stairs, escalators, rooms etc. We identify this research gap and formally define the problem of category aware multi-criteria route planning query, denoted by CAM, which returns the optimal route from an indoor source point to an indoor target point that passes through at least one indoor point from each given category while minimizing the total cost of the route in terms of travel distance and other relevant attributes. We show that CAM query is NP-hard. Based on a novel dominance-based pruning, we propose an efficient algorithm which generates high-quality results. We provide an extensive experimental study conducted on the largest shopping centre in Australia and compare our algorithm with alternative approaches. The experiments demonstrate that our algorithm is highly efficient and produces quality results.

</details>

<details>

<summary>2018-09-18 05:26:40 - Automatic Judgment Prediction via Legal Reading Comprehension</summary>

- *Shangbang Long, Cunchao Tu, Zhiyuan Liu, Maosong Sun*

- `1809.06537v1` - [abs](http://arxiv.org/abs/1809.06537v1) - [pdf](http://arxiv.org/pdf/1809.06537v1)

> Automatic judgment prediction aims to predict the judicial results based on case materials. It has been studied for several decades mainly by lawyers and judges, considered as a novel and prospective application of artificial intelligence techniques in the legal field. Most existing methods follow the text classification framework, which fails to model the complex interactions among complementary case materials. To address this issue, we formalize the task as Legal Reading Comprehension according to the legal scenario. Following the working protocol of human judges, LRC predicts the final judgment results based on three types of information, including fact description, plaintiffs' pleas, and law articles. Moreover, we propose a novel LRC model, AutoJudge, which captures the complex semantic interactions among facts, pleas, and laws. In experiments, we construct a real-world civil case dataset for LRC. Experimental results on this dataset demonstrate that our model achieves significant improvement over state-of-the-art models. We will publish all source codes and datasets of this work on \urlgithub.com for further research.

</details>

<details>

<summary>2018-09-18 06:38:49 - Block Chain based Intelligent Industrial Network (DSDIN)</summary>

- *Barco You, Matthias Hub, Mengzhe You, Bo Xu, Mingzhi Yu, Ivan Uemlianin*

- `1809.06551v1` - [abs](http://arxiv.org/abs/1809.06551v1) - [pdf](http://arxiv.org/pdf/1809.06551v1)

> The manufacturing industry featured centralization in the past due to technical limitations, and factories (especially large manufacturers) gathered almost all of the resources for manufacturing, including: technologies, raw materials, equipment, workers, market information, etc. However, such centralized production is costly, inefficient and inflexible, and difficult to respond to rapidly changing, diverse and personalized user needs. This paper introduces an Intelligent Industrial Network (DSDIN), which provides a fully distributed manufacturing network where everyone can participate in manufacturing due to decentralization and no intermediate links, allowing them to quickly get the products or services they want and also to be authorized, recognized and get returns in a low-cost way due to their efforts (such as providing creative ideas, designs or equipment, raw materials or physical strength). DSDIN is a blockchain based IoT and AI technology platform, and also an IoT based intelligent service standard. Due to the intelligent network formed by DSDIN, the manufacturing center is no longer a factory, and actually there are no manufacturing centers. DSDIN provides a multi-participation peer-to-peer network for people and things (including raw materials, equipment, finished / semi-finished products, etc.). The information transmitted through the network is called Intelligent Service Algorithm (ISA). The user can send a process model, formula or control parameter to a device via an ISA, and every transaction in DSDIN is an intelligent service defined by ISA.

</details>

<details>

<summary>2018-09-18 07:08:59 - User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks</summary>

- *Yilin Shen, Xiangyu Zeng, Yu Wang, Hongxia Jin*

- `1809.06559v1` - [abs](http://arxiv.org/abs/1809.06559v1) - [pdf](http://arxiv.org/pdf/1809.06559v1)

> Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.

</details>

<details>

<summary>2018-09-18 10:19:35 - SCC-rFMQ Learning in Cooperative Markov Games with Continuous Actions</summary>

- *Chengwei Zhang, Xiaohong Li, Jianye Hao, Siqi Chen, Karl Tuyls, Zhiyong Feng, Wanli Xue, Rong Chen*

- `1809.06625v1` - [abs](http://arxiv.org/abs/1809.06625v1) - [pdf](http://arxiv.org/pdf/1809.06625v1)

> Although many reinforcement learning methods have been proposed for learning the optimal solutions in single-agent continuous-action domains, multiagent coordination domains with continuous actions have received relatively few investigations. In this paper, we propose an independent learner hierarchical method, named Sample Continuous Coordination with recursive Frequency Maximum Q-Value (SCC-rFMQ), which divides the cooperative problem with continuous actions into two layers. The first layer samples a finite set of actions from the continuous action spaces by a re-sampling mechanism with variable exploratory rates, and the second layer evaluates the actions in the sampled action set and updates the policy using a reinforcement learning cooperative method. By constructing cooperative mechanisms at both levels, SCC-rFMQ can handle cooperative problems in continuous action cooperative Markov games effectively. The effectiveness of SCC-rFMQ is experimentally demonstrated on two well-designed games, i.e., a continuous version of the climbing game and a cooperative version of the boat problem. Experimental results show that SCC-rFMQ outperforms other reinforcement learning algorithms.

</details>

<details>

<summary>2018-09-18 10:51:07 - Multi-Scale Deep Compressive Sensing Network</summary>

- *Thuong Nguyen Canh, Byeungwoo Jeon*

- `1809.05717v2` - [abs](http://arxiv.org/abs/1809.05717v2) - [pdf](http://arxiv.org/pdf/1809.05717v2)

> With joint learning of sampling and recovery, the deep learning-based compressive sensing (DCS) has shown significant improvement in performance and running time reduction. Its reconstructed image, however, losses high-frequency content especially at low subrates. This happens similarly in the multi-scale sampling scheme which also samples more low-frequency components. In this paper, we propose a multi-scale DCS convolutional neural network (MS-DCSNet) in which we convert image signal using multiple scale-based wavelet transform, then capture it through convolution block by block across scales. The initial reconstructed image is directly recovered from multi-scale measurements. Multi-scale wavelet convolution is utilized to enhance the final reconstruction quality. The network is able to learn both multi-scale sampling and multi-scale reconstruction, thus results in better reconstruction quality.

</details>

<details>

<summary>2018-09-18 10:54:40 - Towards Abstraction in ASP with an Application on Reasoning about Agent Policies</summary>

- *Zeynep G. Saribatur, Thomas Eiter*

- `1809.06638v1` - [abs](http://arxiv.org/abs/1809.06638v1) - [pdf](http://arxiv.org/pdf/1809.06638v1)

> ASP programs are a convenient tool for problem solving, whereas with large problem instances the size of the state space can be prohibitive. We consider abstraction as a means of over-approximation and introduce a method to automatically abstract (possibly non-ground) ASP programs that preserves their structure, while reducing the size of the problem. One particular application case is the problem of defining declarative policies for reactive agents and reasoning about them, which we illustrate on examples.

</details>

<details>

<summary>2018-09-18 10:55:03 - Lung Cancer Concept Annotation from Spanish Clinical Narratives</summary>

- *Marjan Najafabadipour, Juan Manuel Tuñas, Alejandro Rodríguez-González, Ernestina Menasalvas*

- `1809.06639v1` - [abs](http://arxiv.org/abs/1809.06639v1) - [pdf](http://arxiv.org/pdf/1809.06639v1)

> Recent rapid increase in the generation of clinical data and rapid development of computational science make us able to extract new insights from massive datasets in healthcare industry. Oncological clinical notes are creating rich databases for documenting patients history and they potentially contain lots of patterns that could help in better management of the disease. However, these patterns are locked within free text (unstructured) portions of clinical documents and consequence in limiting health professionals to extract useful information from them and to finally perform Query and Answering (QA) process in an accurate way. The Information Extraction (IE) process requires Natural Language Processing (NLP) techniques to assign semantics to these patterns. Therefore, in this paper, we analyze the design of annotators for specific lung cancer concepts that can be integrated over Apache Unstructured Information Management Architecture (UIMA) framework. In addition, we explain the details of generation and storage of annotation outcomes.

</details>

<details>

<summary>2018-09-18 14:40:19 - A generalized financial time series forecasting model based on automatic feature engineering using genetic algorithms and support vector machine</summary>

- *Norberto Ritzmann Junior, Julio Cesar Nievola*

- `1809.06775v1` - [abs](http://arxiv.org/abs/1809.06775v1) - [pdf](http://arxiv.org/pdf/1809.06775v1)

> We propose the genetic algorithm for time window optimization, which is an embedded genetic algorithm (GA), to optimize the time window (TW) of the attributes using feature selection and support vector machine. This GA is evolved using the results of a trading simulation, and it determines the best TW for each technical indicator. An appropriate evaluation was conducted using a walk-forward trading simulation, and the trained model was verified to be generalizable for forecasting other stock data. The results show that using the GA to determine the TW can improve the rate of return, leading to better prediction models than those resulting from using the default TW.

</details>

<details>

<summary>2018-09-18 14:59:52 - Phase Transitions of the Typical Algorithmic Complexity of the Random Satisfiability Problem Studied with Linear Programming</summary>

- *Hendrik Schawe, Roman Bleim, Alexander K. Hartmann*

- `1702.02821v2` - [abs](http://arxiv.org/abs/1702.02821v2) - [pdf](http://arxiv.org/pdf/1702.02821v2)

> Here we study the NP-complete $K$-SAT problem. Although the worst-case complexity of NP-complete problems is conjectured to be exponential, there exist parametrized random ensembles of problems where solutions can typically be found in polynomial time for suitable ranges of the parameter. In fact, random $K$-SAT, with $\alpha=M/N $ as control parameter, can be solved quickly for small enough values of $\alpha$. It shows a phase transition between a satisfiable phase and an unsatisfiable phase. For branch and bound algorithms, which operate in the space of feasible Boolean configurations, the empirically hardest problems are located only close to this phase transition. Here we study $K$-SAT ($K=3,4$) and the related optimization problem MAX-SAT by a linear programming approach, which is widely used for practical problems and allows for polynomial run time. In contrast to branch and bound it operates outside the space of feasible configurations. On the other hand, finding a solution within polynomial time is not guaranteed. We investigated several variants like including artificial objective functions, so called cutting-plane approaches, and a mapping to the NP-complete vertex-cover problem. We observed several easy-hard transitions, from where the problems are typically solvable (in polynomial time) using the given algorithms, respectively, to where they are not solvable in polynomial time. For the related vertex-cover problem on random graphs these easy-hard transitions can be identified with structural properties of the graphs, like percolation transitions. For the present random $K$-SAT problem we have investigated numerous structural properties also exhibiting clear transitions, but they appear not be correlated to the here observed easy-hard transitions. This renders the behaviour of random $K$-SAT more complex than, e.g., the vertex-cover problem.

</details>

<details>

<summary>2018-09-18 19:08:03 - Global Constraint Catalog, Volume II, Time-Series Constraints</summary>

- *Ekaterina Arafailova, Nicolas Beldiceanu, Rémi Douence, Mats Carlsson, Pierre Flener, María Andreína Francisco Rodríguez, Justin Pearson, Helmut Simonis*

- `1609.08925v2` - [abs](http://arxiv.org/abs/1609.08925v2) - [pdf](http://arxiv.org/pdf/1609.08925v2)

> First this report presents a restricted set of finite transducers used to synthesise structural time-series constraints described by means of a multi-layered function composition scheme. Second it provides the corresponding synthesised catalogue of structural time-series constraints where each constraint is explicitly described in terms of automata with registers.

</details>

<details>

<summary>2018-09-19 02:49:53 - Revisiting Random Binning Features: Fast Convergence and Strong Parallelizability</summary>

- *Lingfei Wu, Ian E. H. Yen, Jie Chen, Rui Yan*

- `1809.05247v2` - [abs](http://arxiv.org/abs/1809.05247v2) - [pdf](http://arxiv.org/pdf/1809.05247v2)

> Kernel method has been developed as one of the standard approaches for nonlinear learning, which however, does not scale to large data set due to its quadratic complexity in the number of samples. A number of kernel approximation methods have thus been proposed in the recent years, among which the random features method gains much popularity due to its simplicity and direct reduction of nonlinear problem to a linear one. The Random Binning (RB) feature, proposed in the first random-feature paper \cite{rahimi2007random}, has drawn much less attention than the Random Fourier (RF) feature. In this work, we observe that the RB features, with right choice of optimization solver, could be orders-of-magnitude more efficient than other random features and kernel approximation methods under the same requirement of accuracy. We thus propose the first analysis of RB from the perspective of optimization, which by interpreting RB as a Randomized Block Coordinate Descent in the infinite-dimensional space, gives a faster convergence rate compared to that of other random features. In particular, we show that by drawing $R$ random grids with at least $\kappa$ number of non-empty bins per grid in expectation, RB method achieves a convergence rate of $O(1/(\kappa R))$, which not only sharpens its $O(1/\sqrt{R})$ rate from Monte Carlo analysis, but also shows a $\kappa$ times speedup over other random features under the same analysis framework. In addition, we demonstrate another advantage of RB in the L1-regularized setting, where unlike other random features, a RB-based Coordinate Descent solver can be parallelized with guaranteed speedup proportional to $\kappa$. Our extensive experiments demonstrate the superior performance of the RB features over other random features and kernel approximation methods. Our code and data is available at { \url{https://github.com/teddylfwu/RB_GEN}}.

</details>

<details>

<summary>2018-09-19 03:55:54 - Leveraging Contact Forces for Learning to Grasp</summary>

- *Hamza Merzic, Miroslav Bogdanovic, Daniel Kappler, Ludovic Righetti, Jeannette Bohg*

- `1809.07004v1` - [abs](http://arxiv.org/abs/1809.07004v1) - [pdf](http://arxiv.org/pdf/1809.07004v1)

> Grasping objects under uncertainty remains an open problem in robotics research. This uncertainty is often due to noisy or partial observations of the object pose or shape. To enable a robot to react appropriately to unforeseen effects, it is crucial that it continuously takes sensor feedback into account. While visual feedback is important for inferring a grasp pose and reaching for an object, contact feedback offers valuable information during manipulation and grasp acquisition. In this paper, we use model-free deep reinforcement learning to synthesize control policies that exploit contact sensing to generate robust grasping under uncertainty. We demonstrate our approach on a multi-fingered hand that exhibits more complex finger coordination than the commonly used two-fingered grippers. We conduct extensive experiments in order to assess the performance of the learned policies, with and without contact sensing. While it is possible to learn grasping policies without contact sensing, our results suggest that contact feedback allows for a significant improvement of grasping robustness under object pose uncertainty and for objects with a complex shape.

</details>

<details>

<summary>2018-09-19 05:23:11 - ClusterNet: 3D Instance Segmentation in RGB-D Images</summary>

- *Lin Shao, Ye Tian, Jeannette Bohg*

- `1807.08894v2` - [abs](http://arxiv.org/abs/1807.08894v2) - [pdf](http://arxiv.org/pdf/1807.08894v2)

> We propose a method for instance-level segmentation that uses RGB-D data as input and provides detailed information about the location, geometry and number of individual objects in the scene. This level of understanding is fundamental for autonomous robots. It enables safe and robust decision-making under the large uncertainty of the real-world. In our model, we propose to use the first and second order moments of the object occupancy function to represent an object instance. We train an hourglass Deep Neural Network (DNN) where each pixel in the output votes for the 3D position of the corresponding object center and for the object's size and pose. The final instance segmentation is achieved through clustering in the space of moments. The object-centric training loss is defined on the output of the clustering. Our method outperforms the state-of-the-art instance segmentation method on our synthesized dataset. We show that our method generalizes well on real-world data achieving visually better segmentation results.

</details>

<details>

<summary>2018-09-19 07:01:53 - The Key Concepts of Ethics of Artificial Intelligence - A Keyword based Systematic Mapping Study</summary>

- *Ville Vakkuri, Pekka Abrahamsson*

- `1809.07027v1` - [abs](http://arxiv.org/abs/1809.07027v1) - [pdf](http://arxiv.org/pdf/1809.07027v1)

> The growing influence and decision-making capacities of Autonomous systems and Artificial Intelligence in our lives force us to consider the values embedded in these systems. But how ethics should be implemented into these systems? In this study, the solution is seen on philosophical conceptualization as a framework to form practical implementation model for ethics of AI. To take the first steps on conceptualization main concepts used on the field needs to be identified. A keyword based Systematic Mapping Study (SMS) on the keywords used in AI and ethics was conducted to help in identifying, defying and comparing main concepts used in current AI ethics discourse. Out of 1062 papers retrieved SMS discovered 37 re-occurring keywords in 83 academic papers. We suggest that the focus on finding keywords is the first step in guiding and providing direction for future research in the AI ethics field.

</details>

<details>

<summary>2018-09-19 08:25:25 - Efficient and Scalable Batch Bayesian Optimization Using K-Means</summary>

- *Matthew Groves, Edward O. Pyzer-Knapp*

- `1806.01159v2` - [abs](http://arxiv.org/abs/1806.01159v2) - [pdf](http://arxiv.org/pdf/1806.01159v2)

> We present K-Means Batch Bayesian Optimization (KMBBO), a novel batch sampling algorithm for Bayesian Optimization (BO). KMBBO uses unsupervised learning to efficiently estimate peaks of the model acquisition function. We show in empirical experiments that our method outperforms the current state-of-the-art batch allocation algorithms on a variety of test problems including tuning of algorithm hyper-parameters and a challenging drug discovery problem. In order to accommodate the real-world problem of high dimensional data, we propose a modification to KMBBO by combining it with compressed sensing to project the optimization into a lower dimensional subspace. We demonstrate empirically that this 2-step method outperforms algorithms where no dimensionality reduction has taken place.

</details>

<details>

<summary>2018-09-19 08:46:34 - Prosocial or Selfish? Agents with different behaviors for Contract Negotiation using Reinforcement Learning</summary>

- *Vishal Sunder, Lovekesh Vig, Arnab Chatterjee, Gautam Shroff*

- `1809.07066v1` - [abs](http://arxiv.org/abs/1809.07066v1) - [pdf](http://arxiv.org/pdf/1809.07066v1)

> We present an effective technique for training deep learning agents capable of negotiating on a set of clauses in a contract agreement using a simple communication protocol. We use Multi Agent Reinforcement Learning to train both agents simultaneously as they negotiate with each other in the training environment. We also model selfish and prosocial behavior to varying degrees in these agents. Empirical evidence is provided showing consistency in agent behaviors. We further train a meta agent with a mixture of behaviors by learning an ensemble of different models using reinforcement learning. Finally, to ascertain the deployability of the negotiating agents, we conducted experiments pitting the trained agents against human players. Results demonstrate that the agents are able to hold their own against human players, often emerging as winners in the negotiation. Our experiments demonstrate that the meta agent is able to reasonably emulate human behavior.

</details>

<details>

<summary>2018-09-19 09:38:20 - Novelty-organizing team of classifiers in noisy and dynamic environments</summary>

- *Danilo Vasconcellos Vargas, Hirotaka Takano, Junichi Murata*

- `1809.07098v1` - [abs](http://arxiv.org/abs/1809.07098v1) - [pdf](http://arxiv.org/pdf/1809.07098v1)

> In the real world, the environment is constantly changing with the input variables under the effect of noise. However, few algorithms were shown to be able to work under those circumstances. Here, Novelty-Organizing Team of Classifiers (NOTC) is applied to the continuous action mountain car as well as two variations of it: a noisy mountain car and an unstable weather mountain car. These problems take respectively noise and change of problem dynamics into account. Moreover, NOTC is compared with NeuroEvolution of Augmenting Topologies (NEAT) in these problems, revealing a trade-off between the approaches. While NOTC achieves the best performance in all of the problems, NEAT needs less trials to converge. It is demonstrated that NOTC achieves better performance because of its division of the input space (creating easier problems). Unfortunately, this division of input space also requires a bit of time to bootstrap.

</details>

<details>

<summary>2018-09-19 10:16:52 - Talking to myself: self-dialogues as data for conversational agents</summary>

- *Joachim Fainberg, Ben Krause, Mihai Dobre, Marco Damonte, Emmanuel Kahembwe, Daniel Duma, Bonnie Webber, Federico Fancellu*

- `1809.06641v2` - [abs](http://arxiv.org/abs/1809.06641v2) - [pdf](http://arxiv.org/pdf/1809.06641v2)

> Conversational agents are gaining popularity with the increasing ubiquity of smart devices. However, training agents in a data driven manner is challenging due to a lack of suitable corpora. This paper presents a novel method for gathering topical, unstructured conversational data in an efficient way: self-dialogues through crowd-sourcing. Alongside this paper, we include a corpus of 3.6 million words across 23 topics. We argue the utility of the corpus by comparing self-dialogues with standard two-party conversations as well as data from other corpora.

</details>

<details>

<summary>2018-09-19 12:18:10 - A survey of advances in epistemic logic program solvers</summary>

- *Anthony P. Leclerc, Patrick Thor Kahl*

- `1809.07141v1` - [abs](http://arxiv.org/abs/1809.07141v1) - [pdf](http://arxiv.org/pdf/1809.07141v1)

> Recent research in extensions of Answer Set Programming has included a renewed interest in the language of Epistemic Specifications, which adds modal operators K ("known") and M ("may be true") to provide for more powerful introspective reasoning and enhanced capability, particularly when reasoning with incomplete information. An epistemic logic program is a set of rules in this language. Infused with the research has been the desire for an efficient solver to enable the practical use of such programs for problem solving. In this paper, we report on the current state of development of epistemic logic program solvers.

</details>

<details>

<summary>2018-09-19 12:45:38 - Learning Probabilistic Logic Programs in Continuous Domains</summary>

- *Stefanie Speichert, Vaishak Belle*

- `1807.05527v2` - [abs](http://arxiv.org/abs/1807.05527v2) - [pdf](http://arxiv.org/pdf/1807.05527v2)

> The field of statistical relational learning aims at unifying logic and probability to reason and learn from data. Perhaps the most successful paradigm in the field is probabilistic logic programming: the enabling of stochastic primitives in logic programming, which is now increasingly seen to provide a declarative background to complex machine learning applications. While many systems offer inference capabilities, the more significant challenge is that of learning meaningful and interpretable symbolic representations from data. In that regard, inductive logic programming and related techniques have paved much of the way for the last few decades.   Unfortunately, a major limitation of this exciting landscape is that much of the work is limited to finite-domain discrete probability distributions. Recently, a handful of systems have been extended to represent and perform inference with continuous distributions. The problem, of course, is that classical solutions for inference are either restricted to well-known parametric families (e.g., Gaussians) or resort to sampling strategies that provide correct answers only in the limit. When it comes to learning, moreover, inducing representations remains entirely open, other than "data-fitting" solutions that force-fit points to aforementioned parametric families.   In this paper, we take the first steps towards inducing probabilistic logic programs for continuous and mixed discrete-continuous data, without being pigeon-holed to a fixed set of distribution families. Our key insight is to leverage techniques from piecewise polynomial function approximation theory, yielding a principled way to learn and compositionally construct density functions. We test the framework and discuss the learned representations.

</details>

<details>

<summary>2018-09-19 13:13:20 - Tractable Querying and Learning in Hybrid Domains via Sum-Product Networks</summary>

- *Andreas Bueff, Stefanie Speichert, Vaishak Belle*

- `1807.05464v3` - [abs](http://arxiv.org/abs/1807.05464v3) - [pdf](http://arxiv.org/pdf/1807.05464v3)

> Probabilistic representations, such as Bayesian and Markov networks, are fundamental to much of statistical machine learning. Thus, learning probabilistic representations directly from data is a deep challenge, the main computational bottleneck being inference that is intractable. Tractable learning is a powerful new paradigm that attempts to learn distributions that support efficient probabilistic querying. By leveraging local structure, representations such as sum-product networks (SPNs) can capture high tree-width models with many hidden layers, essentially a deep architecture, while still admitting a range of probabilistic queries to be computable in time polynomial in the network size. The leaf nodes in SPNs, from which more intricate mixtures are formed, are tractable univariate distributions, and so the literature has focused on Bernoulli and Gaussian random variables. This is clearly a restriction for handling mixed discrete-continuous data, especially if the continuous features are generated from non-parametric and non-Gaussian distribution families. In this work, we present a framework that systematically integrates SPN structure learning with weighted model integration, a recently introduced computational abstraction for performing inference in hybrid domains, by means of piecewise polynomial approximations of density functions of arbitrary shape. Our framework is instantiated by exploiting the notion of propositional abstractions, thus minimally interfering with the SPN structure learning module, and supports a powerful query interface for conditioning on interval constraints. Our empirical results show that our approach is effective, and allows a study of the trade off between the granularity of the learned model and its predictive power.

</details>

<details>

<summary>2018-09-19 14:58:04 - Learning Neural Parsers with Deterministic Differentiable Imitation Learning</summary>

- *Tanmay Shankar, Nicholas Rhinehart, Katharina Muelling, Kris M. Kitani*

- `1806.07822v2` - [abs](http://arxiv.org/abs/1806.07822v2) - [pdf](http://arxiv.org/pdf/1806.07822v2)

> We explore the problem of learning to decompose spatial tasks into segments, as exemplified by the problem of a painting robot covering a large object. Inspired by the ability of classical decision tree algorithms to construct structured partitions of their input spaces, we formulate the problem of decomposing objects into segments as a parsing approach. We make the insight that the derivation of a parse-tree that decomposes the object into segments closely resembles a decision tree constructed by ID3, which can be done when the ground-truth available. We learn to imitate an expert parsing oracle, such that our neural parser can generalize to parse natural images without ground truth. We introduce a novel deterministic policy gradient update, DRAG (i.e., DeteRministically AGgrevate) in the form of a deterministic actor-critic variant of AggreVaTeD, to train our neural parser. From another perspective, our approach is a variant of the Deterministic Policy Gradient suitable for the imitation learning setting. The deterministic policy representation offered by training our neural parser with DRAG allows it to outperform state of the art imitation and reinforcement learning approaches.

</details>

<details>

<summary>2018-09-19 14:58:43 - Autonomous Driving System Design for Formula Student Driverless Racecar</summary>

- *Hanqing Tian, Jun Ni, Jibin Hu*

- `1809.07636v1` - [abs](http://arxiv.org/abs/1809.07636v1) - [pdf](http://arxiv.org/pdf/1809.07636v1)

> This paper summarizes the work of building the autonomous system including detection system and path tracking controller for a formula student autonomous racecar. A LIDAR-vision cooperating method of detecting traffic cone which is used as track mark is proposed. Detection algorithm of the racecar also implements a precise and high rate localization method which combines the GPS-INS data and LIDAR odometry. Besides, a track map including the location and color information of the cones is built simultaneously. Finally, the system and vehicle performance on a closed loop track is tested. This paper also briefly introduces the Formula Student Autonomous Competition (FSAC) in 2017.

</details>

<details>

<summary>2018-09-19 18:00:51 - A Generalized Representer Theorem for Hilbert Space - Valued Functions</summary>

- *Sanket Diwale, Colin Jones*

- `1809.07347v1` - [abs](http://arxiv.org/abs/1809.07347v1) - [pdf](http://arxiv.org/pdf/1809.07347v1)

> The necessary and sufficient conditions for existence of a generalized representer theorem are presented for learning Hilbert space-valued functions. Representer theorems involving explicit basis functions and Reproducing Kernels are a common occurrence in various machine learning algorithms like generalized least squares, support vector machines, Gaussian process regression and kernel based deep neural networks to name a few. Due to the more general structure of the underlying variational problems, the theory is also relevant to other application areas like optimal control, signal processing and decision making. We present the generalized representer as a unified view for supervised and semi-supervised learning methods, using the theory of linear operators and subspace valued maps. The implications of the theorem are presented with examples of multi input-multi output regression, kernel based deep neural networks, stochastic regression and sparsity learning problems as being special cases in this unified view.

</details>

<details>

<summary>2018-09-19 19:11:15 - DiCE: The Infinitely Differentiable Monte-Carlo Estimator</summary>

- *Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim Rocktäschel, Eric P. Xing, Shimon Whiteson*

- `1802.05098v3` - [abs](http://arxiv.org/abs/1802.05098v3) - [pdf](http://arxiv.org/pdf/1802.05098v3)

> The score function estimator is widely used for estimating gradients of stochastic objectives in stochastic computation graphs (SCG), eg, in reinforcement learning and meta-learning. While deriving the first-order gradient estimators by differentiating a surrogate loss (SL) objective is computationally and conceptually simple, using the same approach for higher-order derivatives is more challenging. Firstly, analytically deriving and implementing such estimators is laborious and not compliant with automatic differentiation. Secondly, repeatedly applying SL to construct new objectives for each order derivative involves increasingly cumbersome graph manipulations. Lastly, to match the first-order gradient under differentiation, SL treats part of the cost as a fixed sample, which we show leads to missing and wrong terms for estimators of higher-order derivatives. To address all these shortcomings in a unified way, we introduce DiCE, which provides a single objective that can be differentiated repeatedly, generating correct estimators of derivatives of any order in SCGs. Unlike SL, DiCE relies on automatic differentiation for performing the requisite graph manipulations. We verify the correctness of DiCE both through a proof and numerical evaluation of the DiCE derivative estimates. We also use DiCE to propose and evaluate a novel approach for multi-agent learning. Our code is available at https://www.github.com/alshedivat/lola.

</details>

<details>

<summary>2018-09-19 19:22:48 - Learning with Opponent-Learning Awareness</summary>

- *Jakob N. Foerster, Richard Y. Chen, Maruan Al-Shedivat, Shimon Whiteson, Pieter Abbeel, Igor Mordatch*

- `1709.04326v4` - [abs](http://arxiv.org/abs/1709.04326v4) - [pdf](http://arxiv.org/pdf/1709.04326v4)

> Multi-agent settings are quickly gathering importance in machine learning. This includes a plethora of recent work on deep multi-agent reinforcement learning, but also can be extended to hierarchical RL, generative adversarial networks and decentralised optimisation. In all these settings the presence of multiple learning agents renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method in which each agent shapes the anticipated learning of the other agents in the environment. The LOLA learning rule includes a term that accounts for the impact of one agent's policy on the anticipated parameter update of the other agents. Results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to repeated matching pennies, LOLA agents converge to the Nash equilibrium. In a round robin tournament we show that LOLA agents successfully shape the learning of a range of multi-agent learning algorithms from literature, resulting in the highest average returns on the IPD. We also show that the LOLA update rule can be efficiently calculated using an extension of the policy gradient estimator, making the method suitable for model-free RL. The method thus scales to large parameter and input spaces and nonlinear function approximators. We apply LOLA to a grid world task with an embedded social dilemma using recurrent policies and opponent modelling. By explicitly considering the learning of the other agent, LOLA agents learn to cooperate out of self-interest. The code is at github.com/alshedivat/lola.

</details>

<details>

<summary>2018-09-19 20:01:10 - Cognitive Consistency Routing Algorithm of Capsule-network</summary>

- *Huayu Li*

- `1808.09062v3` - [abs](http://arxiv.org/abs/1808.09062v3) - [pdf](http://arxiv.org/pdf/1808.09062v3)

> Artificial Neural Networks (ANNs) are computational models inspired by the central nervous system (especially the brain) of animals and are used to estimate or generate unknown approximation functions relied on large amounts of inputs. Capsule Neural Network (Sabour S, et al.[2017]) is a novel structure of Convolutional Neural Networks which simulates the visual processing system of human brain. In this paper, we introduce psychological theories which called Cognitive Consistency to optimize the routing algorithm of Capsnet to make it more close to the work pattern of human brain. It has been shown in the experiment that a progress had been made compared with the baseline.

</details>

<details>

<summary>2018-09-19 20:22:28 - Towards the Development of a Rule-based Drought Early Warning Expert Systems using Indigenous Knowledge</summary>

- *A. K. Akanbi, M. Masinde*

- `1809.08101v1` - [abs](http://arxiv.org/abs/1809.08101v1) - [pdf](http://arxiv.org/pdf/1809.08101v1)

> Drought forecasting and prediction is a complicated process due to the complexity and scalability of the environmental parameters involved. Hence, it required a high level of expertise to predict. In this paper, we describe the research and development of a rule-based drought early warning expert systems (RB-DEWES) for forecasting drought using local indigenous knowledge obtained from domain experts. The system generates inference by using rule set and provides drought advisory information with attributed certainty factor (CF) based on the user's input. The system is believed to be the first expert system for drought forecasting to use local indigenous knowledge on drought. The architecture and components such as knowledge base, JESS inference engine and model base of the system and their functions are presented.

</details>

<details>

<summary>2018-09-19 22:03:32 - Machine Translation Evaluation Resources and Methods: A Survey</summary>

- *Lifeng Han*

- `1605.04515v8` - [abs](http://arxiv.org/abs/1605.04515v8) - [pdf](http://arxiv.org/pdf/1605.04515v8)

> We introduce the Machine Translation (MT) evaluation survey that contains both manual and automatic evaluation methods. The traditional human evaluation criteria mainly include the intelligibility, fidelity, fluency, adequacy, comprehension, and informativeness. The advanced human assessments include task-oriented measures, post-editing, segment ranking, and extended criteriea, etc. We classify the automatic evaluation methods into two categories, including lexical similarity scenario and linguistic features application. The lexical similarity methods contain edit distance, precision, recall, F-measure, and word order. The linguistic features can be divided into syntactic features and semantic features respectively. The syntactic features include part of speech tag, phrase types and sentence structures, and the semantic features include named entity, synonyms, textual entailment, paraphrase, semantic roles, and language models. The deep learning models for evaluation are very newly proposed. Subsequently, we also introduce the evaluation methods for MT evaluation including different correlation scores, and the recent quality estimation (QE) tasks for MT.   This paper differs from the existing works \cite{GALEprogram2009,EuroMatrixProject2007} from several aspects, by introducing some recent development of MT evaluation measures, the different classifications from manual to automatic evaluation measures, the introduction of recent QE tasks of MT, and the concise construction of the content.   We hope this work will be helpful for MT researchers to easily pick up some metrics that are best suitable for their specific MT model development, and help MT evaluation researchers to get a general clue of how MT evaluation research developed. Furthermore, hopefully, this work can also shine some light on other evaluation tasks, except for translation, of NLP fields.

</details>

<details>

<summary>2018-09-19 22:53:46 - Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing System Failure</summary>

- *Besmira Nushi, Ece Kamar, Eric Horvitz*

- `1809.07424v1` - [abs](http://arxiv.org/abs/1809.07424v1) - [pdf](http://arxiv.org/pdf/1809.07424v1)

> As machine learning systems move from computer-science laboratories into the open world, their accountability becomes a high priority problem. Accountability requires deep understanding of system behavior and its failures. Current evaluation methods such as single-score error metrics and confusion matrices provide aggregate views of system performance that hide important shortcomings. Understanding details about failures is important for identifying pathways for refinement, communicating the reliability of systems in different settings, and for specifying appropriate human oversight and engagement. Characterization of failures and shortcomings is particularly complex for systems composed of multiple machine learned components. For such systems, existing evaluation methods have limited expressiveness in describing and explaining the relationship among input content, the internal states of system components, and final output quality. We present Pandora, a set of hybrid human-machine methods and tools for describing and explaining system failures. Pandora leverages both human and system-generated observations to summarize conditions of system malfunction with respect to the input content and system architecture. We share results of a case study with a machine learning pipeline for image captioning that show how detailed performance views can be beneficial for analysis and debugging.

</details>

<details>

<summary>2018-09-20 00:07:27 - Predicting Periodicity with Temporal Difference Learning</summary>

- *Kristopher De Asis, Brendan Bennett, Richard S. Sutton*

- `1809.07435v1` - [abs](http://arxiv.org/abs/1809.07435v1) - [pdf](http://arxiv.org/pdf/1809.07435v1)

> Temporal difference (TD) learning is an important approach in reinforcement learning, as it combines ideas from dynamic programming and Monte Carlo methods in a way that allows for online and incremental model-free learning. A key idea of TD learning is that it is learning predictive knowledge about the environment in the form of value functions, from which it can derive its behavior to address long-term sequential decision making problems. The agent's horizon of interest, that is, how immediate or long-term a TD learning agent predicts into the future, is adjusted through a discount rate parameter. In this paper, we introduce an alternative view on the discount rate, with insight from digital signal processing, to include complex-valued discounting. Our results show that setting the discount rate to appropriately chosen complex numbers allows for online and incremental estimation of the Discrete Fourier Transform (DFT) of a signal of interest with TD learning. We thereby extend the types of knowledge representable by value functions, which we show are particularly useful for identifying periodic effects in the reward sequence.

</details>

<details>

<summary>2018-09-20 02:26:38 - Federated AI for building AI Solutions across Multiple Agencies</summary>

- *Dinesh Verma, Simon Julier, Greg Cirincione*

- `1809.10036v1` - [abs](http://arxiv.org/abs/1809.10036v1) - [pdf](http://arxiv.org/pdf/1809.10036v1)

> The different sets of regulations existing for differ-ent agencies within the government make the task of creating AI enabled solutions in government dif-ficult. Regulatory restrictions inhibit sharing of da-ta across different agencies, which could be a significant impediment to training AI models. We discuss the challenges that exist in environments where data cannot be freely shared and assess tech-nologies which can be used to work around these challenges. We present results on building AI models using the concept of federated AI, which al-lows creation of models without moving the training data around.

</details>

<details>

<summary>2018-09-20 05:27:47 - Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter</summary>

- *Jiachen Li, Wei Zhan, Masayoshi Tomizuka*

- `1809.10237v1` - [abs](http://arxiv.org/abs/1809.10237v1) - [pdf](http://arxiv.org/pdf/1809.10237v1)

> Accurate and robust tracking of surrounding road participants plays an important role in autonomous driving. However, there is usually no prior knowledge of the number of tracking targets due to object emergence, object disappearance and false alarms. To overcome this challenge, we propose a generic vehicle tracking framework based on modified mixture particle filter, which can make the number of tracking targets adaptive to real-time observations and track all the vehicles within sensor range simultaneously in a uniform architecture without explicit data association. Each object corresponds to a mixture component whose distribution is non-parametric and approximated by particle hypotheses. Most tracking approaches employ vehicle kinematic models as the prediction model. However, it is hard for these models to make proper predictions when sensor measurements are lost or become low quality due to partial or complete occlusions. Moreover, these models are incapable of forecasting sudden maneuvers. To address these problems, we propose to incorporate learning-based behavioral models instead of pure vehicle kinematic models to realize prediction in the prior update of recursive Bayesian state estimation. Two typical driving scenarios including lane keeping and lane change are demonstrated to verify the effectiveness and accuracy of the proposed framework as well as the advantages of employing learning-based models.

</details>

<details>

<summary>2018-09-20 07:08:38 - MASON: A Model AgnoStic ObjectNess Framework</summary>

- *K J Joseph, Vineeth N Balasubramanian*

- `1809.07499v1` - [abs](http://arxiv.org/abs/1809.07499v1) - [pdf](http://arxiv.org/pdf/1809.07499v1)

> This paper proposes a simple, yet very effective method to localize dominant foreground objects in an image, to pixel-level precision. The proposed method 'MASON' (Model-AgnoStic ObjectNess) uses a deep convolutional network to generate category-independent and model-agnostic heat maps for any image. The network is not explicitly trained for the task, and hence, can be used off-the-shelf in tandem with any other network or task. We show that this framework scales to a wide variety of images, and illustrate the effectiveness of MASON in three varied application contexts.

</details>

<details>

<summary>2018-09-20 07:16:33 - Human activity recognition based on time series analysis using U-Net</summary>

- *Yong Zhang, Yu Zhang, Zhao Zhang, Jie Bao, Yunpeng Song*

- `1809.08113v1` - [abs](http://arxiv.org/abs/1809.08113v1) - [pdf](http://arxiv.org/pdf/1809.08113v1)

> Traditional human activity recognition (HAR) based on time series adopts sliding window analysis method. This method faces the multi-class window problem which mistakenly labels different classes of sampling points within a window as a class. In this paper, a HAR algorithm based on U-Net is proposed to perform activity labeling and prediction at each sampling point. The activity data of the triaxial accelerometer is mapped into an image with the single pixel column and multi-channel which is input into the U-Net network for training and recognition. Our proposal can complete the pixel-level gesture recognition function. The method does not need manual feature extraction and can effectively identify short-term behaviors in long-term activity sequences. We collected the Sanitation dataset and tested the proposed scheme with four open data sets. The experimental results show that compared with Support Vector Machine (SVM), k-Nearest Neighbor (kNN), Decision Tree(DT), Quadratic Discriminant Analysis (QDA), Convolutional Neural Network (CNN) and Fully Convolutional Networks (FCN) methods, our proposal has the highest accuracy and F1-socre in each dataset, and has stable performance and high robustness. At the same time, after the U-Net has finished training, our proposal can achieve fast enough recognition speed.

</details>

<details>

<summary>2018-09-20 07:18:57 - C4Synth: Cross-Caption Cycle-Consistent Text-to-Image Synthesis</summary>

- *K J Joseph, Arghya Pal, Sailaja Rajanala, Vineeth N Balasubramanian*

- `1809.10238v1` - [abs](http://arxiv.org/abs/1809.10238v1) - [pdf](http://arxiv.org/pdf/1809.10238v1)

> Generating an image from its description is a challenging task worth solving because of its numerous practical applications ranging from image editing to virtual reality. All existing methods use one single caption to generate a plausible image. A single caption by itself, can be limited, and may not be able to capture the variety of concepts and behavior that may be present in the image. We propose two deep generative models that generate an image by making use of multiple captions describing it. This is achieved by ensuring 'Cross-Caption Cycle Consistency' between the multiple captions and the generated image(s). We report quantitative and qualitative results on the standard Caltech-UCSD Birds (CUB) and Oxford-102 Flowers datasets to validate the efficacy of the proposed approach.

</details>

<details>

<summary>2018-09-20 11:20:11 - Symbolic Music Genre Transfer with CycleGAN</summary>

- *Gino Brunner, Yuyi Wang, Roger Wattenhofer, Sumu Zhao*

- `1809.07575v1` - [abs](http://arxiv.org/abs/1809.07575v1) - [pdf](http://arxiv.org/pdf/1809.07575v1)

> Deep generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have recently been applied to style and domain transfer for images, and in the case of VAEs, music. GAN-based models employing several generators and some form of cycle consistency loss have been among the most successful for image domain transfer. In this paper we apply such a model to symbolic music and show the feasibility of our approach for music genre transfer. Evaluations using separate genre classifiers show that the style transfer works well. In order to improve the fidelity of the transformed music, we add additional discriminators that cause the generators to keep the structure of the original music mostly intact, while still achieving strong genre transfer. Visual and audible results further show the potential of our approach. To the best of our knowledge, this paper represents the first application of GANs to symbolic music domain transfer.

</details>

<details>

<summary>2018-09-20 12:32:47 - Deep Domain Adaptation under Deep Label Scarcity</summary>

- *Amar Prakash Azad, Dinesh Garg, Priyanka Agrawal, Arun Kumar*

- `1809.08097v1` - [abs](http://arxiv.org/abs/1809.08097v1) - [pdf](http://arxiv.org/pdf/1809.08097v1)

> The goal behind Domain Adaptation (DA) is to leverage the labeled examples from a source domain so as to infer an accurate model in a target domain where labels are not available or in scarce at the best. A state-of-the-art approach for the DA is due to (Ganin et al. 2016), known as DANN, where they attempt to induce a common representation of source and target domains via adversarial training. This approach requires a large number of labeled examples from the source domain to be able to infer a good model for the target domain. However, in many situations obtaining labels in the source domain is expensive which results in deteriorated performance of DANN and limits its applicability in such scenarios. In this paper, we propose a novel approach to overcome this limitation. In our work, we first establish that DANN reduces the original DA problem into a semi-supervised learning problem over the space of common representation. Next, we propose a learning approach, namely TransDANN, that amalgamates adversarial learning and transductive learning to mitigate the detrimental impact of limited source labels and yields improved performance. Experimental results (both on text and images) show a significant boost in the performance of TransDANN over DANN under such scenarios. We also provide theoretical justification for the performance boost.

</details>

<details>

<summary>2018-09-20 12:39:27 - Multiple-Step Greedy Policies in Online and Approximate Reinforcement Learning</summary>

- *Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor*

- `1805.07956v2` - [abs](http://arxiv.org/abs/1805.07956v2) - [pdf](http://arxiv.org/pdf/1805.07956v2)

> Multiple-step lookahead policies have demonstrated high empirical competence in Reinforcement Learning, via the use of Monte Carlo Tree Search or Model Predictive Control. In a recent work \cite{efroni2018beyond}, multiple-step greedy policies and their use in vanilla Policy Iteration algorithms were proposed and analyzed. In this work, we study multiple-step greedy algorithms in more practical setups. We begin by highlighting a counter-intuitive difficulty, arising with soft-policy updates: even in the absence of approximations, and contrary to the 1-step-greedy case, monotonic policy improvement is not guaranteed unless the update stepsize is sufficiently large. Taking particular care about this difficulty, we formulate and analyze online and approximate algorithms that use such a multi-step greedy operator.

</details>

<details>

<summary>2018-09-20 15:09:11 - A Generic Framework for Interesting Subspace Cluster Detection in Multi-attributed Networks</summary>

- *Feng Chen, Baojian Zhou, Adil Alim, Liang Zhao*

- `1709.05246v2` - [abs](http://arxiv.org/abs/1709.05246v2) - [pdf](http://arxiv.org/pdf/1709.05246v2)

> Detection of interesting (e.g., coherent or anomalous) clusters has been studied extensively on plain or univariate networks, with various applications. Recently, algorithms have been extended to networks with multiple attributes for each node in the real-world. In a multi-attributed network, often, a cluster of nodes is only interesting for a subset (subspace) of attributes, and this type of clusters is called subspace clusters. However, in the current literature, few methods are capable of detecting subspace clusters, which involves concurrent feature selection and network cluster detection. These relevant methods are mostly heuristic-driven and customized for specific application scenarios.   In this work, we present a generic and theoretical framework for detection of interesting subspace clusters in large multi-attributed networks. Specifically, we propose a subspace graph-structured matching pursuit algorithm, namely, SG-Pursuit, to address a broad class of such problems for different score functions (e.g., coherence or anomalous functions) and topology constraints (e.g., connected subgraphs and dense subgraphs). We prove that our algorithm 1) runs in nearly-linear time on the network size and the total number of attributes and 2) enjoys rigorous guarantees (geometrical convergence rate and tight error bound) analogous to those of the state-of-the-art algorithms for sparse feature selection problems and subgraph detection problems. As a case study, we specialize SG-Pursuit to optimize a number of well-known score functions for two typical tasks, including detection of coherent dense and anomalous connected subspace clusters in real-world networks. Empirical evidence demonstrates that our proposed generic algorithm SG-Pursuit performs superior over state-of-the-art methods that are designed specifically for these two tasks.

</details>

<details>

<summary>2018-09-20 16:46:04 - Benchmarking Reinforcement Learning Algorithms on Real-World Robots</summary>

- *A. Rupam Mahmood, Dmytro Korenkevych, Gautham Vasan, William Ma, James Bergstra*

- `1809.07731v1` - [abs](http://arxiv.org/abs/1809.07731v1) - [pdf](http://arxiv.org/pdf/1809.07731v1)

> Through many recent successes in simulation, model-free reinforcement learning has emerged as a promising approach to solving continuous control robotic tasks. The research community is now able to reproduce, analyze and build quickly on these results due to open source implementations of learning algorithms and simulated benchmark tasks. To carry forward these successes to real-world applications, it is crucial to withhold utilizing the unique advantages of simulations that do not transfer to the real world and experiment directly with physical robots. However, reinforcement learning research with physical robots faces substantial resistance due to the lack of benchmark tasks and supporting source code. In this work, we introduce several reinforcement learning tasks with multiple commercially available robots that present varying levels of learning difficulty, setup, and repeatability. On these tasks, we test the learning performance of off-the-shelf implementations of four reinforcement learning algorithms and analyze sensitivity to their hyper-parameters to determine their readiness for applications in various real-world tasks. Our results show that with a careful setup of the task interface and computations, some of these implementations can be readily applicable to physical robots. We find that state-of-the-art learning algorithms are highly sensitive to their hyper-parameters and their relative ordering does not transfer across tasks, indicating the necessity of re-tuning them for each task for best performance. On the other hand, the best hyper-parameter configuration from one task may often result in effective learning on held-out tasks even with different robots, providing a reasonable default. We make the benchmark tasks publicly available to enhance reproducibility in real-world reinforcement learning.

</details>

<details>

<summary>2018-09-20 17:36:24 - Spline-Based Probability Calibration</summary>

- *Brian Lucena*

- `1809.07751v1` - [abs](http://arxiv.org/abs/1809.07751v1) - [pdf](http://arxiv.org/pdf/1809.07751v1)

> In many classification problems it is desirable to output well-calibrated probabilities on the different classes. We propose a robust, non-parametric method of calibrating probabilities called SplineCalib that utilizes smoothing splines to determine a calibration function. We demonstrate how applying certain transformations as part of the calibration process can improve performance on problems in deep learning and other domains where the scores tend to be "overconfident". We adapt the approach to multi-class problems and find that better calibration can improve accuracy as well as log-loss by better resolving uncertain cases. Finally, we present a cross-validated approach to calibration which conserves data. Significant improvements to log-loss and accuracy are shown on several different problems. We also introduce the ml-insights python package which contains an implementation of the SplineCalib algorithm.

</details>

<details>

<summary>2018-09-20 18:12:51 - IASIS and BigMedilytics: Towards personalized medicine in Europe</summary>

- *Ernestina Menasalvas Ruiz, Alejandro Rodríguez-González, Consuelo Gonzalo Martín, Massimiliano Zanin, Juan Manuel Tuñas, Mariano Provencio, Maria Torrente, Fabio Franco, Virginia Calvo, Beatriz Nuñez*

- `1809.07784v1` - [abs](http://arxiv.org/abs/1809.07784v1) - [pdf](http://arxiv.org/pdf/1809.07784v1)

> One field of application of Big Data and Artificial Intelligence that is receiving increasing attention is the biomedical domain. The huge volume of data that is customary generated by hospitals and pharmaceutical companies all over the world could potentially enable a plethora of new applications. Yet, due to the complexity of such data, this comes at a high cost. We here review the activities of the research group composed by people of the Universidad Polit\'ecnica de Madrid and the Hospital Universitario Puerta de Hierro de Majadahonda, Spain; discuss their activities within two European projects, IASIS and BigMedilytics; and present some initial results.

</details>

<details>

<summary>2018-09-20 20:29:56 - Bias Amplification in Artificial Intelligence Systems</summary>

- *Kirsten Lloyd*

- `1809.07842v1` - [abs](http://arxiv.org/abs/1809.07842v1) - [pdf](http://arxiv.org/pdf/1809.07842v1)

> As Artificial Intelligence (AI) technologies proliferate, concern has centered around the long-term dangers of job loss or threats of machines causing harm to humans. All of this concern, however, detracts from the more pertinent and already existing threats posed by AI today: its ability to amplify bias found in training datasets, and swiftly impact marginalized populations at scale. Government and public sector institutions have a responsibility to citizens to establish a dialogue with technology developers and release thoughtful policy around data standards to ensure diverse representation in datasets to prevent bias amplification and ensure that AI systems are built with inclusion in mind.

</details>

<details>

<summary>2018-09-20 20:31:45 - Towards automated neural design: An open source, distributed neural architecture research framework</summary>

- *George Kyriakides, Konstantinos Margaritis*

- `1810.08648v1` - [abs](http://arxiv.org/abs/1810.08648v1) - [pdf](http://arxiv.org/pdf/1810.08648v1)

> NORD (Neural Operations Research & Development) is an open source distributed deep learning architectural research framework, based on PyTorch, MPI and Horovod. It aims to make research of deep architectures easier for experts of different domains, in order to accelerate the process of finding better architectures, as well as study the best architectures generated for different datasets. Although currently under heavy development, the framework aims to allow the easy implementation of different design and optimization method families (optimization algorithms, meta-heuristics, reinforcement learning etc.) as well as the fair comparison between them. Furthermore, due to the computational resources required in order to optimize and evaluate network architectures, it leverage the use of distributed computing, while aiming to minimize the researcher's overhead required to implement it. Moreover, it strives to make the creation of architectures more intuitive, by implementing network descriptors, allowing to separately define the architecture's nodes and connections. In this paper, we present the framework's current state of development, while presenting its basic concepts, providing simple examples as well as their experimental results.

</details>

<details>

<summary>2018-09-20 22:15:06 - Uncertainty Aware AI ML: Why and How</summary>

- *Lance Kaplan, Federico Cerutti, Murat Sensoy, Alun Preece, Paul Sullivan*

- `1809.07882v1` - [abs](http://arxiv.org/abs/1809.07882v1) - [pdf](http://arxiv.org/pdf/1809.07882v1)

> This paper argues the need for research to realize uncertainty-aware artificial intelligence and machine learning (AI\&ML) systems for decision support by describing a number of motivating scenarios. Furthermore, the paper defines uncertainty-awareness and lays out the challenges along with surveying some promising research directions. A theoretical demonstration illustrates how two emerging uncertainty-aware ML and AI technologies could be integrated and be of value for a route planning operation.

</details>

<details>

<summary>2018-09-21 01:50:44 - Internal node bagging</summary>

- *Shun Yi*

- `1805.00215v5` - [abs](http://arxiv.org/abs/1805.00215v5) - [pdf](http://arxiv.org/pdf/1805.00215v5)

> We introduce a novel view to understand how dropout works as an inexplicit ensemble learning method, which doesn't point out how many and which nodes to learn a certain feature. We propose a new training method named internal node bagging, it explicitly forces a group of nodes to learn a certain feature in training time, and combine those nodes to be one node in inference time. It means we can use much more parameters to improve model's fitting ability in training time while keeping model small in inference time. We test our method on several benchmark datasets and find it performs significantly better than dropout on small models.

</details>

<details>

<summary>2018-09-21 02:04:16 - Secure Phrase Search for Intelligent Processing of Encrypted Data in Cloud-Based IoT</summary>

- *Meng Shen, Baoli Ma, Liehuang Zhu, Xiaojiang Du, Ke Xu*

- `1809.07914v1` - [abs](http://arxiv.org/abs/1809.07914v1) - [pdf](http://arxiv.org/pdf/1809.07914v1)

> Phrase search allows retrieval of documents containing an exact phrase, which plays an important role in many machine learning applications for cloud-based IoT, such as intelligent medical data analytics. In order to protect sensitive information from being leaked by service providers, documents (e.g., clinic records) are usually encrypted by data owners before being outsourced to the cloud. This, however, makes the search operation an extremely challenging task. Existing searchable encryption schemes for multi-keyword search operations fail to perform phrase search, as they are unable to determine the location relationship of multiple keywords in a queried phrase over encrypted data on the cloud server side. In this paper, we propose P3, an efficient privacy-preserving phrase search scheme for intelligent encrypted data processing in cloud-based IoT. Our scheme exploits the homomorphic encryption and bilinear map to determine the location relationship of multiple queried keywords over encrypted data. It also utilizes a probabilistic trapdoor generation algorithm to protect users search patterns. Thorough security analysis demonstrates the security guarantees achieved by P3. We implement a prototype and conduct extensive experiments on real-world datasets. The evaluation results show that compared with existing multikeyword search schemes, P3 can greatly improve the search accuracy with moderate overheads.

</details>

<details>

<summary>2018-09-21 05:31:26 - Target Transfer Q-Learning and Its Convergence Analysis</summary>

- *Yue Wang, Qi Meng, Wei Cheng, Yuting Liug, Zhi-Ming Ma, Tie-Yan Liu*

- `1809.08923v1` - [abs](http://arxiv.org/abs/1809.08923v1) - [pdf](http://arxiv.org/pdf/1809.08923v1)

> Q-learning is one of the most popular methods in Reinforcement Learning (RL). Transfer Learning aims to utilize the learned knowledge from source tasks to help new tasks to improve the sample complexity of the new tasks. Considering that data collection in RL is both more time and cost consuming and Q-learning converges slowly comparing to supervised learning, different kinds of transfer RL algorithms are designed. However, most of them are heuristic with no theoretical guarantee of the convergence rate. Therefore, it is important for us to clearly understand when and how will transfer learning help RL method and provide the theoretical guarantee for the improvement of the sample complexity. In this paper, we propose to transfer the Q-function learned in the source task to the target of the Q-learning in the new task when certain safe conditions are satisfied. We call this new transfer Q-learning method target transfer Q-Learning. The safe conditions are necessary to avoid the harm to the new tasks and thus ensure the convergence of the algorithm. We study the convergence rate of the target transfer Q-learning. We prove that if the two tasks are similar with respect to the MDPs, the optimal Q-functions in the source and new RL tasks are similar which means the error of the transferred target Q-function in new MDP is small. Also, the convergence rate analysis shows that the target transfer Q-Learning will converge faster than Q-learning if the error of the transferred target Q-function is smaller than the current Q-function in the new task. Based on our theoretical results, we design the safe condition as the Bellman error of the transferred target Q-function is less than the current Q-function. Our experiments are consistent with our theoretical founding and verified the effectiveness of our proposed target transfer Q-learning method.

</details>

<details>

<summary>2018-09-21 06:09:21 - Finite Sample Analysis of the GTD Policy Evaluation Algorithms in Markov Setting</summary>

- *Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, Tie-Yan Liu*

- `1809.08926v1` - [abs](http://arxiv.org/abs/1809.08926v1) - [pdf](http://arxiv.org/pdf/1809.08926v1)

> In reinforcement learning (RL) , one of the key components is policy evaluation, which aims to estimate the value function (i.e., expected long-term accumulated reward) of a policy. With a good policy evaluation method, the RL algorithms will estimate the value function more accurately and find a better policy. When the state space is large or continuous \emph{Gradient-based Temporal Difference(GTD)} policy evaluation algorithms with linear function approximation are widely used. Considering that the collection of the evaluation data is both time and reward consuming, a clear understanding of the finite sample performance of the policy evaluation algorithms is very important to reinforcement learning. Under the assumption that data are i.i.d. generated, previous work provided the finite sample analysis of the GTD algorithms with constant step size by converting them into convex-concave saddle point problems. However, it is well-known that, the data are generated from Markov processes rather than i.i.d. in RL problems.. In this paper, in the realistic Markov setting, we derive the finite sample bounds for the general convex-concave saddle point problems, and hence for the GTD algorithms. We have the following discussions based on our bounds. (1) With variants of step size, GTD algorithms converge. (2) The convergence rate is determined by the step size, with the mixing time of the Markov process as the coefficient. The faster the Markov processes mix, the faster the convergence. (3) We explain that the experience replay trick is effective by improving the mixing property of the Markov process. To the best of our knowledge, our analysis is the first to provide finite sample bounds for the GTD algorithms in Markov setting.

</details>

<details>

<summary>2018-09-21 06:11:11 - Constrained Exploration and Recovery from Experience Shaping</summary>

- *Tu-Hoa Pham, Giovanni De Magistris, Don Joven Agravante, Subhajit Chaudhury, Asim Munawar, Ryuki Tachibana*

- `1809.08925v1` - [abs](http://arxiv.org/abs/1809.08925v1) - [pdf](http://arxiv.org/pdf/1809.08925v1)

> We consider the problem of reinforcement learning under safety requirements, in which an agent is trained to complete a given task, typically formalized as the maximization of a reward signal over time, while concurrently avoiding undesirable actions or states, associated to lower rewards, or penalties. The construction and balancing of different reward components can be difficult in the presence of multiple objectives, yet is crucial for producing a satisfying policy. For example, in reaching a target while avoiding obstacles, low collision penalties can lead to reckless movements while high penalties can discourage exploration. To circumvent this limitation, we examine the effect of past actions in terms of safety to estimate which are acceptable or should be avoided in the future. We then actively reshape the action space of the agent during reinforcement learning, so that reward-driven exploration is constrained within safety limits. We propose an algorithm enabling the learning of such safety constraints in parallel with reinforcement learning and demonstrate its effectiveness in terms of both task completion and training time.

</details>

<details>

<summary>2018-09-21 06:51:54 - Mining Non-Redundant Local Process Models From Sequence Databases</summary>

- *Niek Tax, Marlon Dumas*

- `1712.04159v2` - [abs](http://arxiv.org/abs/1712.04159v2) - [pdf](http://arxiv.org/pdf/1712.04159v2)

> Sequential pattern mining techniques extract patterns corresponding to frequent subsequences from a sequence database. A practical limitation of these techniques is that they overload the user with too many patterns. Local Process Model (LPM) mining is an alternative approach coming from the field of process mining. While in traditional sequential pattern mining, a pattern describes one subsequence, an LPM captures a set of subsequences. Also, while traditional sequential patterns only match subsequences that are observed in the sequence database, an LPM may capture subsequences that are not explicitly observed, but that are related to observed subsequences. In other words, LPMs generalize the behavior observed in the sequence database. These properties make it possible for a set of LPMs to cover the behavior of a much larger set of sequential patterns. Yet, existing LPM mining techniques still suffer from the pattern explosion problem because they produce sets of redundant LPMs. In this paper, we propose several heuristics to mine a set of non-redundant LPMs either from a set of redundant LPMs or from a set of sequential patterns. We empirically compare the proposed heuristics between them and against existing (local) process mining techniques in terms of coverage, redundancy, and complexity of the produced sets of LPMs.

</details>

<details>

<summary>2018-09-21 08:27:01 - Adversarial Training in Affective Computing and Sentiment Analysis: Recent Advances and Perspectives</summary>

- *Jing Han, Zixing Zhang, Nicholas Cummins, Björn Schuller*

- `1809.08927v1` - [abs](http://arxiv.org/abs/1809.08927v1) - [pdf](http://arxiv.org/pdf/1809.08927v1)

> Over the past few years, adversarial training has become an extremely active research topic and has been successfully applied to various Artificial Intelligence (AI) domains. As a potentially crucial technique for the development of the next generation of emotional AI systems, we herein provide a comprehensive overview of the application of adversarial training to affective computing and sentiment analysis. Various representative adversarial training algorithms are explained and discussed accordingly, aimed at tackling diverse challenges associated with emotional AI systems. Further, we highlight a range of potential future research directions. We expect that this overview will help facilitate the development of adversarial training for affective computing and sentiment analysis in both the academic and industrial communities.

</details>

<details>

<summary>2018-09-21 09:19:12 - Multimodal Dual Attention Memory for Video Story Question Answering</summary>

- *Kyung-Min Kim, Seong-Ho Choi, Jin-Hwa Kim, Byoung-Tak Zhang*

- `1809.07999v1` - [abs](http://arxiv.org/abs/1809.07999v1) - [pdf](http://arxiv.org/pdf/1809.07999v1)

> We propose a video story question-answering (QA) architecture, Multimodal Dual Attention Memory (MDAM). The key idea is to use a dual attention mechanism with late fusion. MDAM uses self-attention to learn the latent concepts in scene frames and captions. Given a question, MDAM uses the second attention over these latent concepts. Multimodal fusion is performed after the dual attention processes (late fusion). Using this processing pipeline, MDAM learns to infer a high-level vision-language joint representation from an abstraction of the full video content. We evaluate MDAM on PororoQA and MovieQA datasets which have large-scale QA annotations on cartoon videos and movies, respectively. For both datasets, MDAM achieves new state-of-the-art results with significant margins compared to the runner-up models. We confirm the best performance of the dual attention mechanism combined with late fusion by ablation studies. We also perform qualitative analysis by visualizing the inference mechanisms of MDAM.

</details>

<details>

<summary>2018-09-21 10:52:08 - Answering the "why" in Answer Set Programming - A Survey of Explanation Approaches</summary>

- *Jorge Fandinno, Claudia Schulz*

- `1809.08034v1` - [abs](http://arxiv.org/abs/1809.08034v1) - [pdf](http://arxiv.org/pdf/1809.08034v1)

> Artificial Intelligence (AI) approaches to problem-solving and decision-making are becoming more and more complex, leading to a decrease in the understandability of solutions. The European Union's new General Data Protection Regulation tries to tackle this problem by stipulating a "right to explanation" for decisions made by AI systems. One of the AI paradigms that may be affected by this new regulation is Answer Set Programming (ASP). Thanks to the emergence of efficient solvers, ASP has recently been used for problem-solving in a variety of domains, including medicine, cryptography, and biology. To ensure the successful application of ASP as a problem-solving paradigm in the future, explanations of ASP solutions are crucial. In this survey, we give an overview of approaches that provide an answer to the question of why an answer set is a solution to a given problem, notably off-line justifications, causal graphs, argumentative explanations and why-not provenance, and highlight their similarities and differences. Moreover, we review methods explaining why a set of literals is not an answer set or why no solution exists at all.

</details>

<details>

<summary>2018-09-21 11:20:05 - Accuracy-based Curriculum Learning in Deep Reinforcement Learning</summary>

- *Pierre Fournier, Olivier Sigaud, Mohamed Chetouani, Pierre-Yves Oudeyer*

- `1806.09614v2` - [abs](http://arxiv.org/abs/1806.09614v2) - [pdf](http://arxiv.org/pdf/1806.09614v2)

> In this paper, we investigate a new form of automated curriculum learning based on adaptive selection of accuracy requirements, called accuracy-based curriculum learning. Using a reinforcement learning agent based on the Deep Deterministic Policy Gradient algorithm and addressing the Reacher environment, we first show that an agent trained with various accuracy requirements sampled randomly learns more efficiently than when asked to be very accurate at all times. Then we show that adaptive selection of accuracy requirements, based on a local measure of competence progress, automatically generates a curriculum where difficulty progressively increases, resulting in a better learning efficiency than sampling randomly.

</details>

<details>

<summary>2018-09-21 12:04:44 - Lexical Bias In Essay Level Prediction</summary>

- *Georgios Balikas*

- `1809.08935v1` - [abs](http://arxiv.org/abs/1809.08935v1) - [pdf](http://arxiv.org/pdf/1809.08935v1)

> Automatically predicting the level of non-native English speakers given their written essays is an interesting machine learning problem. In this work I present the system "balikasg" that achieved the state-of-the-art performance in the CAp 2018 data science challenge among 14 systems. I detail the feature extraction, feature engineering and model selection steps and I evaluate how these decisions impact the system's performance. The paper concludes with remarks for future work.

</details>

<details>

<summary>2018-09-21 12:29:27 - Conducting Feasibility Studies for Knowledge Based Systems</summary>

- *John Kingston*

- `1809.08059v1` - [abs](http://arxiv.org/abs/1809.08059v1) - [pdf](http://arxiv.org/pdf/1809.08059v1)

> This paper describes how to carry out a feasibility study for a potential knowledge based system application. It discusses factors to be considered under three headings: the business case, the technical feasibility, and stakeholder issues. It concludes with a case study of a feasibility study for a KBS to guide surgeons in diagnosis and treatment of thyroid conditions.

</details>

<details>

<summary>2018-09-21 12:47:50 - REBA: A Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics</summary>

- *Mohan Sridharan, Michael Gelfond, Shiqi Zhang, Jeremy Wyatt*

- `1508.03891v4` - [abs](http://arxiv.org/abs/1508.03891v4) - [pdf](http://arxiv.org/pdf/1508.03891v4)

> This paper describes an architecture for robots that combines the complementary strengths of probabilistic graphical models and declarative programming to represent and reason with logic-based and probabilistic descriptions of uncertainty and domain knowledge. An action language is extended to support non-boolean fluents and non-deterministic causal laws. This action language is used to describe tightly-coupled transition diagrams at two levels of granularity, with a fine-resolution transition diagram defined as a refinement of a coarse-resolution transition diagram of the domain. The coarse-resolution system description, and a history that includes (prioritized) defaults, are translated into an Answer Set Prolog (ASP) program. For any given goal, inference in the ASP program provides a plan of abstract actions. To implement each such abstract action, the robot automatically zooms to the part of the fine-resolution transition diagram relevant to this action. A probabilistic representation of the uncertainty in sensing and actuation is then included in this zoomed fine-resolution system description, and used to construct a partially observable Markov decision process (POMDP). The policy obtained by solving the POMDP is invoked repeatedly to implement the abstract action as a sequence of concrete actions, with the corresponding observations being recorded in the coarse-resolution history and used for subsequent reasoning. The architecture is evaluated in simulation and on a mobile robot moving objects in an indoor domain, to show that it supports reasoning with violation of defaults, noisy observations and unreliable actions, in complex domains.

</details>

<details>

<summary>2018-09-21 14:31:57 - Predicting the Usefulness of Amazon Reviews Using Off-The-Shelf Argumentation Mining</summary>

- *Marco Passon, Marco Lippi, Giuseppe Serra, Carlo Tasso*

- `1809.08145v1` - [abs](http://arxiv.org/abs/1809.08145v1) - [pdf](http://arxiv.org/pdf/1809.08145v1)

> Internet users generate content at unprecedented rates. Building intelligent systems capable of discriminating useful content within this ocean of information is thus becoming a urgent need. In this paper, we aim to predict the usefulness of Amazon reviews, and to do this we exploit features coming from an off-the-shelf argumentation mining system. We argue that the usefulness of a review, in fact, is strictly related to its argumentative content, whereas the use of an already trained system avoids the costly need of relabeling a novel dataset. Results obtained on a large publicly available corpus support this hypothesis.

</details>

<details>

<summary>2018-09-21 17:00:56 - Arianna+: Scalable Human Activity Recognition by Reasoning with a Network of Ontologies</summary>

- *Syed Yusha Kareem, Luca Buoncompagni, Fulvio Mastrogiovanni*

- `1809.08208v1` - [abs](http://arxiv.org/abs/1809.08208v1) - [pdf](http://arxiv.org/pdf/1809.08208v1)

> Aging population ratios are rising significantly. Meanwhile, smart home based health monitoring services are evolving rapidly to become a viable alternative to traditional healthcare solutions. Such services can augment qualitative analyses done by gerontologists with quantitative data. Hence, the recognition of Activities of Daily Living (ADL) has become an active domain of research in recent times. For a system to perform human activity recognition in a real-world environment, multiple requirements exist, such as scalability, robustness, ability to deal with uncertainty (e.g., missing sensor data), to operate with multi-occupants and to take into account their privacy and security. This paper attempts to address the requirements of scalability and robustness, by describing a reasoning mechanism based on modular spatial and/or temporal context models as a network of ontologies. The reasoning mechanism has been implemented in a smart home system referred to as Arianna+. The paper presents and discusses a use case, and experiments are performed on a simulated dataset, to showcase Arianna+'s modularity feature, internal working, and computational performance. Results indicate scalability and robustness for human activity recognition processes.

</details>

<details>

<summary>2018-09-21 20:01:30 - Opacity, Obscurity, and the Geometry of Question-Asking</summary>

- *Christina Boyce-Jacino, Simon DeDeo*

- `1809.08291v1` - [abs](http://arxiv.org/abs/1809.08291v1) - [pdf](http://arxiv.org/pdf/1809.08291v1)

> Asking questions is a pervasive human activity, but little is understood about what makes them difficult to answer. An analysis of a pair of large databases, of New York Times crosswords and questions from the quiz-show Jeopardy, establishes two orthogonal dimensions of question difficulty: obscurity (the rarity of the answer) and opacity (the indirectness of question cues, operationalized with word2vec). The importance of opacity, and the role of synergistic information in resolving it, suggests that accounts of difficulty in terms of prior expectations captures only a part of the question-asking process. A further regression analysis shows the presence of additional dimensions to question-asking: question complexity, the answer's local network density, cue intersection, and the presence of signal words. Our work shows how question-askers can help their interlocutors by using contextual cues, or, conversely, how a particular kind of unfamiliarity with the domain in question can make it harder for individuals to learn from others. Taken together, these results suggest how Bayesian models of question difficulty can be supplemented by process models and accounts of the heuristics individuals use to navigate conceptual spaces.

</details>

<details>

<summary>2018-09-21 20:38:17 - onlineSPARC: a Programming Environment for Answer Set Programming</summary>

- *Elias Marcopoulos, Yuanlin Zhang*

- `1809.08304v1` - [abs](http://arxiv.org/abs/1809.08304v1) - [pdf](http://arxiv.org/pdf/1809.08304v1)

> Recent progress in logic programming (e.g., the development of the Answer Set Programming paradigm) has made it possible to teach it to general undergraduate and even middle/high school students. Given the limited exposure of these students to computer science, the complexity of downloading, installing and using tools for writing logic programs could be a major barrier for logic programming to reach a much wider audience. We developed onlineSPARC, an online answer set programming environment with a self contained file system and a simple interface. It allows users to type/edit logic programs and perform several tasks over programs, including asking a query to a program, getting the answer sets of a program, and producing a drawing/animation based on the answer sets of a program.

</details>

<details>

<summary>2018-09-21 21:52:34 - On Quantifying and Understanding the Role of Ethics in AI Research: A Historical Account of Flagship Conferences and Journals</summary>

- *Marcelo Prates, Pedro Avelar, Luis C. Lamb*

- `1809.08328v1` - [abs](http://arxiv.org/abs/1809.08328v1) - [pdf](http://arxiv.org/pdf/1809.08328v1)

> Recent developments in AI, Machine Learning and Robotics have raised concerns about the ethical consequences of both academic and industrial AI research. Leading academics, businessmen and politicians have voiced an increasing number of questions about the consequences of AI not only over people, but also on the large-scale consequences on the the future of work and employment, its social consequences and the sustainability of the planet. In this work, we analyse the use and the occurrence of ethics-related research in leading AI, machine learning and robotics venues. In order to do so we perform long term, historical corpus-based analyses on a large number of flagship conferences and journals. Our experiments identify the prominence of ethics-related terms in published papers and presents several statistics on related topics. Finally, this research provides quantitative evidence on the pressing ethical concerns of the AI community.

</details>

<details>

<summary>2018-09-21 23:38:17 - Interpretable Multi-Objective Reinforcement Learning through Policy Orchestration</summary>

- *Ritesh Noothigattu, Djallel Bouneffouf, Nicholas Mattei, Rachita Chandra, Piyush Madan, Kush Varshney, Murray Campbell, Moninder Singh, Francesca Rossi*

- `1809.08343v1` - [abs](http://arxiv.org/abs/1809.08343v1) - [pdf](http://arxiv.org/pdf/1809.08343v1)

> Autonomous cyber-physical agents and systems play an increasingly large role in our lives. To ensure that agents behave in ways aligned with the values of the societies in which they operate, we must develop techniques that allow these agents to not only maximize their reward in an environment, but also to learn and follow the implicit constraints of society. These constraints and norms can come from any number of sources including regulations, business process guidelines, laws, ethical principles, social norms, and moral values. We detail a novel approach that uses inverse reinforcement learning to learn a set of unspecified constraints from demonstrations of the task, and reinforcement learning to learn to maximize the environment rewards. More precisely, we assume that an agent can observe traces of behavior of members of the society but has no access to the explicit set of constraints that give rise to the observed behavior. Inverse reinforcement learning is used to learn such constraints, that are then combined with a possibly orthogonal value function through the use of a contextual bandit-based orchestrator that picks a contextually-appropriate choice between the two policies (constraint-based and environment reward-based) when taking actions. The contextual bandit orchestrator allows the agent to mix policies in novel ways, taking the best actions from either a reward maximizing or constrained policy. In addition, the orchestrator is transparent on which policy is being employed at each time step. We test our algorithms using a Pac-Man domain and show that the agent is able to learn to act optimally, act within the demonstrated constraints, and mix these two functions in complex ways.

</details>

<details>

<summary>2018-09-21 23:47:42 - Attention-based Encoder-Decoder Networks for Spelling and Grammatical Error Correction</summary>

- *Sina Ahmadi*

- `1810.00660v1` - [abs](http://arxiv.org/abs/1810.00660v1) - [pdf](http://arxiv.org/pdf/1810.00660v1)

> Automatic spelling and grammatical correction systems are one of the most widely used tools within natural language applications. In this thesis, we assume the task of error correction as a type of monolingual machine translation where the source sentence is potentially erroneous and the target sentence should be the corrected form of the input. Our main focus in this project is building neural network models for the task of error correction. In particular, we investigate sequence-to-sequence and attention-based models which have recently shown a higher performance than the state-of-the-art of many language processing problems. We demonstrate that neural machine translation models can be successfully applied to the task of error correction.   While the experiments of this research are performed on an Arabic corpus, our methods in this thesis can be easily applied to any language.

</details>

<details>

<summary>2018-09-22 01:35:38 - A privacy-preserving, decentralized and functional Bitcoin e-voting protocol</summary>

- *Zijian Bao, Bin Wang, Wenbo Shi*

- `1809.08362v1` - [abs](http://arxiv.org/abs/1809.08362v1) - [pdf](http://arxiv.org/pdf/1809.08362v1)

> Bitcoin, as a decentralized digital currency, has caused extensive research interest. There are many studies based on related protocols on Bitcoin, Bitcoin-based voting protocols also received attention in related literature. In this paper, we propose a Bitcoin-based decentralized privacy-preserving voting mechanism. It is assumed that there are n voters and m candidates. The candidate who obtains t ballots can get x Bitcoins from each voter, namely nx Bitcoins in total. We use a shuffling mechanism to protect voter's voting privacy, at the same time, decentralized threshold signatures were used to guarantee security and assign voting rights. The protocol can achieve correctness, decentralization and privacy-preservings. By contrast with other schemes, our protocol has a smaller number of transactions and can achieve a more functional voting method.

</details>

<details>

<summary>2018-09-22 06:42:34 - Understanding Fake Faces</summary>

- *Ryota Natsume, Kazuki Inoue, Yoshihiro Fukuhara, Shintaro Yamamoto, Shigeo Morishima, Hirokatsu Kataoka*

- `1809.08391v1` - [abs](http://arxiv.org/abs/1809.08391v1) - [pdf](http://arxiv.org/pdf/1809.08391v1)

> Face recognition research is one of the most active topics in computer vision (CV), and deep neural networks (DNN) are now filling the gap between human-level and computer-driven performance levels in face verification algorithms. However, although the performance gap appears to be narrowing in terms of accuracy-based expectations, a curious question has arisen; specifically, "Face understanding of AI is really close to that of human?" In the present study, in an effort to confirm the brain-driven concept, we conduct image-based detection, classification, and generation using an in-house created fake face database. This database has two configurations: (i) false positive face detections produced using both the Viola Jones (VJ) method and convolutional neural networks (CNN), and (ii) simulacra that have fundamental characteristics that resemble faces but are completely artificial. The results show a level of suggestive knowledge that indicates the continuing existence of a gap between the capabilities of recent vision-based face recognition algorithms and human-level performance. On a positive note, however, we have obtained knowledge that will advance the progress of face-understanding models.

</details>

<details>

<summary>2018-09-22 09:07:52 - Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing</summary>

- *Jonathan Herzig, Jonathan Berant*

- `1804.07918v2` - [abs](http://arxiv.org/abs/1804.07918v2) - [pdf](http://arxiv.org/pdf/1804.07918v2)

> Building a semantic parser quickly in a new domain is a fundamental challenge for conversational interfaces, as current semantic parsers require expensive supervision and lack the ability to generalize to new domains. In this paper, we introduce a zero-shot approach to semantic parsing that can parse utterances in unseen domains while only being trained on examples in other source domains. First, we map an utterance to an abstract, domain-independent, logical form that represents the structure of the logical form, but contains slots instead of KB constants. Then, we replace slots with KB constants via lexical alignment scores and global inference. Our model reaches an average accuracy of 53.4% on 7 domains in the Overnight dataset, substantially better than other zero-shot baselines, and performs as good as a parser trained on over 30% of the target domain examples.

</details>

<details>

<summary>2018-09-22 10:07:46 - Medical Knowledge Embedding Based on Recursive Neural Network for Multi-Disease Diagnosis</summary>

- *Jingchi Jiang, Huanzheng Wang, Jing Xie, Xitong Guo, Yi Guan, Qiubin Yu*

- `1809.08422v1` - [abs](http://arxiv.org/abs/1809.08422v1) - [pdf](http://arxiv.org/pdf/1809.08422v1)

> The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models. Although symbolic representation enables quantitative reasoning with statistical probability, it is difficult to utilize with machine learning models as they perform numerical operations. In contrast, knowledge embedding (i.e., high-dimensional and continuous vectors) is a feasible approach to complex reasoning that can not only retain the semantic information of knowledge but also establish the quantifiable relationship among them. In this paper, we propose recursive neural knowledge network (RNKN), which combines medical knowledge based on first-order logic with recursive neural network for multi-disease diagnosis. After RNKN is efficiently trained from manually annotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented knowledge embeddings and weight matrixes are learned. Experimental results verify that the diagnostic accuracy of RNKN is superior to that of some classical machine learning models and Markov logic network (MLN). The results also demonstrate that the more explicit the evidence extracted from CEMRs is, the better is the performance achieved. RNKN gradually exhibits the interpretation of knowledge embeddings as the number of training epochs increases.

</details>

<details>

<summary>2018-09-22 22:46:52 - Subgoal Discovery for Hierarchical Dialogue Policy Learning</summary>

- *Da Tang, Xiujun Li, Jianfeng Gao, Chong Wang, Lihong Li, Tony Jebara*

- `1804.07855v3` - [abs](http://arxiv.org/abs/1804.07855v3) - [pdf](http://arxiv.org/pdf/1804.07855v3)

> Developing agents to engage in complex goal-oriented dialogues is challenging partly because the main learning signals are very sparse in long conversations. In this paper, we propose a divide-and-conquer approach that discovers and exploits the hidden structure of the task to enable efficient policy learning. First, given successful example dialogues, we propose the Subgoal Discovery Network (SDN) to divide a complex goal-oriented task into a set of simpler subgoals in an unsupervised fashion. We then use these subgoals to learn a multi-level policy by hierarchical reinforcement learning. We demonstrate our method by building a dialogue agent for the composite task of travel planning. Experiments with simulated and real users show that our approach performs competitively against a state-of-the-art method that requires human-defined subgoals. Moreover, we show that the learned subgoals are often human comprehensible.

</details>

<details>

<summary>2018-09-22 23:49:05 - Stories for Images-in-Sequence by using Visual and Narrative Components</summary>

- *Marko Smilevski, Ilija Lalkovski, Gjorgji Madjarov*

- `1805.05622v3` - [abs](http://arxiv.org/abs/1805.05622v3) - [pdf](http://arxiv.org/pdf/1805.05622v3)

> Recent research in AI is focusing towards generating narrative stories about visual scenes. It has the potential to achieve more human-like understanding than just basic description generation of images- in-sequence. In this work, we propose a solution for generating stories for images-in-sequence that is based on the Sequence to Sequence model. As a novelty, our encoder model is composed of two separate encoders, one that models the behaviour of the image sequence and other that models the sentence-story generated for the previous image in the sequence of images. By using the image sequence encoder we capture the temporal dependencies between the image sequence and the sentence-story and by using the previous sentence-story encoder we achieve a better story flow. Our solution generates long human-like stories that not only describe the visual context of the image sequence but also contains narrative and evaluative language. The obtained results were confirmed by manual human evaluation.

</details>

<details>

<summary>2018-09-23 01:48:50 - A Train Status Assistant for Indian Railways</summary>

- *Himadri Mishra, Ramashish Gaurav, Biplav Srivastava*

- `1809.08509v1` - [abs](http://arxiv.org/abs/1809.08509v1) - [pdf](http://arxiv.org/pdf/1809.08509v1)

> Trains are part-and-parcel of every day lives in countries with large, diverse, multi-lingual population like India. Consequently, an assistant which can accurately predict and explain train delays will help people and businesses alike. We present a novel conversation agent which can engage with people about train status and inform them about its delay at in-line stations. It is trained on past delay data from a subset of trains and generalizes to others.

</details>

<details>

<summary>2018-09-23 04:37:24 - Incorporating GAN for Negative Sampling in Knowledge Representation Learning</summary>

- *Peifeng Wang, Shuangyin Li, Rong pan*

- `1809.11017v1` - [abs](http://arxiv.org/abs/1809.11017v1) - [pdf](http://arxiv.org/pdf/1809.11017v1)

> Knowledge representation learning aims at modeling knowledge graph by encoding entities and relations into a low dimensional space. Most of the traditional works for knowledge embedding need negative sampling to minimize a margin-based ranking loss. However, those works construct negative samples through a random mode, by which the samples are often too trivial to fit the model efficiently. In this paper, we propose a novel knowledge representation learning framework based on Generative Adversarial Networks (GAN). In this GAN-based framework, we take advantage of a generator to obtain high-quality negative samples. Meanwhile, the discriminator in GAN learns the embeddings of the entities and relations in knowledge graph. Thus, we can incorporate the proposed GAN-based framework into various traditional models to improve the ability of knowledge representation learning. Experimental results show that our proposed GAN-based framework outperforms baselines on triplets classification and link prediction tasks.

</details>

<details>

<summary>2018-09-23 12:22:11 - The use of Virtual Reality in Enhancing Interdisciplinary Research and Education</summary>

- *Tiffany Leung, Farhana Zulkernine, Haruna Isah*

- `1809.08585v1` - [abs](http://arxiv.org/abs/1809.08585v1) - [pdf](http://arxiv.org/pdf/1809.08585v1)

> Virtual Reality (VR) is increasingly being recognized for its educational potential and as an effective way to convey new knowledge to people, it supports interactive and collaborative activities. Affordable VR powered by mobile technologies is opening a new world of opportunities that can transform the ways in which we learn and engage with others. This paper reports our study regarding the application of VR in stimulating interdisciplinary communication. It investigates the promises of VR in interdisciplinary education and research. The main contributions of this study are (i) literature review of theories of learning underlying the justification of the use of VR systems in education, (ii) taxonomy of the various types and implementations of VR systems and their application in supporting education and research (iii) evaluation of educational applications of VR from a broad range of disciplines, (iv) investigation of how the learning process and learning outcomes are affected by VR systems, and (v) comparative analysis of VR and traditional methods of teaching in terms of quality of learning. This study seeks to inspire and inform interdisciplinary researchers and learners about the ways in which VR might support them and also VR software developers to push the limits of their craft.

</details>

<details>

<summary>2018-09-23 13:05:28 - Neural Arithmetic Expression Calculator</summary>

- *Kaiyu Chen, Yihan Dong, Xipeng Qiu, Zitian Chen*

- `1809.08590v1` - [abs](http://arxiv.org/abs/1809.08590v1) - [pdf](http://arxiv.org/pdf/1809.08590v1)

> This paper presents a pure neural solver for arithmetic expression calculation (AEC) problem. Previous work utilizes the powerful capabilities of deep neural networks and attempts to build an end-to-end model to solve this problem. However, most of these methods can only deal with the additive operations. It is still a challenging problem to solve the complex expression calculation problem, which includes the adding, subtracting, multiplying, dividing and bracketing operations. In this work, we regard the arithmetic expression calculation as a hierarchical reinforcement learning problem. An arithmetic operation is decomposed into a series of sub-tasks, and each sub-task is dealt with by a skill module. The skill module could be a basic module performing elementary operations, or interactive module performing complex operations by invoking other skill models. With curriculum learning, our model can deal with a complex arithmetic expression calculation with the deep hierarchical structure of skill models. Experiments show that our model significantly outperforms the previous models for arithmetic expression calculation.

</details>

<details>

<summary>2018-09-24 02:21:46 - A family of neighborhood contingency logics</summary>

- *Jie Fan*

- `1809.09495v1` - [abs](http://arxiv.org/abs/1809.09495v1) - [pdf](http://arxiv.org/pdf/1809.09495v1)

> This article proposes the axiomatizations of contingency logics of various natural classes of neighborhood frames. In particular, by defining a suitable canonical neighborhood function, we give sound and complete axiomatizations of monotone contingency logic and regular contingency logic, thereby answering two open questions raised by Bakhtiari, van Ditmarsch, and Hansen. The canonical function is inspired by a function proposed by Kuhn in~1995. We show that Kuhn's function is actually equal to a related function originally given by Humberstone.

</details>

<details>

<summary>2018-09-24 03:42:53 - Shannon Entropy for Neutrosophic Information</summary>

- *Vasile Patrascu*

- `1810.00748v1` - [abs](http://arxiv.org/abs/1810.00748v1) - [pdf](http://arxiv.org/pdf/1810.00748v1)

> The paper presents an extension of Shannon entropy for neutrosophic information. This extension uses a new formula for distance between two neutrosophic triplets. In addition, the obtained results are particularized for bifuzzy, intuitionistic and paraconsistent fuzzy information.

</details>

<details>

<summary>2018-09-24 04:15:37 - A Survey of Conventional and Artificial Intelligence / Learning based Resource Allocation and Interference Mitigation Schemes in D2D Enabled Networks</summary>

- *Kamran Zia, Nauman Javed, Muhammad Nadeem Sial, Sohail Ahmed, Hifsa Iram, Asad Amir Pirzada*

- `1809.08748v1` - [abs](http://arxiv.org/abs/1809.08748v1) - [pdf](http://arxiv.org/pdf/1809.08748v1)

> 5th generation networks are envisioned to provide seamless and ubiquitous connection to 1000-fold more devices and is believed to provide ultra-low latency and higher data rates up to tens of Gbps. Different technologies enabling these requirements are being developed including mmWave communications, Massive MIMO and beamforming, Device to Device (D2D) communications and Heterogeneous Networks. D2D communication is a promising technology to enable applications requiring high bandwidth such as online streaming and online gaming etc. It can also provide ultra- low latencies required for applications like vehicle to vehicle communication for autonomous driving. D2D communication can provide higher data rates with high energy efficiency and spectral efficiency compared to conventional communication. The performance benefits of D2D communication can be best achieved when D2D users reuses the spectrum being utilized by the conventional cellular users. This spectrum sharing in a multi-tier heterogeneous network will introduce complex interference among D2D users and cellular users which needs to be resolved. Motivated by limited number of surveys for interference mitigation and resource allocation in D2D enabled heterogeneous networks, we have surveyed different conventional and artificial intelligence based interference mitigation and resource allocation schemes developed in recent years. Our contribution lies in the analysis of conventional interference mitigation techniques and their shortcomings. Finally, the strengths of AI based techniques are determined and open research challenges deduced from the recent research are presented.

</details>

<details>

<summary>2018-09-24 04:32:17 - Interactions as Social Practices: towards a formalization</summary>

- *Frank Dignum*

- `1809.08751v1` - [abs](http://arxiv.org/abs/1809.08751v1) - [pdf](http://arxiv.org/pdf/1809.08751v1)

> Multi-agent models are a suitable starting point to model complex social interactions. However, as the complexity of the systems increase, we argue that novel modeling approaches are needed that can deal with inter-dependencies at different levels of society, where many heterogeneous parties (software agents, robots, humans) are interacting and reacting to each other. In this paper, we present a formalization of a social framework for agents based in the concept of Social Practices as high level specifications of normal (expected) behavior in a given social context. We argue that social practices facilitate the practical reasoning of agents in standard social interactions.

</details>

<details>

<summary>2018-09-24 06:09:20 - Translating Navigation Instructions in Natural Language to a High-Level Plan for Behavioral Robot Navigation</summary>

- *Xiaoxue Zang, Ashwini Pokle, Marynel Vázquez, Kevin Chen, Juan Carlos Niebles, Alvaro Soto, Silvio Savarese*

- `1810.00663v1` - [abs](http://arxiv.org/abs/1810.00663v1) - [pdf](http://arxiv.org/pdf/1810.00663v1)

> We propose an end-to-end deep learning model for translating free-form natural language instructions to a high-level plan for behavioral robot navigation. We use attention models to connect information from both the user instructions and a topological representation of the environment. We evaluate our model's performance on a new dataset containing 10,050 pairs of navigation instructions. Our model significantly outperforms baseline approaches. Furthermore, our results suggest that it is possible to leverage the environment map as a relevant knowledge base to facilitate the translation of free-form navigational instruction.

</details>

<details>

<summary>2018-09-24 07:31:08 - KDSL: a Knowledge-Driven Supervised Learning Framework for Word Sense Disambiguation</summary>

- *Shi Yin, Yi Zhou, Chenguang Li, Shangfei Wang, Jianmin Ji, Xiaoping Chen, Ruili Wang*

- `1808.09888v4` - [abs](http://arxiv.org/abs/1808.09888v4) - [pdf](http://arxiv.org/pdf/1808.09888v4)

> We propose KDSL, a new word sense disambiguation (WSD) framework that utilizes knowledge to automatically generate sense-labeled data for supervised learning. First, from WordNet, we automatically construct a semantic knowledge base called DisDict, which provides refined feature words that highlight the differences among word senses, i.e., synsets. Second, we automatically generate new sense-labeled data by DisDict from unlabeled corpora. Third, these generated data, together with manually labeled data and unlabeled data, are fed to a neural framework conducting supervised and unsupervised learning jointly to model the semantic relations among synsets, feature words and their contexts. The experimental results show that KDSL outperforms several representative state-of-the-art methods on various major benchmarks. Interestingly, it performs relatively well even when manually labeled data is unavailable, thus provides a potential solution for similar tasks in a lack of manual annotations.

</details>

<details>

<summary>2018-09-24 07:53:53 - Arguing Machines: Human Supervision of Black Box AI Systems That Make Life-Critical Decisions</summary>

- *Lex Fridman, Li Ding, Benedikt Jenik, Bryan Reimer*

- `1710.04459v2` - [abs](http://arxiv.org/abs/1710.04459v2) - [pdf](http://arxiv.org/pdf/1710.04459v2)

> We consider the paradigm of a black box AI system that makes life-critical decisions. We propose an "arguing machines" framework that pairs the primary AI system with a secondary one that is independently trained to perform the same task. We show that disagreement between the two systems, without any knowledge of underlying system design or operation, is sufficient to arbitrarily improve the accuracy of the overall decision pipeline given human supervision over disagreements. We demonstrate this system in two applications: (1) an illustrative example of image classification and (2) on large-scale real-world semi-autonomous driving data. For the first application, we apply this framework to image classification achieving a reduction from 8.0% to 2.8% top-5 error on ImageNet. For the second application, we apply this framework to Tesla Autopilot and demonstrate the ability to predict 90.4% of system disengagements that were labeled by human annotators as challenging and needing human supervision.

</details>

<details>

<summary>2018-09-24 09:55:37 - Representing Sets as Summed Semantic Vectors</summary>

- *Douglas Summers-Stay, Peter Sutor, Dandan Li*

- `1809.08823v1` - [abs](http://arxiv.org/abs/1809.08823v1) - [pdf](http://arxiv.org/pdf/1809.08823v1)

> Representing meaning in the form of high dimensional vectors is a common and powerful tool in biologically inspired architectures. While the meaning of a set of concepts can be summarized by taking a (possibly weighted) sum of their associated vectors, this has generally been treated as a one-way operation. In this paper we show how a technique built to aid sparse vector decomposition allows in many cases the exact recovery of the inputs and weights to such a sum, allowing a single vector to represent an entire set of vectors from a dictionary. We characterize the number of vectors that can be recovered under various conditions, and explore several ways such a tool can be used for vector-based reasoning.

</details>

<details>

<summary>2018-09-24 12:00:37 - A Comparative Study: Adaptive Fuzzy Inference Systems for Energy Prediction in Urban Buildings</summary>

- *Mainak Dan, Seshadhri Srinivasan*

- `1809.08860v1` - [abs](http://arxiv.org/abs/1809.08860v1) - [pdf](http://arxiv.org/pdf/1809.08860v1)

> This investigation aims to study different adaptive fuzzy inference algorithms capable of real-time sequential learning and prediction of time-series data. A brief qualitative description of these algorithms namely meta-cognitive fuzzy inference system (McFIS), sequential adaptive fuzzy inference system (SAFIS) and evolving Takagi-Sugeno (ETS) model provide a comprehensive comparison of their working principle, especially their unique characteristics are discussed. These algorithms are then simulated with dataset collected at one of the academic buildings at Nanyang Technological University, Singapore. The performance are compared by means of the root mean squared error (RMSE) and non-destructive error index (NDEI) of the predicted output. Analysis shows that McFIS shows promising results either with lower RMSE and NDEI or with lower architectural complexity over ETS and SAFIS. Statistical Analysis also reveals the significance of the outcome of these algorithms.

</details>

<details>

<summary>2018-09-24 13:02:09 - Robotics Rights and Ethics Rules</summary>

- *Tuncay Yigit, Utku Kose, Nilgun Sengoz*

- `1809.08885v1` - [abs](http://arxiv.org/abs/1809.08885v1) - [pdf](http://arxiv.org/pdf/1809.08885v1)

> It is very important to adhere strictly to ethical and social influences when delivering most of our life to artificial intelligence systems. With industry 4.0, the internet of things, data analysis and automation have begun to be of great importance in our lives. With the Yapanese version of Industry 5.0, it has come to our attention that machine-human interaction and human intelligence are working in harmony with the cognitive computer. In this context, robots working on artificial intelligence algorithms co-ordinated with the development of technology have begun to enter our lives. But the consequences of the recent complaints of the Robots have been that important issues have arisen about how to be followed in terms of intellectual property and ethics. Although there are no laws regulating robots in our country at present, laws on robot ethics and rights abroad have entered into force. This means that it is important that we organize the necessary arrangements in the way that robots and artificial intelligence are so important in the new world order. In this study, it was aimed to examine the existing rules of machine and robot ethics and to set an example for the arrangements to be made in our country, and various discussions were given in this context.

</details>

<details>

<summary>2018-09-24 13:42:13 - A Preliminary Report on Probabilistic Attack Normal Form for Constellation Semantics</summary>

- *Theofrastos Mantadelis, Stefano Bistarelli*

- `1810.00771v1` - [abs](http://arxiv.org/abs/1810.00771v1) - [pdf](http://arxiv.org/pdf/1810.00771v1)

> After Dung's founding work in Abstract Argumentation Frameworks there has been a growing interest in extending the Dung's semantics in order to describe more complex or real life situations. Several of these approaches take the direction of weighted or probabilistic extensions. One of the most prominent probabilistic approaches is that of constellation Probabilistic Abstract Argumentation Frameworks from Li~et~al. In this paper, we present a normal form for constellation probabilistic abstract argumentation frameworks. Furthermore, we present a transformation from general constellation probabilistic abstract argumentation frameworks to the presented normal form. In this way we illustrate that the simpler normal form has equal representation power with the general one.

</details>

<details>

<summary>2018-09-24 17:08:08 - Deep Confidence: A Computationally Efficient Framework for Calculating Reliable Errors for Deep Neural Networks</summary>

- *Isidro Cortes-Ciriano, Andreas Bender*

- `1809.09060v1` - [abs](http://arxiv.org/abs/1809.09060v1) - [pdf](http://arxiv.org/pdf/1809.09060v1)

> Deep learning architectures have proved versatile in a number of drug discovery applications, including the modelling of in vitro compound activity. While controlling for prediction confidence is essential to increase the trust, interpretability and usefulness of virtual screening models in drug discovery, techniques to estimate the reliability of the predictions generated with deep learning networks remain largely underexplored. Here, we present Deep Confidence, a framework to compute valid and efficient confidence intervals for individual predictions using the deep learning technique Snapshot Ensembling and conformal prediction. Specifically, Deep Confidence generates an ensemble of deep neural networks by recording the network parameters throughout the local minima visited during the optimization phase of a single neural network. This approach serves to derive a set of base learners (i.e., snapshots) with comparable predictive power on average, that will however generate slightly different predictions for a given instance. The variability across base learners and the validation residuals are in turn harnessed to compute confidence intervals using the conformal prediction framework. Using a set of 24 diverse IC50 data sets from ChEMBL 23, we show that Snapshot Ensembles perform on par with Random Forest (RF) and ensembles of independently trained deep neural networks. In addition, we find that the confidence regions predicted using the Deep Confidence framework span a narrower set of values. Overall, Deep Confidence represents a highly versatile error prediction framework that can be applied to any deep learning-based application at no extra computational cost.

</details>

<details>

<summary>2018-09-24 17:13:08 - Bootstrapping with Models: Confidence Intervals for Off-Policy Evaluation</summary>

- *Josiah P. Hanna, Peter Stone, Scott Niekum*

- `1606.06126v3` - [abs](http://arxiv.org/abs/1606.06126v3) - [pdf](http://arxiv.org/pdf/1606.06126v3)

> For an autonomous agent, executing a poor policy may be costly or even dangerous. For such agents, it is desirable to determine confidence interval lower bounds on the performance of any given policy without executing said policy. Current methods for exact high confidence off-policy evaluation that use importance sampling require a substantial amount of data to achieve a tight lower bound. Existing model-based methods only address the problem in discrete state spaces. Since exact bounds are intractable for many domains we trade off strict guarantees of safety for more data-efficient approximate bounds. In this context, we propose two bootstrapping off-policy evaluation methods which use learned MDP transition models in order to estimate lower confidence bounds on policy performance with limited data in both continuous and discrete state spaces. Since direct use of a model may introduce bias, we derive a theoretical upper bound on model bias for when the model transition function is estimated with i.i.d. trajectories. This bound broadens our understanding of the conditions under which model-based methods have high bias. Finally, we empirically evaluate our proposed methods and analyze the settings in which different bootstrapping off-policy confidence interval methods succeed and fail.

</details>

<details>

<summary>2018-09-24 17:49:09 - Autonomous Deep Learning: Incremental Learning of Denoising Autoencoder for Evolving Data Streams</summary>

- *Mahardhika Pratama, Andri Ashfahani, Yew Soon Ong, Savitha Ramasamy, Edwin Lughofer*

- `1809.09081v1` - [abs](http://arxiv.org/abs/1809.09081v1) - [pdf](http://arxiv.org/pdf/1809.09081v1)

> The generative learning phase of Autoencoder (AE) and its successor Denosing Autoencoder (DAE) enhances the flexibility of data stream method in exploiting unlabelled samples. Nonetheless, the feasibility of DAE for data stream analytic deserves in-depth study because it characterizes a fixed network capacity which cannot adapt to rapidly changing environments. An automated construction of a denoising autoeconder, namely deep evolving denoising autoencoder (DEVDAN), is proposed in this paper. DEVDAN features an open structure both in the generative phase and in the discriminative phase where input features can be automatically added and discarded on the fly. A network significance (NS) method is formulated in this paper and is derived from the bias-variance concept. This method is capable of estimating the statistical contribution of the network structure and its hidden units which precursors an ideal state to add or prune input features. Furthermore, DEVDAN is free of the problem- specific threshold and works fully in the single-pass learning fashion. The efficacy of DEVDAN is numerically validated using nine non-stationary data stream problems simulated under the prequential test-then-train protocol where DEVDAN is capable of delivering an improvement of classification accuracy to recently published online learning works while having flexibility in the automatic extraction of robust input features and in adapting to rapidly changing environments.

</details>

<details>

<summary>2018-09-24 18:13:01 - Better Safe than Sorry: Evidence Accumulation Allows for Safe Reinforcement Learning</summary>

- *Akshat Agarwal, Abhinau Kumar V, Kyle Dunovan, Erik Peterson, Timothy Verstynen, Katia Sycara*

- `1809.09147v1` - [abs](http://arxiv.org/abs/1809.09147v1) - [pdf](http://arxiv.org/pdf/1809.09147v1)

> In the real world, agents often have to operate in situations with incomplete information, limited sensing capabilities, and inherently stochastic environments, making individual observations incomplete and unreliable. Moreover, in many situations it is preferable to delay a decision rather than run the risk of making a bad decision. In such situations it is necessary to aggregate information before taking an action; however, most state of the art reinforcement learning (RL) algorithms are biased towards taking actions \textit{at every time step}, even if the agent is not particularly confident in its chosen action. This lack of caution can lead the agent to make critical mistakes, regardless of prior experience and acclimation to the environment. Motivated by theories of dynamic resolution of uncertainty during decision making in biological brains, we propose a simple accumulator module which accumulates evidence in favor of each possible decision, encodes uncertainty as a dynamic competition between actions, and acts on the environment only when it is sufficiently confident in the chosen action. The agent makes no decision by default, and the burden of proof to make a decision falls on the policy to accrue evidence strongly in favor of a single decision. Our results show that this accumulator module achieves near-optimal performance on a simple guessing game, far outperforming deep recurrent networks using traditional, forced action selection policies.

</details>

<details>

<summary>2018-09-24 19:00:42 - Complexity of Shift Bribery in Committee Elections</summary>

- *Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier, Nimrod Talmon*

- `1601.01492v2` - [abs](http://arxiv.org/abs/1601.01492v2) - [pdf](http://arxiv.org/pdf/1601.01492v2)

> Given an election, a preferred candidate p, and a budget, the SHIFT BRIBERY problem asks whether p can win the election after shifting p higher in some voters' preference orders. Of course, shifting comes at a price (depending on the voter and on the extent of the shift) and one must not exceed the given budget. We study the (parameterized) computational complexity of S HIFT BRIBERY for multiwinner voting rules where winning the election means to be part of some winning committee. We focus on the well-established SNTV, Bloc, k-Borda, and Chamberlin-Courant rules, as well as on approximate variants of the Chamberlin-Courant rule, since the original rule is NP-hard to compute. We show that SHIFT BRIBERY tends to be harder in the multiwinner setting than in the single-winner one by showing settings where SHIFT BRIBERY is easy in the single-winner cases, but is hard (and hard to approximate) in the multiwinner ones. Moreover, we show that the non-monotonicity of those rules which are based on approximation algorithms for the Chamberlin-Courant rule sometimes affects the complexity of SHIFT BRIBERY.

</details>

<details>

<summary>2018-09-25 00:07:20 - Resilient Computing with Reinforcement Learning on a Dynamical System: Case Study in Sorting</summary>

- *Aleksandra Faust, James B. Aimone, Conrad D. James, Lydia Tapia*

- `1809.09261v1` - [abs](http://arxiv.org/abs/1809.09261v1) - [pdf](http://arxiv.org/pdf/1809.09261v1)

> Robots and autonomous agents often complete goal-based tasks with limited resources, relying on imperfect models and sensor measurements. In particular, reinforcement learning (RL) and feedback control can be used to help a robot achieve a goal. Taking advantage of this body of work, this paper formulates general computation as a feedback-control problem, which allows the agent to autonomously overcome some limitations of standard procedural language programming: resilience to errors and early program termination. Our formulation considers computation to be trajectory generation in the program's variable space. The computing then becomes a sequential decision making problem, solved with reinforcement learning (RL), and analyzed with Lyapunov stability theory to assess the agent's resilience and progression to the goal. We do this through a case study on a quintessential computer science problem, array sorting. Evaluations show that our RL sorting agent makes steady progress to an asymptotically stable goal, is resilient to faulty components, and performs less array manipulations than traditional Quicksort and Bubble sort.

</details>

<details>

<summary>2018-09-25 02:45:19 - Covfefe: A Computer Vision Approach For Estimating Force Exertion</summary>

- *Vaneet Aggarwal, Hamed Asadi, Mayank Gupta, Jae Joong Lee, Denny Yu*

- `1809.09293v1` - [abs](http://arxiv.org/abs/1809.09293v1) - [pdf](http://arxiv.org/pdf/1809.09293v1)

> Cumulative exposure to repetitive and forceful activities may lead to musculoskeletal injuries which not only reduce workers' efficiency and productivity, but also affect their quality of life. Thus, widely accessible techniques for reliable detection of unsafe muscle force exertion levels for human activity is necessary for their well-being. However, measurement of force exertion levels is challenging and the existing techniques pose a great challenge as they are either intrusive, interfere with human-machine interface, and/or subjective in the nature, thus are not scalable for all workers. In this work, we use face videos and the photoplethysmography (PPG) signals to classify force exertion levels of 0\%, 50\%, and 100\% (representing rest, moderate effort, and high effort), thus providing a non-intrusive and scalable approach. Efficient feature extraction approaches have been investigated, including standard deviation of the movement of different landmarks of the face, distances between peaks and troughs in the PPG signals. We note that the PPG signals can be obtained from the face videos, thus giving an efficient classification algorithm for the force exertion levels using face videos. Based on the data collected from 20 subjects, features extracted from the face videos give 90\% accuracy in classification among the 100\% and the combination of 0\% and 50\% datasets. Further combining the PPG signals provide 81.7\% accuracy. The approach is also shown to be robust to the correctly identify force level when the person is talking, even though such datasets are not included in the training.

</details>

<details>

<summary>2018-09-25 08:38:05 - Inferring Complementary Products from Baskets and Browsing Sessions</summary>

- *Ilya Trofimov*

- `1809.09621v1` - [abs](http://arxiv.org/abs/1809.09621v1) - [pdf](http://arxiv.org/pdf/1809.09621v1)

> Complementary products recommendation is an important problem in e-commerce. Such recommendations increase the average order price and the number of products in baskets. Complementary products are typically inferred from basket data. In this study, we propose the BB2vec model. The BB2vec model learns vector representations of products by analyzing jointly two types of data - Baskets and Browsing sessions (visiting web pages of products). These vector representations are used for making complementary products recommendation. The proposed model alleviates the cold start problem by delivering better recommendations for products having few or no purchases. We show that the BB2vec model has better performance than other models which use only basket data.

</details>

<details>

<summary>2018-09-25 11:54:46 - Explainable PCGML via Game Design Patterns</summary>

- *Matthew Guzdial, Joshua Reno, Jonathan Chen, Gillian Smith, Mark Riedl*

- `1809.09419v1` - [abs](http://arxiv.org/abs/1809.09419v1) - [pdf](http://arxiv.org/pdf/1809.09419v1)

> Procedural content generation via Machine Learning (PCGML) is the umbrella term for approaches that generate content for games via machine learning. One of the benefits of PCGML is that, unlike search or grammar-based PCG, it does not require hand authoring of initial content or rules. Instead, PCGML relies on existing content and black box models, which can be difficult to tune or tweak without expert knowledge. This is especially problematic when a human designer needs to understand how to manipulate their data or models to achieve desired results. We present an approach to Explainable PCGML via Design Patterns in which the design patterns act as a vocabulary and mode of interaction between user and model. We demonstrate that our technique outperforms non-explainable versions of our system in interactions with five expert designers, four of whom lack any machine learning expertise.

</details>

<details>

<summary>2018-09-25 11:56:52 - Co-Creative Level Design via Machine Learning</summary>

- *Matthew Guzdial, Nicholas Liao, Mark Riedl*

- `1809.09420v1` - [abs](http://arxiv.org/abs/1809.09420v1) - [pdf](http://arxiv.org/pdf/1809.09420v1)

> Procedural Level Generation via Machine Learning (PLGML), the study of generating game levels with machine learning, has received a large amount of recent academic attention. For certain measures these approaches have shown success at replicating the quality of existing game levels. However, it is unclear the extent to which they might benefit human designers. In this paper we present a framework for co-creative level design with a PLGML agent. In support of this framework we present results from a user study and results from a comparative study of PLGML approaches.

</details>

<details>

<summary>2018-09-25 12:09:52 - Towards Automated Let's Play Commentary</summary>

- *Matthew Guzdial, Shukan Shah, Mark Riedl*

- `1809.09424v1` - [abs](http://arxiv.org/abs/1809.09424v1) - [pdf](http://arxiv.org/pdf/1809.09424v1)

> We introduce the problem of generating Let's Play-style commentary of gameplay video via machine learning. We propose an analysis of Let's Play commentary and a framework for building such a system. To test this framework we build an initial, naive implementation, which we use to interrogate the assumptions of the framework. We demonstrate promising results towards future Let's Play commentary generation.

</details>

<details>

<summary>2018-09-25 12:27:36 - Logic Programming as a Service</summary>

- *Roberta Calegari, Enrico Denti, Stefano Mariani, Andrea Omicini*

- `1806.02577v2` - [abs](http://arxiv.org/abs/1806.02577v2) - [pdf](http://arxiv.org/pdf/1806.02577v2)

> New generations of distributed systems are opening novel perspectives for logic programming (LP): on the one hand, service-oriented architectures represent nowadays the standard approach for distributed systems engineering; on the other hand, pervasive systems mandate for situated intelligence. In this paper we introduce the notion of Logic Programming as a Service (LPaaS) as a means to address the needs of pervasive intelligent systems through logic engines exploited as a distributed service. First we define the abstract architectural model by re-interpreting classical LP notions in the new context; then we elaborate on the nature of LP interpreted as a service by describing the basic LPaaS interface. Finally, we show how LPaaS works in practice by discussing its implementation in terms of distributed tuProlog engines, accounting for basic issues such as interoperability and configurability.

</details>

<details>

<summary>2018-09-25 12:42:11 - A Framework for Data-Driven Physical Security and Insider Threat Detection</summary>

- *Vasileios Mavroeidis, Kamer Vishi, Audun Jøsang*

- `1809.09434v1` - [abs](http://arxiv.org/abs/1809.09434v1) - [pdf](http://arxiv.org/pdf/1809.09434v1)

> This paper presents PS0, an ontological framework and a methodology for improving physical security and insider threat detection. PS0 can facilitate forensic data analysis and proactively mitigate insider threats by leveraging rule-based anomaly detection. In all too many cases, rule-based anomaly detection can detect employee deviations from organizational security policies. In addition, PS0 can be considered a security provenance solution because of its ability to fully reconstruct attack patterns. Provenance graphs can be further analyzed to identify deceptive actions and overcome analytical mistakes that can result in bad decision-making, such as false attribution. Moreover, the information can be used to enrich the available intelligence (about intrusion attempts) that can form use cases to detect and remediate limitations in the system, such as loosely-coupled provenance graphs that in many cases indicate weaknesses in the physical security architecture. Ultimately, validation of the framework through use cases demonstrates and proves that PS0 can improve an organization's security posture in terms of physical security and insider threat detection.

</details>

<details>

<summary>2018-09-25 12:57:30 - Defining the Collective Intelligence Supply Chain</summary>

- *Iain Barclay, Alun Preece, Ian Taylor*

- `1809.09444v1` - [abs](http://arxiv.org/abs/1809.09444v1) - [pdf](http://arxiv.org/pdf/1809.09444v1)

> Organisations are increasingly open to scrutiny, and need to be able to prove that they operate in a fair and ethical way. Accountability should extend to the production and use of the data and knowledge assets used in AI systems, as it would for any raw material or process used in production of physical goods. This paper considers collective intelligence, comprising data and knowledge generated by crowd-sourced workforces, which can be used as core components of AI systems. A proposal is made for the development of a supply chain model for tracking the creation and use of crowdsourced collective intelligence assets, with a blockchain based decentralised architecture identified as an appropriate means of providing validation, accountability and fairness.

</details>

<details>

<summary>2018-09-25 13:32:41 - Automatic brain tumor grading from MRI data using convolutional neural networks and quality assessment</summary>

- *Sergio Pereira, Raphael Meier, Victor Alves, Mauricio Reyes, Carlos A. Silva*

- `1809.09468v1` - [abs](http://arxiv.org/abs/1809.09468v1) - [pdf](http://arxiv.org/pdf/1809.09468v1)

> Glioblastoma Multiforme is a high grade, very aggressive, brain tumor, with patients having a poor prognosis. Lower grade gliomas are less aggressive, but they can evolve into higher grade tumors over time. Patient management and treatment can vary considerably with tumor grade, ranging from tumor resection followed by a combined radio- and chemotherapy to a "wait and see" approach. Hence, tumor grading is important for adequate treatment planning and monitoring. The gold standard for tumor grading relies on histopathological diagnosis of biopsy specimens. However, this procedure is invasive, time consuming, and prone to sampling error. Given these disadvantages, automatic tumor grading from widely used MRI protocols would be clinically important, as a way to expedite treatment planning and assessment of tumor evolution. In this paper, we propose to use Convolutional Neural Networks for predicting tumor grade directly from imaging data. In this way, we overcome the need for expert annotations of regions of interest. We evaluate two prediction approaches: from the whole brain, and from an automatically defined tumor region. Finally, we employ interpretability methodologies as a quality assurance stage to check if the method is using image regions indicative of tumor grade for classification.

</details>

<details>

<summary>2018-09-25 18:34:47 - Pop Music Highlighter: Marking the Emotion Keypoints</summary>

- *Yu-Siang Huang, Szu-Yu Chou, Yi-Hsuan Yang*

- `1802.10495v2` - [abs](http://arxiv.org/abs/1802.10495v2) - [pdf](http://arxiv.org/pdf/1802.10495v2)

> The goal of music highlight extraction is to get a short consecutive segment of a piece of music that provides an effective representation of the whole piece. In a previous work, we introduced an attention-based convolutional recurrent neural network that uses music emotion classification as a surrogate task for music highlight extraction, for Pop songs. The rationale behind that approach is that the highlight of a song is usually the most emotional part. This paper extends our previous work in the following two aspects. First, methodology-wise we experiment with a new architecture that does not need any recurrent layers, making the training process faster. Moreover, we compare a late-fusion variant and an early-fusion variant to study which one better exploits the attention mechanism. Second, we conduct and report an extensive set of experiments comparing the proposed attention-based methods against a heuristic energy-based method, a structural repetition-based method, and a few other simple feature-based methods for this task. Due to the lack of public-domain labeled data for highlight extraction, following our previous work we use the RWC POP 100-song data set to evaluate how the detected highlights overlap with any chorus sections of the songs. The experiments demonstrate the effectiveness of our methods over competing methods. For reproducibility, we open source the code and pre-trained model at https://github.com/remyhuang/pop-music-highlighter/.

</details>

<details>

<summary>2018-09-25 18:55:07 - Personalizing Dialogue Agents: I have a dog, do you have pets too?</summary>

- *Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston*

- `1801.07243v5` - [abs](http://arxiv.org/abs/1801.07243v5) - [pdf](http://arxiv.org/pdf/1801.07243v5)

> Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i) condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.

</details>

<details>

<summary>2018-09-25 22:10:42 - Automata Guided Reinforcement Learning With Demonstrations</summary>

- *Xiao Li, Yao Ma, Calin Belta*

- `1809.06305v2` - [abs](http://arxiv.org/abs/1809.06305v2) - [pdf](http://arxiv.org/pdf/1809.06305v2)

> Tasks with complex temporal structures and long horizons pose a challenge for reinforcement learning agents due to the difficulty in specifying the tasks in terms of reward functions as well as large variances in the learning signals. We propose to address these problems by combining temporal logic (TL) with reinforcement learning from demonstrations. Our method automatically generates intrinsic rewards that align with the overall task goal given a TL task specification. The policy resulting from our framework has an interpretable and hierarchical structure. We validate the proposed method experimentally on a set of robotic manipulation tasks.

</details>

<details>

<summary>2018-09-25 23:39:34 - How can deep learning advance computational modeling of sensory information processing?</summary>

- *Jessica A. F. Thompson, Yoshua Bengio, Elia Formisano, Marc Schönwiesner*

- `1810.08651v1` - [abs](http://arxiv.org/abs/1810.08651v1) - [pdf](http://arxiv.org/pdf/1810.08651v1)

> Deep learning, computational neuroscience, and cognitive science have overlapping goals related to understanding intelligence such that perception and behaviour can be simulated in computational systems. In neuroimaging, machine learning methods have been used to test computational models of sensory information processing. Recently, these model comparison techniques have been used to evaluate deep neural networks (DNNs) as models of sensory information processing. However, the interpretation of such model evaluations is muddied by imprecise statistical conclusions. Here, we make explicit the types of conclusions that can be drawn from these existing model comparison techniques and how these conclusions change when the model in question is a DNN. We discuss how DNNs are amenable to new model comparison techniques that allow for stronger conclusions to be made about the computational mechanisms underlying sensory information processing.

</details>

<details>

<summary>2018-09-26 00:05:47 - Towards Game-based Metrics for Computational Co-creativity</summary>

- *Rodrigo Canaan, Stefan Menzel, Julian Togelius, Andy Nealen*

- `1809.09762v1` - [abs](http://arxiv.org/abs/1809.09762v1) - [pdf](http://arxiv.org/pdf/1809.09762v1)

> We propose the following question: what game-like interactive system would provide a good environment for measuring the impact and success of a co-creative, cooperative agent? Creativity is often formulated in terms of novelty, value, surprise and interestingness. We review how these concepts are measured in current computational intelligence research and provide a mapping from modern electronic and tabletop games to open research problems in mixed-initiative systems and computational co-creativity. We propose application scenarios for future research, and a number of metrics under which the performance of cooperative agents in these environments will be evaluated.

</details>

<details>

<summary>2018-09-26 00:12:03 - Evolving Agents for the Hanabi 2018 CIG Competition</summary>

- *Rodrigo Canaan, Haotian Shen, Ruben Rodriguez Torrado, Julian Togelius, Andy Nealen, Stefan Menzel*

- `1809.09764v1` - [abs](http://arxiv.org/abs/1809.09764v1) - [pdf](http://arxiv.org/pdf/1809.09764v1)

> Hanabi is a cooperative card game with hidden information that has won important awards in the industry and received some recent academic attention. A two-track competition of agents for the game will take place in the 2018 CIG conference. In this paper, we develop a genetic algorithm that builds rule-based agents by determining the best sequence of rules from a fixed rule set to use as strategy. In three separate experiments, we remove human assumptions regarding the ordering of rules, add new, more expressive rules to the rule set and independently evolve agents specialized at specific game sizes. As result, we achieve scores superior to previously published research for the mirror and mixed evaluation of agents.

</details>

<details>

<summary>2018-09-26 04:11:21 - Early Identification of Pathogenic Social Media Accounts</summary>

- *Hamidreza Alvari, Elham Shaabani, Paulo Shakarian*

- `1809.09331v2` - [abs](http://arxiv.org/abs/1809.09331v2) - [pdf](http://arxiv.org/pdf/1809.09331v2)

> Pathogenic Social Media (PSM) accounts such as terrorist supporters exploit large communities of supporters for conducting attacks on social media. Early detection of these accounts is crucial as they are high likely to be key users in making a harmful message "viral". In this paper, we make the first attempt on utilizing causal inference to identify PSMs within a short time frame around their activity. We propose a time-decay causality metric and incorporate it into a causal community detection-based algorithm. The proposed algorithm is applied to groups of accounts sharing similar causality features and is followed by a classification algorithm to classify accounts as PSM or not. Unlike existing techniques that take significant time to collect information such as network, cascade path, or content, our scheme relies solely on action log of users. Results on a real-world dataset from Twitter demonstrate effectiveness and efficiency of our approach. We achieved precision of 0.84 for detecting PSMs only based on their first 10 days of activity; the misclassified accounts were then detected 10 days later.

</details>

<details>

<summary>2018-09-26 07:30:52 - Dynamic Difficulty Awareness Training for Continuous Emotion Prediction</summary>

- *Zixing Zhang, Jing Han, Eduardo Coutinho, Björn Schuller*

- `1810.05507v1` - [abs](http://arxiv.org/abs/1810.05507v1) - [pdf](http://arxiv.org/pdf/1810.05507v1)

> Time-continuous emotion prediction has become an increasingly compelling task in machine learning. Considerable efforts have been made to advance the performance of these systems. Nonetheless, the main focus has been the development of more sophisticated models and the incorporation of different expressive modalities (e. g., speech, face, and physiology). In this paper, motivated by the benefit of difficulty awareness in a human learning procedure, we propose a novel machine learning framework, namely, Dynamic Difficulty Awareness Training (DDAT), which sheds fresh light on the research -- directly exploiting the difficulties in learning to boost the machine learning process. The DDAT framework consists of two stages: information retrieval and information exploitation. In the first stage, we make use of the reconstruction error of input features or the annotation uncertainty to estimate the difficulty of learning specific information. The obtained difficulty level is then used in tandem with original features to update the model input in a second learning stage with the expectation that the model can learn to focus on high difficulty regions of the learning process. We perform extensive experiments on a benchmark database (RECOLA) to evaluate the effectiveness of the proposed framework. The experimental results show that our approach outperforms related baselines as well as other well-established time-continuous emotion prediction systems, which suggests that dynamically integrating the difficulty information for neural networks can help enhance the learning process.

</details>

<details>

<summary>2018-09-26 07:55:02 - Verisimilar Image Synthesis for Accurate Detection and Recognition of Texts in Scenes</summary>

- *Fangneng Zhan, Shijian Lu, Chuhui Xue*

- `1807.03021v2` - [abs](http://arxiv.org/abs/1807.03021v2) - [pdf](http://arxiv.org/pdf/1807.03021v2)

> The requirement of large amounts of annotated images has become one grand challenge while training deep neural network models for various visual detection and recognition tasks. This paper presents a novel image synthesis technique that aims to generate a large amount of annotated scene text images for training accurate and robust scene text detection and recognition models. The proposed technique consists of three innovative designs. First, it realizes "semantic coherent" synthesis by embedding texts at semantically sensible regions within the background image, where the semantic coherence is achieved by leveraging the semantic annotations of objects and image regions that have been created in the prior semantic segmentation research. Second, it exploits visual saliency to determine the embedding locations within each semantic sensible region, which coincides with the fact that texts are often placed around homogeneous regions for better visibility in scenes. Third, it designs an adaptive text appearance model that determines the color and brightness of embedded texts by learning from the feature of real scene text images adaptively. The proposed technique has been evaluated over five public datasets and the experiments show its superior performance in training accurate and robust scene text detection and recognition models.

</details>

<details>

<summary>2018-09-26 09:31:11 - A novel approach for venue recommendation using cross-domain techniques</summary>

- *Pablo Sánchez, Alejandro Bellogín*

- `1809.09864v1` - [abs](http://arxiv.org/abs/1809.09864v1) - [pdf](http://arxiv.org/pdf/1809.09864v1)

> Finding the next venue to be visited by a user in a specific city is an interesting, but challenging, problem. Different techniques have been proposed, combining collaborative, content, social, and geographical signals; however it is not trivial to decide which tech- nique works best, since this may depend on the data density or the amount of activity logged for each user or item. At the same time, cross-domain strategies have been exploited in the recommender systems literature when dealing with (very) sparse situations, such as those inherently arising when recommendations are produced based on information from a single city.   In this paper, we address the problem of venue recommendation from a novel perspective: applying cross-domain recommenda- tion techniques considering each city as a different domain. We perform an experimental comparison of several recommendation techniques in a temporal split under two conditions: single-domain (only information from the target city is considered) and cross- domain (information from many other cities is incorporated into the recommendation algorithm). For the latter, we have explored two strategies to transfer knowledge from one domain to another: testing the target city and training a model with information of the k cities with more ratings or only using the k closest cities.   Our results show that, in general, applying cross-domain by proximity increases the performance of the majority of the recom- menders in terms of relevance. This is the first work, to the best of our knowledge, where so many domains (eight) are combined in the tourism context where a temporal split is used, and thus we expect these results could provide readers with an overall picture of what can be achieved in a real-world environment.

</details>

<details>

<summary>2018-09-26 10:25:17 - Adversarial Attacks on Cognitive Self-Organizing Networks: The Challenge and the Way Forward</summary>

- *Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha*

- `1810.07242v1` - [abs](http://arxiv.org/abs/1810.07242v1) - [pdf](http://arxiv.org/pdf/1810.07242v1)

> Future communications and data networks are expected to be largely cognitive self-organizing networks (CSON). Such networks will have the essential property of cognitive self-organization, which can be achieved using machine learning techniques (e.g., deep learning). Despite the potential of these techniques, these techniques in their current form are vulnerable to adversarial attacks that can cause cascaded damages with detrimental consequences for the whole network. In this paper, we explore the effect of adversarial attacks on CSON. Our experiments highlight the level of threat that CSON have to deal with in order to meet the challenges of next-generation networks and point out promising directions for future work.

</details>

<details>

<summary>2018-09-26 11:59:00 - Every Node Counts: Self-Ensembling Graph Convolutional Networks for Semi-Supervised Learning</summary>

- *Yawei Luo, Tao Guan, Junqing Yu, Ping Liu, Yi Yang*

- `1809.09925v1` - [abs](http://arxiv.org/abs/1809.09925v1) - [pdf](http://arxiv.org/pdf/1809.09925v1)

> Graph convolutional network (GCN) provides a powerful means for graph-based semi-supervised tasks. However, as a localized first-order approximation of spectral graph convolution, the classic GCN can not take full advantage of unlabeled data, especially when the unlabeled node is far from labeled ones. To capitalize on the information from unlabeled nodes to boost the training for GCN, we propose a novel framework named Self-Ensembling GCN (SEGCN), which marries GCN with Mean Teacher - another powerful model in semi-supervised learning. SEGCN contains a student model and a teacher model. As a student, it not only learns to correctly classify the labeled nodes, but also tries to be consistent with the teacher on unlabeled nodes in more challenging situations, such as a high dropout rate and graph collapse. As a teacher, it averages the student model weights and generates more accurate predictions to lead the student. In such a mutual-promoting process, both labeled and unlabeled samples can be fully utilized for backpropagating effective gradients to train GCN. In three article classification tasks, i.e. Citeseer, Cora and Pubmed, we validate that the proposed method matches the state of the arts in the classification accuracy.

</details>

<details>

<summary>2018-09-26 13:43:01 - Universal Network Representation for Heterogeneous Information Networks</summary>

- *Ruiqi Hu, Celina Ping Yu, Sai-Fu Fung, Shirui Pan, Haishuai Wang, Guodong Long*

- `1811.12157v1` - [abs](http://arxiv.org/abs/1811.12157v1) - [pdf](http://arxiv.org/pdf/1811.12157v1)

> Network representation aims to represent the nodes in a network as continuous and compact vectors, and has attracted much attention in recent years due to its ability to capture complex structure relationships inside networks. However, existing network representation methods are commonly designed for homogeneous information networks where all the nodes (entities) of a network are of the same type, e.g., papers in a citation network. In this paper, we propose a universal network representation approach (UNRA), that represents different types of nodes in heterogeneous information networks in a continuous and common vector space. The UNRA is built on our latest mutually updated neural language module, which simultaneously captures inter-relationship among homogeneous nodes and node-content correlation. Relationships between different types of nodes are also assembled and learned in a unified framework. Experiments validate that the UNRA achieves outstanding performance, compared to six other state-of-the-art algorithms, in node representation, node classification, and network visualization. In node classification, the UNRA achieves a 3\% to 132\% performance improvement in terms of accuracy.

</details>

<details>

<summary>2018-09-26 14:55:34 - Hyperspherical Variational Auto-Encoders</summary>

- *Tim R. Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, Jakub M. Tomczak*

- `1804.00891v2` - [abs](http://arxiv.org/abs/1804.00891v2) - [pdf](http://arxiv.org/pdf/1804.00891v2)

> The Variational Auto-Encoder (VAE) is one of the most used unsupervised machine learning models. But although the default choice of a Gaussian distribution for both the prior and posterior represents a mathematically convenient distribution often leading to competitive results, we show that this parameterization fails to model data with a latent hyperspherical structure. To address this issue we propose using a von Mises-Fisher (vMF) distribution instead, leading to a hyperspherical latent space. Through a series of experiments we show how such a hyperspherical VAE, or $\mathcal{S}$-VAE, is more suitable for capturing data with a hyperspherical latent structure, while outperforming a normal, $\mathcal{N}$-VAE, in low dimensions on other data types.

</details>

<details>

<summary>2018-09-26 15:08:08 - Sampling Theory for Graph Signals on Product Graphs</summary>

- *Rohan Varma, Jelena Kovačević*

- `1809.10049v1` - [abs](http://arxiv.org/abs/1809.10049v1) - [pdf](http://arxiv.org/pdf/1809.10049v1)

> In this paper, we extend the sampling theory on graphs by constructing a framework that exploits the structure in product graphs for efficient sampling and recovery of bandlimited graph signals that lie on them. Product graphs are graphs that are composed from smaller graph atoms; we motivate how this model is a flexible and useful way to model richer classes of data that can be multi-modal in nature. Previous works have established a sampling theory on graphs for bandlimited signals. Importantly, the framework achieves significant savings in both sample complexity and computational complexity

</details>

<details>

<summary>2018-09-26 15:12:14 - General-purpose Declarative Inductive Programming with Domain-Specific Background Knowledge for Data Wrangling Automation</summary>

- *Lidia Contreras-Ochando, César Ferri, José Hernández-Orallo, Fernando Martínez-Plumed, María José Ramírez-Quintana, Susumu Katayama*

- `1809.10054v1` - [abs](http://arxiv.org/abs/1809.10054v1) - [pdf](http://arxiv.org/pdf/1809.10054v1)

> Given one or two examples, humans are good at understanding how to solve a problem independently of its domain, because they are able to detect what the problem is and to choose the appropriate background knowledge according to the context. For instance, presented with the string "8/17/2017" to be transformed to "17th of August of 2017", humans will process this in two steps: (1) they recognise that it is a date and (2) they map the date to the 17th of August of 2017. Inductive Programming (IP) aims at learning declarative (functional or logic) programs from examples. Two key advantages of IP are the use of background knowledge and the ability to synthesise programs from a few input/output examples (as humans do). In this paper we propose to use IP as a means for automating repetitive data manipulation tasks, frequently presented during the process of {\em data wrangling} in many data manipulation problems. Here we show that with the use of general-purpose declarative (programming) languages jointly with generic IP systems and the definition of domain-specific knowledge, many specific data wrangling problems from different application domains can be automatically solved from very few examples. We also propose an integrated benchmark for data wrangling, which we share publicly for the community.

</details>

<details>

<summary>2018-09-26 18:25:32 - The Intelligent ICU Pilot Study: Using Artificial Intelligence Technology for Autonomous Patient Monitoring</summary>

- *Anis Davoudi, Kumar Rohit Malhotra, Benjamin Shickel, Scott Siegel, Seth Williams, Matthew Ruppert, Emel Bihorac, Tezcan Ozrazgat-Baslanti, Patrick J. Tighe, Azra Bihorac, Parisa Rashidi*

- `1804.10201v2` - [abs](http://arxiv.org/abs/1804.10201v2) - [pdf](http://arxiv.org/pdf/1804.10201v2)

> Currently, many critical care indices are repetitively assessed and recorded by overburdened nurses, e.g. physical function or facial pain expressions of nonverbal patients. In addition, many essential information on patients and their environment are not captured at all, or are captured in a non-granular manner, e.g. sleep disturbance factors such as bright light, loud background noise, or excessive visitations. In this pilot study, we examined the feasibility of using pervasive sensing technology and artificial intelligence for autonomous and granular monitoring of critically ill patients and their environment in the Intensive Care Unit (ICU). As an exemplar prevalent condition, we also characterized delirious and non-delirious patients and their environment. We used wearable sensors, light and sound sensors, and a high-resolution camera to collected data on patients and their environment. We analyzed collected data using deep learning and statistical analysis. Our system performed face detection, face recognition, facial action unit detection, head pose detection, facial expression recognition, posture recognition, actigraphy analysis, sound pressure and light level detection, and visitation frequency detection. We were able to detect patient's face (Mean average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their postures (F1=0.94). We also found that all facial expressions, 11 activity features, visitation frequency during the day, visitation frequency during the night, light levels, and sound pressure levels during the night were significantly different between delirious and non-delirious patients (p-value<0.05). In summary, we showed that granular and autonomous monitoring of critically ill patients and their environment is feasible and can be used for characterizing critical care conditions and related environment factors.

</details>

<details>

<summary>2018-09-26 18:58:24 - Content Based Image Retrieval from AWiFS Images Repository of IRS Resourcesat-2 Satellite Based on Water Bodies and Burnt Areas</summary>

- *Suraj Kothawade, Kunjan Mhaske, Sahil Sharma, Furkhan Shaikh*

- `1809.10190v1` - [abs](http://arxiv.org/abs/1809.10190v1) - [pdf](http://arxiv.org/pdf/1809.10190v1)

> Satellite Remote Sensing Technology is becoming a major milestone in the prediction of weather anomalies, natural disasters as well as finding alternative resources in proximity using multiple multi-spectral sensors emitting electromagnetic waves at distinct wavelengths. Hence, it is imperative to extract water bodies and burnt areas from orthorectified tiles and correspondingly rank them using similarity measures. Different objects in all the spheres of the earth have the inherent capability of absorbing electromagnetic waves of distant wavelengths. This creates various unique masks in terms of reflectance on the receptor. We propose Dynamic Semantic Segmentation (DSS) algorithms that utilized the mentioned capability to extract and rank Advanced Wide Field Sensor (AWiFS) images according to various features. This system stores data intelligently in the form of a sparse feature vector which drastically mitigates the computational and spatial costs incurred for further analysis. The compressed source image is divided into chunks and stored in the database for quicker retrieval. This work is intended to utilize readily available and cost effective resources like AWiFS dataset instead of depending on advanced technologies like Moderate Resolution Imaging Spectroradiometer (MODIS) for data which is scarce.

</details>

<details>

<summary>2018-09-26 19:33:13 - Modular Semantics and Characteristics for Bipolar Weighted Argumentation Graphs</summary>

- *Till Mossakowski, Fabian Neuhaus*

- `1807.06685v2` - [abs](http://arxiv.org/abs/1807.06685v2) - [pdf](http://arxiv.org/pdf/1807.06685v2)

> This paper addresses the semantics of weighted argumentation graphs that are bipolar, i.e. contain both attacks and supports for arguments. It builds on previous work by Amgoud, Ben-Naim et. al. We study the various characteristics of acceptability semantics that have been introduced in these works, and introduce the notion of a modular acceptability semantics. A semantics is modular if it cleanly separates aggregation of attacking and supporting arguments (for a given argument $a$) from the computation of their influence on $a$'s initial weight.   We show that the various semantics for bipolar argumentation graphs from the literature may be analysed as a composition of an aggregation function with an influence function. Based on this modular framework, we prove general convergence and divergence theorems. We demonstrate that all well-behaved modular acceptability semantics converge for all acyclic graphs and that no sum-based semantics can converge for all graphs. In particular, we show divergence of Euler-based semantics (Amgoud et al.) for certain cyclic graphs. Further, we provide the first semantics for bipolar weighted graphs that converges for all graphs.

</details>

<details>

<summary>2018-09-26 21:45:53 - Bayesian Inference of Regular Expressions from Human-Generated Example Strings</summary>

- *Long Ouyang*

- `1805.08427v2` - [abs](http://arxiv.org/abs/1805.08427v2) - [pdf](http://arxiv.org/pdf/1805.08427v2)

> In programming by example, users "write" programs by generating a small number of input-output examples and asking the computer to synthesize consistent programs. We consider a challenging problem in this domain: learning regular expressions (regexes) from positive and negative example strings. This problem is challenging, as (1) user-generated examples may not be informative enough to sufficiently constrain the hypothesis space, and (2) even if user-generated examples are in principle informative, there is still a massive search space to examine. We frame regex induction as the problem of inferring a probabilistic regular grammar and propose an efficient inference approach that uses a novel stochastic process recognition model. This model incrementally "grows" a grammar using positive examples as a scaffold. We show that this approach is competitive with human ability to learn regexes from examples.

</details>

<details>

<summary>2018-09-26 22:14:55 - Deeply Informed Neural Sampling for Robot Motion Planning</summary>

- *Ahmed H. Qureshi, Michael C. Yip*

- `1809.10252v1` - [abs](http://arxiv.org/abs/1809.10252v1) - [pdf](http://arxiv.org/pdf/1809.10252v1)

> Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.

</details>

<details>

<summary>2018-09-26 23:38:19 - Semantic Sentence Embeddings for Paraphrasing and Text Summarization</summary>

- *Chi Zhang, Shagan Sah, Thang Nguyen, Dheeraj Peri, Alexander Loui, Carl Salvaggio, Raymond Ptucha*

- `1809.10267v1` - [abs](http://arxiv.org/abs/1809.10267v1) - [pdf](http://arxiv.org/pdf/1809.10267v1)

> This paper introduces a sentence to vector encoding framework suitable for advanced natural language processing. Our latent representation is shown to encode sentences with common semantic information with similar vector representations. The vector representation is extracted from an encoder-decoder model which is trained on sentence paraphrase pairs. We demonstrate the application of the sentence representations for two different tasks -- sentence paraphrasing and paragraph summarization, making it attractive for commonly used recurrent frameworks that process text. Experimental results help gain insight how vector representations are suitable for advanced language embedding.

</details>

<details>

<summary>2018-09-27 00:06:53 - Semantically Enhanced Models for Commonsense Knowledge Acquisition</summary>

- *Ikhlas Alhussien, Erik Cambria, Zhang NengSheng*

- `1809.04708v2` - [abs](http://arxiv.org/abs/1809.04708v2) - [pdf](http://arxiv.org/pdf/1809.04708v2)

> Commonsense knowledge is paramount to enable intelligent systems. Typically, it is characterized as being implicit and ambiguous, hindering thereby the automation of its acquisition. To address these challenges, this paper presents semantically enhanced models to enable reasoning through resolving part of commonsense ambiguity. The proposed models enhance in a knowledge graph embedding (KGE) framework for knowledge base completion. Experimental results show the effectiveness of the new semantic models in commonsense reasoning.

</details>

<details>

<summary>2018-09-27 00:17:18 - Growing and Retaining AI Talent for the United States Government</summary>

- *Edward Raff*

- `1809.10276v1` - [abs](http://arxiv.org/abs/1809.10276v1) - [pdf](http://arxiv.org/pdf/1809.10276v1)

> Artificial Intelligence and Machine Learning have become transformative to a number of industries, and as such many industries need for AI talent is increasing the demand for individuals with these skills. This continues to exacerbate the difficulty of acquiring and retaining talent for the United States Federal Government, both for its direct employees as well as the companies that support it. We take the position that by focusing on growing and retaining current talent through a number of cultural changes, the government can work to remediate this problem today.

</details>

<details>

<summary>2018-09-27 07:58:48 - Identification of Wearable Devices with Bluetooth</summary>

- *Hidayet Aksu, A. Selcuk Uluagac, Elizabeth S. Bentley*

- `1809.10387v1` - [abs](http://arxiv.org/abs/1809.10387v1) - [pdf](http://arxiv.org/pdf/1809.10387v1)

> With wearable devices such as smartwatches on the rise in the consumer electronics market, securing these wearables is vital. However, the current security mechanisms only focus on validating the user not the device itself. Indeed, wearables can be (1) unauthorized wearable devices with correct credentials accessing valuable systems and networks, (2) passive insiders or outsider wearable devices, or (3) information-leaking wearables devices. Fingerprinting via machine learning can provide necessary cyber threat intelligence to address all these cyber attacks. In this work, we introduce a wearable fingerprinting technique focusing on Bluetooth classic protocol, which is a common protocol used by the wearables and other IoT devices. Specifically, we propose a non-intrusive wearable device identification framework which utilizes 20 different Machine Learning (ML) algorithms in the training phase of the classification process and selects the best performing algorithm for the testing phase. Furthermore, we evaluate the performance of proposed wearable fingerprinting technique on real wearable devices, including various off-the-shelf smartwatches. Our evaluation demonstrates the feasibility of the proposed technique to provide reliable cyber threat intelligence. Specifically, our detailed accuracy results show on average 98.5%, 98.3% precision and recall for identifying wearables using the Bluetooth classic protocol.

</details>

<details>

<summary>2018-09-27 10:10:20 - Generating Ontologies from Templates: A Rule-Based Approach for Capturing Regularity</summary>

- *Henrik Forssell, Christian Kindermann, Daniel P. Lupp, Uli Sattler, Evgenij Thorstensen*

- `1809.10436v1` - [abs](http://arxiv.org/abs/1809.10436v1) - [pdf](http://arxiv.org/pdf/1809.10436v1)

> We present a second-order language that can be used to succinctly specify ontologies in a consistent and transparent manner. This language is based on ontology templates (OTTR), a framework for capturing recurring patterns of axioms in ontological modelling. The language and our results are independent of any specific DL. We define the language and its semantics, including the case of negation-as-failure, investigate reasoning over ontologies specified using our language, and show results about the decidability of useful reasoning tasks about the language itself. We also state and discuss some open problems that we believe to be of interest.

</details>

<details>

<summary>2018-09-27 10:13:06 - Wafer Quality Inspection using Memristive LSTM, ANN, DNN and HTM</summary>

- *Kazybek Adam, Kamilya Smagulova, Olga Krestinskaya, Alex Pappachen James*

- `1809.10438v1` - [abs](http://arxiv.org/abs/1809.10438v1) - [pdf](http://arxiv.org/pdf/1809.10438v1)

> The automated wafer inspection and quality control is a complex and time-consuming task, which can speed up using neuromorphic memristive architectures, as a separate inspection device or integrating directly into sensors. This paper presents the performance analysis and comparison of different neuromorphic architectures for patterned wafer quality inspection and classification. The application of non-volatile memristive devices in these architectures ensures low power consumption, small on-chip area scalability. We demonstrate that Long-Short Term Memory (LSTM) outperforms other architectures for the same number of training iterations, and has relatively low on-chip area and power consumption.

</details>

<details>

<summary>2018-09-27 13:03:57 - Inequity aversion improves cooperation in intertemporal social dilemmas</summary>

- *Edward Hughes, Joel Z. Leibo, Matthew G. Phillips, Karl Tuyls, Edgar A. Duéñez-Guzmán, Antonio García Castañeda, Iain Dunning, Tina Zhu, Kevin R. McKee, Raphael Koster, Heather Roff, Thore Graepel*

- `1803.08884v3` - [abs](http://arxiv.org/abs/1803.08884v3) - [pdf](http://arxiv.org/pdf/1803.08884v3)

> Groups of humans are often able to find ways to cooperate with one another in complex, temporally extended social dilemmas. Models based on behavioral economics are only able to explain this phenomenon for unrealistic stateless matrix games. Recently, multi-agent reinforcement learning has been applied to generalize social dilemma problems to temporally and spatially extended Markov games. However, this has not yet generated an agent that learns to cooperate in social dilemmas as humans do. A key insight is that many, but not all, human individuals have inequity averse social preferences. This promotes a particular resolution of the matrix game social dilemma wherein inequity-averse individuals are personally pro-social and punish defectors. Here we extend this idea to Markov games and show that it promotes cooperation in several types of sequential social dilemma, via a profitable interaction with policy learnability. In particular, we find that inequity aversion improves temporal credit assignment for the important class of intertemporal social dilemmas. These results help explain how large-scale cooperation may emerge and persist.

</details>

<details>

<summary>2018-09-27 15:12:54 - A novel active learning framework for classification: using weighted rank aggregation to achieve multiple query criteria</summary>

- *Yu Zhao, Zhenhui Shi, Jingyang Zhang, Dong Chen, Lixu Gu*

- `1809.10565v1` - [abs](http://arxiv.org/abs/1809.10565v1) - [pdf](http://arxiv.org/pdf/1809.10565v1)

> Multiple query criteria active learning (MQCAL) methods have a higher potential performance than conventional active learning methods in which only one criterion is deployed for sample selection. A central issue related to MQCAL methods concerns the development of an integration criteria strategy (ICS) that makes full use of all criteria. The conventional ICS adopted in relevant research all facilitate the desired effects, but several limitations still must be addressed. For instance, some of the strategies are not sufficiently scalable during the design process, and the number and type of criteria involved are dictated. Thus, it is challenging for the user to integrate other criteria into the original process unless modifications are made to the algorithm. Other strategies are too dependent on empirical parameters, which can only be acquired by experience or cross-validation and thus lack generality; additionally, these strategies are counter to the intention of active learning, as samples need to be labeled in the validation set before the active learning process can begin. To address these limitations, we propose a novel MQCAL method for classification tasks that employs a third strategy via weighted rank aggregation. The proposed method serves as a heuristic means to select high-value samples of high scalability and generality and is implemented through a three-step process: (1) the transformation of the sample selection to sample ranking and scoring, (2) the computation of the self-adaptive weights of each criterion, and (3) the weighted aggregation of each sample rank list. Ultimately, the sample at the top of the aggregated ranking list is the most comprehensively valuable and must be labeled. Several experiments generating 257 wins, 194 ties and 49 losses against other state-of-the-art MQCALs are conducted to verify that the proposed method can achieve superior results.

</details>

<details>

<summary>2018-09-27 16:10:01 - AlphaGomoku: An AlphaGo-based Gomoku Artificial Intelligence using Curriculum Learning</summary>

- *Zheng Xie, XingYu Fu, JinYuan Yu*

- `1809.10595v1` - [abs](http://arxiv.org/abs/1809.10595v1) - [pdf](http://arxiv.org/pdf/1809.10595v1)

> In this project, we combine AlphaGo algorithm with Curriculum Learning to crack the game of Gomoku. Modifications like Double Networks Mechanism and Winning Value Decay are implemented to solve the intrinsic asymmetry and short-sight of Gomoku. Our final AI AlphaGomoku, through two days' training on a single GPU, has reached humans' playing level.

</details>

<details>

<summary>2018-09-27 18:39:19 - Learning What Information to Give in Partially Observed Domains</summary>

- *Rohan Chitnis, Leslie Pack Kaelbling, Tomás Lozano-Pérez*

- `1805.08263v4` - [abs](http://arxiv.org/abs/1805.08263v4) - [pdf](http://arxiv.org/pdf/1805.08263v4)

> In many robotic applications, an autonomous agent must act within and explore a partially observed environment that is unobserved by its human teammate. We consider such a setting in which the agent can, while acting, transmit declarative information to the human that helps them understand aspects of this unseen environment. In this work, we address the algorithmic question of how the agent should plan out what actions to take and what information to transmit. Naturally, one would expect the human to have preferences, which we model information-theoretically by scoring transmitted information based on the change it induces in weighted entropy of the human's belief state. We formulate this setting as a belief MDP and give a tractable algorithm for solving it approximately. Then, we give an algorithm that allows the agent to learn the human's preferences online, through exploration. We validate our approach experimentally in simulated discrete and continuous partially observed search-and-recover domains. Visit http://tinyurl.com/chitnis-corl-18 for a supplementary video.

</details>

<details>

<summary>2018-09-27 20:18:25 - Interactive Surveillance Technologies for Dense Crowds</summary>

- *Aniket Bera, Dinesh Manocha*

- `1810.03965v1` - [abs](http://arxiv.org/abs/1810.03965v1) - [pdf](http://arxiv.org/pdf/1810.03965v1)

> We present an algorithm for realtime anomaly detection in low to medium density crowd videos using trajectory-level behavior learning. Our formulation combines online tracking algorithms from computer vision, non-linear pedestrian motion models from crowd simulation, and Bayesian learning techniques to automatically compute the trajectory-level pedestrian behaviors for each agent in the video. These learned behaviors are used to segment the trajectories and motions of different pedestrians or agents and detect anomalies. We demonstrate the interactive performance on the PETS ARENA dataset as well as indoor and outdoor crowd video benchmarks consisting of tens of human agents. We also discuss the implications of recent public policy and law enforcement issues relating to surveillance and our research.

</details>

<details>

<summary>2018-09-27 20:44:23 - An Introduction to Probabilistic Programming</summary>

- *Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, Frank Wood*

- `1809.10756v1` - [abs](http://arxiv.org/abs/1809.10756v1) - [pdf](http://arxiv.org/pdf/1809.10756v1)

> This document is designed to be a first-year graduate-level introduction to probabilistic programming. It not only provides a thorough background for anyone wishing to use a probabilistic programming system, but also introduces the techniques needed to design and build these systems. It is aimed at people who have an undergraduate-level understanding of either or, ideally, both probabilistic machine learning and programming languages.   We start with a discussion of model-based reasoning and explain why conditioning as a foundational computation is central to the fields of probabilistic machine learning and artificial intelligence. We then introduce a simple first-order probabilistic programming language (PPL) whose programs define static-computation-graph, finite-variable-cardinality models. In the context of this restricted PPL we introduce fundamental inference algorithms and describe how they can be implemented in the context of models denoted by probabilistic programs.   In the second part of this document, we introduce a higher-order probabilistic programming language, with a functionality analogous to that of established programming languages. This affords the opportunity to define models with dynamic computation graphs, at the cost of requiring inference methods that generate samples by repeatedly executing the program. Foundational inference algorithms for this kind of probabilistic programming language are explained in the context of an interface between program executions and an inference controller.   This document closes with a chapter on advanced topics which we believe to be, at the time of writing, interesting directions for probabilistic programming research; directions that point towards a tight integration with deep neural network research and the development of systems for next-generation artificial intelligence applications.

</details>

<details>

<summary>2018-09-27 22:39:45 - Learning and Acting in Peripersonal Space: Moving, Reaching, and Grasping</summary>

- *Jonathan Juett, Benjamin Kuipers*

- `1809.10788v1` - [abs](http://arxiv.org/abs/1809.10788v1) - [pdf](http://arxiv.org/pdf/1809.10788v1)

> The young infant explores its body, its sensorimotor system, and the immediately accessible parts of its environment, over the course of a few months creating a model of peripersonal space useful for reaching and grasping objects around it. Drawing on constraints from the empirical literature on infant behavior, we present a preliminary computational model of this learning process, implemented and evaluated on a physical robot. The learning agent explores the relationship between the configuration space of the arm, sensing joint angles through proprioception, and its visual perceptions of the hand and grippers. The resulting knowledge is represented as the peripersonal space (PPS) graph, where nodes represent states of the arm, edges represent safe movements, and paths represent safe trajectories from one pose to another. In our model, the learning process is driven by intrinsic motivation. When repeatedly performing an action, the agent learns the typical result, but also detects unusual outcomes, and is motivated to learn how to make those unusual results reliable. Arm motions typically leave the static background unchanged, but occasionally bump an object, changing its static position. The reach action is learned as a reliable way to bump and move an object in the environment. Similarly, once a reliable reach action is learned, it typically makes a quasi-static change in the environment, moving an object from one static position to another. The unusual outcome is that the object is accidentally grasped (thanks to the innate Palmar reflex), and thereafter moves dynamically with the hand. Learning to make grasps reliable is more complex than for reaches, but we demonstrate significant progress. Our current results are steps toward autonomous sensorimotor learning of motion, reaching, and grasping in peripersonal space, based on unguided exploration and intrinsic motivation.

</details>

<details>

<summary>2018-09-27 22:49:29 - Estimation of Personalized Effects Associated With Causal Pathways</summary>

- *Razieh Nabi, Phyllis Kanki, Ilya Shpitser*

- `1809.10791v1` - [abs](http://arxiv.org/abs/1809.10791v1) - [pdf](http://arxiv.org/pdf/1809.10791v1)

> The goal of personalized decision making is to map a unit's characteristics to an action tailored to maximize the expected outcome for that unit. Obtaining high-quality mappings of this type is the goal of the dynamic regime literature. In healthcare settings, optimizing policies with respect to a particular causal pathway may be of interest as well. For example, we may wish to maximize the chemical effect of a drug given data from an observational study where the chemical effect of the drug on the outcome is entangled with the indirect effect mediated by differential adherence. In such cases, we may wish to optimize the direct effect of a drug, while keeping the indirect effect to that of some reference treatment. [16] shows how to combine mediation analysis and dynamic treatment regime ideas to defines policies associated with causal pathways and counterfactual responses to these policies. In this paper, we derive a variety of methods for learning high quality policies of this type from data, in a causal model corresponding to a longitudinal setting of practical importance. We illustrate our methods via a dataset of HIV patients undergoing therapy, gathered in the Nigerian PEPFAR program.

</details>

<details>

<summary>2018-09-28 03:30:37 - Learning and Planning with a Semantic Model</summary>

- *Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari, Yuandong Tian*

- `1809.10842v1` - [abs](http://arxiv.org/abs/1809.10842v1) - [pdf](http://arxiv.org/pdf/1809.10842v1)

> Building deep reinforcement learning agents that can generalize and adapt to unseen environments remains a fundamental challenge for AI. This paper describes progresses on this challenge in the context of man-made environments, which are visually diverse but contain intrinsic semantic regularities. We propose a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-policy to execute, and updates the semantic model based on new observations. We perform experiments in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content.

</details>

<details>

<summary>2018-09-28 04:09:35 - Light Field Neural Network</summary>

- *Yuchi Huo, Sung-Eui Yoon*

- `1809.07009v2` - [abs](http://arxiv.org/abs/1809.07009v2) - [pdf](http://arxiv.org/pdf/1809.07009v2)

> We introduce an optical neural network system made by off-the-shelf components. In order to test the evaluate the physical property of the proposed system, we are making a prototype. After further discussions with our cooperators, we are agreed that the prototype implementation may take longer time than we expected earlier. Therefore we reach a consensus on withdrawing the paper until the physical data is available.

</details>

<details>

<summary>2018-09-28 06:34:08 - A Polynomial Time Subsumption Algorithm for Nominal Safe $\mathcal{ELO}_\bot$ under Rational Closure</summary>

- *Giovanni Casini, Umberto Straccia, Thomas Meyer*

- `1802.08201v2` - [abs](http://arxiv.org/abs/1802.08201v2) - [pdf](http://arxiv.org/pdf/1802.08201v2)

> Description Logics (DLs) under Rational Closure (RC) is a well-known framework for non-monotonic reasoning in DLs. In this paper, we address the concept subsumption decision problem under RC for nominal safe $\mathcal{ELO}_\bot$, a notable and practically important DL representative of the OWL 2 profile OWL 2 EL.   Our contribution here is to define a polynomial time subsumption procedure for nominal safe $\mathcal{ELO}_\bot$ under RC that relies entirely on a series of classical, monotonic $\mathcal{EL}_\bot$ subsumption tests. Therefore, any existing classical monotonic $\mathcal{EL}_\bot$ reasoner can be used as a black box to implement our method. We then also adapt the method to one of the known extensions of RC for DLs, namely Defeasible Inheritance-based DLs without losing the computational tractability.

</details>

<details>

<summary>2018-09-28 07:29:21 - HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting</summary>

- *Zheyi Pan, Yuxuan Liang, Junbo Zhang, Xiuwen Yi, Yong Yu, Yu Zheng*

- `1809.10889v1` - [abs](http://arxiv.org/abs/1809.10889v1) - [pdf](http://arxiv.org/pdf/1809.10889v1)

> Spatio-temporal (ST) data, which represent multiple time series data corresponding to different spatial locations, are ubiquitous in real-world dynamic systems, such as air quality readings. Forecasting over ST data is of great importance but challenging as it is affected by many complex factors, including spatial characteristics, temporal characteristics and the intrinsic causality between them. In this paper, we propose a general framework (HyperST-Net) based on hypernetworks for deep ST models. More specifically, it consists of three major modules: a spatial module, a temporal module and a deduction module. Among them, the deduction module derives the parameter weights of the temporal module from the spatial characteristics, which are extracted by the spatial module. Then, we design a general form of HyperST layer as well as different forms for several basic layers in neural networks, including the dense layer (HyperST-Dense) and the convolutional layer (HyperST-Conv). Experiments on three types of real-world tasks demonstrate that the predictive models integrated with our framework achieve significant improvements, and outperform the state-of-the-art baselines as well.

</details>

<details>

<summary>2018-09-28 08:05:47 - Evidential community detection based on density peaks</summary>

- *Kuang Zhou, Quan Pan, Arnaud Martin*

- `1809.10903v1` - [abs](http://arxiv.org/abs/1809.10903v1) - [pdf](http://arxiv.org/pdf/1809.10903v1)

> Credal partitions in the framework of belief functions can give us a better understanding of the analyzed data set. In order to find credal community structure in graph data sets, in this paper, we propose a novel evidential community detection algorithm based on density peaks (EDPC). Two new metrics, the local density $\rho$ and the minimum dissimi-larity $\delta$, are first defined for each node in the graph. Then the nodes with both higher $\rho$ and $\delta$ values are identified as community centers. Finally, the remaing nodes are assigned with corresponding community labels through a simple two-step evidential label propagation strategy. The membership of each node is described in the form of basic belief assignments , which can well express the uncertainty included in the community structure of the graph. The experiments demonstrate the effectiveness of the proposed method on real-world networks.

</details>

<details>

<summary>2018-09-28 08:24:26 - A belief combination rule for a large number of sources</summary>

- *Kuang Zhou, Arnaud Martin, Quan Pan*

- `1810.00685v1` - [abs](http://arxiv.org/abs/1810.00685v1) - [pdf](http://arxiv.org/pdf/1810.00685v1)

> The theory of belief functions is widely used for data from multiple sources. Different evidence combination rules have been proposed in this framework according to the properties of the sources to combine. However, most of these combination rules are not efficient when there are a large number of sources. This is due to either the complexity or the existence of an absorbing element such as the total conflict mass function for the conjunctive based rules when applied on unreliable evidence. In this paper, based on the assumption that the majority of sources are reliable, a combination rule for a large number of sources is proposed using a simple idea: the more common ideas the sources share, the more reliable these sources are supposed to be. This rule is adaptable for aggregating a large number of sources which may not all be reliable. It will keep the spirit of the conjunctive rule to reinforce the belief on the focal elements with which the sources are in agreement. The mass on the emptyset will be kept as an indicator of the conflict. The proposed rule, called LNS-CR (Conjunctive combinationRule for a Large Number of Sources), is evaluated on synthetic mass functions. The experimental results verify that the rule can be effectively used to combine a large number of mass functions and to elicit the major opinion.

</details>

<details>

<summary>2018-09-28 12:15:44 - VAIN: Attentional Multi-agent Predictive Modeling</summary>

- *Yedid Hoshen*

- `1706.06122v2` - [abs](http://arxiv.org/abs/1706.06122v2) - [pdf](http://arxiv.org/pdf/1706.06122v2)

> Multi-agent predictive modeling is an essential step for understanding physical, social and team-play systems. Recently, Interaction Networks (INs) were proposed for the task of modeling multi-agent physical systems, INs scale with the number of interactions in the system (typically quadratic or higher order in the number of agents). In this paper we introduce VAIN, a novel attentional architecture for multi-agent predictive modeling that scales linearly with the number of agents. We show that VAIN is effective for multi-agent predictive modeling. Our method is evaluated on tasks from challenging multi-agent prediction domains: chess and soccer, and outperforms competing multi-agent approaches.

</details>

<details>

<summary>2018-09-28 14:10:39 - Relational Forward Models for Multi-Agent Learning</summary>

- *Andrea Tacchetti, H. Francis Song, Pedro A. M. Mediano, Vinicius Zambaldi, Neil C. Rabinowitz, Thore Graepel, Matthew Botvinick, Peter W. Battaglia*

- `1809.11044v1` - [abs](http://arxiv.org/abs/1809.11044v1) - [pdf](http://arxiv.org/pdf/1809.11044v1)

> The behavioral dynamics of multi-agent systems have a rich and orderly structure, which can be leveraged to understand these systems, and to improve how artificial agents learn to operate in them. Here we introduce Relational Forward Models (RFM) for multi-agent learning, networks that can learn to make accurate predictions of agents' future behavior in multi-agent environments. Because these models operate on the discrete entities and relations present in the environment, they produce interpretable intermediate representations which offer insights into what drives agents' behavior, and what events mediate the intensity and valence of social interactions. Furthermore, we show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. As more and more of the autonomous systems we develop and interact with become multi-agent in nature, developing richer analysis tools for characterizing how and why agents make decisions is increasingly necessary. Moreover, developing artificial agents that quickly and safely learn to coordinate with one another, and with humans in shared environments, is crucial.

</details>

<details>

<summary>2018-09-28 15:32:21 - A Systems Approach to Achieving the Benefits of Artificial Intelligence in UK Defence</summary>

- *Gavin Pearson, Phil Jolley, Geraint Evans*

- `1809.11089v1` - [abs](http://arxiv.org/abs/1809.11089v1) - [pdf](http://arxiv.org/pdf/1809.11089v1)

> The ability to exploit the opportunities offered by AI within UK Defence calls for an understanding of systemic issues required to achieve an effective operational capability. This paper provides the authors' views of issues which currently block UK Defence from fully benefitting from AI technology. These are situated within a reference model for the AI Value Train, so enabling the community to address the exploitation of such data and software intensive systems in a systematic, end to end manner. The paper sets out the conditions for success including: Researching future solutions to known problems and clearly defined use cases; Addressing achievable use cases to show benefit; Enhancing the availability of Defence-relevant data; Enhancing Defence 'know how' in AI; Operating Software Intensive supply chain eco-systems at required breadth and pace; Governance and, the integration of software and platform supply chains and operating models.

</details>

<details>

<summary>2018-09-28 15:36:19 - DATA Agent</summary>

- *Michael Cerny Green, Gabriella A. B. Barros, Antonios Liapis, Julian Togelius*

- `1810.02251v1` - [abs](http://arxiv.org/abs/1810.02251v1) - [pdf](http://arxiv.org/pdf/1810.02251v1)

> This paper introduces DATA Agent, a system which creates murder mystery adventures from open data. In the game, the player takes on the role of a detective tasked with finding the culprit of a murder. All characters, places, and items in DATA Agent games are generated using open data as source content. The paper discusses the general game design and user interface of DATA Agent, and provides details on the generative algorithms which transform linked data into different game objects. Findings from a user study with 30 participants playing through two games of DATA Agent show that the game is easy and fun to play, and that the mysteries it generates are straightforward to solve.

</details>

<details>

<summary>2018-09-28 15:44:21 - Which Knowledge Graph Is Best for Me?</summary>

- *Michael Färber, Achim Rettinger*

- `1809.11099v1` - [abs](http://arxiv.org/abs/1809.11099v1) - [pdf](http://arxiv.org/pdf/1809.11099v1)

> In recent years, DBpedia, Freebase, OpenCyc, Wikidata, and YAGO have been published as noteworthy large, cross-domain, and freely available knowledge graphs. Although extensively in use, these knowledge graphs are hard to compare against each other in a given setting. Thus, it is a challenge for researchers and developers to pick the best knowledge graph for their individual needs. In our recent survey, we devised and applied data quality criteria to the above-mentioned knowledge graphs. Furthermore, we proposed a framework for finding the most suitable knowledge graph for a given setting. With this paper we intend to ease the access to our in-depth survey by presenting simplified rules that map individual data quality requirements to specific knowledge graphs. However, this paper does not intend to replace our previously introduced decision-support framework. For an informed decision on which KG is best for you we still refer to our in-depth survey.

</details>

<details>

<summary>2018-09-28 17:48:15 - Formal Context Generation using Dirichlet Distributions</summary>

- *Maximilian Felde, Tom Hanika*

- `1809.11160v1` - [abs](http://arxiv.org/abs/1809.11160v1) - [pdf](http://arxiv.org/pdf/1809.11160v1)

> We suggest an improved way to randomly generate formal contexts based on Dirichlet distributions. For this purpose we investigate the predominant way to generate formal contexts, a coin-tossing model, recapitulate some of its shortcomings and examine its stochastic model. Building up on this we propose our Dirichlet model and develop an algorithm employing this idea. By comparing our generation model to a coin-tossing model we show that our approach is a significant improvement with respect to the variety of contexts generated. Finally, we outline a possible application in null model generation for formal contexts.

</details>

<details>

<summary>2018-09-28 18:13:26 - Explainable Black-Box Attacks Against Model-based Authentication</summary>

- *Washington Garcia, Joseph I. Choi, Suman K. Adari, Somesh Jha, Kevin R. B. Butler*

- `1810.00024v1` - [abs](http://arxiv.org/abs/1810.00024v1) - [pdf](http://arxiv.org/pdf/1810.00024v1)

> Establishing unique identities for both humans and end systems has been an active research problem in the security community, giving rise to innovative machine learning-based authentication techniques. Although such techniques offer an automated method to establish identity, they have not been vetted against sophisticated attacks that target their core machine learning technique. This paper demonstrates that mimicking the unique signatures generated by host fingerprinting and biometric authentication systems is possible. We expose the ineffectiveness of underlying machine learning classification models by constructing a blind attack based around the query synthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an attack in under 130 queries on a state-of-the-art face authentication system, and under 100 queries on a host authentication system. We examine how these attacks can be defended against and explore their limitations. XAI provides an effective means for adversaries to infer decision boundaries and provides a new way forward in constructing attacks against systems using machine learning models for authentication.

</details>

<details>

<summary>2018-09-28 21:42:17 - Cell Grid Architecture for Maritime Route Prediction on AIS Data Streams</summary>

- *Ciprian Amariei, Paul Diac, Emanuel Onica, Valentin Roşca*

- `1810.00090v1` - [abs](http://arxiv.org/abs/1810.00090v1) - [pdf](http://arxiv.org/pdf/1810.00090v1)

> The 2018 Grand Challenge targets the problem of accurate predictions on data streams produced by automatic identification system (AIS) equipment, describing naval traffic. This paper reports the technical details of a custom solution, which exposes multiple tuning parameters, making its configurability one of the main strengths. Our solution employs a cell grid architecture essentially based on a sequence of hash tables, specifically built for the targeted use case. This makes it particularly effective in prediction on AIS data, obtaining a high accuracy and scalable performance results. Moreover, the architecture proposed accommodates also an optionally semi-supervised learning process besides the basic supervised mode.

</details>

<details>

<summary>2018-09-28 21:42:41 - The Partially Observable Games We Play for Cyber Deception</summary>

- *Mohamadreza Ahmadi, Murat Cubuktepe, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen, Ufuk Topcu*

- `1810.00092v1` - [abs](http://arxiv.org/abs/1810.00092v1) - [pdf](http://arxiv.org/pdf/1810.00092v1)

> Progressively intricate cyber infiltration mechanisms have made conventional means of defense, such as firewalls and malware detectors, incompetent. These sophisticated infiltration mechanisms can study the defender's behavior, identify security caveats, and modify their actions adaptively. To tackle these security challenges, cyber-infrastructures require active defense techniques that incorporate cyber deception, in which the defender (deceiver) implements a strategy to mislead the infiltrator. To this end, we use a two-player partially observable stochastic game (POSG) framework, wherein the deceiver has full observability over the states of the POSG, and the infiltrator has partial observability. Then, the deception problem is to compute a strategy for the deceiver that minimizes the expected cost of deception against all strategies of the infiltrator. We first show that the underlying problem is a robust mixed-integer linear program, which is intractable to solve in general. Towards a scalable approach, we compute optimal finite-memory strategies for the infiltrator by a reduction to a series of synthesis problems for parametric Markov decision processes. We use these infiltration strategies to find robust strategies for the deceiver using mixed-integer linear programming. We illustrate the performance of our technique on a POSG model for network security. Our experiments demonstrate that the proposed approach handles scenarios considerably larger than those of the state-of-the-art methods.

</details>

<details>

<summary>2018-09-29 03:25:06 - Smooth Inter-layer Propagation of Stabilized Neural Networks for Classification</summary>

- *Jingfeng Zhang, Laura Wynter*

- `1809.10315v2` - [abs](http://arxiv.org/abs/1809.10315v2) - [pdf](http://arxiv.org/pdf/1809.10315v2)

> Recent work has studied the reasons for the remarkable performance of deep neural networks in image classification. We examine batch normalization on the one hand and the dynamical systems view of residual networks on the other hand. Our goal is in understanding the notions of stability and smoothness of the inter-layer propagation of ResNets so as to explain when they contribute to significantly enhanced performance. We postulate that such stability is of importance for the trained ResNet to transfer.

</details>

<details>

<summary>2018-09-29 04:47:24 - DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human Activity Recognition</summary>

- *Zhan Yang, Osolo Ian Raymond, ChengYuan Zhang, Ying Wan, Jun Long*

- `1808.04228v2` - [abs](http://arxiv.org/abs/1808.04228v2) - [pdf](http://arxiv.org/pdf/1808.04228v2)

> Deep Convolutional Neural Networks (DCNNs) are currently popular in human activity recognition applications. However, in the face of modern artificial intelligence sensor-based games, many research achievements cannot be practically applied on portable devices. DCNNs are typically resource-intensive and too large to be deployed on portable devices, thus this limits the practical application of complex activity detection. In addition, since portable devices do not possess high-performance Graphic Processing Units (GPUs), there is hardly any improvement in Action Game (ACT) experience. Besides, in order to deal with multi-sensor collaboration, all previous human activity recognition models typically treated the representations from different sensor signal sources equally. However, distinct types of activities should adopt different fusion strategies. In this paper, a novel scheme is proposed. This scheme is used to train 2-bit Convolutional Neural Networks with weights and activations constrained to {-0.5,0,0.5}. It takes into account the correlation between different sensor signal sources and the activity types. This model, which we refer to as DFTerNet, aims at producing a more reliable inference and better trade-offs for practical applications. Our basic idea is to exploit quantization of weights and activations directly in pre-trained filter banks and adopt dynamic fusion strategies for different activity types. Experiments demonstrate that by using dynamic fusion strategy can exceed the baseline model performance by up to ~5% on activity recognition like OPPORTUNITY and PAMAP2 datasets. Using the quantization method proposed, we were able to achieve performances closer to that of full-precision counterpart. These results were also verified using the UniMiB-SHAR dataset. In addition, the proposed method can achieve ~9x acceleration on CPUs and ~11x memory saving.

</details>

<details>

<summary>2018-09-29 09:15:27 - Refining Manually-Designed Symbol Grounding and High-Level Planning by Policy Gradients</summary>

- *Takuya Hiraoka, Takashi Onishi, Takahisa Imagawa, Yoshimasa Tsuruoka*

- `1810.00177v1` - [abs](http://arxiv.org/abs/1810.00177v1) - [pdf](http://arxiv.org/pdf/1810.00177v1)

> Hierarchical planners that produce interpretable and appropriate plans are desired, especially in its application to supporting human decision making. In the typical development of the hierarchical planners, higher-level planners and symbol grounding functions are manually created, and this manual creation requires much human effort. In this paper, we propose a framework that can automatically refine symbol grounding functions and a high-level planner to reduce human effort for designing these modules. In our framework, symbol grounding and high-level planning, which are based on manually-designed knowledge bases, are modeled with semi-Markov decision processes. A policy gradient method is then applied to refine the modules, in which two terms for updating the modules are considered. The first term, called a reinforcement term, contributes to updating the modules to improve the overall performance of a hierarchical planner to produce appropriate plans. The second term, called a penalty term, contributes to keeping refined modules consistent with the manually-designed original modules. Namely, it keeps the planner, which uses the refined modules, producing interpretable plans. We perform preliminary experiments to solve the Mountain car problem, and its results show that a manually-designed high-level planner and symbol grounding function were successfully refined by our framework.

</details>

<details>

<summary>2018-09-29 10:15:18 - Stakeholders in Explainable AI</summary>

- *Alun Preece, Dan Harborne, Dave Braines, Richard Tomsett, Supriyo Chakraborty*

- `1810.00184v1` - [abs](http://arxiv.org/abs/1810.00184v1) - [pdf](http://arxiv.org/pdf/1810.00184v1)

> There is general consensus that it is important for artificial intelligence (AI) and machine learning systems to be explainable and/or interpretable. However, there is no general consensus over what is meant by 'explainable' and 'interpretable'. In this paper, we argue that this lack of consensus is due to there being several distinct stakeholder communities. We note that, while the concerns of the individual communities are broadly compatible, they are not identical, which gives rise to different intents and requirements for explainability/interpretability. We use the software engineering distinction between validation and verification, and the epistemological distinctions between knowns/unknowns, to tease apart the concerns of the stakeholder communities and highlight the areas where their foci overlap or diverge. It is not the purpose of the authors of this paper to 'take sides' - we count ourselves as members, to varying degrees, of multiple communities - but rather to help disambiguate what stakeholders mean when they ask 'Why?' of an AI.

</details>

<details>

<summary>2018-09-29 14:29:02 - Dynamic Ensemble Active Learning: A Non-Stationary Bandit with Expert Advice</summary>

- *Kunkun Pang, Mingzhi Dong, Yang Wu, Timothy M. Hospedales*

- `1810.07778v1` - [abs](http://arxiv.org/abs/1810.07778v1) - [pdf](http://arxiv.org/pdf/1810.07778v1)

> Active learning aims to reduce annotation cost by predicting which samples are useful for a human teacher to label. However it has become clear there is no best active learning algorithm. Inspired by various philosophies about what constitutes a good criteria, different algorithms perform well on different datasets. This has motivated research into ensembles of active learners that learn what constitutes a good criteria in a given scenario, typically via multi-armed bandit algorithms. Though algorithm ensembles can lead to better results, they overlook the fact that not only does algorithm efficacy vary across datasets, but also during a single active learning session. That is, the best criteria is non-stationary. This breaks existing algorithms' guarantees and hampers their performance in practice. In this paper, we propose dynamic ensemble active learning as a more general and promising research direction. We develop a dynamic ensemble active learner based on a non-stationary multi-armed bandit with expert advice algorithm. Our dynamic ensemble selects the right criteria at each step of active learning. It has theoretical guarantees, and shows encouraging results on $13$ popular datasets.

</details>

<details>

<summary>2018-09-29 17:25:40 - Reinforcement Learning in R</summary>

- *Nicolas Pröllochs, Stefan Feuerriegel*

- `1810.00240v1` - [abs](http://arxiv.org/abs/1810.00240v1) - [pdf](http://arxiv.org/pdf/1810.00240v1)

> Reinforcement learning refers to a group of methods from artificial intelligence where an agent performs learning through trial and error. It differs from supervised learning, since reinforcement learning requires no explicit labels; instead, the agent interacts continuously with its environment. That is, the agent starts in a specific state and then performs an action, based on which it transitions to a new state and, depending on the outcome, receives a reward. Different strategies (e.g. Q-learning) have been proposed to maximize the overall reward, resulting in a so-called policy, which defines the best possible action in each state. Mathematically, this process can be formalized by a Markov decision process and it has been implemented by packages in R; however, there is currently no package available for reinforcement learning. As a remedy, this paper demonstrates how to perform reinforcement learning in R and, for this purpose, introduces the ReinforcementLearning package. The package provides a remarkably flexible framework and is easily applied to a wide range of different problems. We demonstrate its use by drawing upon common examples from the literature (e.g. finding optimal game strategies).

</details>

<details>

<summary>2018-09-29 17:43:21 - Training Machine Learning Models by Regularizing their Explanations</summary>

- *Andrew Slavin Ross*

- `1810.00869v1` - [abs](http://arxiv.org/abs/1810.00869v1) - [pdf](http://arxiv.org/pdf/1810.00869v1)

> Neural networks are among the most accurate supervised learning methods in use today. However, their opacity makes them difficult to trust in critical applications, especially when conditions in training may differ from those in practice. Recent efforts to develop explanations for neural networks and machine learning models more generally have produced tools to shed light on the implicit rules behind predictions. These tools can help us identify when models are right for the wrong reasons. However, they do not always scale to explaining predictions for entire datasets, are not always at the right level of abstraction, and most importantly cannot correct the problems they reveal. In this thesis, we explore the possibility of training machine learning models (with a particular focus on neural networks) using explanations themselves. We consider approaches where models are penalized not only for making incorrect predictions but also for providing explanations that are either inconsistent with domain knowledge or overly complex. These methods let us train models which can not only provide more interpretable rationales for their predictions but also generalize better when training data is confounded or meaningfully different from test data (even adversarially so).

</details>

<details>

<summary>2018-09-30 00:27:49 - META-DES: A Dynamic Ensemble Selection Framework using Meta-Learning</summary>

- *Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti, Tsang Ing Ren*

- `1810.01270v1` - [abs](http://arxiv.org/abs/1810.01270v1) - [pdf](http://arxiv.org/pdf/1810.01270v1)

> Dynamic ensemble selection systems work by estimating the level of competence of each classifier from a pool of classifiers. Only the most competent ones are selected to classify a given test sample. This is achieved by defining a criterion to measure the level of competence of a base classifier, such as, its accuracy in local regions of the feature space around the query instance. However, using only one criterion about the behavior of a base classifier is not sufficient to accurately estimate its level of competence. In this paper, we present a novel dynamic ensemble selection framework using meta-learning. We propose five distinct sets of meta-features, each one corresponding to a different criterion to measure the level of competence of a classifier for the classification of input samples. The meta-features are extracted from the training data and used to train a meta-classifier to predict whether or not a base classifier is competent enough to classify an input instance. During the generalization phase, the meta-features are extracted from the query instance and passed down as input to the meta-classifier. The meta-classifier estimates, whether a base classifier is competent enough to be added to the ensemble. Experiments are conducted over several small sample size classification problems, i.e., problems with a high degree of uncertainty due to the lack of training data. Experimental results show the proposed meta-learning framework greatly improves classification accuracy when compared against current state-of-the-art dynamic ensemble selection techniques.

</details>

<details>

<summary>2018-09-30 01:23:53 - Cost Adaptation for Robust Decentralized Swarm Behaviour</summary>

- *Peter Henderson, Matthew Vertescher, David Meger, Mark Coates*

- `1709.07114v2` - [abs](http://arxiv.org/abs/1709.07114v2) - [pdf](http://arxiv.org/pdf/1709.07114v2)

> Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multi-agent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process -- cost adaptation -- which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.

</details>

<details>

<summary>2018-09-30 03:14:16 - Ray: A Distributed Framework for Emerging AI Applications</summary>

- *Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, Ion Stoica*

- `1712.05889v2` - [abs](http://arxiv.org/abs/1712.05889v2) - [pdf](http://arxiv.org/pdf/1712.05889v2)

> The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray---a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system's control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.

</details>

<details>

<summary>2018-09-30 07:34:20 - An Overview of Blockchain Integration with Robotics and Artificial Intelligence</summary>

- *Vasco Lopes, Luís A. Alexandre*

- `1810.00329v1` - [abs](http://arxiv.org/abs/1810.00329v1) - [pdf](http://arxiv.org/pdf/1810.00329v1)

> Blockchain technology is growing everyday at a fast-passed rhythm and it's possible to integrate it with many systems, namely Robotics with AI services. However, this is still a recent field and there isn't yet a clear understanding of what it could potentially become. In this paper, we conduct an overview of many different methods and platforms that try to leverage the power of blockchain into robotic systems, to improve AI services or to solve problems that are present in the major blockchains, which can lead to the ability of creating robotic systems with increased capabilities and security. We present an overview, discuss the methods and conclude the paper with our view on the future of the integration of these technologies.

</details>

<details>

<summary>2018-09-30 09:28:57 - Neural Entity Reasoner for Global Consistency in NER</summary>

- *Xiaoxiao Yin, Daqi Zheng, Zhengdong Lu, Ruifang Liu*

- `1810.00347v1` - [abs](http://arxiv.org/abs/1810.00347v1) - [pdf](http://arxiv.org/pdf/1810.00347v1)

> We propose Neural Entity Reasoner (NE-Reasoner), a framework to introduce global consistency of recognized entities into Neural Reasoner over Named Entity Recognition (NER) task. Given an input sentence, the NE-Reasoner layer can infer over multiple entities to increase the global consistency of output labels, which then be transfered into entities for the input of next layer. NE-Reasoner inherits and develops some features from Neural Reasoner 1) a symbolic memory, allowing it to exchange entities between layers. 2) the specific interaction-pooling mechanism, allowing it to connect each local word to multiple global entities, and 3) the deep architecture, allowing it to bootstrap the recognized entity set from coarse to fine. Like human beings, NE-Reasoner is able to accommodate ambiguous words and Name Entities that rarely or never met before. Despite the symbolic information the model introduced, NE-Reasoner can still be trained effectively in an end-to-end manner via parameter sharing strategy. NE-Reasoner can outperform conventional NER models in most cases on both English and Chinese NER datasets. For example, it achieves state-of-art on CoNLL-2003 English NER dataset.

</details>

<details>

<summary>2018-09-30 09:42:11 - IDMoB: IoT Data Marketplace on Blockchain</summary>

- *Kazım Rıfat Özyılmaz, Mehmet Doğan, Arda Yurdakul*

- `1810.00349v1` - [abs](http://arxiv.org/abs/1810.00349v1) - [pdf](http://arxiv.org/pdf/1810.00349v1)

> Today, Internet of Things (IoT) devices are the powerhouse of data generation with their ever-increasing numbers and widespread penetration. Similarly, artificial intelligence (AI) and machine learning (ML) solutions are getting integrated to all kinds of services, making products significantly more "smarter". The centerpiece of these technologies is "data". IoT device vendors should be able keep up with the increased throughput and come up with new business models. On the other hand, AI/ML solutions will produce better results if training data is diverse and plentiful.   In this paper, we propose a blockchain-based, decentralized and trustless data marketplace where IoT device vendors and AI/ML solution providers may interact and collaborate. By facilitating a transparent data exchange platform, access to consented data will be democratized and the variety of services targeting end-users will increase. Proposed data marketplace is implemented as a smart contract on Ethereum blockchain and Swarm is used as the distributed storage platform.

</details>

<details>

<summary>2018-09-30 11:29:55 - Using State Predictions for Value Regularization in Curiosity Driven Deep Reinforcement Learning</summary>

- *Gino Brunner, Manuel Fritsche, Oliver Richter, Roger Wattenhofer*

- `1810.00361v1` - [abs](http://arxiv.org/abs/1810.00361v1) - [pdf](http://arxiv.org/pdf/1810.00361v1)

> Learning in sparse reward settings remains a challenge in Reinforcement Learning, which is often addressed by using intrinsic rewards. One promising strategy is inspired by human curiosity, requiring the agent to learn to predict the future. In this paper a curiosity-driven agent is extended to use these predictions directly for training. To achieve this, the agent predicts the value function of the next state at any point in time. Subsequently, the consistency of this prediction with the current value function is measured, which is then used as a regularization term in the loss function of the algorithm. Experiments were made on grid-world environments as well as on a 3D navigation task, both with sparse rewards. In the first case the extended agent is able to learn significantly faster than the baselines.

</details>

<details>

<summary>2018-09-30 17:31:52 - Efficient Sequence Labeling with Actor-Critic Training</summary>

- *Saeed Najafi, Colin Cherry, Grzegorz Kondrak*

- `1810.00428v1` - [abs](http://arxiv.org/abs/1810.00428v1) - [pdf](http://arxiv.org/pdf/1810.00428v1)

> Neural approaches to sequence labeling often use a Conditional Random Field (CRF) to model their output dependencies, while Recurrent Neural Networks (RNN) are used for the same purpose in other tasks. We set out to establish RNNs as an attractive alternative to CRFs for sequence labeling. To do so, we address one of the RNN's most prominent shortcomings, the fact that it is not exposed to its own errors with the maximum-likelihood training. We frame the prediction of the output sequence as a sequential decision-making process, where we train the network with an adjusted actor-critic algorithm (AC-RNN). We comprehensively compare this strategy with maximum-likelihood training for both RNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently matches the performance of the CRF on NER and CCG tagging, and outperforms it on Machine Transliteration. We also show that our training strategy is significantly better than other techniques for addressing RNN's exposure bias, such as Scheduled Sampling, and Self-Critical policy training.

</details>

<details>

<summary>2018-09-30 18:39:23 - An Application of ASP Theories of Intentions to Understanding Restaurant Scenarios: Insights and Narrative Corpus</summary>

- *Qinglin Zhang, Chris Benton, Daniela Inclezan*

- `1810.00445v1` - [abs](http://arxiv.org/abs/1810.00445v1) - [pdf](http://arxiv.org/pdf/1810.00445v1)

> This paper presents a practical application of Answer Set Programming to the understanding of narratives about restaurants. While this task was investigated in depth by Erik Mueller, exceptional scenarios remained a serious challenge for his script-based story comprehension system. We present a methodology that remedies this issue by modeling characters in a restaurant episode as intentional agents. We focus especially on the refinement of certain components of this methodology in order to increase coverage and performance. We present a restaurant story corpus that we created to design and evaluate our methodology. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>

<details>

<summary>2018-09-30 20:34:49 - Learning Synergies between Pushing and Grasping with Self-supervised Deep Reinforcement Learning</summary>

- *Andy Zeng, Shuran Song, Stefan Welker, Johnny Lee, Alberto Rodriguez, Thomas Funkhouser*

- `1803.09956v3` - [abs](http://arxiv.org/abs/1803.09956v3) - [pdf](http://arxiv.org/pdf/1803.09956v3)

> Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors amid challenging cases of clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after only a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu

</details>

<details>

<summary>2018-09-30 22:57:58 - Few-Shot Goal Inference for Visuomotor Learning and Planning</summary>

- *Annie Xie, Avi Singh, Sergey Levine, Chelsea Finn*

- `1810.00482v1` - [abs](http://arxiv.org/abs/1810.00482v1) - [pdf](http://arxiv.org/pdf/1810.00482v1)

> Reinforcement learning and planning methods require an objective or reward function that encodes the desired behavior. Yet, in practice, there is a wide range of scenarios where an objective is difficult to provide programmatically, such as tasks with visual observations involving unknown object positions or deformable objects. In these cases, prior methods use engineered problem-specific solutions, e.g., by instrumenting the environment with additional sensors to measure a proxy for the objective. Such solutions require a significant engineering effort on a per-task basis, and make it impractical for robots to continuously learn complex skills outside of laboratory settings. We aim to find a more general and scalable solution for specifying goals for robot learning in unconstrained environments. To that end, we formulate the few-shot objective learning problem, where the goal is to learn a task objective from only a few example images of successful end states for that task. We propose a simple solution to this problem: meta-learn a classifier that can recognize new goals from a few examples. We show how this approach can be used with both model-free reinforcement learning and visual model-based planning and show results in three domains: rope manipulation from images in simulation, visual navigation in a simulated 3D environment, and object arrangement into user-specified configurations on a real robot.

</details>


## 2018-10

<details>

<summary>2018-10-01 02:55:07 - Interactive Agent Modeling by Learning to Probe</summary>

- *Tianmin Shu, Caiming Xiong, Ying Nian Wu, Song-Chun Zhu*

- `1810.00510v1` - [abs](http://arxiv.org/abs/1810.00510v1) - [pdf](http://arxiv.org/pdf/1810.00510v1)

> The ability of modeling the other agents, such as understanding their intentions and skills, is essential to an agent's interactions with other agents. Conventional agent modeling relies on passive observation from demonstrations. In this work, we propose an interactive agent modeling scheme enabled by encouraging an agent to learn to probe. In particular, the probing agent (i.e. a learner) learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. Our framework consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning for an efficient probing policy to discover new behaviors that otherwise can not be observed. We have validated our approach in four different tasks. The experimental results suggest that the agent model learned by our approach i) generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiosity-driven approaches do, and ii) can be used for enhancing performance in multiple applications including distilling optimal planning to a policy net, collaboration, and competition. A video demo is available at https://www.dropbox.com/s/8mz6rd3349tso67/Probing_Demo.mov?dl=0

</details>

<details>

<summary>2018-10-01 03:58:00 - A Simple Machine Learning Method for Commonsense Reasoning? A Short Commentary on Trinh & Le (2018)</summary>

- *Walid S. Saba*

- `1810.00521v1` - [abs](http://arxiv.org/abs/1810.00521v1) - [pdf](http://arxiv.org/pdf/1810.00521v1)

> This is a short Commentary on Trinh & Le (2018) ("A Simple Method for Commonsense Reasoning") that outlines three serious flaws in the cited paper and discusses why data-driven approaches cannot be considered as serious models for the commonsense reasoning needed in natural language understanding in general, and in reference resolution, in particular.

</details>

<details>

<summary>2018-10-01 07:15:32 - Probabilistic Meta-Representations Of Neural Networks</summary>

- *Theofanis Karaletsos, Peter Dayan, Zoubin Ghahramani*

- `1810.00555v1` - [abs](http://arxiv.org/abs/1810.00555v1) - [pdf](http://arxiv.org/pdf/1810.00555v1)

> Existing Bayesian treatments of neural networks are typically characterized by weak prior and approximate posterior distributions according to which all the weights are drawn independently. Here, we consider a richer prior distribution in which units in the network are represented by latent variables, and the weights between units are drawn conditionally on the values of the collection of those variables. This allows rich correlations between related weights, and can be seen as realizing a function prior with a Bayesian complexity regularizer ensuring simple solutions. We illustrate the resulting meta-representations and representations, elucidating the power of this prior.

</details>

<details>

<summary>2018-10-01 12:56:06 - Pooling of Causal Models under Counterfactual Fairness via Causal Judgement Aggregation</summary>

- *Fabio Massimo Zennaro, Magdalena Ivanovska*

- `1805.09866v2` - [abs](http://arxiv.org/abs/1805.09866v2) - [pdf](http://arxiv.org/pdf/1805.09866v2)

> In this paper we consider the problem of combining multiple probabilistic causal models, provided by different experts, under the requirement that the aggregated model satisfy the criterion of counterfactual fairness. We build upon the work on causal models and fairness in machine learning, and we express the problem of combining multiple models within the framework of opinion pooling. We propose two simple algorithms, grounded in the theory of counterfactual fairness and causal judgment aggregation, that are guaranteed to generate aggregated probabilistic causal models respecting the criterion of fairness, and we compare their behaviors on a toy case study.

</details>

<details>

<summary>2018-10-01 13:11:27 - Counterfactually Fair Prediction Using Multiple Causal Models</summary>

- *Fabio Massimo Zennaro, Magdalena Ivanovska*

- `1810.00694v1` - [abs](http://arxiv.org/abs/1810.00694v1) - [pdf](http://arxiv.org/pdf/1810.00694v1)

> In this paper we study the problem of making predictions using multiple structural casual models defined by different agents, under the constraint that the prediction satisfies the criterion of counterfactual fairness. Relying on the frameworks of causality, fairness and opinion pooling, we build upon and extend previous work focusing on the qualitative aggregation of causal Bayesian networks and causal models. In order to complement previous qualitative results, we devise a method based on Monte Carlo simulations. This method enables a decision-maker to aggregate the outputs of the causal models provided by different experts while guaranteeing the counterfactual fairness of the result. We demonstrate our approach on a simple, yet illustrative, toy case study.

</details>

<details>

<summary>2018-10-01 13:22:41 - Data-driven Discovery of Cyber-Physical Systems</summary>

- *Ye Yuan, Xiuchuan Tang, Wei Pan, Xiuting Li, Wei Zhou, Hai-Tao Zhang, Han Ding, Jorge Goncalves*

- `1810.00697v1` - [abs](http://arxiv.org/abs/1810.00697v1) - [pdf](http://arxiv.org/pdf/1810.00697v1)

> Cyber-physical systems (CPSs) embed software into the physical world. They appear in a wide range of applications such as smart grids, robotics, intelligent manufacture and medical monitoring. CPSs have proved resistant to modeling due to their intrinsic complexity arising from the combination of physical components and cyber components and the interaction between them. This study proposes a general framework for reverse engineering CPSs directly from data. The method involves the identification of physical systems as well as the inference of transition logic. It has been applied successfully to a number of real-world examples ranging from mechanical and electrical systems to medical applications. The novel framework seeks to enable researchers to make predictions concerning the trajectory of CPSs based on the discovered model. Such information has been proven essential for the assessment of the performance of CPS, the design of failure-proof CPS and the creation of design guidelines for new CPSs.

</details>

<details>

<summary>2018-10-01 14:01:46 - Modular Vehicle Control for Transferring Semantic Information Between Weather Conditions Using GANs</summary>

- *Patrick Wenzel, Qadeer Khan, Daniel Cremers, Laura Leal-Taixé*

- `1807.01001v2` - [abs](http://arxiv.org/abs/1807.01001v2) - [pdf](http://arxiv.org/pdf/1807.01001v2)

> Even though end-to-end supervised learning has shown promising results for sensorimotor control of self-driving cars, its performance is greatly affected by the weather conditions under which it was trained, showing poor generalization to unseen conditions. In this paper, we show how knowledge can be transferred using semantic maps to new weather conditions without the need to obtain new ground truth data. To this end, we propose to divide the task of vehicle control into two independent modules: a control module which is only trained on one weather condition for which labeled steering data is available, and a perception module which is used as an interface between new weather conditions and the fixed control module. To generate the semantic data needed to train the perception module, we propose to use a generative adversarial network (GAN)-based model to retrieve the semantic information for the new conditions in an unsupervised manner. We introduce a master-servant architecture, where the master model (semantic labels available) trains the servant model (semantic labels not available). We show that our proposed method trained with ground truth data for a single weather condition is capable of achieving similar results on the task of steering angle prediction as an end-to-end model trained with ground truth data of 15 different weather conditions.

</details>

<details>

<summary>2018-10-01 14:24:20 - A categorisation and implementation of digital pen features for behaviour characterisation</summary>

- *Alexander Prange, Michael Barz, Daniel Sonntag*

- `1810.03970v1` - [abs](http://arxiv.org/abs/1810.03970v1) - [pdf](http://arxiv.org/pdf/1810.03970v1)

> In this paper we provide a categorisation and implementation of digital ink features for behaviour characterisation. Based on four feature sets taken from literature, we provide a categorisation in different classes of syntactic and semantic features. We implemented a publicly available framework to calculate these features and show its deployment in the use case of analysing cognitive assessments performed using a digital pen.

</details>

<details>

<summary>2018-10-01 16:03:49 - The Profiling Machine: Active Generalization over Knowledge</summary>

- *Filip Ilievski, Eduard Hovy, Qizhe Xie, Piek Vossen*

- `1810.00782v1` - [abs](http://arxiv.org/abs/1810.00782v1) - [pdf](http://arxiv.org/pdf/1810.00782v1)

> The human mind is a powerful multifunctional knowledge storage and management system that performs generalization, type inference, anomaly detection, stereotyping, and other tasks. A dynamic KR system that appropriately profiles over sparse inputs to provide complete expectations for unknown facets can help with all these tasks. In this paper, we introduce the task of profiling, inspired by theories and findings in social psychology about the potential of profiles for reasoning and information processing. We describe two generic state-of-the-art neural architectures that can be easily instantiated as profiling machines to generate expectations and applied to any kind of knowledge to fill gaps. We evaluate these methods against Wikidata and crowd expectations, and compare the results to gain insight in the nature of knowledge captured by various profiling methods. We make all code and data available to facilitate future research.

</details>

<details>

<summary>2018-10-01 16:15:18 - Generating Levels That Teach Mechanics</summary>

- *Michael Cerny Green, Ahmed Khalifa, Gabriella A. B. Barros, Andy Nealen, Julian Togelius*

- `1807.06734v4` - [abs](http://arxiv.org/abs/1807.06734v4) - [pdf](http://arxiv.org/pdf/1807.06734v4)

> The automatic generation of game tutorials is a challenging AI problem. While it is possible to generate annotations and instructions that explain to the player how the game is played, this paper focuses on generating a gameplay experience that introduces the player to a game mechanic. It evolves small levels for the Mario AI Framework that can only be beaten by an agent that knows how to perform specific actions in the game. It uses variations of a perfect A* agent that are limited in various ways, such as not being able to jump high or see enemies, to test how failing to do certain actions can stop the player from beating the level.

</details>

<details>

<summary>2018-10-01 17:55:37 - IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles</summary>

- *Tianze Shi, Kedar Tatwawadi, Kaushik Chakrabarti, Yi Mao, Oleksandr Polozov, Weizhu Chen*

- `1809.05054v2` - [abs](http://arxiv.org/abs/1809.05054v2) - [pdf](http://arxiv.org/pdf/1809.05054v2)

> We present a sequence-to-action parsing approach for the natural language to SQL task that incrementally fills the slots of a SQL query with feasible actions from a pre-defined inventory. To account for the fact that typically there are multiple correct SQL queries with the same or very similar semantics, we draw inspiration from syntactic parsing techniques and propose to train our sequence-to-action models with non-deterministic oracles. We evaluate our models on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the test set, a 2.1% absolute improvement over the models trained with traditional static oracles assuming a single correct target SQL query. When further combined with the execution-guided decoding strategy, our model sets a new state-of-the-art performance at an execution accuracy of 87.1%.

</details>

<details>

<summary>2018-10-01 18:37:05 - Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition</summary>

- *Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, Devi Parikh*

- `1810.00912v1` - [abs](http://arxiv.org/abs/1810.00912v1) - [pdf](http://arxiv.org/pdf/1810.00912v1)

> In an open-world setting, it is inevitable that an intelligent agent (e.g., a robot) will encounter visual objects, attributes or relationships it does not recognize. In this work, we develop an agent empowered with visual curiosity, i.e. the ability to ask questions to an Oracle (e.g., human) about the contents in images (e.g., What is the object on the left side of the red cube?) and build visual recognition model based on the answers received (e.g., Cylinder). In order to do this, the agent must (1) understand what it recognizes and what it does not, (2) formulate a valid, unambiguous and informative language query (a question) to ask the Oracle, (3) derive the parameters of visual classifiers from the Oracle response and (4) leverage the updated visual classifiers to ask more clarified questions. Specifically, we propose a novel framework and formulate the learning of visual curiosity as a reinforcement learning problem. In this framework, all components of our agent, visual recognition module (to see), question generation policy (to ask), answer digestion module (to understand) and graph memory module (to memorize), are learned entirely end-to-end to maximize the reward derived from the scene graph obtained by the agent as a consequence of the dialog with the Oracle. Importantly, the question generation policy is disentangled from the visual recognition system and specifics of the environment. Consequently, we demonstrate a sort of double generalization. Our question generation policy generalizes to new environments and a new pair of eyes, i.e., new visual system. Trained on a synthetic dataset, our results show that our agent learns new visual concepts significantly faster than several heuristic baselines, even when tested on synthetic environments with novel objects, as well as in a realistic environment.

</details>

<details>

<summary>2018-10-01 18:40:57 - Handling Nominals and Inverse Roles using Algebraic Reasoning</summary>

- *Humaira Farid, Volker Haarslev*

- `1810.00916v1` - [abs](http://arxiv.org/abs/1810.00916v1) - [pdf](http://arxiv.org/pdf/1810.00916v1)

> This paper presents a novel SHOI tableau calculus which incorporates algebraic reasoning for deciding ontology consistency. Numerical restrictions imposed by nominals, existential and universal restrictions are encoded into a set of linear inequalities. Column generation and branch-and-price algorithms are used to solve these inequalities. Our preliminary experiments indicate that this calculus performs better on SHOI ontologies than standard tableau methods.

</details>

<details>

<summary>2018-10-01 21:02:53 - Extended Bit-Plane Compression for Convolutional Neural Network Accelerators</summary>

- *Lukas Cavigelli, Luca Benini*

- `1810.03979v1` - [abs](http://arxiv.org/abs/1810.03979v1) - [pdf](http://arxiv.org/pdf/1810.03979v1)

> After the tremendous success of convolutional neural networks in image classification, object detection, speech recognition, etc., there is now rising demand for deployment of these compute-intensive ML models on tightly power constrained embedded and mobile systems at low cost as well as for pushing the throughput in data centers. This has triggered a wave of research towards specialized hardware accelerators. Their performance is often constrained by I/O bandwidth and the energy consumption is dominated by I/O transfers to off-chip memory. We introduce and evaluate a novel, hardware-friendly compression scheme for the feature maps present within convolutional neural networks. We show that an average compression ratio of 4.4x relative to uncompressed data and a gain of 60% over existing method can be achieved for ResNet-34 with a compression block requiring <300 bit of sequential cells and minimal combinational logic.

</details>

<details>

<summary>2018-10-02 00:04:20 - Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network using Truncated Gaussian Approximation</summary>

- *Zhezhi He, Deliang Fan*

- `1810.01018v1` - [abs](http://arxiv.org/abs/1810.01018v1) - [pdf](http://arxiv.org/pdf/1810.01018v1)

> In the past years, Deep convolution neural network has achieved great success in many artificial intelligence applications. However, its enormous model size and massive computation cost have become the main obstacle for deployment of such powerful algorithm in the low power and resource-limited mobile systems. As the countermeasure to this problem, deep neural networks with ternarized weights (i.e. -1, 0, +1) have been widely explored to greatly reduce the model size and computational cost, with limited accuracy degradation. In this work, we propose a novel ternarized neural network training method which simultaneously optimizes both weights and quantizer during training, differentiating from prior works. Instead of fixed and uniform weight ternarization, we are the first to incorporate the thresholds of weight ternarization into a closed-form representation using the truncated Gaussian approximation, enabling simultaneous optimization of weights and quantizer through back-propagation training. With both of the first and last layer ternarized, the experiments on the ImageNet classification task show that our ternarized ResNet-18/34/50 only has 3.9/2.52/2.16% accuracy degradation in comparison to the full-precision counterparts.

</details>

<details>

<summary>2018-10-02 03:27:04 - Predicting Factuality of Reporting and Bias of News Media Sources</summary>

- *Ramy Baly, Georgi Karadzhov, Dimitar Alexandrov, James Glass, Preslav Nakov*

- `1810.01765v1` - [abs](http://arxiv.org/abs/1810.01765v1) - [pdf](http://arxiv.org/pdf/1810.01765v1)

> We present a study on predicting the factuality of reporting and bias of news media. While previous work has focused on studying the veracity of claims or documents, here we are interested in characterizing entire news media. These are under-studied but arguably important research problems, both in their own right and as a prior for fact-checking systems. We experiment with a large list of news websites and with a rich set of features derived from (i) a sample of articles from the target news medium, (ii) its Wikipedia page, (iii) its Twitter account, (iv) the structure of its URL, and (v) information about the Web traffic it attracts. The experimental results show sizable performance gains over the baselines, and confirm the importance of each feature type.

</details>

<details>

<summary>2018-10-02 03:27:41 - LIT: Block-wise Intermediate Representation Training for Model Compression</summary>

- *Animesh Koratana, Daniel Kang, Peter Bailis, Matei Zaharia*

- `1810.01937v1` - [abs](http://arxiv.org/abs/1810.01937v1) - [pdf](http://arxiv.org/pdf/1810.01937v1)

> Knowledge distillation (KD) is a popular method for reducing the computational overhead of deep network inference, in which the output of a teacher model is used to train a smaller, faster student model. Hint training (i.e., FitNets) extends KD by regressing a student model's intermediate representation to a teacher model's intermediate representation. In this work, we introduce bLock-wise Intermediate representation Training (LIT), a novel model compression technique that extends the use of intermediate representations in deep network compression, outperforming KD and hint training. LIT has two key ideas: 1) LIT trains a student of the same width (but shallower depth) as the teacher by directly comparing the intermediate representations, and 2) LIT uses the intermediate representation from the previous block in the teacher model as an input to the current student block during training, avoiding unstable intermediate representations in the student network. We show that LIT provides substantial reductions in network depth without loss in accuracy -- for example, LIT can compress a ResNeXt-110 to a ResNeXt-20 (5.5x) on CIFAR10 and a VDCNN-29 to a VDCNN-9 (3.2x) on Amazon Reviews without loss in accuracy, outperforming KD and hint training in network size for a given accuracy. We also show that applying LIT to identical student/teacher architectures increases the accuracy of the student model above the teacher model, outperforming the recently-proposed Born Again Networks procedure on ResNet, ResNeXt, and VDCNN. Finally, we show that LIT can effectively compress GAN generators, which are not supported in the KD framework because GANs output pixels as opposed to probabilities.

</details>

<details>

<summary>2018-10-02 03:48:42 - ChainQueen: A Real-Time Differentiable Physical Simulator for Soft Robotics</summary>

- *Yuanming Hu, Jiancheng Liu, Andrew Spielberg, Joshua B. Tenenbaum, William T. Freeman, Jiajun Wu, Daniela Rus, Wojciech Matusik*

- `1810.01054v1` - [abs](http://arxiv.org/abs/1810.01054v1) - [pdf](http://arxiv.org/pdf/1810.01054v1)

> Physical simulators have been widely used in robot planning and control. Among them, differentiable simulators are particularly favored, as they can be incorporated into gradient-based optimization algorithms that are efficient in solving inverse problems such as optimal control and motion planning. Simulating deformable objects is, however, more challenging compared to rigid body dynamics. The underlying physical laws of deformable objects are more complex, and the resulting systems have orders of magnitude more degrees of freedom and therefore they are significantly more computationally expensive to simulate. Computing gradients with respect to physical design or controller parameters is typically even more computationally challenging. In this paper, we propose a real-time, differentiable hybrid Lagrangian-Eulerian physical simulator for deformable objects, ChainQueen, based on the Moving Least Squares Material Point Method (MLS-MPM). MLS-MPM can simulate deformable objects including contact and can be seamlessly incorporated into inference, control and co-design systems. We demonstrate that our simulator achieves high precision in both forward simulation and backward gradient computation. We have successfully employed it in a diverse set of control tasks for soft robots, including problems with nearly 3,000 decision variables.

</details>

<details>

<summary>2018-10-02 04:16:54 - End-to-end Multimodal Emotion and Gender Recognition with Dynamic Joint Loss Weights</summary>

- *Myungsu Chae, Tae-Ho Kim, Young Hoon Shin, June-Woo Kim, Soo-Young Lee*

- `1809.00758v3` - [abs](http://arxiv.org/abs/1809.00758v3) - [pdf](http://arxiv.org/pdf/1809.00758v3)

> Multi-task learning is a method for improving the generalizability of multiple tasks. In order to perform multiple classification tasks with one neural network model, the losses of each task should be combined. Previous studies have mostly focused on multiple prediction tasks using joint loss with static weights for training models, choosing the weights between tasks without making sufficient considerations by setting them uniformly or empirically. In this study, we propose a method to calculate joint loss using dynamic weights to improve the total performance, instead of the individual performance, of tasks. We apply this method to design an end-to-end multimodal emotion and gender recognition model using audio and video data. This approach provides proper weights for the loss of each task when the training process ends. In our experiments, emotion and gender recognition with the proposed method yielded a lower joint loss, which is computed as the negative log-likelihood, than using static weights for joint loss. Moreover, our proposed model has better generalizability than other models. To the best of our knowledge, this research is the first to demonstrate the strength of using dynamic weights for joint loss for maximizing overall performance in emotion and gender recognition tasks.

</details>

<details>

<summary>2018-10-02 08:01:48 - Target Aware Network Adaptation for Efficient Representation Learning</summary>

- *Yang Zhong, Vladimir Li, Ryuzo Okada, Atsuto Maki*

- `1810.01104v1` - [abs](http://arxiv.org/abs/1810.01104v1) - [pdf](http://arxiv.org/pdf/1810.01104v1)

> This paper presents an automatic network adaptation method that finds a ConvNet structure well-suited to a given target task, e.g., image classification, for efficiency as well as accuracy in transfer learning. We call the concept target-aware transfer learning. Given only small-scale labeled data, and starting from an ImageNet pre-trained network, we exploit a scheme of removing its potential redundancy for the target task through iterative operations of filter-wise pruning and network optimization. The basic motivation is that compact networks are on one hand more efficient and should also be more tolerant, being less complex, against the risk of overfitting which would hinder the generalization of learned representations in the context of transfer learning. Further, unlike existing methods involving network simplification, we also let the scheme identify redundant portions across the entire network, which automatically results in a network structure adapted to the task at hand. We achieve this with a few novel ideas: (i) cumulative sum of activation statistics for each layer, and (ii) a priority evaluation of pruning across multiple layers. Experimental results by the method on five datasets (Flower102, CUB200-2011, Dog120, MIT67, and Stanford40) show favorable accuracies over the related state-of-the-art techniques while enhancing the computational and storage efficiency of the transferred model.

</details>

<details>

<summary>2018-10-02 08:31:39 - The Dreaming Variational Autoencoder for Reinforcement Learning Environments</summary>

- *Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo*

- `1810.01112v1` - [abs](http://arxiv.org/abs/1810.01112v1) - [pdf](http://arxiv.org/pdf/1810.01112v1)

> Reinforcement learning has shown great potential in generalizing over raw sensory data using only a single neural network for value optimization. There are several challenges in the current state-of-the-art reinforcement learning algorithms that prevent them from converging towards the global optima. It is likely that the solution to these problems lies in short- and long-term planning, exploration and memory management for reinforcement learning algorithms. Games are often used to benchmark reinforcement learning algorithms as they provide a flexible, reproducible, and easy to control environment. Regardless, few games feature a state-space where results in exploration, memory, and planning are easily perceived. This paper presents The Dreaming Variational Autoencoder (DVAE), a neural network based generative modeling architecture for exploration in environments with sparse feedback. We further present Deep Maze, a novel and flexible maze engine that challenges DVAE in partial and fully-observable state-spaces, long-horizon tasks, and deterministic and stochastic problems. We show initial findings and encourage further work in reinforcement learning driven by generative exploration.

</details>

<details>

<summary>2018-10-02 09:15:00 - Predicate learning in neural systems: Discovering latent generative structures</summary>

- *Andrea E. Martin, Leonidas A. A. Doumas*

- `1810.01127v1` - [abs](http://arxiv.org/abs/1810.01127v1) - [pdf](http://arxiv.org/pdf/1810.01127v1)

> Humans learn complex latent structures from their environments (e.g., natural language, mathematics, music, social hierarchies). In cognitive science and cognitive neuroscience, models that infer higher-order structures from sensory or first-order representations have been proposed to account for the complexity and flexibility of human behavior. But how do the structures that these models invoke arise in neural systems in the first place? To answer this question, we explain how a system can learn latent representational structures (i.e., predicates) from experience with wholly unstructured data. During the process of predicate learning, an artificial neural network exploits the naturally occurring dynamic properties of distributed computing across neuronal assemblies in order to learn predicates, but also to combine them compositionally, two computational aspects which appear to be necessary for human behavior as per formal theories in multiple domains. We describe how predicates can be combined generatively using neural oscillations to achieve human-like extrapolation and compositionality in an artificial neural network. The ability to learn predicates from experience, to represent structures compositionally, and to extrapolate to unseen data offers an inroads to understanding and modeling the most complex human behaviors.

</details>

<details>

<summary>2018-10-02 13:47:04 - Efficient Fastest-Path Computations in Road Maps</summary>

- *Renjie Chen, Craig Gotsman*

- `1810.01776v1` - [abs](http://arxiv.org/abs/1810.01776v1) - [pdf](http://arxiv.org/pdf/1810.01776v1)

> In the age of real-time online traffic information and GPS-enabled devices, fastest-path computations between two points in a road network modeled as a directed graph, where each directed edge is weighted by a "travel time" value, are becoming a standard feature of many navigation-related applications. To support this, very efficient computation of these paths in very large road networks is critical. Fastest paths may be computed as minimal-cost paths in a weighted directed graph, but traditional minimal-cost path algorithms based on variants of the classic Dijkstra algorithm do not scale well, as in the worst case they may traverse the entire graph. A common improvement, which can dramatically reduce the number of traversed graph vertices, is the A* algorithm, which requires a good heuristic lower bound on the minimal cost. We introduce a simple, but very effective, heuristic function based on a small number of values assigned to each graph vertex. The values are based on graph separators and computed efficiently in a preprocessing stage. We present experimental results demonstrating that our heuristic provides estimates of the minimal cost which are superior to those of other heuristics. Our experiments show that when used in the A* algorithm, this heuristic can reduce the number of vertices traversed by an order of magnitude compared to other heuristics.

</details>

<details>

<summary>2018-10-02 16:16:31 - Two-Stream RNN/CNN for Action Recognition in 3D Videos</summary>

- *Rui Zhao, Haider Ali, Patrick van der Smagt*

- `1703.09783v2` - [abs](http://arxiv.org/abs/1703.09783v2) - [pdf](http://arxiv.org/pdf/1703.09783v2)

> The recognition of actions from video sequences has many applications in health monitoring, assisted living, surveillance, and smart homes. Despite advances in sensing, in particular related to 3D video, the methodologies to process the data are still subject to research. We demonstrate superior results by a system which combines recurrent neural networks with convolutional neural networks in a voting approach. The gated-recurrent-unit-based neural networks are particularly well-suited to distinguish actions based on long-term information from optical tracking data; the 3D-CNNs focus more on detailed, recent information from video data. The resulting features are merged in an SVM which then classifies the movement. In this architecture, our method improves recognition rates of state-of-the-art methods by 14% on standard data sets.

</details>

<details>

<summary>2018-10-02 17:44:16 - Rough set based lattice structure for knowledge representation in medical expert systems: low back pain management case study</summary>

- *Debarpita Santra, Swapan Kumar Basu, Jyotsna Kumar Mandal, Subrata Goswami*

- `1810.01560v1` - [abs](http://arxiv.org/abs/1810.01560v1) - [pdf](http://arxiv.org/pdf/1810.01560v1)

> The aim of medical knowledge representation is to capture the detailed domain knowledge in a clinically efficient manner and to offer a reliable resolution with the acquired knowledge. The knowledge base to be used by a medical expert system should allow incremental growth with inclusion of updated knowledge over the time. As knowledge are gathered from a variety of knowledge sources by different knowledge engineers, the problem of redundancy is an important concern here due to increased processing time of knowledge and occupancy of large computational storage to accommodate all the gathered knowledge. Also there may exist many inconsistent knowledge in the knowledge base. In this paper, we have proposed a rough set based lattice structure for knowledge representation in medical expert systems which overcomes the problem of redundancy and inconsistency in knowledge and offers computational efficiency with respect to both time and space. We have also generated an optimal set of decision rules that would be used directly by the inference engine. The reliability of each rule has been measured using a new metric called credibility factor, and the certainty and coverage factors of a decision rule have been re-defined. With a set of decisions rules arranged in descending order according to their reliability measures, the medical expert system will consider the highly reliable and certain rules at first, then it would search for the possible and uncertain rules at later stage, if recommended by physicians. The proposed knowledge representation technique has been illustrated using an example from the domain of low back pain. The proposed scheme ensures completeness, consistency, integrity, non-redundancy, and ease of access.

</details>

<details>

<summary>2018-10-02 19:30:21 - Is One Hyperparameter Optimizer Enough?</summary>

- *Huy Tu, Vivek Nair*

- `1807.11112v4` - [abs](http://arxiv.org/abs/1807.11112v4) - [pdf](http://arxiv.org/pdf/1807.11112v4)

> Hyperparameter tuning is the black art of automatically finding a good combination of control parameters for a data miner. While widely applied in empirical Software Engineering, there has not been much discussion on which hyperparameter tuner is best for software analytics. To address this gap in the literature, this paper applied a range of hyperparameter optimizers (grid search, random search, differential evolution, and Bayesian optimization) to defect prediction problem. Surprisingly, no hyperparameter optimizer was observed to be `best' and, for one of the two evaluation measures studied here (F-measure), hyperparameter optimization, in 50\% cases, was no better than using default configurations.   We conclude that hyperparameter optimization is more nuanced than previously believed. While such optimization can certainly lead to large improvements in the performance of classifiers used in software analytics, it remains to be seen which specific optimizers should be applied to a new dataset.

</details>

<details>

<summary>2018-10-02 20:01:43 - Human Indignity: From Legal AI Personhood to Selfish Memes</summary>

- *Roman V. Yampolskiy*

- `1810.02724v1` - [abs](http://arxiv.org/abs/1810.02724v1) - [pdf](http://arxiv.org/pdf/1810.02724v1)

> It is possible to rely on current corporate law to grant legal personhood to Artificially Intelligent (AI) agents. In this paper, after introducing pathways to AI personhood, we analyze consequences of such AI empowerment on human dignity, human safety and AI rights. We emphasize possibility of creating selfish memes and legal system hacking in the context of artificial entities. Finally, we consider some potential solutions for addressing described problems.

</details>

<details>

<summary>2018-10-02 20:19:13 - UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural Networks</summary>

- *Chaim Baskin, Eli Schwartz, Evgenii Zheltonozhskii, Natan Liss, Raja Giryes, Alex M. Bronstein, Avi Mendelson*

- `1804.10969v3` - [abs](http://arxiv.org/abs/1804.10969v3) - [pdf](http://arxiv.org/pdf/1804.10969v3)

> We present a novel method for neural network quantization that emulates a non-uniform $k$-quantile quantizer, which adapts to the distribution of the quantized parameters. Our approach provides a novel alternative to the existing uniform quantization techniques for neural networks. We suggest to compare the results as a function of the bit-operations (BOPS) performed, assuming a look-up table availability for the non-uniform case. In this setup, we show the advantages of our strategy in the low computational budget regime. While the proposed solution is harder to implement in hardware, we believe it sets a basis for new alternatives to neural networks quantization.

</details>

<details>

<summary>2018-10-02 23:41:43 - Co-Arg: Cogent Argumentation with Crowd Elicitation</summary>

- *Mihai Boicu, Dorin Marcu, Gheorghe Tecuci, Lou Kaiser, Chirag Uttamsingh, Navya Kalale*

- `1810.01541v1` - [abs](http://arxiv.org/abs/1810.01541v1) - [pdf](http://arxiv.org/pdf/1810.01541v1)

> This paper presents Co-Arg, a new type of cognitive assistant to an intelligence analyst that enables the synergistic integration of analyst imagination and expertise, computer knowledge and critical reasoning, and crowd wisdom, to draw defensible and persuasive conclusions from masses of evidence of all types, in a world that is changing all the time. Co-Arg's goal is to improve the quality of the analytic results and enhance their understandability for both experts and novices. The performed analysis is based on a sound and transparent argumentation that links evidence to conclusions in a way that shows very clearly how the conclusions have been reached, what evidence was used and how, what is not known, and what assumptions have been made. The analytic results are presented in a report describes the analytic conclusion and its probability, the main favoring and disfavoring arguments, the justification of the key judgments and assumptions, and the missing information that might increase the accuracy of the solution.

</details>

<details>

<summary>2018-10-03 07:39:45 - High-throughput, high-resolution registration-free generated adversarial network microscopy</summary>

- *Hao Zhang, Xinlin Xie, Chunyu Fang, Yicong Yang, Di Jin, Peng Fei*

- `1801.07330v2` - [abs](http://arxiv.org/abs/1801.07330v2) - [pdf](http://arxiv.org/pdf/1801.07330v2)

> We combine generative adversarial network (GAN) with light microscopy to achieve deep learning super-resolution under a large field of view (FOV). By appropriately adopting prior microscopy data in an adversarial training, the neural network can recover a high-resolution, accurate image of new specimen from its single low-resolution measurement. Its capacity has been broadly demonstrated via imaging various types of samples, such as USAF resolution target, human pathological slides, fluorescence-labelled fibroblast cells, and deep tissues in transgenic mouse brain, by both wide-field and light-sheet microscopes. The gigapixel, multi-color reconstruction of these samples verifies a successful GAN-based single image super-resolution procedure. We also propose an image degrading model to generate low resolution images for training, making our approach free from the complex image registration during training dataset preparation. After a welltrained network being created, this deep learning-based imaging approach is capable of recovering a large FOV (~95 mm2), high-resolution (~1.7 {\mu}m) image at high speed (within 1 second), while not necessarily introducing any changes to the setup of existing microscopes.

</details>

<details>

<summary>2018-10-03 08:10:03 - Towards WARSHIP: Combining Components of Brain-Inspired Computing of RSH for Image Super Resolution</summary>

- *Wendi Xu, Ming Zhang*

- `1810.01620v1` - [abs](http://arxiv.org/abs/1810.01620v1) - [pdf](http://arxiv.org/pdf/1810.01620v1)

> Evolution of deep learning shows that some algorithmic tricks are more durable , while others are not. To the best of our knowledge, we firstly summarize 5 more durable and complete deep learning components for vision, that is, WARSHIP. Moreover, we give a biological overview of WARSHIP, emphasizing brain-inspired computing of WARSHIP. As a step towards WARSHIP, our case study of image super resolution combines 3 components of RSH to deploy a CNN model of WARSHIP-XZNet, which performs a happy medium between speed and performance.

</details>

<details>

<summary>2018-10-03 08:10:51 - Theory of Generative Deep Learning : Probe Landscape of Empirical Error via Norm Based Capacity Control</summary>

- *Wendi Xu, Ming Zhang*

- `1810.01622v1` - [abs](http://arxiv.org/abs/1810.01622v1) - [pdf](http://arxiv.org/pdf/1810.01622v1)

> Despite its remarkable empirical success as a highly competitive branch of artificial intelligence, deep learning is often blamed for its widely known low interpretation and lack of firm and rigorous mathematical foundation. However, most theoretical endeavor is devoted in discriminative deep learning case, whose complementary part is generative deep learning. To the best of our knowledge, we firstly highlight landscape of empirical error in generative case to complete the full picture through exquisite design of image super resolution under norm based capacity control. Our theoretical advance in interpretation of the training dynamic is achieved from both mathematical and biological sides.

</details>

<details>

<summary>2018-10-03 08:43:11 - Exploiting Contextual Information via Dynamic Memory Network for Event Detection</summary>

- *Shaobo Liu, Rui Cheng, Xiaoming Yu, Xueqi Cheng*

- `1810.03449v1` - [abs](http://arxiv.org/abs/1810.03449v1) - [pdf](http://arxiv.org/pdf/1810.03449v1)

> The task of event detection involves identifying and categorizing event triggers. Contextual information has been shown effective on the task. However, existing methods which utilize contextual information only process the context once. We argue that the context can be better exploited by processing the context multiple times, allowing the model to perform complex reasoning and to generate better context representation, thus improving the overall performance. Meanwhile, dynamic memory network (DMN) has demonstrated promising capability in capturing contextual information and has been applied successfully to various tasks. In light of the multi-hop mechanism of the DMN to model the context, we propose the trigger detection dynamic memory network (TD-DMN) to tackle the event detection problem. We performed a five-fold cross-validation on the ACE-2005 dataset and experimental results show that the multi-hop mechanism does improve the performance and the proposed model achieves best $F_1$ score compared to the state-of-the-art methods.

</details>

<details>

<summary>2018-10-03 11:47:51 - Discovering space - Grounding spatial topology and metric regularity in a naive agent's sensorimotor experience</summary>

- *Alban Laflaquière, J. Kevin O'Regan, Bruno Gas, Alexander Terekhov*

- `1806.02739v2` - [abs](http://arxiv.org/abs/1806.02739v2) - [pdf](http://arxiv.org/pdf/1806.02739v2)

> In line with the sensorimotor contingency theory, we investigate the problem of the perception of space from a fundamental sensorimotor perspective. Despite its pervasive nature in our perception of the world, the origin of the concept of space remains largely mysterious. For example in the context of artificial perception, this issue is usually circumvented by having engineers pre-define the spatial structure of the problem the agent has to face. We here show that the structure of space can be autonomously discovered by a naive agent in the form of sensorimotor regularities, that correspond to so called compensable sensory experiences: these are experiences that can be generated either by the agent or its environment. By detecting such compensable experiences the agent can infer the topological and metric structure of the external space in which its body is moving. We propose a theoretical description of the nature of these regularities and illustrate the approach on a simulated robotic arm equipped with an eye-like sensor, and which interacts with an object. Finally we show how these regularities can be used to build an internal representation of the sensor's external spatial configuration.

</details>

<details>

<summary>2018-10-03 13:30:47 - Can everyday AI be ethical. Fairness of Machine Learning Algorithms</summary>

- *Philippe Besse, Celine Castets-Renard, Aurelien Garivier, Jean-Michel Loubes*

- `1810.01729v1` - [abs](http://arxiv.org/abs/1810.01729v1) - [pdf](http://arxiv.org/pdf/1810.01729v1)

> Combining big data and machine learning algorithms, the power of automatic decision tools induces as much hope as fear. Many recently enacted European legislation (GDPR) and French laws attempt to regulate the use of these tools. Leaving aside the well-identified problems of data confidentiality and impediments to competition, we focus on the risks of discrimination, the problems of transparency and the quality of algorithmic decisions. The detailed perspective of the legal texts, faced with the complexity and opacity of the learning algorithms, reveals the need for important technological disruptions for the detection or reduction of the discrimination risk, and for addressing the right to obtain an explanation of the auto- matic decision. Since trust of the developers and above all of the users (citizens, litigants, customers) is essential, algorithms exploiting personal data must be deployed in a strict ethical framework. In conclusion, to answer this need, we list some ways of controls to be developed: institutional control, ethical charter, external audit attached to the issue of a label.

</details>

<details>

<summary>2018-10-03 13:31:41 - Grounding Perception: A Developmental Approach to Sensorimotor Contingencies</summary>

- *Alban Laflaquière, Nikolas Hemion, Michaël Garcia Ortiz, Jean-Christophe Baillie*

- `1810.01870v1` - [abs](http://arxiv.org/abs/1810.01870v1) - [pdf](http://arxiv.org/pdf/1810.01870v1)

> Sensorimotor contingency theory offers a promising account of the nature of perception, a topic rarely addressed in the robotics community. We propose a developmental framework to address the problem of the autonomous acquisition of sensorimotor contingencies by a naive robot. While exploring the world, the robot internally encodes contingencies as predictive models that capture the structure they imply in its sensorimotor experience. Three preliminary applications are presented to illustrate our approach to the acquisition of perceptive abilities: discovering the environment, discovering objects, and discovering a visual field.

</details>

<details>

<summary>2018-10-03 13:42:43 - Grounding the Experience of a Visual Field through Sensorimotor Contingencies</summary>

- *Alban Laflaquière*

- `1810.01871v1` - [abs](http://arxiv.org/abs/1810.01871v1) - [pdf](http://arxiv.org/pdf/1810.01871v1)

> Artificial perception is traditionally handled by hand-designing task specific algorithms. However, a truly autonomous robot should develop perceptive abilities on its own, by interacting with its environment, and adapting to new situations. The sensorimotor contingencies theory proposes to ground the development of those perceptive abilities in the way the agent can actively transform its sensory inputs. We propose a sensorimotor approach, inspired by this theory, in which the agent explores the world and discovers its properties by capturing the sensorimotor regularities they induce. This work presents an application of this approach to the discovery of a so-called visual field as the set of regularities that a visual sensor imposes on a naive agent's experience. A formalism is proposed to describe how those regularities can be captured in a sensorimotor predictive model. Finally, the approach is evaluated on a simulated system coarsely inspired from the human retina.

</details>

<details>

<summary>2018-10-03 14:30:48 - Algorithms for Destructive Shift Bribery</summary>

- *Andrzej Kaczmarczyk, Piotr Faliszewski*

- `1810.01763v1` - [abs](http://arxiv.org/abs/1810.01763v1) - [pdf](http://arxiv.org/pdf/1810.01763v1)

> We study the complexity of Destructive Shift Bribery. In this problem, we are given an election with a set of candidates and a set of voters (each ranking the candidates from the best to the worst), a despised candidate $d$, a budget $B$, and prices for shifting $d$ back in the voters' rankings. The goal is to ensure that $d$ is not a winner of the election. We show that this problem is polynomial-time solvable for scoring protocols (encoded in unary), the Bucklin and Simplified Bucklin rules, and the Maximin rule, but is NP-hard for the Copeland rule. This stands in contrast to the results for the constructive setting (known from the literature), for which the problem is polynomial-time solvable for $k$-Approval family of rules, but is NP-hard for the Borda, Copeland, and Maximin rules. We complement the analysis of the Copeland rule showing W-hardness for the parameterization by the budget value, and by the number of affected voters. We prove that the problem is W-hard when parameterized by the number of voters even for unit prices. From the positive perspective we provide an efficient algorithm for solving the problem parameterized by the combined parameter the number of candidates and the maximum bribery price (alternatively the number of different bribery prices).

</details>

<details>

<summary>2018-10-03 15:20:59 - FixaTons: A collection of Human Fixations Datasets and Metrics for Scanpath Similarity</summary>

- *Dario Zanca, Valeria Serchi, Pietro Piu, Francesca Rosini, Alessandra Rufa*

- `1802.02534v3` - [abs](http://arxiv.org/abs/1802.02534v3) - [pdf](http://arxiv.org/pdf/1802.02534v3)

> In the last three decades, human visual attention has been a topic of great interest in various disciplines. In computer vision, many models have been proposed to predict the distribution of human fixations on a visual stimulus. Recently, thanks to the creation of large collections of data, machine learning algorithms have obtained state-of-the-art performance on the task of saliency map estimation. On the other hand, computational models of scanpath are much less studied. Works are often only descriptive or task specific. This is due to the fact that the scanpath is harder to model because it must include the description of a dynamic. General purpose computational models are present in the literature, but are then evaluated in tasks of saliency prediction, losing therefore information about the dynamics and the behaviour. In addition, two technical reasons have limited the research. The first reason is the lack of robust and uniformly used set of metrics to compare the similarity between scanpath. The second reason is the lack of sufficiently large and varied scanpath datasets. In this report we want to help in both directions. We present FixaTons, a large collection of datasets human scanpaths (temporally ordered sequences of fixations) and saliency maps. It comes along with a software library for easy data usage, statistics calculation and implementation of metrics for scanpath and saliency prediction evaluation.

</details>

<details>

<summary>2018-10-03 15:42:51 - Testing Untestable Neural Machine Translation: An Industrial Case</summary>

- *Wujie Zheng, Wenyu Wang, Dian Liu, Changrong Zhang, Qinsong Zeng, Yuetang Deng, Wei Yang, Pinjia He, Tao Xie*

- `1807.02340v2` - [abs](http://arxiv.org/abs/1807.02340v2) - [pdf](http://arxiv.org/pdf/1807.02340v2)

> Neural Machine Translation (NMT) has been widely adopted recently due to its advantages compared with the traditional Statistical Machine Translation (SMT). However, an NMT system still often produces translation failures due to the complexity of natural language and sophistication in designing neural networks. While in-house black-box system testing based on reference translations (i.e., examples of valid translations) has been a common practice for NMT quality assurance, an increasingly critical industrial practice, named in-vivo testing, exposes unseen types or instances of translation failures when real users are using a deployed industrial NMT system. To fill the gap of lacking test oracle for in-vivo testing of an NMT system, in this paper, we propose a new approach for automatically identifying translation failures, without requiring reference translations for a translation task; our approach can directly serve as a test oracle for in-vivo testing. Our approach focuses on properties of natural language translation that can be checked systematically and uses information from both the test inputs (i.e., the texts to be translated) and the test outputs (i.e., the translations under inspection) of the NMT system. Our evaluation conducted on real-world datasets shows that our approach can effectively detect targeted property violations as translation failures. Our experiences on deploying our approach in both production and development environments of WeChat (a messenger app with over one billion monthly active users) demonstrate high effectiveness of our approach along with high industry impact.

</details>

<details>

<summary>2018-10-03 15:49:43 - Disambiguating Music Artists at Scale with Audio Metric Learning</summary>

- *Jimena Royo-Letelier, Romain Hennequin, Viet-Anh Tran, Manuel Moussallam*

- `1810.01807v1` - [abs](http://arxiv.org/abs/1810.01807v1) - [pdf](http://arxiv.org/pdf/1810.01807v1)

> We address the problem of disambiguating large scale catalogs through the definition of an unknown artist clustering task. We explore the use of metric learning techniques to learn artist embeddings directly from audio, and using a dedicated homonym artists dataset, we compare our method with a recent approach that learn similar embeddings using artist classifiers. While both systems have the ability to disambiguate unknown artists relying exclusively on audio, we show that our system is more suitable in the case when enough audio data is available for each artist in the train dataset. We also propose a new negative sampling method for metric learning that takes advantage of side information such as music genre during the learning phase and shows promising results for the artist clustering task.

</details>

<details>

<summary>2018-10-03 16:36:22 - Human-Centered Autonomous Vehicle Systems: Principles of Effective Shared Autonomy</summary>

- *Lex Fridman*

- `1810.01835v1` - [abs](http://arxiv.org/abs/1810.01835v1) - [pdf](http://arxiv.org/pdf/1810.01835v1)

> Building effective, enjoyable, and safe autonomous vehicles is a lot harder than has historically been considered. The reason is that, simply put, an autonomous vehicle must interact with human beings. This interaction is not a robotics problem nor a machine learning problem nor a psychology problem nor an economics problem nor a policy problem. It is all of these problems put into one. It challenges our assumptions about the limitations of human beings at their worst and the capabilities of artificial intelligence systems at their best. This work proposes a set of principles for designing and building autonomous vehicles in a human-centered way that does not run away from the complexity of human nature but instead embraces it. We describe our development of the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study of implementing these principles in practice.

</details>

<details>

<summary>2018-10-03 16:42:33 - Mining Contrasting Quasi-Clique Patterns</summary>

- *Roberto Alonso, Stephan Günnemann*

- `1810.01836v1` - [abs](http://arxiv.org/abs/1810.01836v1) - [pdf](http://arxiv.org/pdf/1810.01836v1)

> Mining dense quasi-cliques is a well-known clustering task with applications ranging from social networks over collaboration graphs to document analysis. Recent work has extended this task to multiple graphs; i.e. the goal is to find groups of vertices highly dense among multiple graphs. In this paper, we argue that in a multi-graph scenario the sparsity is valuable for knowledge extraction as well. We introduce the concept of contrasting quasi-clique patterns: a collection of vertices highly dense in one graph but highly sparse (i.e. less connected) in a second graph. Thus, these patterns specifically highlight the difference/contrast between the considered graphs. Based on our novel model, we propose an algorithm that enables fast computation of contrasting patterns by exploiting intelligent traversal and pruning techniques. We showcase the potential of contrasting patterns on a variety of synthetic and real-world datasets.

</details>

<details>

<summary>2018-10-03 17:24:06 - SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation</summary>

- *Sudeep Pillai, Rares Ambrus, Adrien Gaidon*

- `1810.01849v1` - [abs](http://arxiv.org/abs/1810.01849v1) - [pdf](http://arxiv.org/pdf/1810.01849v1)

> Recent techniques in self-supervised monocular depth estimation are approaching the performance of supervised methods, but operate in low resolution only. We show that high resolution is key towards high-fidelity self-supervised monocular depth prediction. Inspired by recent deep learning methods for Single-Image Super-Resolution, we propose a sub-pixel convolutional layer extension for depth super-resolution that accurately synthesizes high-resolution disparities from their corresponding low-resolution convolutional features. In addition, we introduce a differentiable flip-augmentation layer that accurately fuses predictions from the image and its horizontally flipped version, reducing the effect of left and right shadow regions generated in the disparity map due to occlusions. Both contributions provide significant performance gains over the state-of-the-art in self-supervised depth and pose estimation on the public KITTI benchmark. A video of our approach can be found at https://youtu.be/jKNgBeBMx0I.

</details>

<details>

<summary>2018-10-03 17:45:04 - Detecting egregious responses in neural sequence-to-sequence models</summary>

- *Tianxing He, James Glass*

- `1809.04113v2` - [abs](http://arxiv.org/abs/1809.04113v2) - [pdf](http://arxiv.org/pdf/1809.04113v2)

> In this work, we attempt to answer a critical question: whether there exists some input sequence that will cause a well-trained discrete-space neural network sequence-to-sequence (seq2seq) model to generate egregious outputs (aggressive, malicious, attacking, etc.). And if such inputs exist, how to find them efficiently. We adopt an empirical methodology, in which we first create lists of egregious output sequences, and then design a discrete optimization algorithm to find input sequences that will cause the model to generate them. Moreover, the optimization algorithm is enhanced for large vocabulary search and constrained to search for input sequences that are likely to be input by real-world users. In our experiments, we apply this approach to dialogue response generation models trained on three real-world dialogue data-sets: Ubuntu, Switchboard and OpenSubtitles, testing whether the model can generate malicious responses. We demonstrate that given the trigger inputs our algorithm finds, a significant number of malicious sentences are assigned large probability by the model, which reveals an undesirable consequence of standard seq2seq training.

</details>

<details>

<summary>2018-10-03 20:18:35 - AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias</summary>

- *Rachel K. E. Bellamy, Kuntal Dey, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovic, Seema Nagar, Karthikeyan Natesan Ramamurthy, John Richards, Diptikalyan Saha, Prasanna Sattigeri, Moninder Singh, Kush R. Varshney, Yunfeng Zhang*

- `1810.01943v1` - [abs](http://arxiv.org/abs/1810.01943v1) - [pdf](http://arxiv.org/pdf/1810.01943v1)

> Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license {https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms.   The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (https://aif360.mybluemix.net) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.

</details>

<details>

<summary>2018-10-03 21:01:51 - Sparse Winograd Convolutional neural networks on small-scale systolic arrays</summary>

- *Feng Shi, Haochen Li, Yuhe Gao, Benjamin Kuschner, Song-Chun Zhu*

- `1810.01973v1` - [abs](http://arxiv.org/abs/1810.01973v1) - [pdf](http://arxiv.org/pdf/1810.01973v1)

> The reconfigurability, energy-efficiency, and massive parallelism on FPGAs make them one of the best choices for implementing efficient deep learning accelerators. However, state-of-art implementations seldom consider the balance between high throughput of computation power and the ability of the memory subsystem to support it. In this paper, we implement an accelerator on FPGA by combining the sparse Winograd convolution, clusters of small-scale systolic arrays, and a tailored memory layout design. We also provide an analytical model analysis for the general Winograd convolution algorithm as a design reference. Experimental results on VGG16 show that it achieves very high computational resource utilization, 20x ~ 30x energy efficiency, and more than 5x speedup compared with the dense implementation.

</details>

<details>

<summary>2018-10-03 22:12:05 - Verification for Machine Learning, Autonomy, and Neural Networks Survey</summary>

- *Weiming Xiang, Patrick Musau, Ayana A. Wild, Diego Manzanas Lopez, Nathaniel Hamilton, Xiaodong Yang, Joel Rosenfeld, Taylor T. Johnson*

- `1810.01989v1` - [abs](http://arxiv.org/abs/1810.01989v1) - [pdf](http://arxiv.org/pdf/1810.01989v1)

> This survey presents an overview of verification techniques for autonomous systems, with a focus on safety-critical autonomous cyber-physical systems (CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances in artificial intelligence (AI) and machine learning (ML) through approaches such as deep neural networks (DNNs), embedded in so-called learning enabled components (LECs) that accomplish tasks from classification to control. Recently, the formal methods and formal verification community has developed methods to characterize behaviors in these LECs with eventual goals of formally verifying specifications for LECs, and this article presents a survey of many of these recent approaches.

</details>

<details>

<summary>2018-10-03 22:30:44 - Action Model Acquisition using LSTM</summary>

- *Ankuj Arora, Humbert Fiorino, Damien Pellier, Sylvie Pesty*

- `1810.01992v1` - [abs](http://arxiv.org/abs/1810.01992v1) - [pdf](http://arxiv.org/pdf/1810.01992v1)

> In the field of Automated Planning and Scheduling (APS), intelligent agents by virtue require an action model (blueprints of actions whose interleaved executions effectuates transitions of the system state) in order to plan and solve real world problems. It is, however, becoming increasingly cumbersome to codify this model, and is more efficient to learn it from observed plan execution sequences (training data). While the underlying objective is to subsequently plan from this learnt model, most approaches fall short as anything less than a flawless reconstruction of the underlying model renders it unusable in certain domains. This work presents a novel approach using long short-term memory (LSTM) techniques for the acquisition of the underlying action model. We use the sequence labelling capabilities of LSTMs to isolate from an exhaustive model set a model identical to the one responsible for producing the training data. This isolation capability renders our approach as an effective one.

</details>

<details>

<summary>2018-10-03 22:43:58 - Controlling Over-generalization and its Effect on Adversarial Examples Generation and Detection</summary>

- *Mahdieh Abbasi, Arezoo Rajabi, Azadeh Sadat Mozafari, Rakesh B. Bobba, Christian Gagne*

- `1808.08282v2` - [abs](http://arxiv.org/abs/1808.08282v2) - [pdf](http://arxiv.org/pdf/1808.08282v2)

> Convolutional Neural Networks (CNNs) significantly improve the state-of-the-art for many applications, especially in computer vision. However, CNNs still suffer from a tendency to confidently classify out-distribution samples from unknown classes into pre-defined known classes. Further, they are also vulnerable to adversarial examples. We are relating these two issues through the tendency of CNNs to over-generalize for areas of the input space not covered well by the training set. We show that a CNN augmented with an extra output class can act as a simple yet effective end-to-end model for controlling over-generalization. As an appropriate training set for the extra class, we introduce two resources that are computationally efficient to obtain: a representative natural out-distribution set and interpolated in-distribution samples. To help select a representative natural out-distribution set among available ones, we propose a simple measurement to assess an out-distribution set's fitness. We also demonstrate that training such an augmented CNN with representative out-distribution natural datasets and some interpolated samples allows it to better handle a wide range of unseen out-distribution samples and black-box adversarial examples without training it on any adversaries. Finally, we show that generation of white-box adversarial attacks using our proposed augmented CNN can become harder, as the attack algorithms have to get around the rejection regions when generating actual adversaries.

</details>

<details>

<summary>2018-10-04 04:12:12 - McTorch, a manifold optimization library for deep learning</summary>

- *Mayank Meghwanshi, Pratik Jawanpuria, Anoop Kunchukuttan, Hiroyuki Kasai, Bamdev Mishra*

- `1810.01811v2` - [abs](http://arxiv.org/abs/1810.01811v2) - [pdf](http://arxiv.org/pdf/1810.01811v2)

> In this paper, we introduce McTorch, a manifold optimization library for deep learning that extends PyTorch. It aims to lower the barrier for users wishing to use manifold constraints in deep learning applications, i.e., when the parameters are constrained to lie on a manifold. Such constraints include the popular orthogonality and rank constraints, and have been recently used in a number of applications in deep learning. McTorch follows PyTorch's architecture and decouples manifold definitions and optimizers, i.e., once a new manifold is added it can be used with any existing optimizer and vice-versa. McTorch is available at https://github.com/mctorch .

</details>

<details>

<summary>2018-10-04 06:29:59 - Towards Fast and Energy-Efficient Binarized Neural Network Inference on FPGA</summary>

- *Cheng Fu, Shilin Zhu, Hao Su, Ching-En Lee, Jishen Zhao*

- `1810.02068v1` - [abs](http://arxiv.org/abs/1810.02068v1) - [pdf](http://arxiv.org/pdf/1810.02068v1)

> Binarized Neural Network (BNN) removes bitwidth redundancy in classical CNN by using a single bit (-1/+1) for network parameters and intermediate representations, which has greatly reduced the off-chip data transfer and storage overhead. However, a large amount of computation redundancy still exists in BNN inference. By analyzing local properties of images and the learned BNN kernel weights, we observe an average of $\sim$78% input similarity and $\sim$59% weight similarity among weight kernels, measured by our proposed metric in common network architectures. Thus there does exist redundancy that can be exploited to further reduce the amount of on-chip computations.   Motivated by the observation, in this paper, we proposed two types of fast and energy-efficient architectures for BNN inference. We also provide analysis and insights to pick the better strategy of these two for different datasets and network models. By reusing the results from previous computation, much cycles for data buffer access and computations can be skipped. By experiments, we demonstrate that 80% of the computation and 40% of the buffer access can be skipped by exploiting BNN similarity. Thus, our design can achieve 17% reduction in total power consumption, 54% reduction in on-chip power consumption and 2.4$\times$ maximum speedup, compared to the baseline without applying our reuse technique. Our design also shows 1.9$\times$ more area-efficiency compared to state-of-the-art BNN inference design. We believe our deployment of BNN on FPGA leads to a promising future of running deep learning models on mobile devices.

</details>

<details>

<summary>2018-10-04 08:58:54 - The Algorithm Selection Competitions 2015 and 2017</summary>

- *Marius Lindauer, Jan N. van Rijn, Lars Kotthoff*

- `1805.01214v2` - [abs](http://arxiv.org/abs/1805.01214v2) - [pdf](http://arxiv.org/pdf/1805.01214v2)

> The algorithm selection problem is to choose the most suitable algorithm for solving a given problem instance. It leverages the complementarity between different approaches that is present in many areas of AI. We report on the state of the art in algorithm selection, as defined by the Algorithm Selection competitions in 2015 and 2017. The results of these competitions show how the state of the art improved over the years. We show that although performance in some cases is very good, there is still room for improvement in other cases. Finally, we provide insights into why some scenarios are hard, and pose challenges to the community on how to advance the current state of the art.

</details>

<details>

<summary>2018-10-04 09:46:56 - Quantum Artificial Life in an IBM Quantum Computer</summary>

- *U. Alvarez-Rodriguez, M. Sanz, L. Lamata, E. Solano*

- `1711.09442v2` - [abs](http://arxiv.org/abs/1711.09442v2) - [pdf](http://arxiv.org/pdf/1711.09442v2)

> We present the first experimental realization of a quantum artificial life algorithm in a quantum computer. The quantum biomimetic protocol encodes tailored quantum behaviors belonging to living systems, namely, self-replication, mutation, interaction between individuals, and death, into the cloud quantum computer IBM ibmqx4. In this experiment, entanglement spreads throughout generations of individuals, where genuine quantum information features are inherited through genealogical networks. As a pioneering proof-of-principle, experimental data fits the ideal model with accuracy. Thereafter, these and other models of quantum artificial life, for which no classical device may predict its quantum supremacy evolution, can be further explored in novel generations of quantum computers. Quantum biomimetics, quantum machine learning, and quantum artificial intelligence will move forward hand in hand through more elaborate levels of quantum complexity.

</details>

<details>

<summary>2018-10-04 09:58:34 - Learning Finer-class Networks for Universal Representations</summary>

- *Julien Girard, Youssef Tamaazousti, Hervé Le Borgne, Céline Hudelot*

- `1810.02126v1` - [abs](http://arxiv.org/abs/1810.02126v1) - [pdf](http://arxiv.org/pdf/1810.02126v1)

> Many real-world visual recognition use-cases can not directly benefit from state-of-the-art CNN-based approaches because of the lack of many annotated data. The usual approach to deal with this is to transfer a representation pre-learned on a large annotated source-task onto a target-task of interest. This raises the question of how well the original representation is "universal", that is to say directly adapted to many different target-tasks. To improve such universality, the state-of-the-art consists in training networks on a diversified source problem, that is modified either by adding generic or specific categories to the initial set of categories. In this vein, we proposed a method that exploits finer-classes than the most specific ones existing, for which no annotation is available. We rely on unsupervised learning and a bottom-up split and merge strategy. We show that our method learns more universal representations than state-of-the-art, leading to significantly better results on 10 target-tasks from multiple domains, using several network architectures, either alone or combined with networks learned at a coarser semantic level.

</details>

<details>

<summary>2018-10-04 14:09:20 - Italian Event Detection Goes Deep Learning</summary>

- *Tommaso Caselli*

- `1810.02229v1` - [abs](http://arxiv.org/abs/1810.02229v1) - [pdf](http://arxiv.org/pdf/1810.02229v1)

> This paper reports on a set of experiments with different word embeddings to initialize a state-of-the-art Bi-LSTM-CRF network for event detection and classification in Italian, following the EVENTI evaluation exercise. The net- work obtains a new state-of-the-art result by improving the F1 score for detection of 1.3 points, and of 6.5 points for classification, by using a single step approach. The results also provide further evidence that embeddings have a major impact on the performance of such architectures.

</details>

<details>

<summary>2018-10-04 15:04:10 - Concept-drifting Data Streams are Time Series; The Case for Continuous Adaptation</summary>

- *Jesse Read*

- `1810.02266v1` - [abs](http://arxiv.org/abs/1810.02266v1) - [pdf](http://arxiv.org/pdf/1810.02266v1)

> Learning from data streams is an increasingly important topic in data mining, machine learning, and artificial intelligence in general. A major focus in the data stream literature is on designing methods that can deal with concept drift, a challenge where the generating distribution changes over time. A general assumption in most of this literature is that instances are independently distributed in the stream. In this work we show that, in the context of concept drift, this assumption is contradictory, and that the presence of concept drift necessarily implies temporal dependence; and thus some form of time series. This has important implications on model design and deployment. We explore and highlight the these implications, and show that Hoeffding-tree based ensembles, which are very popular for learning in streams, are not naturally suited to learning \emph{within} drift; and can perform in this scenario only at significant computational cost of destructive adaptation. On the other hand, we develop and parameterize gradient-descent methods and demonstrate how they can perform \emph{continuous} adaptation with no explicit drift-detection mechanism, offering major advantages in terms of accuracy and efficiency. As a consequence of our theoretical discussion and empirical observations, we outline a number of recommendations for deploying methods in concept-drifting streams.

</details>

<details>

<summary>2018-10-04 17:09:04 - Computer vision-based framework for extracting geological lineaments from optical remote sensing data</summary>

- *Ehsan Farahbakhsh, Rohitash Chandra, Hugo K. H. Olierook, Richard Scalzo, Chris Clark, Steven M. Reddy, R. Dietmar Muller*

- `1810.02320v1` - [abs](http://arxiv.org/abs/1810.02320v1) - [pdf](http://arxiv.org/pdf/1810.02320v1)

> The extraction of geological lineaments from digital satellite data is a fundamental application in remote sensing. The location of geological lineaments such as faults and dykes are of interest for a range of applications, particularly because of their association with hydrothermal mineralization. Although a wide range of applications have utilized computer vision techniques, a standard workflow for application of these techniques to mineral exploration is lacking. We present a framework for extracting geological lineaments using computer vision techniques which is a combination of edge detection and line extraction algorithms for extracting geological lineaments using optical remote sensing data. It features ancillary computer vision techniques for reducing data dimensionality, removing noise and enhancing the expression of lineaments. We test the proposed framework on Landsat 8 data of a mineral-rich portion of the Gascoyne Province in Western Australia using different dimension reduction techniques and convolutional filters. To validate the results, the extracted lineaments are compared to our manual photointerpretation and geologically mapped structures by the Geological Survey of Western Australia (GSWA). The results show that the best correlation between our extracted geological lineaments and the GSWA geological lineament map is achieved by applying a minimum noise fraction transformation and a Laplacian filter. Application of a directional filter instead shows a stronger correlation with the output of our manual photointerpretation and known sites of hydrothermal mineralization. Hence, our framework using either filter can be used for mineral prospectivity mapping in other regions where faults are exposed and observable in optical remote sensing data.

</details>

<details>

<summary>2018-10-04 17:20:39 - A Practical Approach to Sizing Neural Networks</summary>

- *Gerald Friedland, Alfredo Metere, Mario Krell*

- `1810.02328v1` - [abs](http://arxiv.org/abs/1810.02328v1) - [pdf](http://arxiv.org/pdf/1810.02328v1)

> Memorization is worst-case generalization. Based on MacKay's information theoretic model of supervised machine learning, this article discusses how to practically estimate the maximum size of a neural network given a training data set. First, we present four easily applicable rules to analytically determine the capacity of neural network architectures. This allows the comparison of the efficiency of different network architectures independently of a task. Second, we introduce and experimentally validate a heuristic method to estimate the neural network capacity requirement for a given dataset and labeling. This allows an estimate of the required size of a neural network for a given problem. We conclude the article with a discussion on the consequences of sizing the network wrongly, which includes both increased computation effort for training as well as reduced generalization capability.

</details>

<details>

<summary>2018-10-05 02:53:26 - Current Trends and Future Research Directions for Interactive Music</summary>

- *Mauricio Toro*

- `1810.04276v1` - [abs](http://arxiv.org/abs/1810.04276v1) - [pdf](http://arxiv.org/pdf/1810.04276v1)

> In this review, it is explained and compared different software and formalisms used in music interaction: sequencers, computer-assisted improvisation, meta- instruments, score-following, asynchronous dataflow languages, synchronous dataflow languages, process calculi, temporal constraints and interactive scores. Formal approaches have the advantage of providing rigorous semantics of the behavior of the model and proving correctness during execution. The main disadvantage of formal approaches is lack of commercial tools.

</details>

<details>

<summary>2018-10-05 05:08:37 - Model-Ensemble Trust-Region Policy Optimization</summary>

- *Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, Pieter Abbeel*

- `1802.10592v2` - [abs](http://arxiv.org/abs/1802.10592v2) - [pdf](http://arxiv.org/pdf/1802.10592v2)

> Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity, which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.

</details>

<details>

<summary>2018-10-05 05:52:49 - Where Did My Optimum Go?: An Empirical Analysis of Gradient Descent Optimization in Policy Gradient Methods</summary>

- *Peter Henderson, Joshua Romoff, Joelle Pineau*

- `1810.02525v1` - [abs](http://arxiv.org/abs/1810.02525v1) - [pdf](http://arxiv.org/pdf/1810.02525v1)

> Recent analyses of certain gradient descent optimization methods have shown that performance can degrade in some settings - such as with stochasticity or implicit momentum. In deep reinforcement learning (Deep RL), such optimization methods are often used for training neural networks via the temporal difference error or policy gradient. As an agent improves over time, the optimization target changes and thus the loss landscape (and local optima) change. Due to the failure modes of those methods, the ideal choice of optimizer for Deep RL remains unclear. As such, we provide an empirical analysis of the effects that a wide range of gradient descent optimizers and their hyperparameters have on policy gradient methods, a subset of Deep RL algorithms, for benchmark continuous control tasks. We find that adaptive optimizers have a narrow window of effective learning rates, diverging in other cases, and that the effectiveness of momentum varies depending on the properties of the environment. Our analysis suggests that there is significant interplay between the dynamics of the environment and Deep RL algorithm properties which aren't necessarily accounted for by traditional adaptive gradient methods. We provide suggestions for optimal settings of current methods and further lines of research based on our findings.

</details>

<details>

<summary>2018-10-05 08:40:30 - Memory Aware Synapses: Learning what (not) to forget</summary>

- *Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, Tinne Tuytelaars*

- `1711.09601v4` - [abs](http://arxiv.org/abs/1711.09601v4) - [pdf](http://arxiv.org/pdf/1711.09601v4)

> Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb's rule,which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting $<$subject, predicate, object$>$ triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary depending on test conditions.

</details>

<details>

<summary>2018-10-05 11:04:06 - Spatially-weighted Anomaly Detection</summary>

- *Minori Narita, Daiki Kimura, Ryuki Tachibana*

- `1810.02607v1` - [abs](http://arxiv.org/abs/1810.02607v1) - [pdf](http://arxiv.org/pdf/1810.02607v1)

> Many types of anomaly detection methods have been proposed recently, and applied to a wide variety of fields including medical screening and production quality checking. Some methods have utilized images, and, in some cases, a part of the anomaly images is known beforehand. However, this kind of information is dismissed by previous methods, because the methods can only utilize a normal pattern. Moreover, the previous methods suffer a decrease in accuracy due to negative effects from surrounding noises. In this study, we propose a spatially-weighted anomaly detection method (SPADE) that utilizes all of the known patterns and lessens the vulnerability to ambient noises by applying Grad-CAM, which is the visualization method of a CNN. We evaluated our method quantitatively using two datasets, the MNIST dataset with noise and a dataset based on a brief screening test for dementia.

</details>

<details>

<summary>2018-10-05 12:32:55 - Hybrid Active Inference</summary>

- *André Ofner, Sebastian Stober*

- `1810.02647v1` - [abs](http://arxiv.org/abs/1810.02647v1) - [pdf](http://arxiv.org/pdf/1810.02647v1)

> We describe a framework of hybrid cognition by formulating a hybrid cognitive agent that performs hierarchical active inference across a human and a machine part. We suggest that, in addition to enhancing human cognitive functions with an intelligent and adaptive interface, integrated cognitive processing could accelerate emergent properties within artificial intelligence. To establish this, a machine learning part learns to integrate into human cognition by explaining away multi-modal sensory measurements from the environment and physiology simultaneously with the brain signal. With ongoing training, the amount of predictable brain signal increases. This lends the agent the ability to self-supervise on increasingly high levels of cognitive processing in order to further minimize surprise in predicting the brain signal. Furthermore, with increasing level of integration, the access to sensory information about environment and physiology is substituted with access to their representation in the brain. While integrating into a joint embodiment of human and machine, human action and perception are treated as the machine's own. The framework can be implemented with invasive as well as non-invasive sensors for environment, body and brain interfacing. Online and offline training with different machine learning approaches are thinkable. Building on previous research on shared representation learning, we suggest a first implementation leading towards hybrid active inference with non-invasive brain interfacing and state of the art probabilistic deep learning methods. We further discuss how implementation might have effect on the meta-cognitive abilities of the described agent and suggest that with adequate implementation the machine part can continue to execute and build upon the learned cognitive processes autonomously.

</details>

<details>

<summary>2018-10-05 12:39:37 - Data-Efficient Hierarchical Reinforcement Learning</summary>

- *Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine*

- `1805.08296v4` - [abs](http://arxiv.org/abs/1805.08296v4) - [pdf](http://arxiv.org/pdf/1805.08296v4)

> Hierarchical reinforcement learning (HRL) is a promising approach to extend traditional reinforcement learning (RL) methods to solve more complex tasks. Yet, the majority of current HRL methods require careful task-specific design and on-policy training, making them difficult to apply in real-world scenarios. In this paper, we study how we can develop HRL algorithms that are general, in that they do not make onerous additional assumptions beyond standard RL algorithms, and efficient, in the sense that they can be used with modest numbers of interaction samples, making them suitable for real-world problems such as robotic control. For generality, we develop a scheme where lower-level controllers are supervised with goals that are learned and proposed automatically by the higher-level controllers. To address efficiency, we propose to use off-policy experience for both higher and lower-level training. This poses a considerable challenge, since changes to the lower-level behaviors change the action space for the higher-level policy, and we introduce an off-policy correction to remedy this challenge. This allows us to take advantage of recent advances in off-policy model-free RL to learn both higher- and lower-level policies using substantially fewer environment interactions than on-policy algorithms. We term the resulting HRL agent HIRO and find that it is generally applicable and highly sample-efficient. Our experiments show that HIRO can be used to learn highly complex behaviors for simulated robots, such as pushing objects and utilizing them to reach target locations, learning from only a few million samples, equivalent to a few days of real-time interaction. In comparisons with a number of prior HRL methods, we find that our approach substantially outperforms previous state-of-the-art techniques.

</details>

<details>

<summary>2018-10-05 13:43:08 - Local Interpretable Model-agnostic Explanations of Bayesian Predictive Models via Kullback-Leibler Projections</summary>

- *Tomi Peltola*

- `1810.02678v1` - [abs](http://arxiv.org/abs/1810.02678v1) - [pdf](http://arxiv.org/pdf/1810.02678v1)

> We introduce a method, KL-LIME, for explaining predictions of Bayesian predictive models by projecting the information in the predictive distribution locally to a simpler, interpretable explanation model. The proposed approach combines the recent Local Interpretable Model-agnostic Explanations (LIME) method with ideas from Bayesian projection predictive variable selection methods. The information theoretic basis helps in navigating the trade-off between explanation fidelity and complexity. We demonstrate the method in explaining MNIST digit classifications made by a Bayesian deep convolutional neural network.

</details>

<details>

<summary>2018-10-05 14:14:34 - Ockham's Razor in Memetic Computing: Three Stage Optimal Memetic Exploration</summary>

- *G. Iacca, F. Neri, E. Mininno, Y. S. Ong, M. H. Lim*

- `1810.08669v1` - [abs](http://arxiv.org/abs/1810.08669v1) - [pdf](http://arxiv.org/pdf/1810.08669v1)

> Memetic Computing is a subject in computer science which considers complex structures as the combination of simple agents, memes, whose evolutionary interactions lead to intelligent structures capable of problem-solving. This paper focuses on Memetic Computing optimization algorithms and proposes a counter-tendency approach for algorithmic design. Research in the field tends to go in the direction of improving existing algorithms by combining different methods or through the formulation of more complicated structures. Contrary to this trend, we instead focus on simplicity, proposing a structurally simple algorithm with emphasis on processing only one solution at a time. The proposed algorithm, namely Three Stage Optimal Memetic Exploration, is composed of three memes; the first stochastic and with a long search radius, the second stochastic and with a moderate search radius and the third deterministic and with a short search radius. The bottom-up combination of the three operators by means of a natural trial and error logic, generates a robust and efficient optimizer, capable of competing with modern complex and computationally expensive algorithms. This is suggestive of the fact that complexity in algorithmic structures can be unnecessary, if not detrimental, and that simple bottom-up approaches are likely to be competitive is here invoked as an extension to Memetic Computing basing on the philosophical concept of Ockham's Razor. An extensive experimental setup on various test problems and one digital signal processing application is presented. Numerical results show that the proposed approach, despite its simplicity and low computational cost displays a very good performance on several problems, and is competitive with sophisticated algorithms representing the-state-of-the-art in computational intelligence optimization.

</details>

<details>

<summary>2018-10-05 15:36:51 - Continuous Learning of Context-dependent Processing in Neural Networks</summary>

- *Guanxiong Zeng, Yang Chen, Bo Cui, Shan Yu*

- `1810.01256v2` - [abs](http://arxiv.org/abs/1810.01256v2) - [pdf](http://arxiv.org/pdf/1810.01256v2)

> Deep artificial neural networks (DNNs) are powerful tools for recognition and classification as they learn sophisticated mapping rules between the inputs and the outputs. However, the rules that learned by the majority of current DNNs used for pattern recognition are largely fixed and do not vary with different conditions. This limits the network's ability to work in more complex and dynamical situations in which the mapping rules themselves are not fixed but constantly change according to contexts, such as different environments and goals. Inspired by the role of the prefrontal cortex (PFC) in mediating context-dependent processing in the primate brain, here we propose a novel approach, involving a learning algorithm named orthogonal weights modification (OWM) with the addition of a PFC-like module, that enables networks to continually learn different mapping rules in a context-dependent way. We demonstrate that with OWM to protect previously acquired knowledge, the networks could sequentially learn up to thousands of different mapping rules without interference, and needing as few as $\sim$10 samples to learn each, reaching a human level ability in online, continual learning. In addition, by using a PFC-like module to enable contextual information to modulate the representation of sensory features, a network could sequentially learn different, context-specific mappings for identical stimuli. Taken together, these approaches allow us to teach a single network numerous context-dependent mapping rules in an online, continual manner. This would enable highly compact systems to gradually learn myriad of regularities of the real world and eventually behave appropriately within it.

</details>

<details>

<summary>2018-10-05 17:37:37 - POIReviewQA: A Semantically Enriched POI Retrieval and Question Answering Dataset</summary>

- *Gengchen Mai, Krzysztof Janowicz, Cheng He, Sumang Liu, Ni Lao*

- `1810.02802v1` - [abs](http://arxiv.org/abs/1810.02802v1) - [pdf](http://arxiv.org/pdf/1810.02802v1)

> Many services that perform information retrieval for Points of Interest (POI) utilize a Lucene-based setup with spatial filtering. While this type of system is easy to implement it does not make use of semantics but relies on direct word matches between a query and reviews leading to a loss in both precision and recall. To study the challenging task of semantically enriching POIs from unstructured data in order to support open-domain search and question answering (QA), we introduce a new dataset POIReviewQA. It consists of 20k questions (e.g."is this restaurant dog friendly?") for 1022 Yelp business types. For each question we sampled 10 reviews, and annotated each sentence in the reviews whether it answers the question and what the corresponding answer is. To test a system's ability to understand the text we adopt an information retrieval evaluation by ranking all the review sentences for a question based on the likelihood that they answer this question. We build a Lucene-based baseline model, which achieves 77.0% AUC and 48.8% MAP. A sentence embedding-based model achieves 79.2% AUC and 41.8% MAP, indicating that the dataset presents a challenging problem for future research by the GIR community. The result technology can help exploit the thematic content of web documents and social media for characterisation of locations.

</details>

<details>

<summary>2018-10-05 18:47:38 - TVM: An Automated End-to-End Optimizing Compiler for Deep Learning</summary>

- *Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, Arvind Krishnamurthy*

- `1802.04799v3` - [abs](http://arxiv.org/abs/1802.04799v3) - [pdf](http://arxiv.org/pdf/1802.04799v3)

> There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms -- such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) -- requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.

</details>

<details>

<summary>2018-10-05 19:54:58 - Artificial Intelligence Assisted Power Grid Hardening in Response to Extreme Weather Events</summary>

- *Rozhin Eskandarpour, Amin Khodaei, A. Paaso, N. M. Abdullah*

- `1810.02866v1` - [abs](http://arxiv.org/abs/1810.02866v1) - [pdf](http://arxiv.org/pdf/1810.02866v1)

> In this paper, an artificial intelligence based grid hardening model is proposed with the objective of improving power grid resilience in response to extreme weather events. At first, a machine learning model is proposed to predict the component states (either operational or outage) in response to the extreme event. Then, these predictions are fed into a hardening model, which determines strategic locations for placement of distributed generation (DG) units. In contrast to existing literature in hardening and resilience enhancement, this paper co-optimizes grid economic and resilience objectives by considering the intricate dependencies of the two. The numerical simulations on the standard IEEE 118-bus test system illustrate the merits and applicability of the proposed hardening model. The results indicate that the proposed hardening model through decentralized and distributed local energy resources can produce a more robust solution that can protect the system significantly against multiple component outages due to an extreme event.

</details>

<details>

<summary>2018-10-05 20:03:00 - A New Method for the Semantic Integration of Multiple OWL Ontologies using Alignments</summary>

- *Inès Osman*

- `1810.02869v1` - [abs](http://arxiv.org/abs/1810.02869v1) - [pdf](http://arxiv.org/pdf/1810.02869v1)

> This work is done as part of a master's thesis project. The goal is to integrate two or more ontologies (of the same or close domains) in a new consistent and coherent OWL ontology to insure semantic interoperability between them. To do this, we have chosen to create a bridge ontology that includes all source ontologies and their bridging axioms in a customized way. In addition, we introduced a new criterion for obtaining an ontology of better quality (having the minimum of semantic/logical conflicts). We have also proposed new terminology and definitions that clarify the unclear and misplaced "integration" and "merging" notions that are randomly used in state-of-the-art works. Finally, we tested and evaluated our OIA2R tool using ontologies and reference alignments of the OAEI campaign. It turned out that it is generic, efficient and powerful enough.

</details>

<details>

<summary>2018-10-05 21:50:26 - Neural Generation of Diverse Questions using Answer Focus, Contextual and Linguistic Features</summary>

- *Vrindavan Harrison, Marilyn Walker*

- `1809.02637v2` - [abs](http://arxiv.org/abs/1809.02637v2) - [pdf](http://arxiv.org/pdf/1809.02637v2)

> Question Generation is the task of automatically creating questions from textual input. In this work we present a new Attentional Encoder--Decoder Recurrent Neural Network model for automatic question generation. Our model incorporates linguistic features and an additional sentence embedding to capture meaning at both sentence and word levels. The linguistic features are designed to capture information related to named entity recognition, word case, and entity coreference resolution. In addition our model uses a copying mechanism and a special answer signal that enables generation of numerous diverse questions on a given sentence. Our model achieves state of the art results of 19.98 Bleu_4 on a benchmark Question Generation dataset, outperforming all previously published results by a significant margin. A human evaluation also shows that these added features improve the quality of the generated questions.

</details>

<details>

<summary>2018-10-05 22:21:28 - Design and Evaluation of A Data Partitioning-Based Intrusion Management Architecture for Database Systems</summary>

- *Muhamad Felemban, Yahya Javeed, Jason Kobes, Thamir Qadah, Arif Ghafoor, Walid Aref*

- `1810.02061v2` - [abs](http://arxiv.org/abs/1810.02061v2) - [pdf](http://arxiv.org/pdf/1810.02061v2)

> Data-intensive applications exhibit increasing reliance on Database Management Systems (DBMSs, for short). With the growing cyber-security threats to government and commercial infrastructures, the need to develop high resilient cyber systems is becoming increasingly important. Cyber-attacks on DBMSs include intrusion attacks that may result in severe degradation in performance. Several efforts have been directed towards designing an integrated management system to detect, respond, and recover from malicious attacks. In this paper, we propose a data Partitioning-based Intrusion Management System (PIMS, for short) that can endure intense malicious intrusion attacks on DBMS. The novelty in PIMS is the ability to contain the damage into data partitions, termed Intrusion Boundaries (IBs, for short). The IB Demarcation Problem (IBDP, for short) is formulated as a mixed integer nonlinear programming. We prove that IBDP is NP-hard. Accordingly, two heuristic solutions for IBDP are introduced. The proposed architecture for PIMS includes novel IB-centric response and recovery mechanisms, which executes compensating transactions. PIMS is prototyped within PostgreSQL, an open-source DBMS. Finally, empirical and experimental performance evaluation of PIMS are conducted to demonstrate that intelligent partitioning of data tuples improves the overall availability of the DBMS under intrusion attacks.

</details>

<details>

<summary>2018-10-06 05:25:24 - Co-Stack Residual Affinity Networks with Multi-level Attention Refinement for Matching Text Sequences</summary>

- *Yi Tay, Luu Anh Tuan, Siu Cheung Hui*

- `1810.02938v1` - [abs](http://arxiv.org/abs/1810.02938v1) - [pdf](http://arxiv.org/pdf/1810.02938v1)

> Learning a matching function between two text sequences is a long standing problem in NLP research. This task enables many potential applications such as question answering and paraphrase identification. This paper proposes Co-Stack Residual Affinity Networks (CSRAN), a new and universal neural architecture for this problem. CSRAN is a deep architecture, involving stacked (multi-layered) recurrent encoders. Stacked/Deep architectures are traditionally difficult to train, due to the inherent weaknesses such as difficulty with feature propagation and vanishing gradients. CSRAN incorporates two novel components to take advantage of the stacked architecture. Firstly, it introduces a new bidirectional alignment mechanism that learns affinity weights by fusing sequence pairs across stacked hierarchies. Secondly, it leverages a multi-level attention refinement component between stacked recurrent layers. The key intuition is that, by leveraging information across all network hierarchies, we can not only improve gradient flow but also improve overall performance. We conduct extensive experiments on six well-studied text sequence matching datasets, achieving state-of-the-art performance on all.

</details>

<details>

<summary>2018-10-06 13:25:54 - When logic lays down the law</summary>

- *Bjørn Jespersen, Ana de Almeida Borges, Jorge del Castillo Tierz, Juan José Conejero Rodríguez, Eric Sancho Adamson, Aleix Solé Sánchez, Nika Pona, Joost J. Joosten*

- `1810.03002v1` - [abs](http://arxiv.org/abs/1810.03002v1) - [pdf](http://arxiv.org/pdf/1810.03002v1)

> We analyse so-called computable laws, i.e., laws that can be enforced by automatic procedures. These laws should be logically perfect and unambiguous, but sometimes they are not. We use a regulation on road transport to illustrate this issue, and show what some fragments of this regulation would look like if rewritten in the image of logic. We further propose desiderata to be fulfilled by computable laws, and provide a critical platform from which to assess existing laws and a guideline for composing future ones.

</details>

<details>

<summary>2018-10-06 15:08:20 - Convolutional Generative Adversarial Networks with Binary Neurons for Polyphonic Music Generation</summary>

- *Hao-Wen Dong, Yi-Hsuan Yang*

- `1804.09399v3` - [abs](http://arxiv.org/abs/1804.09399v3) - [pdf](http://arxiv.org/pdf/1804.09399v3)

> It has been shown recently that deep convolutional generative adversarial networks (GANs) can learn to generate music in the form of piano-rolls, which represent music by binary-valued time-pitch matrices. However, existing models can only generate real-valued piano-rolls and require further post-processing, such as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final binary-valued results. In this paper, we study whether we can have a convolutional GAN model that directly creates binary-valued piano-rolls by using binary neurons. Specifically, we propose to append to the generator an additional refiner network, which uses binary neurons at the output layer. The whole network is trained in two stages. Firstly, the generator and the discriminator are pretrained. Then, the refiner network is trained along with the discriminator to learn to binarize the real-valued piano-rolls the pretrained generator creates. Experimental results show that using binary neurons instead of HT or BS indeed leads to better results in a number of objective measures. Moreover, deterministic binary neurons perform better than stochastic ones in both objective measures and a subjective test. The source code, training data and audio examples of the generated results can be found at https://salu133445.github.io/bmusegan/ .

</details>

<details>

<summary>2018-10-06 17:08:47 - Discretizing Logged Interaction Data Biases Learning for Decision-Making</summary>

- *Peter Schulam, Suchi Saria*

- `1810.03025v1` - [abs](http://arxiv.org/abs/1810.03025v1) - [pdf](http://arxiv.org/pdf/1810.03025v1)

> Time series data that are not measured at regular intervals are commonly discretized as a preprocessing step. For example, data about customer arrival times might be simplified by summing the number of arrivals within hourly intervals, which produces a discrete-time time series that is easier to model. In this abstract, we show that discretization introduces a bias that affects models trained for decision-making. We refer to this phenomenon as discretization bias, and show that we can avoid it by using continuous-time models instead.

</details>

<details>

<summary>2018-10-06 17:24:11 - Solving the clustered traveling salesman problem with d-relaxed priority rule</summary>

- *Hoa Nguyen Phuong, Huyen Tran Ngoc Nhat, Minh Hoàng Hà, André Langevin, Martin Trépanier*

- `1810.03981v1` - [abs](http://arxiv.org/abs/1810.03981v1) - [pdf](http://arxiv.org/pdf/1810.03981v1)

> The Clustered Traveling Salesman Problem with a Prespecified Order on the Clusters, a variant of the well-known traveling salesman problem is studied in literature. In this problem, delivery locations are divided into clusters with different urgency levels and more urgent locations must be visited before less urgent ones. However, this could lead to an inefficient route in terms of traveling cost. This priority-oriented constraint can be relaxed by a rule called d-relaxed priority that provides a trade-off between transportation cost and emergency level. Our research proposes two approaches to solve the problem with d-relaxed priority rule. We improve the mathematical formulation proposed in the literature to construct an exact solution method. A meta-heuristic method based on the framework of Iterated Local Search with problem-tailored operators is also introduced to find approximate solutions. Experimental results show the effectiveness of our methods.

</details>

<details>

<summary>2018-10-06 17:29:28 - OpenTag: Open Attribute Value Extraction from Product Profiles [Deep Learning, Active Learning, Named Entity Recognition]</summary>

- *Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, Feifei Li*

- `1806.01264v2` - [abs](http://arxiv.org/abs/1806.01264v2) - [pdf](http://arxiv.org/pdf/1806.01264v2)

> Extraction of missing attribute values is to find values describing an attribute of interest from a free text input. Most past related work on extraction of missing attribute values work with a closed world assumption with the possible set of values known beforehand, or use dictionaries of values and hand-crafted features. How can we discover new attribute values that we have never seen before? Can we do this with limited human annotation or supervision? We study this problem in the context of product catalogs that often have missing values for many attributes of interest.   In this work, we leverage product profile information such as titles and descriptions to discover missing values of product attributes. We develop a novel deep tagging model OpenTag for this extraction problem with the following contributions: (1) we formalize the problem as a sequence tagging task, and propose a joint model exploiting recurrent neural networks (specifically, bidirectional LSTM) to capture context and semantics, and Conditional Random Fields (CRF) to enforce tagging consistency, (2) we develop a novel attention mechanism to provide interpretable explanation for our model's decisions, (3) we propose a novel sampling strategy exploring active learning to reduce the burden of human annotation. OpenTag does not use any dictionary or hand-crafted features as in prior works. Extensive experiments in real-life datasets in different domains show that OpenTag with our active learning strategy discovers new attribute values from as few as 150 annotated samples (reduction in 3.3x amount of annotation effort) with a high F-score of 83%, outperforming state-of-the-art models.

</details>

<details>

<summary>2018-10-06 17:42:19 - Text-based Sentiment Analysis and Music Emotion Recognition</summary>

- *Erion Çano*

- `1810.03031v1` - [abs](http://arxiv.org/abs/1810.03031v1) - [pdf](http://arxiv.org/pdf/1810.03031v1)

> Sentiment polarity of tweets, blog posts or product reviews has become highly attractive and is utilized in recommender systems, market predictions, business intelligence and more. Deep learning techniques are becoming top performers on analyzing such texts. There are however several problems that need to be solved for efficient use of deep neural networks on text mining and text polarity analysis. First, deep neural networks need to be fed with data sets that are big in size as well as properly labeled. Second, there are various uncertainties regarding the use of word embedding vectors: should they be generated from the same data set that is used to train the model or it is better to source them from big and popular collections? Third, to simplify model creation it is convenient to have generic neural network architectures that are effective and can adapt to various texts, encapsulating much of design complexity. This thesis addresses the above problems to provide methodological and practical insights for utilizing neural networks on sentiment analysis of texts and achieving state of the art results. Regarding the first problem, the effectiveness of various crowdsourcing alternatives is explored and two medium-sized and emotion-labeled song data sets are created utilizing social tags. To address the second problem, a series of experiments with large text collections of various contents and domains were conducted, trying word embeddings of various parameters. Regarding the third problem, a series of experiments involving convolution and max-pooling neural layers were conducted. Combining convolutions of words, bigrams, and trigrams with regional max-pooling layers in a couple of stacks produced the best results. The derived architecture achieves competitive performance on sentiment polarity analysis of movie, business and product reviews.

</details>

<details>

<summary>2018-10-06 19:51:46 - Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning</summary>

- *Frederik Ebert, Sudeep Dasari, Alex X. Lee, Sergey Levine, Chelsea Finn*

- `1810.03043v1` - [abs](http://arxiv.org/abs/1810.03043v1) - [pdf](http://arxiv.org/pdf/1810.03043v1)

> Prediction is an appealing objective for self-supervised learning of behavioral skills, particularly for autonomous robots. However, effectively utilizing predictive models for control, especially with raw image inputs, poses a number of major challenges. How should the predictions be used? What happens when they are inaccurate? In this paper, we tackle these questions by proposing a method for learning robotic skills from raw image observations, using only autonomously collected experience. We show that even an imperfect model can complete complex tasks if it can continuously retry, but this requires the model to not lose track of the objective (e.g., the object of interest). To enable a robot to continuously retry a task, we devise a self-supervised algorithm for learning image registration, which can keep track of objects of interest for the duration of the trial. We demonstrate that this idea can be combined with a video-prediction based controller to enable complex behaviors to be learned from scratch using only raw visual inputs, including grasping, repositioning objects, and non-prehensile manipulation. Our real-world experiments demonstrate that a model trained with 160 robot hours of autonomously collected, unlabeled data is able to successfully perform complex manipulation tasks with a wide range of objects not seen during training.

</details>

<details>

<summary>2018-10-07 00:16:43 - Solving Large Sequential Games with the Excessive Gap Technique</summary>

- *Christian Kroer, Gabriele Farina, Tuomas Sandholm*

- `1810.03063v1` - [abs](http://arxiv.org/abs/1810.03063v1) - [pdf](http://arxiv.org/pdf/1810.03063v1)

> There has been tremendous recent progress on equilibrium-finding algorithms for zero-sum imperfect-information extensive-form games, but there has been a puzzling gap between theory and practice. First-order methods have significantly better theoretical convergence rates than any counterfactual-regret minimization (CFR) variant. Despite this, CFR variants have been favored in practice. Experiments with first-order methods have only been conducted on small- and medium-sized games because those methods are complicated to implement in this setting, and because CFR variants have been enhanced extensively for over a decade they perform well in practice. In this paper we show that a particular first-order method, a state-of-the-art variant of the excessive gap technique---instantiated with the dilated entropy distance function---can efficiently solve large real-world problems competitively with CFR and its variants. We show this on large endgames encountered by the Libratus poker AI, which recently beat top human poker specialist professionals at no-limit Texas hold'em. We show experimental results on our variant of the excessive gap technique as well as a prior version. We introduce a numerically friendly implementation of the smoothed best response computation associated with first-order methods for extensive-form game solving. We present, to our knowledge, the first GPU implementation of a first-order method for extensive-form games. We present comparisons of several excessive gap technique and CFR variants.

</details>

<details>

<summary>2018-10-07 01:54:50 - Spatio-temporal Edge Service Placement: A Bandit Learning Approach</summary>

- *Lixing Chen, Jie Xu, Shaolei Ren, Pan Zhou*

- `1810.03069v1` - [abs](http://arxiv.org/abs/1810.03069v1) - [pdf](http://arxiv.org/pdf/1810.03069v1)

> Shared edge computing platforms deployed at the radio access network are expected to significantly improve quality of service delivered by Application Service Providers (ASPs) in a flexible and economic way. However, placing edge service in every possible edge site by an ASP is practically infeasible due to the ASP's prohibitive budget requirement. In this paper, we investigate the edge service placement problem of an ASP under a limited budget, where the ASP dynamically rents computing/storage resources in edge sites to host its applications in close proximity to end users. Since the benefit of placing edge service in a specific site is usually unknown to the ASP a priori, optimal placement decisions must be made while learning this benefit. We pose this problem as a novel combinatorial contextual bandit learning problem. It is "combinatorial" because only a limited number of edge sites can be rented to provide the edge service given the ASP's budget. It is "contextual" because we utilize user context information to enable finer-grained learning and decision making. To solve this problem and optimize the edge computing performance, we propose SEEN, a Spatial-temporal Edge sErvice placemeNt algorithm. Furthermore, SEEN is extended to scenarios with overlapping service coverage by incorporating a disjunctively constrained knapsack problem. In both cases, we prove that our algorithm achieves a sublinear regret bound when it is compared to an oracle algorithm that knows the exact benefit information. Simulations are carried out on a real-world dataset, whose results show that SEEN significantly outperforms benchmark solutions.

</details>

<details>

<summary>2018-10-07 03:31:10 - Graphlet Count Estimation via Convolutional Neural Networks</summary>

- *Xutong Liu, Yu-Zhen Janice Chen, John C. S. Lui, Konstantin Avrachenkov*

- `1810.03078v1` - [abs](http://arxiv.org/abs/1810.03078v1) - [pdf](http://arxiv.org/pdf/1810.03078v1)

> Graphlets are defined as k-node connected induced subgraph patterns. For an undirected graph, 3-node graphlets include close triangle and open triangle. When k = 4, there are six types of graphlets, e.g., tailed-triangle and clique are two possible 4-node graphlets. The number of each graphlet, called graphlet count, is a signature which characterizes the local network structure of a given graph. Graphlet count plays a prominent role in network analysis of many fields, most notably bioinformatics and social science.   However, computing exact graphlet count is inherently difficult and computational expensive because the number of graphlets grows exponentially large as the graph size and/or graphlet size k grow. To deal with this difficulty, many sampling methods were proposed to estimate graphlet count with bounded error. Nevertheless, these methods require large number of samples to be statistically reliable, which is still computationally demanding. Moreover, they have to repeat laborious counting procedure even if a new graph is similar or exactly the same as previous studied graphs.   Intuitively, learning from historic graphs can make estimation more accurate and avoid many repetitive counting to reduce computational cost. Based on this idea, we propose a convolutional neural network (CNN) framework and two preprocessing techniques to estimate graphlet count. Extensive experiments on two types of random graphs and real world biochemistry graphs show that our framework can offer substantial speedup on estimating graphlet count of new graphs with high accuracy.

</details>

<details>

<summary>2018-10-07 05:53:06 - An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification</summary>

- *Ahmed Imtiaz Humayun, Md. Tauhiduzzaman Khan, Shabnam Ghaffarzadegan, Zhe Feng, Taufiq Hasan*

- `1806.06506v2` - [abs](http://arxiv.org/abs/1806.06506v2) - [pdf](http://arxiv.org/pdf/1806.06506v2)

> In this work, we propose an ensemble of classifiers to distinguish between various degrees of abnormalities of the heart using Phonocardiogram (PCG) signals acquired using digital stethoscopes in a clinical setting, for the INTERSPEECH 2018 Computational Paralinguistics (ComParE) Heart Beats SubChallenge. Our primary classification framework constitutes a convolutional neural network with 1D-CNN time-convolution (tConv) layers, which uses features transferred from a model trained on the 2016 Physionet Heart Sound Database. We also employ a Representation Learning (RL) approach to generate features in an unsupervised manner using Deep Recurrent Autoencoders and use Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) classifiers. Finally, we utilize an SVM classifier on a high-dimensional segment-level feature extracted using various functionals on short-term acoustic features, i.e., Low-Level Descriptors (LLD). An ensemble of the three different approaches provides a relative improvement of 11.13% compared to our best single sub-system in terms of the Unweighted Average Recall (UAR) performance metric on the evaluation dataset.

</details>

<details>

<summary>2018-10-07 08:21:09 - Polar Feature Based Deep Architectures for Automatic Modulation Classification Considering Channel Fading</summary>

- *Chieh-Fang Teng, Ching-Chun Liao, Chun-Hsiang Chen, An-Yeu Wu*

- `1810.02027v2` - [abs](http://arxiv.org/abs/1810.02027v2) - [pdf](http://arxiv.org/pdf/1810.02027v2)

> To develop intelligent receivers, automatic modulation classification (AMC) plays an important role for better spectrum utilization. The emerging deep learning (DL) technique has received much attention in AMC due to its superior performance in classifying data with deep structure. In this work, a novel polar-based deep learning architecture with channel compensation network (CCN) is proposed. Our test results show that learning features from polar domain (r-theta) can improve recognition accuracy by 5% and reduce training overhead by 48%. Besides, the proposed CCN is also robust to channel fading, such as amplitude and phase offsets, and can improve the recognition accuracy by 14% under practical channel environments.

</details>

<details>

<summary>2018-10-07 13:57:25 - Real-Time Workload Classification during Driving using HyperNetworks</summary>

- *Ruohan Wang, Pierluigi V. Amadori, Yiannis Demiris*

- `1810.03145v1` - [abs](http://arxiv.org/abs/1810.03145v1) - [pdf](http://arxiv.org/pdf/1810.03145v1)

> Classifying human cognitive states from behavioral and physiological signals is a challenging problem with important applications in robotics. The problem is challenging due to the data variability among individual users, and sensor artefacts. In this work, we propose an end-to-end framework for real-time cognitive workload classification with mixture Hyper Long Short Term Memory Networks, a novel variant of HyperNetworks. Evaluating the proposed approach on an eye-gaze pattern dataset collected from simulated driving scenarios of different cognitive demands, we show that the proposed framework outperforms previous baseline methods and achieves 83.9\% precision and 87.8\% recall during test. We also demonstrate the merit of our proposed architecture by showing improved performance over other LSTM-based methods.

</details>

<details>

<summary>2018-10-07 14:26:11 - A Minesweeper Solver Using Logic Inference, CSP and Sampling</summary>

- *Yimin Tang, Tian Jiang, Yanpeng Hu*

- `1810.03151v1` - [abs](http://arxiv.org/abs/1810.03151v1) - [pdf](http://arxiv.org/pdf/1810.03151v1)

> Minesweeper as a puzzle video game and is proved that it is an NPC problem. We use CSP, Logic Inference and Sampling to make a minesweeper solver and we limit us each select in 5 seconds.

</details>

<details>

<summary>2018-10-07 16:13:02 - NEXUS Network: Connecting the Preceding and the Following in Dialogue Generation</summary>

- *Hui Su, Xiaoyu Shen, Wenjie Li, Dietrich Klakow*

- `1810.00671v2` - [abs](http://arxiv.org/abs/1810.00671v2) - [pdf](http://arxiv.org/pdf/1810.00671v2)

> Sequence-to-Sequence (seq2seq) models have become overwhelmingly popular in building end-to-end trainable dialogue systems. Though highly efficient in learning the backbone of human-computer communications, they suffer from the problem of strongly favoring short generic responses. In this paper, we argue that a good response should smoothly connect both the preceding dialogue history and the following conversations. We strengthen this connection through mutual information maximization. To sidestep the non-differentiability of discrete natural language tokens, we introduce an auxiliary continuous code space and map such code space to a learnable prior distribution for generation purpose. Experiments on two dialogue datasets validate the effectiveness of our model, where the generated responses are closely related to the dialogue context and lead to more interactive conversations.

</details>

<details>

<summary>2018-10-07 21:24:19 - Understanding and Improving Recurrent Networks for Human Activity Recognition by Continuous Attention</summary>

- *Ming Zeng, Haoxiang Gao, Tong Yu, Ole J. Mengshoel, Helge Langseth, Ian Lane, Xiaobing Liu*

- `1810.04038v1` - [abs](http://arxiv.org/abs/1810.04038v1) - [pdf](http://arxiv.org/pdf/1810.04038v1)

> Deep neural networks, including recurrent networks, have been successfully applied to human activity recognition. Unfortunately, the final representation learned by recurrent networks might encode some noise (irrelevant signal components, unimportant sensor modalities, etc.). Besides, it is difficult to interpret the recurrent networks to gain insight into the models' behavior. To address these issues, we propose two attention models for human activity recognition: temporal attention and sensor attention. These two mechanisms adaptively focus on important signals and sensor modalities. To further improve the understandability and mean F1 score, we add continuity constraints, considering that continuous sensor signals are more robust than discrete ones. We evaluate the approaches on three datasets and obtain state-of-the-art results. Furthermore, qualitative analysis shows that the attention learned by the models agree well with human intuition.

</details>

<details>

<summary>2018-10-07 23:34:51 - Mugeetion: Musical Interface Using Facial Gesture and Emotion</summary>

- *Eunjeong Stella Koh, Shahrokh Yadegari*

- `1809.05502v2` - [abs](http://arxiv.org/abs/1809.05502v2) - [pdf](http://arxiv.org/pdf/1809.05502v2)

> People feel emotions when listening to music. However, emotions are not tangible objects that can be exploited in the music composition process as they are difficult to capture and quantify in algorithms. We present a novel musical interface, Mugeetion, designed to capture occurring instances of emotional states from users' facial gestures and relay that data to associated musical features. Mugeetion can translate qualitative data of emotional states into quantitative data, which can be utilized in the sound generation process. We also presented and tested this work in the exhibition of sound installation, Hearing Seascape, using the audiences' facial expressions. Audiences heard changes in the background sound based on their emotional state. The process contributes multiple research areas, such as gesture tracking systems, emotion-sound modeling, and the connection between sound and facial gesture.

</details>

<details>

<summary>2018-10-08 00:57:24 - Task-Embedded Control Networks for Few-Shot Imitation Learning</summary>

- *Stephen James, Michael Bloesch, Andrew J. Davison*

- `1810.03237v1` - [abs](http://arxiv.org/abs/1810.03237v1) - [pdf](http://arxiv.org/pdf/1810.03237v1)

> Much like humans, robots should have the ability to leverage knowledge from previously learned tasks in order to learn new tasks quickly in new and unfamiliar environments. Despite this, most robot learning approaches have focused on learning a single task, from scratch, with a limited notion of generalisation, and no way of leveraging the knowledge to learn other tasks more efficiently. One possible solution is meta-learning, but many of the related approaches are limited in their ability to scale to a large number of tasks and to learn further tasks without forgetting previously learned ones. With this in mind, we introduce Task-Embedded Control Networks, which employ ideas from metric learning in order to create a task embedding that can be used by a robot to learn new tasks from one or more demonstrations. In the area of visually-guided manipulation, we present simulation results in which we surpass the performance of a state-of-the-art method when using only visual information from each demonstration. Additionally, we demonstrate that our approach can also be used in conjunction with domain randomisation to train our few-shot learning ability in simulation and then deploy in the real world without any additional training. Once deployed, the robot can learn new tasks from a single real-world demonstration.

</details>

<details>

<summary>2018-10-08 01:32:02 - Sim-to-Real Reinforcement Learning for Deformable Object Manipulation</summary>

- *Jan Matas, Stephen James, Andrew J. Davison*

- `1806.07851v2` - [abs](http://arxiv.org/abs/1806.07851v2) - [pdf](http://arxiv.org/pdf/1806.07851v2)

> We have seen much recent progress in rigid object manipulation, but interaction with deformable objects has notably lagged behind. Due to the large configuration space of deformable objects, solutions using traditional modelling approaches require significant engineering work. Perhaps then, bypassing the need for explicit modelling and instead learning the control in an end-to-end manner serves as a better approach? Despite the growing interest in the use of end-to-end robot learning approaches, only a small amount of work has focused on their applicability to deformable object manipulation. Moreover, due to the large amount of data needed to learn these end-to-end solutions, an emerging trend is to learn control policies in simulation and then transfer them over to the real world. To-date, no work has explored whether it is possible to learn and transfer deformable object policies. We believe that if sim-to-real methods are to be employed further, then it should be possible to learn to interact with a wide variety of objects, and not only rigid objects. In this work, we use a combination of state-of-the-art deep reinforcement learning algorithms to solve the problem of manipulating deformable objects (specifically cloth). We evaluate our approach on three tasks --- folding a towel up to a mark, folding a face towel diagonally, and draping a piece of cloth over a hanger. Our agents are fully trained in simulation with domain randomisation, and then successfully deployed in the real world without having seen any real deformable objects.

</details>

<details>

<summary>2018-10-08 01:57:55 - Building and Measuring Privacy-Preserving Predictive Blacklists</summary>

- *Luca Melis, Apostolos Pyrgelis, Emiliano De Cristofaro*

- `1512.04114v5` - [abs](http://arxiv.org/abs/1512.04114v5) - [pdf](http://arxiv.org/pdf/1512.04114v5)

> (Withdrawn) Collaborative security initiatives are increasingly often advocated to improve timeliness and effectiveness of threat mitigation. Among these, collaborative predictive blacklisting (CPB) aims to forecast attack sources based on alerts contributed by multiple organizations that might be targeted in similar ways. Alas, CPB proposals thus far have only focused on improving hit counts, but overlooked the impact of collaboration on false positives and false negatives. Moreover, sharing threat intelligence often prompts important privacy, confidentiality, and liability issues. In this paper, we first provide a comprehensive measurement analysis of two state-of-the-art CPB systems: one that uses a trusted central party to collect alerts [Soldo et al., Infocom'10] and a peer-to-peer one relying on controlled data sharing [Freudiger et al., DIMVA'15], studying the impact of collaboration on both correct and incorrect predictions. Then, we present a novel privacy-friendly approach that significantly improves over previous work, achieving a better balance of true and false positive rates, while minimizing information disclosure. Finally, we present an extension that allows our system to scale to very large numbers of organizations.

</details>

<details>

<summary>2018-10-08 04:13:39 - Person-Job Fit: Adapting the Right Talent for the Right Job with Joint Representation Learning</summary>

- *Chen Zhu, Hengshu Zhu, Hui Xiong, Chao Ma, Fang Xie, Pengliang Ding, Pan Li*

- `1810.04040v1` - [abs](http://arxiv.org/abs/1810.04040v1) - [pdf](http://arxiv.org/pdf/1810.04040v1)

> Person-Job Fit is the process of matching the right talent for the right job by identifying talent competencies that are required for the job. While many qualitative efforts have been made in related fields, it still lacks of quantitative ways of measuring talent competencies as well as the job's talent requirements. To this end, in this paper, we propose a novel end-to-end data-driven model based on Convolutional Neural Network (CNN), namely Person-Job Fit Neural Network (PJFNN), for matching a talent qualification to the requirements of a job. To be specific, PJFNN is a bipartite neural network which can effectively learn the joint representation of Person-Job fitness from historical job applications. In particular, due to the design of a hierarchical representation structure, PJFNN can not only estimate whether a candidate fits a job, but also identify which specific requirement items in the job posting are satisfied by the candidate by measuring the distances between corresponding latent representations. Finally, the extensive experiments on a large-scale real-world dataset clearly validate the performance of PJFNN in terms of Person-Job Fit prediction. Also, we provide effective data visualization to show some job and talent benchmark insights obtained by PJFNN.

</details>

<details>

<summary>2018-10-08 08:45:53 - IriTrack: Liveness Detection Using Irises Tracking for Preventing Face Spoofing Attacks</summary>

- *Meng Shen, Zelin Liao, Liehuang Zhu, Rashid Mijumbi, Xiaojiang Du, Jiankun Hu*

- `1810.03323v1` - [abs](http://arxiv.org/abs/1810.03323v1) - [pdf](http://arxiv.org/pdf/1810.03323v1)

> Face liveness detection has become a widely used technique with a growing importance in various authentication scenarios to withstand spoofing attacks. Existing methods that perform liveness detection generally focus on designing intelligent classifiers or customized hardware to differentiate between the image or video samples of a real legitimate user and the imitated ones. Although effective, they can be resource-consuming and detection results may be sensitive to environmental changes. In this paper, we take iris movement as a significant liveness sign and propose a simple and efficient liveness detection system named IriTrack. Users are required to move their eyes along with a randomly generated poly-line, and trajectories of irises are then used as evidences for liveness detection. IriTrack allows checking liveness by using data collected during user-device interactions. We implemented a prototype and conducted extensive experiments to evaluate the performance of the proposed system. The results show that IriTrack can fend against spoofing attacks with a moderate and adjustable time overhead.

</details>

<details>

<summary>2018-10-08 10:42:57 - Avoiding Echo-Responses in a Retrieval-Based Conversation System</summary>

- *Denis Fedorenko, Nikita Smetanin, Artem Rodichev*

- `1712.05626v2` - [abs](http://arxiv.org/abs/1712.05626v2) - [pdf](http://arxiv.org/pdf/1712.05626v2)

> Retrieval-based conversation systems generally tend to highly rank responses that are semantically similar or even identical to the given conversation context. While the system's goal is to find the most appropriate response, rather than the most semantically similar one, this tendency results in low-quality responses. We refer to this challenge as the echoing problem. To mitigate this problem, we utilize a hard negative mining approach at the training stage. The evaluation shows that the resulting model reduces echoing and achieves better results in terms of Average Precision and Recall@N metrics, compared to the models trained without the proposed approach.

</details>

<details>

<summary>2018-10-08 11:34:38 - Deep learning cardiac motion analysis for human survival prediction</summary>

- *Ghalib A. Bello, Timothy J. W. Dawes, Jinming Duan, Carlo Biffi, Antonio de Marvao, Luke S. G. E. Howard, J. Simon R. Gibbs, Martin R. Wilkins, Stuart A. Cook, Daniel Rueckert, Declan P. O'Regan*

- `1810.03382v1` - [abs](http://arxiv.org/abs/1810.03382v1) - [pdf](http://arxiv.org/pdf/1810.03382v1)

> Motion analysis is used in computer vision to understand the behaviour of moving objects in sequences of images. Optimising the interpretation of dynamic biological systems requires accurate and precise motion tracking as well as efficient representations of high-dimensional motion trajectories so that these can be used for prediction tasks. Here we use image sequences of the heart, acquired using cardiac magnetic resonance imaging, to create time-resolved three-dimensional segmentations using a fully convolutional network trained on anatomical shape priors. This dense motion model formed the input to a supervised denoising autoencoder (4Dsurvival), which is a hybrid network consisting of an autoencoder that learns a task-specific latent code representation trained on observed outcome data, yielding a latent representation optimised for survival prediction. To handle right-censored survival outcomes, our network used a Cox partial likelihood loss function. In a study of 302 patients the predictive accuracy (quantified by Harrell's C-index) was significantly higher (p < .0001) for our model C=0.73 (95$\%$ CI: 0.68 - 0.78) than the human benchmark of C=0.59 (95$\%$ CI: 0.53 - 0.65). This work demonstrates how a complex computer vision task using high-dimensional medical image data can efficiently predict human survival.

</details>

<details>

<summary>2018-10-08 12:12:42 - Hierarchical clustering that takes advantage of both density-peak and density-connectivity</summary>

- *Ye Zhu, Kai Ming Ting, Yuan Jin, Maia Angelova*

- `1810.03393v1` - [abs](http://arxiv.org/abs/1810.03393v1) - [pdf](http://arxiv.org/pdf/1810.03393v1)

> This paper focuses on density-based clustering, particularly the Density Peak (DP) algorithm and the one based on density-connectivity DBSCAN; and proposes a new method which takes advantage of the individual strengths of these two methods to yield a density-based hierarchical clustering algorithm. Our investigation begins with formally defining the types of clusters DP and DBSCAN are designed to detect; and then identifies the kinds of distributions that DP and DBSCAN individually fail to detect all clusters in a dataset. These identified weaknesses inspire us to formally define a new kind of clusters and propose a new method called DC-HDP to overcome these weaknesses to identify clusters with arbitrary shapes and varied densities. In addition, the new method produces a richer clustering result in terms of hierarchy or dendrogram for better cluster structures understanding. Our empirical evaluation results show that DC-HDP produces the best clustering results on 14 datasets in comparison with 7 state-of-the-art clustering algorithms.

</details>

<details>

<summary>2018-10-08 13:02:02 - A Unified Dynamic Approach to Sparse Model Selection</summary>

- *Chendi Huang, Yuan Yao*

- `1810.03608v1` - [abs](http://arxiv.org/abs/1810.03608v1) - [pdf](http://arxiv.org/pdf/1810.03608v1)

> Sparse model selection is ubiquitous from linear regression to graphical models where regularization paths, as a family of estimators upon the regularization parameter varying, are computed when the regularization parameter is unknown or decided data-adaptively. Traditional computational methods rely on solving a set of optimization problems where the regularization parameters are fixed on a grid that might be inefficient. In this paper, we introduce a simple iterative regularization path, which follows the dynamics of a sparse Mirror Descent algorithm or a generalization of Linearized Bregman Iterations with nonlinear loss. Its performance is competitive to \texttt{glmnet} with a further bias reduction. A path consistency theory is presented that under the Restricted Strong Convexity (RSC) and the Irrepresentable Condition (IRR), the path will first evolve in a subspace with no false positives and reach an estimator that is sign-consistent or of minimax optimal $\ell_2$ error rate. Early stopping regularization is required to prevent overfitting. Application examples are given in sparse logistic regression and Ising models for NIPS coauthorship.

</details>

<details>

<summary>2018-10-08 13:25:05 - Cross Script Hindi English NER Corpus from Wikipedia</summary>

- *Mohd Zeeshan Ansari, Tanvir Ahmad, Md Arshad Ali*

- `1810.03430v1` - [abs](http://arxiv.org/abs/1810.03430v1) - [pdf](http://arxiv.org/pdf/1810.03430v1)

> The text generated on social media platforms is essentially a mixed lingual text. The mixing of language in any form produces considerable amount of difficulty in language processing systems. Moreover, the advancements in language processing research depends upon the availability of standard corpora. The development of mixed lingual Indian Named Entity Recognition (NER) systems are facing obstacles due to unavailability of the standard evaluation corpora. Such corpora may be of mixed lingual nature in which text is written using multiple languages predominantly using a single script only. The motivation of our work is to emphasize the automatic generation such kind of corpora in order to encourage mixed lingual Indian NER. The paper presents the preparation of a Cross Script Hindi-English Corpora from Wikipedia category pages. The corpora is successfully annotated using standard CoNLL-2003 categories of PER, LOC, ORG, and MISC. Its evaluation is carried out on a variety of machine learning algorithms and favorable results are achieved.

</details>

<details>

<summary>2018-10-08 13:38:52 - Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards</summary>

- *Mel Vecerik, Todd Hester, Jonathan Scholz, Fumin Wang, Olivier Pietquin, Bilal Piot, Nicolas Heess, Thomas Rothörl, Thomas Lampe, Martin Riedmiller*

- `1707.08817v2` - [abs](http://arxiv.org/abs/1707.08817v2) - [pdf](http://arxiv.org/pdf/1707.08817v2)

> We propose a general and model-free approach for Reinforcement Learning (RL) on real robotics with sparse rewards. We build upon the Deep Deterministic Policy Gradient (DDPG) algorithm to use demonstrations. Both demonstrations and actual interactions are used to fill a replay buffer and the sampling ratio between demonstrations and transitions is automatically tuned via a prioritized replay mechanism. Typically, carefully engineered shaping rewards are required to enable the agents to efficiently explore on high dimensional control problems such as robotics. They are also required for model-based acceleration methods relying on local solvers such as iLQG (e.g. Guided Policy Search and Normalized Advantage Function). The demonstrations replace the need for carefully engineered rewards, and reduce the exploration problem encountered by classical RL approaches in these domains. Demonstrations are collected by a robot kinesthetically force-controlled by a human demonstrator. Results on four simulated insertion tasks show that DDPG from demonstrations out-performs DDPG, and does not require engineered rewards. Finally, we demonstrate the method on a real robotics task consisting of inserting a clip (flexible object) into a rigid object.

</details>

<details>

<summary>2018-10-08 15:35:07 - Effective Parallelisation for Machine Learning</summary>

- *Michael Kamp, Mario Boley, Olana Missura, Thomas Gärtner*

- `1810.03530v1` - [abs](http://arxiv.org/abs/1810.03530v1) - [pdf](http://arxiv.org/pdf/1810.03530v1)

> We present a novel parallelisation scheme that simplifies the adaptation of learning algorithms to growing amounts of data as well as growing needs for accurate and confident predictions in critical applications. In contrast to other parallelisation techniques, it can be applied to a broad class of learning algorithms without further mathematical derivations and without writing dedicated code, while at the same time maintaining theoretical performance guarantees. Moreover, our parallelisation scheme is able to reduce the runtime of many learning algorithms to polylogarithmic time on quasi-polynomially many processing units. This is a significant step towards a general answer to an open question on the efficient parallelisation of machine learning algorithms in the sense of Nick's Class (NC). The cost of this parallelisation is in the form of a larger sample complexity. Our empirical study confirms the potential of our parallelisation scheme with fixed numbers of processors and instances in realistic application scenarios.

</details>

<details>

<summary>2018-10-08 15:51:23 - Combinatorial Attacks on Binarized Neural Networks</summary>

- *Elias B. Khalil, Amrita Gupta, Bistra Dilkina*

- `1810.03538v1` - [abs](http://arxiv.org/abs/1810.03538v1) - [pdf](http://arxiv.org/pdf/1810.03538v1)

> Binarized Neural Networks (BNNs) have recently attracted significant interest due to their computational efficiency. Concurrently, it has been shown that neural networks may be overly sensitive to "attacks" - tiny adversarial changes in the input - which may be detrimental to their use in safety-critical domains. Designing attack algorithms that effectively fool trained models is a key step towards learning robust neural networks. The discrete, non-differentiable nature of BNNs, which distinguishes them from their full-precision counterparts, poses a challenge to gradient-based attacks. In this work, we study the problem of attacking a BNN through the lens of combinatorial and integer optimization. We propose a Mixed Integer Linear Programming (MILP) formulation of the problem. While exact and flexible, the MILP quickly becomes intractable as the network and perturbation space grow. To address this issue, we propose IProp, a decomposition-based algorithm that solves a sequence of much smaller MILP problems. Experimentally, we evaluate both proposed methods against the standard gradient-based attack (FGSM) on MNIST and Fashion-MNIST, and show that IProp performs favorably compared to FGSM, while scaling beyond the limits of the MILP.

</details>

<details>

<summary>2018-10-08 16:35:06 - The 30-Year Cycle In The AI Debate</summary>

- *Jean-Marie Chauvet*

- `1810.04053v1` - [abs](http://arxiv.org/abs/1810.04053v1) - [pdf](http://arxiv.org/pdf/1810.04053v1)

> In the last couple of years, the rise of Artificial Intelligence and the successes of academic breakthroughs in the field have been inescapable. Vast sums of money have been thrown at AI start-ups. Many existing tech companies -- including the giants like Google, Amazon, Facebook, and Microsoft -- have opened new research labs. The rapid changes in these everyday work and entertainment tools have fueled a rising interest in the underlying technology itself; journalists write about AI tirelessly, and companies -- of tech nature or not -- brand themselves with AI, Machine Learning or Deep Learning whenever they get a chance. Confronting squarely this media coverage, several analysts are starting to voice concerns about over-interpretation of AI's blazing successes and the sometimes poor public reporting on the topic. This paper reviews briefly the track-record in AI and Machine Learning and finds this pattern of early dramatic successes, followed by philosophical critique and unexpected difficulties, if not downright stagnation, returning almost to the clock in 30-year cycles since 1958.

</details>

<details>

<summary>2018-10-08 16:42:59 - SALSA-TEXT : self attentive latent space based adversarial text generation</summary>

- *Jules Gagnon-Marchand, Hamed Sadeghi, Md. Akmal Haidar, Mehdi Rezagholizadeh*

- `1809.11155v2` - [abs](http://arxiv.org/abs/1809.11155v2) - [pdf](http://arxiv.org/pdf/1809.11155v2)

> Inspired by the success of self attention mechanism and Transformer architecture in sequence transduction and image generation applications, we propose novel self attention-based architectures to improve the performance of adversarial latent code- based schemes in text generation. Adversarial latent code-based text generation has recently gained a lot of attention due to their promising results. In this paper, we take a step to fortify the architectures used in these setups, specifically AAE and ARAE. We benchmark two latent code-based methods (AAE and ARAE) designed based on adversarial setups. In our experiments, the Google sentence compression dataset is utilized to compare our method with these methods using various objective and subjective measures. The experiments demonstrate the proposed (self) attention-based models outperform the state-of-the-art in adversarial code-based text generation.

</details>

<details>

<summary>2018-10-08 16:44:32 - Multi-Source Pointer Network for Product Title Summarization</summary>

- *Fei Sun, Peng Jiang, Hanxiao Sun, Changhua Pei, Wenwu Ou, Xiaobo Wang*

- `1808.06885v3` - [abs](http://arxiv.org/abs/1808.06885v3) - [pdf](http://arxiv.org/pdf/1808.06885v3)

> In this paper, we study the product title summarization problem in E-commerce applications for display on mobile devices. Comparing with conventional sentence summarization, product title summarization has some extra and essential constraints. For example, factual errors or loss of the key information are intolerable for E-commerce applications. Therefore, we abstract two more constraints for product title summarization: (i) do not introduce irrelevant information; (ii) retain the key information (e.g., brand name and commodity name). To address these issues, we propose a novel multi-source pointer network by adding a new knowledge encoder for pointer network. The first constraint is handled by pointer mechanism. For the second constraint, we restore the key information by copying words from the knowledge encoder with the help of the soft gating mechanism. For evaluation, we build a large collection of real-world product titles along with human-written short titles. Experimental results demonstrate that our model significantly outperforms the other baselines. Finally, online deployment of our proposed model has yielded a significant business impact, as measured by the click-through rate.

</details>

<details>

<summary>2018-10-08 17:02:49 - Iterative Bayesian Learning for Crowdsourced Regression</summary>

- *Jungseul Ok, Sewoong Oh, Yunhun Jang, Jinwoo Shin, Yung Yi*

- `1702.08840v3` - [abs](http://arxiv.org/abs/1702.08840v3) - [pdf](http://arxiv.org/pdf/1702.08840v3)

> Crowdsourcing platforms emerged as popular venues for purchasing human intelligence at low cost for large volume of tasks. As many low-paid workers are prone to give noisy answers, a common practice is to add redundancy by assigning multiple workers to each task and then simply average out these answers. However, to fully harness the wisdom of the crowd, one needs to learn the heterogeneous quality of each worker. We resolve this fundamental challenge in crowdsourced regression tasks, i.e., the answer takes continuous labels, where identifying good or bad workers becomes much more non-trivial compared to a classification setting of discrete labels. In particular, we introduce a Bayesian iterative scheme and show that it provably achieves the optimal mean squared error. Our evaluations on synthetic and real-world datasets support our theoretical results and show the superiority of the proposed scheme.

</details>

<details>

<summary>2018-10-08 17:14:58 - Towards Robot-Centric Conceptual Knowledge Acquisition</summary>

- *Georg Jäger, Christian A. Mueller, Madhura Thosar, Sebastian Zug, Andreas Birk*

- `1810.03583v1` - [abs](http://arxiv.org/abs/1810.03583v1) - [pdf](http://arxiv.org/pdf/1810.03583v1)

> Robots require knowledge about objects in order to efficiently perform various household tasks involving objects. The existing knowledge bases for robots acquire symbolic knowledge about objects from manually-coded external common sense knowledge bases such as ConceptNet, Word-Net etc. The problem with such approaches is the discrepancy between human-centric symbolic knowledge and robot-centric object perception due to its limited perception capabilities. Ultimately, significant portion of knowledge in the knowledge base remains ungrounded into robot's perception. To overcome this discrepancy, we propose an approach to enable robots to generate robot-centric symbolic knowledge about objects from their own sensory data, thus, allowing them to assemble their own conceptual understanding of objects. With this goal in mind, the presented paper elaborates on the work-in-progress of the proposed approach followed by the preliminary results.

</details>

<details>

<summary>2018-10-08 19:45:10 - Efficient Hierarchical Robot Motion Planning Under Uncertainty and Hybrid Dynamics</summary>

- *Ajinkya Jain, Scott Niekum*

- `1802.04205v4` - [abs](http://arxiv.org/abs/1802.04205v4) - [pdf](http://arxiv.org/pdf/1802.04205v4)

> Noisy observations coupled with nonlinear dynamics pose one of the biggest challenges in robot motion planning. By decomposing nonlinear dynamics into a discrete set of local dynamics models, hybrid dynamics provide a natural way to model nonlinear dynamics, especially in systems with sudden discontinuities in dynamics due to factors such as contacts. We propose a hierarchical POMDP planner that develops cost-optimized motion plans for hybrid dynamics models. The hierarchical planner first develops a high-level motion plan to sequence the local dynamics models to be visited and then converts it into a detailed continuous state plan. This hierarchical planning approach results in a decomposition of the POMDP planning problem into smaller sub-parts that can be solved with significantly lower computational costs. The ability to sequence the visitation of local dynamics models also provides a powerful way to leverage the hybrid dynamics to reduce state uncertainty. We evaluate the proposed planner on a navigation task in the simulated domain and on an assembly task with a robotic manipulator, showing that our approach can solve tasks having high observation noise and nonlinear dynamics effectively with significantly lower computational costs compared to direct planning approaches.

</details>

<details>

<summary>2018-10-09 02:03:13 - Wide and Deep Learning for Peer-to-Peer Lending</summary>

- *Kaveh Bastani, Elham Asgari, Hamed Namavari*

- `1810.03466v2` - [abs](http://arxiv.org/abs/1810.03466v2) - [pdf](http://arxiv.org/pdf/1810.03466v2)

> This paper proposes a two-stage scoring approach to help lenders decide their fund allocations in the peer-to-peer (P2P) lending market. The existing scoring approaches focus on only either probability of default (PD) prediction, known as credit scoring, or profitability prediction, known as profit scoring, to identify the best loans for investment. Credit scoring fails to deliver the main need of lenders on how much profit they may obtain through their investment. On the other hand, profit scoring can satisfy that need by predicting the investment profitability. However, profit scoring completely ignores the class imbalance problem where most of the past loans are non-default. Consequently, ignorance of the class imbalance problem significantly affects the accuracy of profitability prediction. Our proposed two-stage scoring approach is an integration of credit scoring and profit scoring to address the above challenges. More specifically, stage 1 is designed as credit scoring to identify non-default loans while the imbalanced nature of loan status is considered in PD prediction. The loans identified as non-default are then moved to stage 2 for prediction of profitability, measured by internal rate of return. Wide and deep learning is used to build the predictive models in both stages to achieve both memorization and generalization. Extensive numerical studies are conducted based on real-world data to verify the effectiveness of the proposed approach. The numerical studies indicate our two-stage scoring approach outperforms the existing credit scoring and profit scoring approaches.

</details>

<details>

<summary>2018-10-09 02:04:07 - Bottom-Up Abstractive Summarization</summary>

- *Sebastian Gehrmann, Yuntian Deng, Alexander M. Rush*

- `1808.10792v2` - [abs](http://arxiv.org/abs/1808.10792v2) - [pdf](http://arxiv.org/pdf/1808.10792v2)

> Neural network-based methods for abstractive summarization produce outputs that are more fluent than other techniques, but which can be poor at content selection. This work proposes a simple technique for addressing this issue: use a data-efficient content selector to over-determine phrases in a source document that should be part of the summary. We use this selector as a bottom-up attention step to constrain the model to likely phrases. We show that this approach improves the ability to compress text, while still generating fluent summaries. This two-step process is both simpler and higher performing than other end-to-end content selection models, leading to significant improvements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the content selector can be trained with as little as 1,000 sentences, making it easy to transfer a trained summarizer to a new domain.

</details>

<details>

<summary>2018-10-09 03:34:18 - Weight Learning in a Probabilistic Extension of Answer Set Programs</summary>

- *Joohyung Lee, Yi Wang*

- `1808.04527v2` - [abs](http://arxiv.org/abs/1808.04527v2) - [pdf](http://arxiv.org/pdf/1808.04527v2)

> LPMLN is a probabilistic extension of answer set programs with the weight scheme derived from that of Markov Logic. Previous work has shown how inference in LPMLN can be achieved. In this paper, we present the concept of weight learning in LPMLN and learning algorithms for LPMLN derived from those for Markov Logic. We also present a prototype implementation that uses answer set solvers for learning as well as some example domains that illustrate distinct features of LPMLN learning. Learning in LPMLN is in accordance with the stable model semantics, thereby it learns parameters for probabilistic extensions of knowledge-rich domains where answer set programming has shown to be useful but limited to the deterministic case, such as reachability analysis and reasoning about actions in dynamic domains. We also apply the method to learn the parameters for probabilistic abductive reasoning about actions.

</details>

<details>

<summary>2018-10-09 03:43:04 - Investigating Enactive Learning for Autonomous Intelligent Agents</summary>

- *Rafik Hadfi*

- `1810.04535v1` - [abs](http://arxiv.org/abs/1810.04535v1) - [pdf](http://arxiv.org/pdf/1810.04535v1)

> The enactive approach to cognition is typically proposed as a viable alternative to traditional cognitive science. Enactive cognition displaces the explanatory focus from the internal representations of the agent to the direct sensorimotor interaction with its environment. In this paper, we investigate enactive learning through means of artificial agent simulations. We compare the performances of the enactive agent to an agent operating on classical reinforcement learning in foraging tasks within maze environments. The characteristics of the agents are analysed in terms of the accessibility of the environmental states, goals, and exploration/exploitation tradeoffs. We confirm that the enactive agent can successfully interact with its environment and learn to avoid unfavourable interactions using intrinsically defined goals. The performance of the enactive agent is shown to be limited by the number of affordable actions.

</details>

<details>

<summary>2018-10-09 07:01:20 - Using Sentiment Representation Learning to Enhance Gender Classification for User Profiling</summary>

- *Yunpei Zheng, Lin Li, Luo Zhong, Jianwei Zhang, Jinhang Liu*

- `1810.06645v1` - [abs](http://arxiv.org/abs/1810.06645v1) - [pdf](http://arxiv.org/pdf/1810.06645v1)

> User profiling means exploiting the technology of machine learning to predict attributes of users, such as demographic attributes, hobby attributes, preference attributes, etc. It's a powerful data support of precision marketing. Existing methods mainly study network behavior, personal preferences, post texts to build user profile. Through our data analysis of micro-blog, we find that females show more positive and have richer emotions than males in online social platform. This difference is very conducive to the distinction between genders. Therefore, we argue that sentiment context is important as well for user profiling.This paper focuses on exploiting microblog user posts to predict one of the demographic labels: gender. We propose a Sentiment Representation Learning based Multi-Layer Perceptron(SRL-MLP) model to classify gender. First we build a sentiment polarity classifier in advance by training Long Short-Term Memory(LSTM) model on e-commerce review corpus. Next we transfer sentiment representation to a basic MLP network. Last we conduct experiments on gender classification by sentiment representation. Experimental results show that our approach can improve gender classification accuracy by 5.53\%, from 84.20\% to 89.73\%.

</details>

<details>

<summary>2018-10-09 07:51:48 - Description of sup- and inf-preserving aggregation functions via families of clusters in data tables</summary>

- *Radomír Halaš, Radko Mesiar, Jozef Pócs*

- `1810.08040v1` - [abs](http://arxiv.org/abs/1810.08040v1) - [pdf](http://arxiv.org/pdf/1810.08040v1)

> Connection between the theory of aggregation functions and formal concept analysis is discussed and studied, thus filling a gap in the literature by building a bridge between these two theories, one of them living in the world of data fusion, the second one in the area of data mining. We show how Galois connections can be used to describe an important class of aggregation functions preserving suprema, and, by duality, to describe aggregation functions preserving infima. Our discovered method gives an elegant and complete description of these classes. Also possible applications of our results within certain biclustering fuzzy FCA-based methods are discussed.

</details>

<details>

<summary>2018-10-09 08:30:44 - Interpreting Winograd Schemas Via the SP Theory of Intelligence and Its Realisation in the SP Computer Model</summary>

- *J Gerard Wolff*

- `1810.04554v1` - [abs](http://arxiv.org/abs/1810.04554v1) - [pdf](http://arxiv.org/pdf/1810.04554v1)

> In 'Winograd Schema' (WS) sentences like "The city councilmen refused the demonstrators a permit because they feared violence" and "The city councilmen refused the demonstrators a permit because they advocated revolution", it is easy for adults to understand what "they" refers to but can be difficult for AI systems. This paper describes how the SP System -- outlined in an appendix -- may solve this kind of problem of interpretation. The central idea is that a knowledge of discontinuous associations amongst linguistic features, and an ability to recognise such patterns of associations, provides a robust means of determining what a pronoun like "they" refers to. For any AI system to solve this kind of problem, it needs appropriate knowledge of relevant syntax and semantics which, ideally, it should learn for itself. Although the SP System has some strengths in unsupervised learning, its capabilities in this area are not yet good enough to learn the kind of knowledge needed to interpret WS examples, so it must be supplied with such knowledge at the outset. However, its existing strengths in unsupervised learning suggest that it has potential to learn the kind of knowledge needed for the interpretation of WS examples. In particular, it has potential to learn the kind of discontinuous association of linguistic features mentioned earlier.

</details>

<details>

<summary>2018-10-09 10:49:35 - Sentence Entailment in Compositional Distributional Semantics</summary>

- *Esma Balkir, Dimitri Kartsaklis, Mehrnoosh Sadrzadeh*

- `1512.04419v2` - [abs](http://arxiv.org/abs/1512.04419v2) - [pdf](http://arxiv.org/pdf/1512.04419v2)

> Distributional semantic models provide vector representations for words by gathering co-occurrence frequencies from corpora of text. Compositional distributional models extend these from words to phrases and sentences. In categorical compositional distributional semantics, phrase and sentence representations are functions of their grammatical structure and representations of the words therein. In this setting, grammatical structures are formalised by morphisms of a compact closed category and meanings of words are formalised by objects of the same category. These can be instantiated in the form of vectors or density matrices. This paper concerns the applications of this model to phrase and sentence level entailment. We argue that entropy-based distances of vectors and density matrices provide a good candidate to measure word-level entailment, show the advantage of density matrices over vectors for word level entailments, and prove that these distances extend compositionally from words to phrases and sentences. We exemplify our theoretical constructions on real data and a toy entailment dataset and provide preliminary experimental evidence.

</details>

<details>

<summary>2018-10-09 13:05:43 - Cooperative Starting Movement Detection of Cyclists Using Convolutional Neural Networks and a Boosted Stacking Ensemble</summary>

- *Maarten Bieshaar, Stefan Zernetsch, Andreas Hubert, Bernhard Sick, Konrad Doll*

- `1803.03487v2` - [abs](http://arxiv.org/abs/1803.03487v2) - [pdf](http://arxiv.org/pdf/1803.03487v2)

> In future, vehicles and other traffic participants will be interconnected and equipped with various types of sensors, allowing for cooperation on different levels, such as situation prediction or intention detection. In this article we present a cooperative approach for starting movement detection of cyclists using a boosted stacking ensemble approach realizing feature- and decision level cooperation. We introduce a novel method based on a 3D Convolutional Neural Network (CNN) to detect starting motions on image sequences by learning spatio-temporal features. The CNN is complemented by a smart device based starting movement detection originating from smart devices carried by the cyclist. Both model outputs are combined in a stacking ensemble approach using an extreme gradient boosting classifier resulting in a fast and yet robust cooperative starting movement detector. We evaluate our cooperative approach on real-world data originating from experiments with 49 test subjects consisting of 84 starting motions.

</details>

<details>

<summary>2018-10-09 13:42:48 - Mathematics as information compression via the matching and unification of patterns</summary>

- *J Gerard Wolff*

- `1808.07004v2` - [abs](http://arxiv.org/abs/1808.07004v2) - [pdf](http://arxiv.org/pdf/1808.07004v2)

> This paper describes a novel perspective on the foundations of mathematics: how mathematics may be seen to be largely about 'information compression via the matching and unification of patterns' (ICMUP). ICMUP is itself a novel approach to information compression, couched in terms of non-mathematical primitives, as is necessary in any investigation of the foundations of mathematics. This new perspective on the foundations of mathematics has grown out of an extensive programme of research developing the "SP Theory of Intelligence" and its realisation in the "SP Computer Model", a system in which a generalised version of ICMUP -- the powerful concept of SP-multiple-alignment -- plays a central role. These ideas may be seen to be part of a "Big Picture" comprising six areas of interest, with information compression as a unifying theme. The paper describes the close relation between mathematics and information compression, and describes examples showing how variants of ICMUP may be seen in widely-used structures and operations in mathematics. Examples are also given to show how the mathematics-related disciplines of logic and computing may be understood as ICMUP. There are many potential benefits and applications of these ideas.

</details>

<details>

<summary>2018-10-09 14:02:56 - The combination of context information to enhance simple question answering</summary>

- *Zhaohui Chao, Lin Li*

- `1810.04000v1` - [abs](http://arxiv.org/abs/1810.04000v1) - [pdf](http://arxiv.org/pdf/1810.04000v1)

> With the rapid development of knowledge base,question answering based on knowledge base has been a hot research issue. In this paper, we focus on answering singlerelation factoid questions based on knowledge base. We build a question answering system and study the effect of context information on fact selection, such as entity's notable type,outdegree. Experimental results show that context information can improve the result of simple question answering.

</details>

<details>

<summary>2018-10-09 14:57:55 - A Distributed Reinforcement Learning Solution With Knowledge Transfer Capability for A Bike Rebalancing Problem</summary>

- *Ian Xiao*

- `1810.04058v1` - [abs](http://arxiv.org/abs/1810.04058v1) - [pdf](http://arxiv.org/pdf/1810.04058v1)

> Rebalancing is a critical service bottleneck for many transportation services, such as Citi Bike. Citi Bike relies on manual orchestrations of rebalancing bikes between dispatchers and field agents. Motivated by such problem and the lack of smart autonomous solutions in this area, this project explored a new RL architecture called Distributed RL (DiRL) with Transfer Learning (TL) capability. The DiRL solution is adaptive to changing traffic dynamics when keeping bike stock under control at the minimum cost. DiRL achieved a 350% improvement in bike rebalancing autonomously and TL offered a 62.4% performance boost in managing an entire bike network. Lastly, a field trip to the dispatch office of Chariot, a ride-sharing service, provided insights to overcome challenges of deploying an RL solution in the real world.

</details>

<details>

<summary>2018-10-09 15:26:41 - Pioneer Networks: Progressively Growing Generative Autoencoder</summary>

- *Ari Heljakka, Arno Solin, Juho Kannala*

- `1807.03026v2` - [abs](http://arxiv.org/abs/1807.03026v2) - [pdf](http://arxiv.org/pdf/1807.03026v2)

> We introduce a novel generative autoencoder network model that learns to encode and reconstruct images with high quality and resolution, and supports smooth random sampling from the latent space of the encoder. Generative adversarial networks (GANs) are known for their ability to simulate random high-quality images, but they cannot reconstruct existing images. Previous works have attempted to extend GANs to support such inference but, so far, have not delivered satisfactory high-quality results. Instead, we propose the Progressively Growing Generative Autoencoder (PIONEER) network which achieves high-quality reconstruction with $128{\times}128$ images without requiring a GAN discriminator. We merge recent techniques for progressively building up the parts of the network with the recently introduced adversarial encoder-generator network. The ability to reconstruct input images is crucial in many real-world applications, and allows for precise intelligent manipulation of existing images. We show promising results in image synthesis and inference, with state-of-the-art results in CelebA inference tasks.

</details>

<details>

<summary>2018-10-09 16:25:03 - Cycle-of-Learning for Autonomous Systems from Human Interaction</summary>

- *Nicholas R. Waytowich, Vinicius G. Goecks, Vernon J. Lawhern*

- `1808.09572v2` - [abs](http://arxiv.org/abs/1808.09572v2) - [pdf](http://arxiv.org/pdf/1808.09572v2)

> We discuss different types of human-robot interaction paradigms in the context of training end-to-end reinforcement learning algorithms. We provide a taxonomy to categorize the types of human interaction and present our Cycle-of-Learning framework for autonomous systems that combines different human-interaction modalities with reinforcement learning. Two key concepts provided by our Cycle-of-Learning framework are how it handles the integration of the different human-interaction modalities (demonstration, intervention, and evaluation) and how to define the switching criteria between them.

</details>

<details>

<summary>2018-10-09 16:27:46 - Enabling Cognitive Smart Cities Using Big Data and Machine Learning: Approaches and Challenges</summary>

- *Mehdi Mohammadi, Ala Al-Fuqaha*

- `1810.04107v1` - [abs](http://arxiv.org/abs/1810.04107v1) - [pdf](http://arxiv.org/pdf/1810.04107v1)

> The development of smart cities and their fast-paced deployment is resulting in the generation of large quantities of data at unprecedented rates. Unfortunately, most of the generated data is wasted without extracting potentially useful information and knowledge because of the lack of established mechanisms and standards that benefit from the availability of such data. Moreover, the high dynamical nature of smart cities calls for new generation of machine learning approaches that are flexible and adaptable to cope with the dynamicity of data to perform analytics and learn from real-time data. In this article, we shed the light on the challenge of under utilizing the big data generated by smart cities from a machine learning perspective. Especially, we present the phenomenon of wasting unlabeled data. We argue that semi-supervision is a must for smart city to address this challenge. We also propose a three-level learning framework for smart cities that matches the hierarchical nature of big data generated by smart cities with a goal of providing different levels of knowledge abstractions. The proposed framework is scalable to meet the needs of smart city services. Fundamentally, the framework benefits from semi-supervised deep reinforcement learning where a small amount of data that has users' feedback serves as labeled data while a larger amount is without such users' feedback serves as unlabeled data. This paper also explores how deep reinforcement learning and its shift toward semi-supervision can handle the cognitive side of smart city services and improve their performance by providing several use cases spanning the different domains of smart cities. We also highlight several challenges as well as promising future research directions for incorporating machine learning and high-level intelligence into smart city services.

</details>

<details>

<summary>2018-10-09 16:47:25 - Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart City Services</summary>

- *Mehdi Mohammadi, Ala Al-Fuqaha, Mohsen Guizani, Jun-Seok Oh*

- `1810.04118v1` - [abs](http://arxiv.org/abs/1810.04118v1) - [pdf](http://arxiv.org/pdf/1810.04118v1)

> Smart services are an important element of the smart cities and the Internet of Things (IoT) ecosystems where the intelligence behind the services is obtained and improved through the sensory data. Providing a large amount of training data is not always feasible; therefore, we need to consider alternative ways that incorporate unlabeled data as well. In recent years, Deep reinforcement learning (DRL) has gained great success in several application domains. It is an applicable method for IoT and smart city scenarios where auto-generated data can be partially labeled by users' feedback for training purposes. In this paper, we propose a semi-supervised deep reinforcement learning model that fits smart city applications as it consumes both labeled and unlabeled data to improve the performance and accuracy of the learning agent. The model utilizes Variational Autoencoders (VAE) as the inference engine for generalizing optimal policies. To the best of our knowledge, the proposed model is the first investigation that extends deep reinforcement learning to the semi-supervised paradigm. As a case study of smart city applications, we focus on smart buildings and apply the proposed model to the problem of indoor localization based on BLE signal strength. Indoor localization is the main component of smart city services since people spend significant time in indoor environments. Our model learns the best action policies that lead to a close estimation of the target locations with an improvement of 23% in terms of distance to the target and at least 67% more received rewards compared to the supervised DRL model.

</details>

<details>

<summary>2018-10-09 18:02:47 - Deterministic Pod Repositioning Problem in Robotic Mobile Fulfillment Systems</summary>

- *Ruslan Krenzler, Lin Xie, Hanyi Li*

- `1810.05514v1` - [abs](http://arxiv.org/abs/1810.05514v1) - [pdf](http://arxiv.org/pdf/1810.05514v1)

> In a robotic mobile fulfillment system, robots bring shelves, called pods, with storage items from the storage area to pick stations. At every pick station there is a person -- the picker -- who takes parts from the pod and packs them into boxes according to orders. Usually there are multiple shelves at the pick station. In this case, they build a queue with the picker at its head. When the picker does not need the pod any more, a robot transports the pod back to the storage area. At that time, we need to answer a question: "Where is the optimal place in the inventory to put this pod back?". It is a tough question, because there are many uncertainties to consider before answering it. Moreover, each decision made to answer the question influences the subsequent ones. The goal of this paper is to answer the question properly. We call this problem the Pod Repositioning Problem and formulate a deterministic model. This model is tested with different algorithms, including binary integer programming, cheapest place, fixed place, random place, genetic algorithms, and a novel algorithm called tetris.

</details>

<details>

<summary>2018-10-09 18:30:41 - Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration</summary>

- *Alexandre Péré, Sébastien Forestier, Olivier Sigaud, Pierre-Yves Oudeyer*

- `1803.00781v3` - [abs](http://arxiv.org/abs/1803.00781v3) - [pdf](http://arxiv.org/pdf/1803.00781v3)

> Intrinsically motivated goal exploration algorithms enable machines to discover repertoires of policies that produce a diversity of effects in complex environments. These exploration algorithms have been shown to allow real world robots to acquire skills such as tool use in high-dimensional continuous state and action spaces. However, they have so far assumed that self-generated goals are sampled in a specifically engineered feature space, limiting their autonomy. In this work, we propose to use deep representation learning algorithms to learn an adequate goal space. This is a developmental 2-stage approach: first, in a perceptual learning stage, deep learning algorithms use passive raw sensor observations of world changes to learn a corresponding latent space; then goal exploration happens in a second stage by sampling goals in this latent space. We present experiments where a simulated robot arm interacts with an object, and we show that exploration algorithms using such learned representations can match the performance obtained using engineered representations.

</details>

<details>

<summary>2018-10-09 21:13:05 - Distributed Wildfire Surveillance with Autonomous Aircraft using Deep Reinforcement Learning</summary>

- *Kyle D. Julian, Mykel J. Kochenderfer*

- `1810.04244v1` - [abs](http://arxiv.org/abs/1810.04244v1) - [pdf](http://arxiv.org/pdf/1810.04244v1)

> Teams of autonomous unmanned aircraft can be used to monitor wildfires, enabling firefighters to make informed decisions. However, controlling multiple autonomous fixed-wing aircraft to maximize forest fire coverage is a complex problem. The state space is high dimensional, the fire propagates stochastically, the sensor information is imperfect, and the aircraft must coordinate with each other to accomplish their mission. This work presents two deep reinforcement learning approaches for training decentralized controllers that accommodate the high dimensionality and uncertainty inherent in the problem. The first approach controls the aircraft using immediate observations of the individual aircraft. The second approach allows aircraft to collaborate on a map of the wildfire's state and maintain a time history of locations visited, which are used as inputs to the controller. Simulation results show that both approaches allow the aircraft to accurately track wildfire expansions and outperform an online receding horizon controller. Additional simulations demonstrate that the approach scales with different numbers of aircraft and generalizes to different wildfire shapes.

</details>

<details>

<summary>2018-10-09 23:19:52 - Diversity is All You Need: Learning Skills without a Reward Function</summary>

- *Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, Sergey Levine*

- `1802.06070v6` - [abs](http://arxiv.org/abs/1802.06070v6) - [pdf](http://arxiv.org/pdf/1802.06070v6)

> Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN ('Diversity is All You Need'), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.

</details>

<details>

<summary>2018-10-10 00:02:55 - Batch Active Preference-Based Learning of Reward Functions</summary>

- *Erdem Bıyık, Dorsa Sadigh*

- `1810.04303v1` - [abs](http://arxiv.org/abs/1810.04303v1) - [pdf](http://arxiv.org/pdf/1810.04303v1)

> Data generation and labeling are usually an expensive part of learning for robotics. While active learning methods are commonly used to tackle the former problem, preference-based learning is a concept that attempts to solve the latter by querying users with preference questions. In this paper, we will develop a new algorithm, batch active preference-based learning, that enables efficient learning of reward functions using as few data samples as possible while still having short query generation times. We introduce several approximations to the batch active learning problem, and provide theoretical guarantees for the convergence of our algorithms. Finally, we present our experimental results for a variety of robotics tasks in simulation. Our results suggest that our batch active learning algorithm requires only a few queries that are computed in a short amount of time. We then showcase our algorithm in a study to learn human users' preferences.

</details>

<details>

<summary>2018-10-10 00:37:12 - Real Vector Spaces and the Cauchy-Schwarz Inequality in ACL2(r)</summary>

- *Carl Kwan, Mark R. Greenstreet*

- `1810.04315v1` - [abs](http://arxiv.org/abs/1810.04315v1) - [pdf](http://arxiv.org/pdf/1810.04315v1)

> We present a mechanical proof of the Cauchy-Schwarz inequality in ACL2(r) and a formalisation of the necessary mathematics to undertake such a proof. This includes the formalisation of $\mathbb{R}^n$ as an inner product space. We also provide an application of Cauchy-Schwarz by formalising $\mathbb R^n$ as a metric space and exhibiting continuity for some simple functions $\mathbb R^n\to\mathbb R$. The Cauchy-Schwarz inequality relates the magnitude of a vector to its projection (or inner product) with another: \[|\langle u,v\rangle| \leq \|u\| \|v\|\] with equality iff the vectors are linearly dependent. It finds frequent use in many branches of mathematics including linear algebra, real analysis, functional analysis, probability, etc. Indeed, the inequality is considered to be among "The Hundred Greatest Theorems" and is listed in the "Formalizing 100 Theorems" project. To the best of our knowledge, our formalisation is the first published proof using ACL2(r) or any other first-order theorem prover.

</details>

<details>

<summary>2018-10-10 00:37:29 - Convex Functions in ACL2(r)</summary>

- *Carl Kwan, Mark R. Greenstreet*

- `1810.04316v1` - [abs](http://arxiv.org/abs/1810.04316v1) - [pdf](http://arxiv.org/pdf/1810.04316v1)

> This paper builds upon our prior formalisation of R^n in ACL2(r) by presenting a set of theorems for reasoning about convex functions. This is a demonstration of the higher-dimensional analytical reasoning possible in our metric space formalisation of R^n. Among the introduced theorems is a set of equivalent conditions for convex functions with Lipschitz continuous gradients from Yurii Nesterov's classic text on convex optimisation. To the best of our knowledge a full proof of the theorem has yet to be published in a single piece of literature. We also explore "proof engineering" issues, such as how to state Nesterov's theorem in a manner that is both clear and useful.

</details>

<details>

<summary>2018-10-10 03:23:38 - Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training</summary>

- *Bei Liu, Jianlong Fu, Makoto P. Kato, Masatoshi Yoshikawa*

- `1804.08473v4` - [abs](http://arxiv.org/abs/1804.08473v4) - [pdf](http://arxiv.org/pdf/1804.08473v4)

> Automatic generation of natural language from images has attracted extensive attention. In this paper, we take one step further to investigate generation of poetic language (with multiple lines) to an image for automatic poetry creation. This task involves multiple challenges, including discovering poetic clues from the image (e.g., hope from green), and generating poems to satisfy both relevance to the image and poeticness in language level. To solve the above challenges, we formulate the task of poem generation into two correlated sub-tasks by multi-adversarial training via policy gradient, through which the cross-modal relevance and poetic language style can be ensured. To extract poetic clues from images, we propose to learn a deep coupled visual-poetic embedding, in which the poetic representation from objects, sentiments and scenes in an image can be jointly learned. Two discriminative networks are further introduced to guide the poem generation, including a multi-modal discriminator and a poem-style discriminator. To facilitate the research, we have released two poem datasets by human annotators with two distinct properties: 1) the first human annotated image-to-poem pair dataset (with 8,292 pairs in total), and 2) to-date the largest public English poem corpus dataset (with 92,265 different poems in total). Extensive experiments are conducted with 8K images, among which 1.5K image are randomly picked for evaluation. Both objective and subjective evaluations show the superior performances against the state-of-the-art methods for poem generation from images. Turing test carried out with over 500 human subjects, among which 30 evaluators are poetry experts, demonstrates the effectiveness of our approach.

</details>

<details>

<summary>2018-10-10 04:12:50 - Semi-supervised clustering for de-duplication</summary>

- *Shrinu Kushagra, Shai Ben-David, Ihab Ilyas*

- `1810.04361v1` - [abs](http://arxiv.org/abs/1810.04361v1) - [pdf](http://arxiv.org/pdf/1810.04361v1)

> Data de-duplication is the task of detecting multiple records that correspond to the same real-world entity in a database. In this work, we view de-duplication as a clustering problem where the goal is to put records corresponding to the same physical entity in the same cluster and putting records corresponding to different physical entities into different clusters.   We introduce a framework which we call promise correlation clustering. Given a complete graph $G$ with the edges labelled $0$ and $1$, the goal is to find a clustering that minimizes the number of $0$ edges within a cluster plus the number of $1$ edges across different clusters (or correlation loss). The optimal clustering can also be viewed as a complete graph $G^*$ with edges corresponding to points in the same cluster being labelled $0$ and other edges being labelled $1$. Under the promise that the edge difference between $G$ and $G^*$ is "small", we prove that finding the optimal clustering (or $G^*$) is still NP-Hard. [Ashtiani et. al, 2016] introduced the framework of semi-supervised clustering, where the learning algorithm has access to an oracle, which answers whether two points belong to the same or different clusters. We further prove that even with access to a same-cluster oracle, the promise version is NP-Hard as long as the number queries to the oracle is not too large ($o(n)$ where $n$ is the number of vertices).   Given these negative results, we consider a restricted version of correlation clustering. As before, the goal is to find a clustering that minimizes the correlation loss. However, we restrict ourselves to a given class $\mathcal F$ of clusterings. We offer a semi-supervised algorithmic approach to solve the restricted variant with success guarantees.

</details>

<details>

<summary>2018-10-10 04:14:59 - DeFind: A Protege Plugin for Computing Concept Definitions in EL Ontologies</summary>

- *Denis Ponomaryov, Stepan Yakovenko*

- `1810.04363v1` - [abs](http://arxiv.org/abs/1810.04363v1) - [pdf](http://arxiv.org/pdf/1810.04363v1)

> We introduce an extension to the Protege ontology editor, which allows for discovering concept definitions, which are not explicitly present in axioms, but are logically implied by an ontology. The plugin supports ontologies formulated in the Description Logic EL, which underpins the OWL 2 EL profile of the Web Ontology Language and despite its limited expressiveness captures most of the biomedical ontologies published on the Web. The developed tool allows to verify whether a concept can be defined using a vocabulary of interest specified by a user. In particular, it allows to decide whether some vocabulary items can be omitted in a formulation of a complex concept. The corresponding definitions are presented to the user and are provided with explanations generated by an ontology reasoner.

</details>

<details>

<summary>2018-10-10 07:38:44 - Parametrized Deep Q-Networks Learning: Reinforcement Learning with Discrete-Continuous Hybrid Action Space</summary>

- *Jiechao Xiong, Qing Wang, Zhuoran Yang, Peng Sun, Lei Han, Yang Zheng, Haobo Fu, Tong Zhang, Ji Liu, Han Liu*

- `1810.06394v1` - [abs](http://arxiv.org/abs/1810.06394v1) - [pdf](http://arxiv.org/pdf/1810.06394v1)

> Most existing deep reinforcement learning (DRL) frameworks consider either discrete action space or continuous action space solely. Motivated by applications in computer games, we consider the scenario with discrete-continuous hybrid action space. To handle hybrid action space, previous works either approximate the hybrid space by discretization, or relax it into a continuous set. In this paper, we propose a parametrized deep Q-network (P- DQN) framework for the hybrid action space without approximation or relaxation. Our algorithm combines the spirits of both DQN (dealing with discrete action space) and DDPG (dealing with continuous action space) by seamlessly integrating them. Empirical results on a simulation example, scoring a goal in simulated RoboCup soccer and the solo mode in game King of Glory (KOG) validate the efficiency and effectiveness of our method.

</details>

<details>

<summary>2018-10-10 13:42:16 - Is there Gender bias and stereotype in Portuguese Word Embeddings?</summary>

- *Brenda Salenave Santana, Vinicius Woloszyn, Leandro Krug Wives*

- `1810.04528v1` - [abs](http://arxiv.org/abs/1810.04528v1) - [pdf](http://arxiv.org/pdf/1810.04528v1)

> In this work, we propose an analysis of the presence of gender bias associated with professions in Portuguese word embeddings. The objective of this work is to study gender implications related to stereotyped professions for women and men in the context of the Portuguese language.

</details>

<details>

<summary>2018-10-10 14:04:08 - Secure Deep Learning Engineering: A Software Quality Assurance Perspective</summary>

- *Lei Ma, Felix Juefei-Xu, Minhui Xue, Qiang Hu, Sen Chen, Bo Li, Yang Liu, Jianjun Zhao, Jianxiong Yin, Simon See*

- `1810.04538v1` - [abs](http://arxiv.org/abs/1810.04538v1) - [pdf](http://arxiv.org/pdf/1810.04538v1)

> Over the past decades, deep learning (DL) systems have achieved tremendous success and gained great popularity in various applications, such as intelligent machines, image processing, speech processing, and medical diagnostics. Deep neural networks are the key driving force behind its recent success, but still seem to be a magic black box lacking interpretability and understanding. This brings up many open safety and security issues with enormous and urgent demands on rigorous methodologies and engineering practice for quality enhancement. A plethora of studies have shown that the state-of-the-art DL systems suffer from defects and vulnerabilities that can lead to severe loss and tragedies, especially when applied to real-world safety-critical applications. In this paper, we perform a large-scale study and construct a paper repository of 223 relevant works to the quality assurance, security, and interpretation of deep learning. We, from a software quality assurance perspective, pinpoint challenges and future opportunities towards universal secure deep learning engineering. We hope this work and the accompanied paper repository can pave the path for the software engineering community towards addressing the pressing industrial demand of secure intelligent applications.

</details>

<details>

<summary>2018-10-10 16:51:39 - Quantum Neural Network and Soft Quantum Computing</summary>

- *Zeng-Bing Chen*

- `1810.05025v1` - [abs](http://arxiv.org/abs/1810.05025v1) - [pdf](http://arxiv.org/pdf/1810.05025v1)

> A new paradigm of quantum computing, namely, soft quantum computing, is proposed for nonclassical computation using real world quantum systems with naturally occurring environment-induced decoherence and dissipation. As a specific example of soft quantum computing, we suggest a quantum neural network, where the neurons connect pairwise via the "controlled Kraus operations", hoping to pave an easier and more realistic way to quantum artificial intelligence and even to better understanding certain functioning of the human brain. Our quantum neuron model mimics as much as possible the realistic neurons and meanwhile, uses quantum laws for processing information. The quantum features of the noisy neural network are uncovered by the presence of quantum discord and by non-commutability of quantum operations. We believe that our model puts quantum computing into a wider context and inspires the hope to build a soft quantum computer much earlier than the standard one.

</details>

<details>

<summary>2018-10-10 18:36:04 - End-to-End Content and Plan Selection for Data-to-Text Generation</summary>

- *Sebastian Gehrmann, Falcon Z. Dai, Henry Elder, Alexander M. Rush*

- `1810.04700v1` - [abs](http://arxiv.org/abs/1810.04700v1) - [pdf](http://arxiv.org/pdf/1810.04700v1)

> Learning to generate fluent natural language from structured data with neural networks has become an common approach for NLG. This problem can be challenging when the form of the structured data varies between examples. This paper presents a survey of several extensions to sequence-to-sequence models to account for the latent content selection process, particularly variants of copy attention and coverage decoding. We further propose a training method based on diverse ensembling to encourage models to learn distinct sentence templates during training. An empirical evaluation of these techniques shows an increase in the quality of generated text across five automated metrics, as well as human evaluation.

</details>

<details>

<summary>2018-10-10 18:59:29 - Introducing a hybrid model of DEA and data mining in evaluating efficiency. Case study: Bank Branches</summary>

- *Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Seyed Esmaeel Najafi*

- `1810.05524v1` - [abs](http://arxiv.org/abs/1810.05524v1) - [pdf](http://arxiv.org/pdf/1810.05524v1)

> The banking industry is very important for an economic cycle of each country and provides some quality of services for us. With the advancement in technology and rapidly increasing of the complexity of the business environment, it has become more competitive than the past so that efficiency analysis in the banking industry attracts much attention in recent years. From many aspects, such analyses at the branch level are more desirable. Evaluating the branch performance with the purpose of eliminating deficiency can be a crucial issue for branch managers to measure branch efficiency. This work not only can lead to a better understanding of bank branch performance but also give further information to enhance managerial decisions to recognize problematic areas. To achieve this purpose, this study presents an integrated approach based on Data Envelopment Analysis (DEA), Clustering algorithms and Polynomial Pattern Classifier for constructing a classifier to identify a class of bank branches. First, the efficiency estimates of individual branches are evaluated by using the DEA approach. Next, when the range and number of classes were identified by experts, the number of clusters is identified by an agglomerative hierarchical clustering algorithm based on some statistical methods. Next, we divide our raw data into k clusters By means of self-organizing map (SOM) neural networks. Finally, all clusters are fed into the reduced multivariate polynomial model to predict the classes of data.

</details>

<details>

<summary>2018-10-10 21:42:29 - Leveraging Textual Specifications for Grammar-based Fuzzing of Network Protocols</summary>

- *Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser, Cristina Nita-Rotaru*

- `1810.04755v1` - [abs](http://arxiv.org/abs/1810.04755v1) - [pdf](http://arxiv.org/pdf/1810.04755v1)

> Grammar-based fuzzing is a technique used to find software vulnerabilities by injecting well-formed inputs generated following rules that encode application semantics. Most grammar-based fuzzers for network protocols rely on human experts to manually specify these rules. In this work we study automated learning of protocol rules from textual specifications (i.e. RFCs). We evaluate the automatically extracted protocol rules by applying them to a state-of-the-art fuzzer for transport protocols and show that it leads to a smaller number of test cases while finding the same attacks as the system that uses manually specified rules.

</details>

<details>

<summary>2018-10-10 22:02:11 - Towards Differentially Private Truth Discovery for Crowd Sensing Systems</summary>

- *Yaliang Li, Houping Xiao, Zhan Qin, Chenglin Miao, Lu Su, Jing Gao, Kui Ren, Bolin Ding*

- `1810.04760v1` - [abs](http://arxiv.org/abs/1810.04760v1) - [pdf](http://arxiv.org/pdf/1810.04760v1)

> Nowadays, crowd sensing becomes increasingly more popular due to the ubiquitous usage of mobile devices. However, the quality of such human-generated sensory data varies significantly among different users. To better utilize sensory data, the problem of truth discovery, whose goal is to estimate user quality and infer reliable aggregated results through quality-aware data aggregation, has emerged as a hot topic. Although the existing truth discovery approaches can provide reliable aggregated results, they fail to protect the private information of individual users. Moreover, crowd sensing systems typically involve a large number of participants, making encryption or secure multi-party computation based solutions difficult to deploy. To address these challenges, in this paper, we propose an efficient privacy-preserving truth discovery mechanism with theoretical guarantees of both utility and privacy. The key idea of the proposed mechanism is to perturb data from each user independently and then conduct weighted aggregation among users' perturbed data. The proposed approach is able to assign user weights based on information quality, and thus the aggregated results will not deviate much from the true results even when large noise is added. We adapt local differential privacy definition to this privacy-preserving task and demonstrate the proposed mechanism can satisfy local differential privacy while preserving high aggregation accuracy. We formally quantify utility and privacy trade-off and further verify the claim by experiments on both synthetic data and a real-world crowd sensing system.

</details>

<details>

<summary>2018-10-10 23:12:01 - The IFF Foundation for Ontological Knowledge Organization</summary>

- *Robert E. Kent*

- `1810.04773v1` - [abs](http://arxiv.org/abs/1810.04773v1) - [pdf](http://arxiv.org/pdf/1810.04773v1)

> This paper discusses an axiomatic approach for the integration of ontologies, an approach that extends to first order logic a previous approach (Kent 2000) based on information flow. This axiomatic approach is represented in the Information Flow Framework (IFF), a metalevel framework for organizing the information that appears in digital libraries, distributed databases and ontologies (Kent 2001). The paper argues that the integration of ontologies is the two-step process of alignment and unification. Ontological alignment consists of the sharing of common terminology and semantics through a mediating ontology. Ontological unification, concentrated in a virtual ontology of community connections, is fusion of the alignment diagram of participant community ontologies - the quotient of the sum of the participant portals modulo the ontological alignment structure.

</details>

<details>

<summary>2018-10-10 23:41:42 - Conceptual Knowledge Markup Language: An Introduction</summary>

- *Robert E. Kent*

- `1810.05534v1` - [abs](http://arxiv.org/abs/1810.05534v1) - [pdf](http://arxiv.org/pdf/1810.05534v1)

> Conceptual Knowledge Markup Language (CKML) is an application of XML. Earlier versions of CKML followed rather exclusively the philosophy of Conceptual Knowledge Processing (CKP), a principled approach to knowledge representation and data analysis that "advocates methods and instruments of conceptual knowledge processing which support people in their rational thinking, judgment and acting and promote critical discussion." The new version of CKML continues to follow this approach, but also incorporates various principles, insights and techniques from Information Flow (IF), the logical design of distributed systems. Among other things, this allows diverse communities of discourse to compare their own information structures, as coded in logical theories, with that of other communities that share a common generic ontology. CKML incorporates the CKP ideas of concept lattice and formal context, along with the IF ideas of classification (= formal context), infomorphism, theory, interpretation and local logic. Ontology Markup Language (OML), a subset of CKML that is a self-sufficient markup language in its own right, follows the principles and ideas of Conceptual Graphs (CG). OML is used for structuring the specifications and axiomatics of metadata into ontologies. OML incorporates the CG ideas of concept, conceptual relation, conceptual graph, conceptual context, participants and ontology. The link from OML to CKML is the process of conceptual scaling, which is the interpretive transformation of ontologically structured knowledge to conceptual structured knowledge.

</details>

<details>

<summary>2018-10-11 00:56:10 - A Practical Algorithm for Distributed Clustering and Outlier Detection</summary>

- *Jiecao Chen, Erfan Sadeqi Azer, Qin Zhang*

- `1805.09495v2` - [abs](http://arxiv.org/abs/1805.09495v2) - [pdf](http://arxiv.org/pdf/1805.09495v2)

> We study the classic $k$-means/median clustering, which are fundamental problems in unsupervised learning, in the setting where data are partitioned across multiple sites, and where we are allowed to discard a small portion of the data by labeling them as outliers. We propose a simple approach based on constructing small summary for the original dataset. The proposed method is time and communication efficient, has good approximation guarantees, and can identify the global outliers effectively. To the best of our knowledge, this is the first practical algorithm with theoretical guarantees for distributed clustering with outliers. Our experiments on both real and synthetic data have demonstrated the clear superiority of our algorithm against all the baseline algorithms in almost all metrics.

</details>

<details>

<summary>2018-10-11 06:15:05 - Policy Design for Active Sequential Hypothesis Testing using Deep Learning</summary>

- *Dhruva Kartik, Ekraam Sabir, Urbashi Mitra, Prem Natarajan*

- `1810.04859v1` - [abs](http://arxiv.org/abs/1810.04859v1) - [pdf](http://arxiv.org/pdf/1810.04859v1)

> Information theory has been very successful in obtaining performance limits for various problems such as communication, compression and hypothesis testing. Likewise, stochastic control theory provides a characterization of optimal policies for Partially Observable Markov Decision Processes (POMDPs) using dynamic programming. However, finding optimal policies for these problems is computationally hard in general and thus, heuristic solutions are employed in practice. Deep learning can be used as a tool for designing better heuristics in such problems. In this paper, the problem of active sequential hypothesis testing is considered. The goal is to design a policy that can reliably infer the true hypothesis using as few samples as possible by adaptively selecting appropriate queries. This problem can be modeled as a POMDP and bounds on its value function exist in literature. However, optimal policies have not been identified and various heuristics are used. In this paper, two new heuristics are proposed: one based on deep reinforcement learning and another based on a KL-divergence zero-sum game. These heuristics are compared with state-of-the-art solutions and it is demonstrated using numerical experiments that the proposed heuristics can achieve significantly better performance than existing methods in some scenarios.

</details>

<details>

<summary>2018-10-11 06:34:18 - Empowerment-driven Exploration using Mutual Information Estimation</summary>

- *Navneet Madhu Kumar*

- `1810.05533v1` - [abs](http://arxiv.org/abs/1810.05533v1) - [pdf](http://arxiv.org/pdf/1810.05533v1)

> Exploration is a difficult challenge in reinforcement learning and is of prime importance in sparse reward environments. However, many of the state of the art deep reinforcement learning algorithms, that rely on epsilon-greedy, fail on these environments. In such cases, empowerment can serve as an intrinsic reward signal to enable the agent to maximize the influence it has over the near future. We formulate empowerment as the channel capacity between states and actions and is calculated by estimating the mutual information between the actions and the following states. The mutual information is estimated using Mutual Information Neural Estimator and a forward dynamics model. We demonstrate that an empowerment driven agent is able to improve significantly the score of a baseline DQN agent on the game of Montezuma's Revenge.

</details>

<details>

<summary>2018-10-11 07:22:54 - A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies</summary>

- *Homanga Bharadhwaj, Zihan Wang, Yoshua Bengio, Liam Paull*

- `1810.04871v1` - [abs](http://arxiv.org/abs/1810.04871v1) - [pdf](http://arxiv.org/pdf/1810.04871v1)

> Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage \textit{simulation} and \textit{off-policy} data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is trained through a meta-learning strategy in simulation first. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with far fewer real world expert demonstrations, we show successful planning performances in different navigation tasks.

</details>

<details>

<summary>2018-10-11 07:33:54 - Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation</summary>

- *Sarah Tan, Rich Caruana, Giles Hooker, Yin Lou*

- `1710.06169v4` - [abs](http://arxiv.org/abs/1710.06169v4) - [pdf](http://arxiv.org/pdf/1710.06169v4)

> Black-box risk scoring models permeate our lives, yet are typically proprietary or opaque. We propose Distill-and-Compare, a model distillation and comparison approach to audit such models. To gain insight into black-box models, we treat them as teachers, training transparent student models to mimic the risk scores assigned by black-box models. We compare the student model trained with distillation to a second un-distilled transparent model trained on ground-truth outcomes, and use differences between the two models to gain insight into the black-box model. Our approach can be applied in a realistic setting, without probing the black-box model API. We demonstrate the approach on four public data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending Club. We also propose a statistical test to determine if a data set is missing key features used to train the black-box model. Our test finds that the ProPublica data is likely missing key feature(s) used in COMPAS.

</details>

<details>

<summary>2018-10-11 08:16:48 - AFRA: Argumentation framework with recursive attacks</summary>

- *Pietro Baroni, Federico Cerutti, Massimiliano Giacomin, Giovanni Guida*

- `1810.04886v1` - [abs](http://arxiv.org/abs/1810.04886v1) - [pdf](http://arxiv.org/pdf/1810.04886v1)

> The issue of representing attacks to attacks in argumentation is receiving an increasing attention as a useful conceptual modelling tool in several contexts. In this paper we present AFRA, a formalism encompassing unlimited recursive attacks within argumentation frameworks. AFRA satisfies the basic requirements of definition simplicity and rigorous compatibility with Dung's theory of argumentation. This paper provides a complete development of the AFRA formalism complemented by illustrative examples and a detailed comparison with other recursive attack formalizations.

</details>

<details>

<summary>2018-10-11 08:26:59 - Automata for Infinite Argumentation Structures</summary>

- *Pietro Baroni, Federico Cerutti, Paul E. Dunne, Massimiliano Giacomin*

- `1810.04892v1` - [abs](http://arxiv.org/abs/1810.04892v1) - [pdf](http://arxiv.org/pdf/1810.04892v1)

> The theory of abstract argumentation frameworks (afs) has, in the main, focused on finite structures, though there are many significant contexts where argumentation can be regarded as a process involving infinite objects. To address this limitation, in this paper we propose a novel approach for describing infinite afs using tools from formal language theory. In particular, the possibly infinite set of arguments is specified through the language recognized by a deterministic finite automaton while a suitable formalism, called attack expression, is introduced to describe the relation of attack between arguments. The proposed approach is shown to satisfy some desirable properties which can not be achieved through other "naive" uses of formal languages. In particular, the approach is shown to be expressive enough to capture (besides any arbitrary finite structure) a large variety of infinite afs including two major examples from previous literature and two sample cases from the domains of multi-agent negotiation and ambient intelligence. On the computational side, we show that several decision and construction problems which are known to be polynomial time solvable in finite afs are decidable in the context of the proposed formalism and we provide the relevant algorithms. Moreover we obtain additional results concerning the case of finitary afs.

</details>

<details>

<summary>2018-10-11 10:32:54 - Interactive Cognitive Assessment Tools: A Case Study on Digital Pens for the Clinical Assessment of Dementia</summary>

- *Daniel Sonntag*

- `1810.04943v1` - [abs](http://arxiv.org/abs/1810.04943v1) - [pdf](http://arxiv.org/pdf/1810.04943v1)

> Interactive cognitive assessment tools may be valuable for doctors and therapists to reduce costs and improve quality in healthcare systems. Use cases and scenarios include the assessment of dementia. In this paper, we present our approach to the semi-automatic assessment of dementia. We describe a case study with digital pens for the patients including background, problem description and possible solutions. We conclude with lessons learned when implementing digital tests, and a generalisation for use outside the cognitive impairments field.

</details>

<details>

<summary>2018-10-11 12:56:56 - Listening for Sirens: Locating and Classifying Acoustic Alarms in City Scenes</summary>

- *Letizia Marchegiani, Paul Newman*

- `1810.04989v1` - [abs](http://arxiv.org/abs/1810.04989v1) - [pdf](http://arxiv.org/pdf/1810.04989v1)

> This paper is about alerting acoustic event detection and sound source localisation in an urban scenario. Specifically, we are interested in spotting the presence of horns, and sirens of emergency vehicles. In order to obtain a reliable system able to operate robustly despite the presence of traffic noise, which can be copious, unstructured and unpredictable, we propose to treat the spectrograms of incoming stereo signals as images, and apply semantic segmentation, based on a Unet architecture, to extract the target sound from the background noise. In a multi-task learning scheme, together with signal denoising, we perform acoustic event classification to identify the nature of the alerting sound. Lastly, we use the denoised signals to localise the acoustic source on the horizon plane, by regressing the direction of arrival of the sound through a CNN architecture. Our experimental evaluation shows an average classification rate of 94%, and a median absolute error on the localisation of 7.5{\deg} when operating on audio frames of 0.5s, and of 2.5{\deg} when operating on frames of 2.5s. The system offers excellent performance in particularly challenging scenarios, where the noise level is remarkably high.

</details>

<details>

<summary>2018-10-11 13:46:18 - One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL</summary>

- *Tom Le Paine, Sergio Gómez Colmenarejo, Ziyu Wang, Scott Reed, Yusuf Aytar, Tobias Pfaff, Matt W. Hoffman, Gabriel Barth-Maron, Serkan Cabi, David Budden, Nando de Freitas*

- `1810.05017v1` - [abs](http://arxiv.org/abs/1810.05017v1) - [pdf](http://arxiv.org/pdf/1810.05017v1)

> Humans are experts at high-fidelity imitation -- closely mimicking a demonstration, often in one attempt. Humans use this ability to quickly solve a task instance, and to bootstrap learning of new tasks. Achieving these abilities in autonomous agents is an open problem. In this paper, we introduce an off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn both (i) policies for high-fidelity one-shot imitation of diverse novel skills, and (ii) policies that enable the agent to solve tasks more efficiently than the demonstrators. MetaMimic relies on the principle of storing all experiences in a memory and replaying these to learn massive deep neural network policies by off-policy RL. This paper introduces, to the best of our knowledge, the largest existing neural networks for deep RL and shows that larger networks with normalization are needed to achieve one-shot high-fidelity imitation on a challenging manipulation task. The results also show that both types of policy can be learned from vision, in spite of the task rewards being sparse, and without access to demonstrator actions.

</details>

<details>

<summary>2018-10-11 14:47:38 - Identification of Invariant Sensorimotor Structures as a Prerequisite for the Discovery of Objects</summary>

- *Nicolas Le Hir, Olivier Sigaud, Alban Laflaquière*

- `1810.05057v1` - [abs](http://arxiv.org/abs/1810.05057v1) - [pdf](http://arxiv.org/pdf/1810.05057v1)

> Perceiving the surrounding environment in terms of objects is useful for any general purpose intelligent agent. In this paper, we investigate a fundamental mechanism making object perception possible, namely the identification of spatio-temporally invariant structures in the sensorimotor experience of an agent. We take inspiration from the Sensorimotor Contingencies Theory to define a computational model of this mechanism through a sensorimotor, unsupervised and predictive approach. Our model is based on processing the unsupervised interaction of an artificial agent with its environment. We show how spatio-temporally invariant structures in the environment induce regularities in the sensorimotor experience of an agent, and how this agent, while building a predictive model of its sensorimotor experience, can capture them as densely connected subgraphs in a graph of sensory states connected by motor commands. Our approach is focused on elementary mechanisms, and is illustrated with a set of simple experiments in which an agent interacts with an environment. We show how the agent can build an internal model of moving but spatio-temporally invariant structures by performing a Spectral Clustering of the graph modeling its overall sensorimotor experiences. We systematically examine properties of the model, shedding light more globally on the specificities of the paradigm with respect to methods based on the supervised processing of collections of static images.

</details>

<details>

<summary>2018-10-11 15:23:50 - Constructing Trustworthy and Safe Communities on a Blockchain-Enabled Social Credits System</summary>

- *Ronghua Xu, Xuheng Lin, Qi Dong, Yu Chen*

- `1809.01031v2` - [abs](http://arxiv.org/abs/1809.01031v2) - [pdf](http://arxiv.org/pdf/1809.01031v2)

> The emergence of big data and Artificial Intelligence (AI) technology is reshaping the world. While the technological revolution improves the quality of our life, new concerns are triggered. The superhuman capability enables AI to outperform human workers in many data- and/or computing-intensive tasks. Also, digital superpowers are showing arrogance towards individuals, which erodes the trust foundation of the society. In this position paper, we suggest to construct trustworthy and safe communities based on a BLockchain-Enabled Social credits System (BLESS) that rewards the residents who commit in socially beneficial activities. Human being's true value lies in serving other people. The BLESS system is considered as an efficient approach to promote the value and dignity in efforts focused on enhancing our communities and regulating business and private behaviors. The BLESS system leverages the decentralized architecture of the blockchain network, which not only allows grassroots individuals to participate rating process of a social credit system (SCS), but also provides tamper proof of transaction data in the trustless network environment. The anonymity in blockchain records also protects individuals from being targeted in the fight against powerful enterprises. Smart contract enabled authentication and authorization strategy prevents any unauthorized entity from accessing the credit system. The BLESS scheme is promising to offer a secure, transparent and decentralized SCS.

</details>

<details>

<summary>2018-10-11 16:24:23 - Quadratic Decomposable Submodular Function Minimization</summary>

- *Pan Li, Niao He, Olgica Milenkovic*

- `1806.09842v3` - [abs](http://arxiv.org/abs/1806.09842v3) - [pdf](http://arxiv.org/pdf/1806.09842v3)

> We introduce a new convex optimization problem, termed quadratic decomposable submodular function minimization. The problem is closely related to decomposable submodular function minimization and arises in many learning on graphs and hypergraphs settings, such as graph-based semi-supervised learning and PageRank. We approach the problem via a new dual strategy and describe an objective that may be optimized via random coordinate descent (RCD) methods and projections onto cones. We also establish the linear convergence rate of the RCD algorithm and develop efficient projection algorithms with provable performance guarantees. Numerical experiments in semi-supervised learning on hypergraphs confirm the efficiency of the proposed algorithm and demonstrate the significant improvements in prediction accuracy with respect to state-of-the-art methods.

</details>

<details>

<summary>2018-10-11 17:59:49 - Towards Scalable Spectral Clustering via Spectrum-Preserving Sparsification</summary>

- *Yongyu Wang, Zhuo Feng*

- `1710.04584v4` - [abs](http://arxiv.org/abs/1710.04584v4) - [pdf](http://arxiv.org/pdf/1710.04584v4)

> The eigendeomposition of nearest-neighbor (NN) graph Laplacian matrices is the main computational bottleneck in spectral clustering. In this work, we introduce a highly-scalable, spectrum-preserving graph sparsification algorithm that enables to build ultra-sparse NN (u-NN) graphs with guaranteed preservation of the original graph spectrums, such as the first few eigenvectors of the original graph Laplacian. Our approach can immediately lead to scalable spectral clustering of large data networks without sacrificing solution quality. The proposed method starts from constructing low-stretch spanning trees (LSSTs) from the original graphs, which is followed by iteratively recovering small portions of "spectrally critical" off-tree edges to the LSSTs by leveraging a spectral off-tree embedding scheme. To determine the suitable amount of off-tree edges to be recovered to the LSSTs, an eigenvalue stability checking scheme is proposed, which enables to robustly preserve the first few Laplacian eigenvectors within the sparsified graph. Additionally, an incremental graph densification scheme is proposed for identifying extra edges that have been missing in the original NN graphs but can still play important roles in spectral clustering tasks. Our experimental results for a variety of well-known data sets show that the proposed method can dramatically reduce the complexity of NN graphs, leading to significant speedups in spectral clustering.

</details>

<details>

<summary>2018-10-11 18:06:27 - Bilinear Factor Matrix Norm Minimization for Robust PCA: Algorithms and Applications</summary>

- *Fanhua Shang, James Cheng, Yuanyuan Liu, Zhi-Quan Luo, Zhouchen Lin*

- `1810.05186v1` - [abs](http://arxiv.org/abs/1810.05186v1) - [pdf](http://arxiv.org/pdf/1810.05186v1)

> The heavy-tailed distributions of corrupted outliers and singular values of all channels in low-level vision have proven effective priors for many applications such as background modeling, photometric stereo and image alignment. And they can be well modeled by a hyper-Laplacian. However, the use of such distributions generally leads to challenging non-convex, non-smooth and non-Lipschitz problems, and makes existing algorithms very slow for large-scale applications. Together with the analytic solutions to lp-norm minimization with two specific values of p, i.e., p=1/2 and p=2/3, we propose two novel bilinear factor matrix norm minimization models for robust principal component analysis. We first define the double nuclear norm and Frobenius/nuclear hybrid norm penalties, and then prove that they are in essence the Schatten-1/2 and 2/3 quasi-norms, respectively, which lead to much more tractable and scalable Lipschitz optimization problems. Our experimental analysis shows that both our methods yield more accurate solutions than original Schatten quasi-norm minimization, even when the number of observations is very limited. Finally, we apply our penalties to various low-level vision problems, e.g., text removal, moving object detection, image alignment and inpainting, and show that our methods usually outperform the state-of-the-art methods.

</details>

<details>

<summary>2018-10-11 19:34:13 - Inventory Balancing with Online Learning</summary>

- *Wang Chi Cheung, Will Ma, David Simchi-Levi, Xinshang Wang*

- `1810.05640v1` - [abs](http://arxiv.org/abs/1810.05640v1) - [pdf](http://arxiv.org/pdf/1810.05640v1)

> We study a general problem of allocating limited resources to heterogeneous customers over time under model uncertainty. Each type of customer can be serviced using different actions, each of which stochastically consumes some combination of resources, and returns different rewards for the resources consumed. We consider a general model where the resource consumption distribution associated with each (customer type, action)-combination is not known, but is consistent and can be learned over time. In addition, the sequence of customer types to arrive over time is arbitrary and completely unknown.   We overcome both the challenges of model uncertainty and customer heterogeneity by judiciously synthesizing two algorithmic frameworks from the literature: inventory balancing, which "reserves" a portion of each resource for high-reward customer types which could later arrive, and online learning, which shows how to "explore" the resource consumption distributions of each customer type under different actions. We define an auxiliary problem, which allows for existing competitive ratio and regret bounds to be seamlessly integrated. Furthermore, we show that the performance guarantee generated by our framework is tight, that is, we provide an information-theoretic lower bound which shows that both the loss from competitive ratio and the loss for regret are relevant in the combined problem.   Finally, we demonstrate the efficacy of our algorithms on a publicly available hotel data set. Our framework is highly practical in that it requires no historical data (no fitted customer choice models, nor forecasting of customer arrival patterns) and can be used to initialize allocation strategies in fast-changing environments.

</details>

<details>

<summary>2018-10-11 22:47:33 - The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories on German Highways for Validation of Highly Automated Driving Systems</summary>

- *Robert Krajewski, Julian Bock, Laurent Kloeker, Lutz Eckstein*

- `1810.05642v1` - [abs](http://arxiv.org/abs/1810.05642v1) - [pdf](http://arxiv.org/pdf/1810.05642v1)

> Scenario-based testing for the safety validation of highly automated vehicles is a promising approach that is being examined in research and industry. This approach heavily relies on data from real-world scenarios to derive the necessary scenario information for testing. Measurement data should be collected at a reasonable effort, contain naturalistic behavior of road users and include all data relevant for a description of the identified scenarios in sufficient quality. However, the current measurement methods fail to meet at least one of the requirements. Thus, we propose a novel method to measure data from an aerial perspective for scenario-based validation fulfilling the mentioned requirements. Furthermore, we provide a large-scale naturalistic vehicle trajectory dataset from German highways called highD. We evaluate the data in terms of quantity, variety and contained scenarios. Our dataset consists of 16.5 hours of measurements from six locations with 110 000 vehicles, a total driven distance of 45 000 km and 5600 recorded complete lane changes. The highD dataset is available online at: http://www.highD-dataset.com

</details>

<details>

<summary>2018-10-12 01:50:24 - Learning to Reason</summary>

- *Brian Groenke*

- `1810.05315v1` - [abs](http://arxiv.org/abs/1810.05315v1) - [pdf](http://arxiv.org/pdf/1810.05315v1)

> Automated theorem proving has long been a key task of artificial intelligence. Proofs form the bedrock of rigorous scientific inquiry. Many tools for both partially and fully automating their derivations have been developed over the last half a century. Some examples of state-of-the-art provers are E (Schulz, 2013), VAMPIRE (Kov\'acs & Voronkov, 2013), and Prover9 (McCune, 2005-2010). Newer theorem provers, such as E, use superposition calculus in place of more traditional resolution and tableau based methods. There have also been a number of past attempts to apply machine learning methods to guiding proof search. Suttner & Ertel proposed a multilayer-perceptron based method using hand-engineered features as far back as 1990; Urban et al (2011) apply machine learning to tableau calculus; and Loos et al (2017) recently proposed a method for guiding the E theorem prover using deep nerual networks. All of this prior work, however, has one common limitation: they all rely on the axioms of classical first-order logic. Very little attention has been paid to automated theorem proving for non-classical logics. One of the only recent examples is McLaughlin & Pfenning (2008) who applied the polarized inverse method to intuitionistic propositional logic. The literature is otherwise mostly silent. This is truly unfortunate, as there are many reasons to desire non-classical proofs over classical. Constructive/intuitionistic proofs should be of particular interest to computer scientists thanks to the well-known Curry-Howard correspondence (Howard, 1980) which tells us that all terminating programs correspond to a proof in intuitionistic logic and vice versa. This work explores using Q-learning (Watkins, 1989) to inform proof search for a specific system called non-classical logic called Core Logic (Tennant, 2017).

</details>

<details>

<summary>2018-10-12 05:02:29 - On The Equivalence of Tries and Dendrograms - Efficient Hierarchical Clustering of Traffic Data</summary>

- *Chia-Tung Kuo, Ian Davidson*

- `1810.05357v1` - [abs](http://arxiv.org/abs/1810.05357v1) - [pdf](http://arxiv.org/pdf/1810.05357v1)

> The widespread use of GPS-enabled devices generates voluminous and continuous amounts of traffic data but analyzing such data for interpretable and actionable insights poses challenges. A hierarchical clustering of the trips has many uses such as discovering shortest paths, common routes and often traversed areas. However, hierarchical clustering typically has time complexity of $O(n^2 \log n)$ where $n$ is the number of instances, and is difficult to scale to large data sets associated with GPS data. Furthermore, incremental hierarchical clustering is still a developing area. Prefix trees (also called tries) can be efficiently constructed and updated in linear time (in $n$). We show how a specially constructed trie can compactly store the trips and further show this trie is equivalent to a dendrogram that would have been built by classic agglomerative hierarchical algorithms using a specific distance metric. This allows creating hierarchical clusterings of GPS trip data and updating this hierarchy in linear time. %we can extract a meaningful kernel and can also interpret the structure as clusterings of differing granularity as one progresses down the tree. We demonstrate the usefulness of our proposed approach on a real world data set of half a million taxis' GPS traces, well beyond the capabilities of agglomerative clustering methods. Our work is not limited to trip data and can be used with other data with a string representation.

</details>

<details>

<summary>2018-10-12 05:06:40 - Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS)</summary>

- *Chen Luo, Anshumali Shrivastava*

- `1802.07444v3` - [abs](http://arxiv.org/abs/1802.07444v3) - [pdf](http://arxiv.org/pdf/1802.07444v3)

> Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and popular variants of MCMC for problems when an MCMC state consists of an unknown number of components. It is well known that state-of-the-art methods for split-merge MCMC do not scale well. Strategies for rapid mixing requires smart and informative proposals to reduce the rejection rate. However, all known smart proposals involve expensive operations to suggest informative transitions. As a result, the cost of each iteration is prohibitive for massive scale datasets. It is further known that uninformative but computationally efficient proposals, such as random split-merge, leads to extremely slow convergence. This tradeoff between mixing time and per update cost seems hard to get around.   In this paper, we show a sweet spot. We leverage some unique properties of weighted MinHash, which is a popular LSH, to design a novel class of split-merge proposals which are significantly more informative than random sampling but at the same time efficient to compute. Overall, we obtain a superior tradeoff between convergence and per update cost. As a direct consequence, our proposals are around 6X faster than the state-of-the-art sampling methods on two large real datasets KDDCUP and PubMed with several millions of entities and thousands of clusters.

</details>

<details>

<summary>2018-10-12 06:01:22 - Measurement-based adaptation protocol with quantum reinforcement learning</summary>

- *F. Albarrán-Arriagada, J. C. Retamal, E. Solano, L. Lamata*

- `1803.05340v2` - [abs](http://arxiv.org/abs/1803.05340v2) - [pdf](http://arxiv.org/pdf/1803.05340v2)

> Machine learning employs dynamical algorithms that mimic the human capacity to learn, where the reinforcement learning ones are among the most similar to humans in this respect. On the other hand, adaptability is an essential aspect to perform any task efficiently in a changing environment, and it is fundamental for many purposes, such as natural selection. Here, we propose an algorithm based on successive measurements to adapt one quantum state to a reference unknown state, in the sense of achieving maximum overlap. The protocol naturally provides many identical copies of the reference state, such that in each measurement iteration more information about it is obtained. In our protocol, we consider a system composed of three parts, the "environment" system, which provides the reference state copies; the register, which is an auxiliary subsystem that interacts with the environment to acquire information from it; and the agent, which corresponds to the quantum state that is adapted by digital feedback with input corresponding to the outcome of the measurements on the register. With this proposal we can achieve an average fidelity between the environment and the agent of more than $90\% $ with less than $30$ iterations of the protocol. In addition, we extend the formalism to $ d $-dimensional states, reaching an average fidelity of around $80\% $ in less than $400$ iterations for $d=$ 11, for a variety of genuinely quantum and semiclassical states. This work paves the way for the development of quantum reinforcement learning protocols using quantum data and for the future deployment of semi-autonomous quantum systems.

</details>

<details>

<summary>2018-10-12 09:33:18 - Axiomatizing Category Theory in Free Logic</summary>

- *Christoph Benzmüller, Dana S. Scott*

- `1609.01493v5` - [abs](http://arxiv.org/abs/1609.01493v5) - [pdf](http://arxiv.org/pdf/1609.01493v5)

> Starting from a generalization of the standard axioms for a monoid we present a stepwise development of various, mutually equivalent foundational axiom systems for category theory. Our axiom sets have been formalized in the Isabelle/HOL interactive proof assistant, and this formalization utilizes a semantically correct embedding of free logic in classical higher-order logic. The modeling and formal analysis of our axiom sets has been significantly supported by series of experiments with automated reasoning tools integrated with Isabelle/HOL. We also address the relation of our axiom systems to alternative proposals from the literature, including an axiom set proposed by Freyd and Scedrov for which we reveal a technical issue (when encoded in free logic where free variables range over defined and undefined objects): either all operations, e.g. morphism composition, are total or their axiom system is inconsistent. The repair for this problem is quite straightforward, however.

</details>

<details>

<summary>2018-10-12 12:48:34 - U-Net: Machine Reading Comprehension with Unanswerable Questions</summary>

- *Fu Sun, Linyang Li, Xipeng Qiu, Yang Liu*

- `1810.06638v1` - [abs](http://arxiv.org/abs/1810.06638v1) - [pdf](http://arxiv.org/pdf/1810.06638v1)

> Machine reading comprehension with unanswerable questions is a new challenging task for natural language processing. A key subtask is to reliably predict whether the question is unanswerable. In this paper, we propose a unified model, called U-Net, with three important components: answer pointer, no-answer pointer, and answer verifier. We introduce a universal node and thus process the question and its context passage as a single contiguous sequence of tokens. The universal node encodes the fused information from both the question and passage, and plays an important role to predict whether the question is answerable and also greatly improves the conciseness of the U-Net. Different from the state-of-art pipeline models, U-Net can be learned in an end-to-end fashion. The experimental results on the SQuAD 2.0 dataset show that U-Net can effectively predict the unanswerability of questions and achieves an F1 score of 71.7 on SQuAD 2.0.

</details>

<details>

<summary>2018-10-12 13:17:35 - SmartPM: Automatic Adaptation of Dynamic Processes at Run-Time</summary>

- *Andrea Marrella*

- `1810.06374v1` - [abs](http://arxiv.org/abs/1810.06374v1) - [pdf](http://arxiv.org/pdf/1810.06374v1)

> The research activity outlined in this PhD thesis is devoted to define a general approach, a concrete architecture and a prototype Process Management System (PMS) for the automated adaptation of dynamic processes at run-time, on the basis of a declarative specification of process tasks and relying on well-established reasoning about actions and planning techniques. The purpose is to demonstrate that the combination of procedural and imperative models with declarative elements, along with the exploitation of techniques from the field of artificial intelligence (AI), such as Situation Calculus, IndiGolog and automated planning, can increase the ability of existing PMSs of supporting dynamic processes. To this end, a prototype PMS named SmartPM, which is specifically tailored for supporting collaborative work of process participants during pervasive scenarios, has been developed. The adaptation mechanism deployed on SmartPM is based on execution monitoring for detecting failures at run-time, which does not require the definition of the adaptation strategy in the process itself (as most of the current approaches do), and on automatic planning techniques for the synthesis of the recovery procedure.

</details>

<details>

<summary>2018-10-12 15:04:14 - Bayesian Inference of Self-intention Attributed by Observer</summary>

- *Yosuke Fukuchi, Masahiko Osawa, Hiroshi Yamakawa, Tatsuji Takahashi, Michita Imai*

- `1810.05564v1` - [abs](http://arxiv.org/abs/1810.05564v1) - [pdf](http://arxiv.org/pdf/1810.05564v1)

> Most of agents that learn policy for tasks with reinforcement learning (RL) lack the ability to communicate with people, which makes human-agent collaboration challenging. We believe that, in order for RL agents to comprehend utterances from human colleagues, RL agents must infer the mental states that people attribute to them because people sometimes infer an interlocutor's mental states and communicate on the basis of this mental inference. This paper proposes PublicSelf model, which is a model of a person who infers how the person's own behavior appears to their colleagues. We implemented the PublicSelf model for an RL agent in a simulated environment and examined the inference of the model by comparing it with people's judgment. The results showed that the agent's intention that people attributed to the agent's movement was correctly inferred by the model in scenes where people could find certain intentionality from the agent's behavior.

</details>

<details>

<summary>2018-10-12 16:48:29 - Analysis and Optimization of Deep Counterfactual Value Networks</summary>

- *Patryk Hopner, Eneldo Loza Mencía*

- `1807.00900v2` - [abs](http://arxiv.org/abs/1807.00900v2) - [pdf](http://arxiv.org/pdf/1807.00900v2)

> Recently a strong poker-playing algorithm called DeepStack was published, which is able to find an approximate Nash equilibrium during gameplay by using heuristic values of future states predicted by deep neural networks. This paper analyzes new ways of encoding the inputs and outputs of DeepStack's deep counterfactual value networks based on traditional abstraction techniques, as well as an unabstracted encoding, which was able to increase the network's accuracy.

</details>

<details>

<summary>2018-10-12 18:26:04 - Rough Concept Analysis</summary>

- *Robert E. Kent*

- `1810.06986v1` - [abs](http://arxiv.org/abs/1810.06986v1) - [pdf](http://arxiv.org/pdf/1810.06986v1)

> The theory introduced, presented and developed in this paper, is concerned with Rough Concept Analysis. This theory is a synthesis of the theory of Rough Sets pioneered by Zdzislaw Pawlak with the theory of Formal Concept Analysis pioneered by Rudolf Wille. The central notion in this paper of a rough formal concept combines in a natural fashion the notion of a rough set with the notion of a formal concept: "rough set + formal concept = rough formal concept". A follow-up paper will provide a synthesis of the two important data modeling techniques: conceptual scaling of Formal Concept Analysis and Entity-Relationship database modeling.

</details>

<details>

<summary>2018-10-12 19:54:11 - Formal Concept Analysis with Many-sorted Attributes</summary>

- *Robert E. Kent, John Brady*

- `1810.05703v1` - [abs](http://arxiv.org/abs/1810.05703v1) - [pdf](http://arxiv.org/pdf/1810.05703v1)

> This paper unites two problem-solving traditions in computer science: (1) constraint-based reasoning, and (2) formal concept analysis. For basic definitions and properties of networks of constraints, we follow the foundational approach of Montanari and Rossi. This paper advocates distributed relations as a more semantic version of networks of constraints. The theory developed here uses the theory of formal concept analysis, pioneered by Rudolf Wille and his colleagues, as a key for unlocking the hidden semantic structure within distributed relations. Conversely, this paper offers distributed relations as a seamless many-sorted extension to the formal contexts of formal concept analysis. Some of the intuitions underlying our approach were discussed in a preliminary fashion by Freuder and Wallace.

</details>

<details>

<summary>2018-10-12 20:54:40 - Interpreting Adversarial Robustness: A View from Decision Surface in Input Space</summary>

- *Fuxun Yu, Chenchen Liu, Yanzhi Wang, Liang Zhao, Xiang Chen*

- `1810.00144v2` - [abs](http://arxiv.org/abs/1810.00144v2) - [pdf](http://arxiv.org/pdf/1810.00144v2)

> One popular hypothesis of neural network generalization is that the flat local minima of loss surface in parameter space leads to good generalization. However, we demonstrate that loss surface in parameter space has no obvious relationship with generalization, especially under adversarial settings. Through visualizing decision surfaces in both parameter space and input space, we instead show that the geometry property of decision surface in input space correlates well with the adversarial robustness. We then propose an adversarial robustness indicator, which can evaluate a neural network's intrinsic robustness property without testing its accuracy under adversarial attacks. Guided by it, we further propose our robust training method. Without involving adversarial training, our method could enhance network's intrinsic adversarial robustness against various adversarial attacks.

</details>

<details>

<summary>2018-10-12 22:58:12 - Exploration vs. Exploitation in Team Formation</summary>

- *Ramesh Johari, Vijay Kamble, Anilesh K. Krishnaswamy, Hannah Li*

- `1809.06937v2` - [abs](http://arxiv.org/abs/1809.06937v2) - [pdf](http://arxiv.org/pdf/1809.06937v2)

> An online labor platform faces an online learning problem in matching workers with jobs and using the performance on these jobs to create better future matches. This learning problem is complicated by the rise of complex tasks on these platforms, such as web development and product design, that require a team of workers to complete. The success of a job is now a function of the skills and contributions of all workers involved, which may be unknown to both the platform and the client who posted the job. These team matchings result in a structured correlation between what is known about the individuals and this information can be utilized to create better future matches. We analyze two natural settings where the performance of a team is dictated by its strongest and its weakest member, respectively. We find that both problems pose an exploration-exploitation tradeoff between learning the performance of untested teams and repeating previously tested teams that resulted in a good performance. We establish fundamental regret bounds and design near-optimal algorithms that uncover several insights into these tradeoffs.

</details>

<details>

<summary>2018-10-12 23:58:42 - A Model for Auto-Programming for General Purposes</summary>

- *Juyang Weng*

- `1810.05764v1` - [abs](http://arxiv.org/abs/1810.05764v1) - [pdf](http://arxiv.org/pdf/1810.05764v1)

> The Universal Turing Machine (TM) is a model for VonNeumann computers --- general-purpose computers. A human brain can inside-skull-automatically learn a universal TM so that he acts as a general-purpose computer and writes a computer program for any practical purposes. It is unknown whether a machine can accomplish the same. This theoretical work shows how the Developmental Network (DN) can accomplish this. Unlike a traditional TM, the TM learned by DN is a super TM --- Grounded, Emergent, Natural, Incremental, Skulled, Attentive, Motivated, and Abstractive (GENISAMA). A DN is free of any central controller (e.g., Master Map, convolution, or error back-propagation). Its learning from a teacher TM is one transition observation at a time, immediate, and error-free until all its neurons have been initialized by early observed teacher transitions. From that point on, the DN is no longer error-free but is always optimal at every time instance in the sense of maximal likelihood, conditioned on its limited computational resources and the learning experience. This letter also extends the Church-Turing thesis to automatic programming for general purposes and sketchily proved it.

</details>

<details>

<summary>2018-10-13 00:02:54 - Hierarchical Game-Theoretic Planning for Autonomous Vehicles</summary>

- *Jaime F. Fisac, Eli Bronstein, Elis Stefansson, Dorsa Sadigh, S. Shankar Sastry, Anca D. Dragan*

- `1810.05766v1` - [abs](http://arxiv.org/abs/1810.05766v1) - [pdf](http://arxiv.org/pdf/1810.05766v1)

> The actions of an autonomous vehicle on the road affect and are affected by those of other drivers, whether overtaking, negotiating a merge, or avoiding an accident. This mutual dependence, best captured by dynamic game theory, creates a strong coupling between the vehicle's planning and its predictions of other drivers' behavior, and constitutes an open problem with direct implications on the safety and viability of autonomous driving technology. Unfortunately, dynamic games are too computationally demanding to meet the real-time constraints of autonomous driving in its continuous state and action space. In this paper, we introduce a novel game-theoretic trajectory planning algorithm for autonomous driving, that enables real-time performance by hierarchically decomposing the underlying dynamic game into a long-horizon "strategic" game with simplified dynamics and full information structure, and a short-horizon "tactical" game with full dynamics and a simplified information structure. The value of the strategic game is used to guide the tactical planning, implicitly extending the planning horizon, pushing the local trajectory optimization closer to global solutions, and, most importantly, quantitatively accounting for the autonomous vehicle and the human driver's ability and incentives to influence each other. In addition, our approach admits non-deterministic models of human decision-making, rather than relying on perfectly rational predictions. Our results showcase richer, safer, and more effective autonomous behavior in comparison to existing techniques.

</details>

<details>

<summary>2018-10-13 02:02:17 - A systematic study of the class imbalance problem in convolutional neural networks</summary>

- *Mateusz Buda, Atsuto Maki, Maciej A. Mazurowski*

- `1710.05381v2` - [abs](http://arxiv.org/abs/1710.05381v2) - [pdf](http://arxiv.org/pdf/1710.05381v2)

> In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.

</details>

<details>

<summary>2018-10-13 06:58:46 - Efficient Multi-level Correlating for Visual Tracking</summary>

- *Yipeng Ma, Chun Yuan, Peng Gao, Fei Wang*

- `1810.05810v1` - [abs](http://arxiv.org/abs/1810.05810v1) - [pdf](http://arxiv.org/pdf/1810.05810v1)

> Correlation filter (CF) based tracking algorithms have demonstrated favorable performance recently. Nevertheless, the top performance trackers always employ complicated optimization methods which constraint their real-time applications. How to accelerate the tracking speed while retaining the tracking accuracy is a significant issue. In this paper, we propose a multi-level CF-based tracking approach named MLCFT which further explores the potential capacity of CF with two-stage detection: primal detection and oriented re-detection. The cascaded detection scheme is simple but competent to prevent model drift and accelerate the speed. An effective fusion method based on relative entropy is introduced to combine the complementary features extracted from deep and shallow layers of convolutional neural networks (CNN). Moreover, a novel online model update strategy is utilized in our tracker, which enhances the tracking performance further. Experimental results demonstrate that our proposed approach outperforms the most state-of-the-art trackers while tracking at speed of exceeded 16 frames per second on challenging benchmarks.

</details>

<details>

<summary>2018-10-13 07:06:14 - High Performance Visual Tracking with Circular and Structural Operators</summary>

- *Peng Gao, Yipeng Ma, Ke Song, Chao Li, Fei Wang, Liyi Xiao, Yan Zhang*

- `1804.08208v3` - [abs](http://arxiv.org/abs/1804.08208v3) - [pdf](http://arxiv.org/pdf/1804.08208v3)

> In this paper, a novel circular and structural operator tracker (CSOT) is proposed for high performance visual tracking, it not only possesses the powerful discriminative capability of SOSVM but also efficiently inherits the superior computational efficiency of DCF. Based on the proposed circular and structural operators, a set of primal confidence score maps can be obtained by circular correlating feature maps with their corresponding structural correlation filters. Furthermore, an implicit interpolation is applied to convert the multi-resolution feature maps to the continuous domain and make all primal confidence score maps have the same spatial resolution. Then, we exploit an efficient ensemble post-processor based on relative entropy, which can coalesce primal confidence score maps and create an optimal confidence score map for more accurate localization. The target is localized on the peak of the optimal confidence score map. Besides, we introduce a collaborative optimization strategy to update circular and structural operators by iteratively training structural correlation filters, which significantly reduces computational complexity and improves robustness. Experimental results demonstrate that our approach achieves state-of-the-art performance in mean AUC scores of 71.5% and 69.4% on the OTB-2013 and OTB-2015 benchmarks respectively, and obtains a third-best expected average overlap (EAO) score of 29.8% on the VOT-2017 benchmark.

</details>

<details>

<summary>2018-10-13 07:50:04 - Categorical Aspects of Parameter Learning</summary>

- *Bart Jacobs*

- `1810.05814v1` - [abs](http://arxiv.org/abs/1810.05814v1) - [pdf](http://arxiv.org/pdf/1810.05814v1)

> Parameter learning is the technique for obtaining the probabilistic parameters in conditional probability tables in Bayesian networks from tables with (observed) data --- where it is assumed that the underlying graphical structure is known. There are basically two ways of doing so, referred to as maximal likelihood estimation (MLE) and as Bayesian learning. This paper provides a categorical analysis of these two techniques and describes them in terms of basic properties of the multiset monad M, the distribution monad D and the Giry monad G. In essence, learning is about the reltionships between multisets (used for counting) on the one hand and probability distributions on the other. These relationsips will be described as suitable natural transformations.

</details>

<details>

<summary>2018-10-13 12:18:57 - Overview of CAIL2018: Legal Judgment Prediction Competition</summary>

- *Haoxi Zhong, Chaojun Xiao, Zhipeng Guo, Cunchao Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng, Xianpei Han, Zhen Hu, Heng Wang, Jianfeng Xu*

- `1810.05851v1` - [abs](http://arxiv.org/abs/1810.05851v1) - [pdf](http://arxiv.org/pdf/1810.05851v1)

> In this paper, we give an overview of the Legal Judgment Prediction (LJP) competition at Chinese AI and Law challenge (CAIL2018). This competition focuses on LJP which aims to predict the judgment results according to the given facts. Specifically, in CAIL2018 , we proposed three subtasks of LJP for the contestants, i.e., predicting relevant law articles, charges and prison terms given the fact descriptions. CAIL2018 has attracted several hundreds participants (601 teams, 1, 144 contestants from 269 organizations). In this paper, we provide a detailed overview of the task definition, related works, outstanding methods and competition results in CAIL2018.

</details>

<details>

<summary>2018-10-13 13:53:32 - PDNet: Prior-model Guided Depth-enhanced Network for Salient Object Detection</summary>

- *Chunbiao Zhu, Xing Cai, Kan Huang, Thomas H Li, Ge Li*

- `1803.08636v2` - [abs](http://arxiv.org/abs/1803.08636v2) - [pdf](http://arxiv.org/pdf/1803.08636v2)

> Fully convolutional neural networks (FCNs) have shown outstanding performance in many computer vision tasks including salient object detection. However, there still remains two issues needed to be addressed in deep learning based saliency detection. One is the lack of tremendous amount of annotated data to train a network. The other is the lack of robustness for extracting salient objects in images containing complex scenes. In this paper, we present a new architecture$ - $PDNet, a robust prior-model guided depth-enhanced network for RGB-D salient object detection. In contrast to existing works, in which RGB-D values of image pixels are fed directly to a network, the proposed architecture is composed of a master network for processing RGB values, and a sub-network making full use of depth cues and incorporate depth-based features into the master network. To overcome the limited size of the labeled RGB-D dataset for training, we employ a large conventional RGB dataset to pre-train the master network, which proves to contribute largely to the final accuracy. Extensive evaluations over five benchmark datasets demonstrate that our proposed method performs favorably against the state-of-the-art approaches.

</details>

<details>

<summary>2018-10-13 17:56:03 - Towards Formal Definitions of Blameworthiness, Intention, and Moral Responsibility</summary>

- *Joseph Y. Halpern, Max Kleiman-Weiner*

- `1810.05903v1` - [abs](http://arxiv.org/abs/1810.05903v1) - [pdf](http://arxiv.org/pdf/1810.05903v1)

> We provide formal definitions of degree of blameworthiness and intention relative to an epistemic state (a probability over causal models and a utility function on outcomes). These, together with a definition of actual causality, provide the key ingredients for moral responsibility judgments. We show that these definitions give insight into commonsense intuitions in a variety of puzzling cases from the literature.

</details>

<details>

<summary>2018-10-13 20:01:54 - Two Can Play That Game: An Adversarial Evaluation of a Cyber-alert Inspection System</summary>

- *Ankit Shah, Arunesh Sinha, Rajesh Ganesan, Sushil Jajodia, Hasan Cam*

- `1810.05921v1` - [abs](http://arxiv.org/abs/1810.05921v1) - [pdf](http://arxiv.org/pdf/1810.05921v1)

> Cyber-security is an important societal concern. Cyber-attacks have increased in numbers as well as in the extent of damage caused in every attack. Large organizations operate a Cyber Security Operation Center (CSOC), which form the first line of cyber-defense. The inspection of cyber-alerts is a critical part of CSOC operations. A recent work, in collaboration with Army Research Lab, USA proposed a reinforcement learning (RL) based approach to prevent the cyber-alert queue length from growing large and overwhelming the defender. Given the potential deployment of this approach to CSOCs run by US defense agencies, we perform a red team (adversarial) evaluation of this approach. Further, with the recent attacks on learning systems, it is even more important to test the limits of this RL approach. Towards that end, we learn an adversarial alert generation policy that is a best response to the defender inspection policy. Surprisingly, we find the defender policy to be quite robust to the best response of the attacker. In order to explain this observation, we extend the earlier RL model to a game model and show that there exists defender policies that can be robust against any adversarial policy. We also derive a competitive baseline from the game theory model and compare it to the RL approach. However, we go further to exploit assumptions made in the MDP in the RL model and discover an attacker policy that overwhelms the defender. We use a double oracle approach to retrain the defender with episodes from this discovered attacker policy. This made the defender robust to the discovered attacker policy and no further harmful attacker policies were discovered. Overall, the adversarial RL and double oracle approach in RL are general techniques that are applicable to other RL usage in adversarial environments.

</details>

<details>

<summary>2018-10-14 02:37:46 - Tentacular Artificial Intelligence, and the Architecture Thereof, Introduced</summary>

- *Selmer Bringsjord, Naveen Sundar Govindarajulu, Atriya Sen, Matthew Peveler, Biplav Srivastava, Kartik Talamadupula*

- `1810.07007v1` - [abs](http://arxiv.org/abs/1810.07007v1) - [pdf](http://arxiv.org/pdf/1810.07007v1)

> We briefly introduce herein a new form of distributed, multi-agent artificial intelligence, which we refer to as "tentacular." Tentacular AI is distinguished by six attributes, which among other things entail a capacity for reasoning and planning based in highly expressive calculi (logics), and which enlists subsidiary agents across distances circumscribed only by the reach of one or more given networks.

</details>

<details>

<summary>2018-10-14 06:34:18 - Finding Similar Medical Questions from Question Answering Websites</summary>

- *Yaliang Li, Liuyi Yao, Nan Du, Jing Gao, Qi Li, Chuishi Meng, Chenwei Zhang, Wei Fan*

- `1810.05983v1` - [abs](http://arxiv.org/abs/1810.05983v1) - [pdf](http://arxiv.org/pdf/1810.05983v1)

> The past few years have witnessed the flourishing of crowdsourced medical question answering (Q&A) websites. Patients who have medical information demands tend to post questions about their health conditions on these crowdsourced Q&A websites and get answers from other users. However, we observe that a large portion of new medical questions cannot be answered in time or receive only few answers from these websites. On the other hand, we notice that solved questions have great potential to solve this challenge. Motivated by these, we propose an end-to-end system that can automatically find similar questions for unsolved medical questions. By learning the vector presentation of unsolved questions and their candidate similar questions, the proposed system outputs similar questions according to the similarity between vector representations. Through the vector representation, the similar questions are found at the question level, and the diversity of medical questions expression issue can be addressed. Further, we handle two more important issues, i.e., training data generation issue and efficiency issue, associated with the LSTM training procedure and the retrieval of candidate similar questions. The effectiveness of the proposed system is validated on a large-scale real-world dataset collected from a crowdsourced maternal-infant Q&A website.

</details>

<details>

<summary>2018-10-14 08:04:43 - Lung Structures Enhancement in Chest Radiographs via CT based FCNN Training</summary>

- *Ophir Gozes, Hayit Greenspan*

- `1810.05989v1` - [abs](http://arxiv.org/abs/1810.05989v1) - [pdf](http://arxiv.org/pdf/1810.05989v1)

> The abundance of overlapping anatomical structures appearing in chest radiographs can reduce the performance of lung pathology detection by automated algorithms (CAD) as well as the human reader. In this paper, we present a deep learning based image processing technique for enhancing the contrast of soft lung structures in chest radiographs using Fully Convolutional Neural Networks (FCNN). Two 2D FCNN architectures were trained to accomplish the task: The first performs 2D lung segmentation which is used for normalization of the lung area. The second FCNN is trained to extract lung structures. To create the training images, we employed Simulated X-Ray or Digitally Reconstructed Radiographs (DRR) derived from 516 scans belonging to the LIDC-IDRI dataset. By first segmenting the lungs in the CT domain, we are able to create a dataset of 2D lung masks to be used for training the segmentation FCNN. For training the extraction FCNN, we create DRR images of only voxels belonging to the 3D lung segmentation which we call "Lung X-ray" and use them as target images. Once the lung structures are extracted, the original image can be enhanced by fusing the original input x-ray and the synthesized "Lung X-ray". We show that our enhancement technique is applicable to real x-ray data, and display our results on the recently released NIH Chest X-Ray-14 dataset. We see promising results when training a DenseNet-121 based architecture to work directly on the lung enhanced X-ray images.

</details>

<details>

<summary>2018-10-14 11:40:30 - AAAI FSS-18: Artificial Intelligence in Government and Public Sector Proceedings</summary>

- *Frank Stein, Alun Preece, Mihai Boicu*

- `1810.06018v1` - [abs](http://arxiv.org/abs/1810.06018v1) - [pdf](http://arxiv.org/pdf/1810.06018v1)

> Proceedings of the AAAI Fall Symposium on Artificial Intelligence in Government and Public Sector, Arlington, Virginia, USA, October 18-20, 2018

</details>

<details>

<summary>2018-10-14 13:15:09 - Internal Model from Observations for Reward Shaping</summary>

- *Daiki Kimura, Subhajit Chaudhury, Ryuki Tachibana, Sakyasingha Dasgupta*

- `1806.01267v4` - [abs](http://arxiv.org/abs/1806.01267v4) - [pdf](http://arxiv.org/pdf/1806.01267v4)

> Reinforcement learning methods require careful design involving a reward function to obtain the desired action policy for a given task. In the absence of hand-crafted reward functions, prior work on the topic has proposed several methods for reward estimation by using expert state trajectories and action pairs. However, there are cases where complete or good action information cannot be obtained from expert demonstrations. We propose a novel reinforcement learning method in which the agent learns an internal model of observation on the basis of expert-demonstrated state trajectories to estimate rewards without completely learning the dynamics of the external environment from state-action pairs. The internal model is obtained in the form of a predictive model for the given expert state distribution. During reinforcement learning, the agent predicts the reward as a function of the difference between the actual state and the state predicted by the internal model. We conducted multiple experiments in environments of varying complexity, including the Super Mario Bros and Flappy Bird games. We show our method successfully trains good policies directly from expert game-play videos.

</details>

<details>

<summary>2018-10-14 15:26:24 - Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost</summary>

- *Henry Zhu, Abhishek Gupta, Aravind Rajeswaran, Sergey Levine, Vikash Kumar*

- `1810.06045v1` - [abs](http://arxiv.org/abs/1810.06045v1) - [pdf](http://arxiv.org/pdf/1810.06045v1)

> Dexterous multi-fingered robotic hands can perform a wide range of manipulation skills, making them an appealing component for general-purpose robotic manipulators. However, such hands pose a major challenge for autonomous control, due to the high dimensionality of their configuration space and complex intermittent contact interactions. In this work, we propose deep reinforcement learning (deep RL) as a scalable solution for learning complex, contact rich behaviors with multi-fingered hands. Deep RL provides an end-to-end approach to directly map sensor readings to actions, without the need for task specific models or policy classes. We show that contact-rich manipulation behavior with multi-fingered hands can be learned by directly training with model-free deep RL algorithms in the real world, with minimal additional assumption and without the aid of simulation. We learn a variety of complex behaviors on two different low-cost hardware platforms. We show that each task can be learned entirely from scratch, and further study how the learning process can be further accelerated by using a small number of human demonstrations to bootstrap learning. Our experiments demonstrate that complex multi-fingered manipulation skills can be learned in the real world in about 4-7 hours for most tasks, and that demonstrations can decrease this to 2-3 hours, indicating that direct deep RL training in the real world is a viable and practical alternative to simulation and model-based control. \url{https://sites.google.com/view/deeprl-handmanipulation}

</details>

<details>

<summary>2018-10-14 18:49:33 - Assessing the Potential of Classical Q-learning in General Game Playing</summary>

- *Hui Wang, Michael Emmerich, Aske Plaat*

- `1810.06078v1` - [abs](http://arxiv.org/abs/1810.06078v1) - [pdf](http://arxiv.org/pdf/1810.06078v1)

> After the recent groundbreaking results of AlphaGo and AlphaZero, we have seen strong interests in deep reinforcement learning and artificial general intelligence (AGI) in game playing. However, deep learning is resource-intensive and the theory is not yet well developed. For small games, simple classical table-based Q-learning might still be the algorithm of choice. General Game Playing (GGP) provides a good testbed for reinforcement learning to research AGI. Q-learning is one of the canonical reinforcement learning methods, and has been used by (Banerjee $\&$ Stone, IJCAI 2007) in GGP. In this paper we implement Q-learning in GGP for three small-board games (Tic-Tac-Toe, Connect Four, Hex)\footnote{source code: https://github.com/wh1992v/ggp-rl}, to allow comparison to Banerjee et al.. We find that Q-learning converges to a high win rate in GGP. For the $\epsilon$-greedy strategy, we propose a first enhancement, the dynamic $\epsilon$ algorithm. In addition, inspired by (Gelly $\&$ Silver, ICML 2007) we combine online search (Monte Carlo Search) to enhance offline learning, and propose QM-learning for GGP. Both enhancements improve the performance of classical Q-learning. In this work, GGP allows us to show, if augmented by appropriate enhancements, that classical table-based Q-learning can perform well in small games.

</details>

<details>

<summary>2018-10-14 19:11:19 - Conceptual Collectives</summary>

- *Robert E. Kent*

- `1810.07632v1` - [abs](http://arxiv.org/abs/1810.07632v1) - [pdf](http://arxiv.org/pdf/1810.07632v1)

> The notions of formal contexts and concept lattices, although introduced by Wille only ten years ago, already have proven to be of great utility in various applications such as data analysis and knowledge representation. In this paper we give arguments that Wille's original notion of formal context, although quite appealing in its simplicity, now should be replaced by a more semantic notion. This new notion of formal context entails a modified approach to concept construction. We base our arguments for these new versions of formal context and concept construction upon Wille's philosophical attitude with reference to the intensional aspect of concepts. We give a brief development of the relational theory of formal contexts and concept construction, demonstrating the equivalence of "concept-lattice construction" of Wille with the well-known "completion by cuts" of MacNeille. Generalization and abstraction of these formal contexts offers a powerful approach to knowledge representation.

</details>

<details>

<summary>2018-10-14 22:41:11 - Variational Neural Networks: Every Layer and Neuron Can Be Unique</summary>

- *Yiwei Li, Enzhi Li*

- `1810.06120v1` - [abs](http://arxiv.org/abs/1810.06120v1) - [pdf](http://arxiv.org/pdf/1810.06120v1)

> The choice of activation function can significantly influence the performance of neural networks. The lack of guiding principles for the selection of activation function is lamentable. We try to address this issue by introducing our variational neural networks, where the activation function is represented as a linear combination of possible candidate functions, and an optimal activation is obtained via minimization of a loss function using gradient descent method. The gradient formulae for the loss function with respect to these expansion coefficients are central for the implementation of gradient descent algorithm, and here we derive these gradient formulae.

</details>

<details>

<summary>2018-10-15 06:10:30 - The Challenge of Crafting Intelligible Intelligence</summary>

- *Daniel S. Weld, Gagan Bansal*

- `1803.04263v3` - [abs](http://arxiv.org/abs/1803.04263v3) - [pdf](http://arxiv.org/pdf/1803.04263v3)

> Since Artificial Intelligence (AI) software uses techniques like deep lookahead search and stochastic optimization of huge neural networks to fit mammoth datasets, it often results in complex behavior that is difficult for people to understand. Yet organizations are deploying AI algorithms in many mission-critical settings. To trust their behavior, we must make AI intelligible, either by using inherently interpretable models or by developing new methods for explaining and controlling otherwise overwhelmingly complex decisions using local approximation, vocabulary alignment, and interactive explanation. This paper argues that intelligibility is essential, surveys recent work on building such systems, and highlights key directions for research.

</details>

<details>

<summary>2018-10-15 06:56:48 - YouTube AV 50K: An Annotated Corpus for Comments in Autonomous Vehicles</summary>

- *Tao Li, Lei Lin, Minsoo Choi, Kaiming Fu, Siyuan Gong, Jian Wang*

- `1807.11227v4` - [abs](http://arxiv.org/abs/1807.11227v4) - [pdf](http://arxiv.org/pdf/1807.11227v4)

> With one billion monthly viewers, and millions of users discussing and sharing opinions, comments below YouTube videos are rich sources of data for opinion mining and sentiment analysis. We introduce the YouTube AV 50K dataset, a freely-available collections of more than 50,000 YouTube comments and metadata below autonomous vehicle (AV)-related videos. We describe its creation process, its content and data format, and discuss its possible usages. Especially, we do a case study of the first self-driving car fatality to evaluate the dataset, and show how we can use this dataset to better understand public attitudes toward self-driving cars and public reactions to the accident. Future developments of the dataset are also discussed.

</details>

<details>

<summary>2018-10-15 08:09:24 - AI Benchmark: Running Deep Neural Networks on Android Smartphones</summary>

- *Andrey Ignatov, Radu Timofte, William Chou, Ke Wang, Max Wu, Tim Hartley, Luc Van Gool*

- `1810.01109v2` - [abs](http://arxiv.org/abs/1810.01109v2) - [pdf](http://arxiv.org/pdf/1810.01109v2)

> Over the last years, the computational power of mobile devices such as smartphones and tablets has grown dramatically, reaching the level of desktop computers available not long ago. While standard smartphone apps are no longer a problem for them, there is still a group of tasks that can easily challenge even high-end devices, namely running artificial intelligence algorithms. In this paper, we present a study of the current state of deep learning in the Android ecosystem and describe available frameworks, programming models and the limitations of running AI on smartphones. We give an overview of the hardware acceleration resources available on four main mobile chipset platforms: Qualcomm, HiSilicon, MediaTek and Samsung. Additionally, we present the real-world performance results of different mobile SoCs collected with AI Benchmark that are covering all main existing hardware configurations.

</details>

<details>

<summary>2018-10-15 10:55:24 - Term Set Expansion based NLP Architect by Intel AI Lab</summary>

- *Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Alon Eirew, Yael Green, Shira Guskin, Peter Izsak, Daniel Korat*

- `1808.08953v2` - [abs](http://arxiv.org/abs/1808.08953v2) - [pdf](http://arxiv.org/pdf/1808.08953v2)

> We present SetExpander, a corpus-based system for expanding a seed set of terms into amore complete set of terms that belong to the same semantic class. SetExpander implements an iterative end-to-end workflow. It enables users to easily select a seed set of terms, expand it, view the expanded set, validate it, re-expand the validated set and store it, thus simplifying the extraction of domain-specific fine-grained semantic classes.SetExpander has been used successfully in real-life use cases including integration into an automated recruitment system and an issues and defects resolution system. A video demo of SetExpander is available at https://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images were blurred for privacy reasons)

</details>

<details>

<summary>2018-10-15 13:13:48 - Towards Providing Explanations for AI Planner Decisions</summary>

- *Rita Borgo, Michael Cashmore, Daniele Magazzeni*

- `1810.06338v1` - [abs](http://arxiv.org/abs/1810.06338v1) - [pdf](http://arxiv.org/pdf/1810.06338v1)

> In order to engender trust in AI, humans must understand what an AI system is trying to achieve, and why. To overcome this problem, the underlying AI process must produce justifications and explanations that are both transparent and comprehensible to the user. AI Planning is well placed to be able to address this challenge. In this paper we present a methodology to provide initial explanations for the decisions made by the planner. Explanations are created by allowing the user to suggest alternative actions in plans and then compare the resulting plans with the one found by the planner. The methodology is implemented in the new XAI-Plan framework.

</details>

<details>

<summary>2018-10-15 13:20:56 - Deep Reinforcement Learning</summary>

- *Yuxi Li*

- `1810.06339v1` - [abs](http://arxiv.org/abs/1810.06339v1) - [pdf](http://arxiv.org/pdf/1810.06339v1)

> We discuss deep reinforcement learning in an overview style. We draw a big picture, filled with details. We discuss six core elements, six important mechanisms, and twelve applications, focusing on contemporary work, and in historical contexts. We start with background of artificial intelligence, machine learning, deep learning, and reinforcement learning (RL), with resources. Next we discuss RL core elements, including value function, policy, reward, model, exploration vs. exploitation, and representation. Then we discuss important mechanisms for RL, including attention and memory, unsupervised learning, hierarchical RL, multi-agent RL, relational RL, and learning to learn. After that, we discuss RL applications, including games, robotics, natural language processing (NLP), computer vision, finance, business management, healthcare, education, energy, transportation, computer systems, and, science, engineering, and art. Finally we summarize briefly, discuss challenges and opportunities, and close with an epilogue.

</details>

<details>

<summary>2018-10-15 14:56:02 - SilentPhone: Inferring User Unavailability based Opportune Moments to Minimize Call Interruptions</summary>

- *Iqbal H. Sarker*

- `1810.10958v1` - [abs](http://arxiv.org/abs/1810.10958v1) - [pdf](http://arxiv.org/pdf/1810.10958v1)

> The increasing popularity of cell phones has made them the most personal and ubiquitous communication devices nowadays. Typically, the ringing notifications of mobile phones are used to inform the users about the incoming calls. However, the notifications of inappropriate incoming calls sometimes cause interruptions not only for the users but also the surrounding people. In this paper, we present a data-driven approach to infer the opportune moments for such phone call interruptions based on user's unavailability, i.e., when a user is unable to answer the incoming phone calls, by analyzing individual's past phone log data, and to discover the corresponding phone silent mode configuring rules for the purpose of minimizing call interruptions in an automated intelligent system. Experiments on the real mobile phone datasets show that our approach is able to identify the opportune moments for call interruptions and generates corresponding silent mode configuring rules by capturing the dominant behavior of individual users' at various times-of-the-day and days-of-the week.

</details>

<details>

<summary>2018-10-15 16:35:14 - Hierarchical Recurrent Filtering for Fully Convolutional DenseNets</summary>

- *Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke*

- `1810.02766v2` - [abs](http://arxiv.org/abs/1810.02766v2) - [pdf](http://arxiv.org/pdf/1810.02766v2)

> Generating a robust representation of the environment is a crucial ability of learning agents. Deep learning based methods have greatly improved perception systems but still fail in challenging situations. These failures are often not solvable on the basis of a single image. In this work, we present a parameter-efficient temporal filtering concept which extends an existing single-frame segmentation model to work with multiple frames. The resulting recurrent architecture temporally filters representations on all abstraction levels in a hierarchical manner, while decoupling temporal dependencies from scene representation. Using a synthetic dataset, we show the ability of our model to cope with data perturbations and highlight the importance of recurrent and hierarchical filtering.

</details>

<details>

<summary>2018-10-15 17:45:02 - Visual Semantic Navigation using Scene Priors</summary>

- *Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi*

- `1810.06543v1` - [abs](http://arxiv.org/abs/1810.06543v1) - [pdf](http://arxiv.org/pdf/1810.06543v1)

> How do humans navigate to target objects in novel scenes? Do we use the semantic/functional priors we have built over years to efficiently search and navigate? For example, to search for mugs, we search cabinets near the coffee machine and for fruits we try the fridge. In this work, we focus on incorporating semantic priors in the task of semantic navigation. We propose to use Graph Convolutional Networks for incorporating the prior knowledge into a deep reinforcement learning framework. The agent uses the features from the knowledge graph to predict the actions. For evaluation, we use the AI2-THOR framework. Our experiments show how semantic knowledge improves performance significantly. More importantly, we show improvement in generalization to unseen scenes and/or objects. The supplementary video can be accessed at the following link: https://youtu.be/otKjuO805dE .

</details>

<details>

<summary>2018-10-15 19:37:20 - What Stands-in for a Missing Tool? A Prototypical Grounded Knowledge-based Approach to Tool Substitution</summary>

- *Madhura Thosar, Christian A. Mueller, Sebastian Zug*

- `1808.06423v3` - [abs](http://arxiv.org/abs/1808.06423v3) - [pdf](http://arxiv.org/pdf/1808.06423v3)

> When a robot is operating in a dynamic environment, it cannot be assumed that a tool required to solve a given task will always be available. In case of a missing tool, an ideal response would be to find a substitute to complete the task. In this paper, we present a proof of concept of a grounded knowledge-based approach to tool substitution. In order to validate the suitability of a substitute, we conducted experiments involving 22 substitution scenarios. The substitutes computed by the proposed approach were validated on the basis of the experts' choices for each scenario. Our evaluation showed, in 20 out of 22 scenarios (91%), the approach identified the same substitutes as experts.

</details>

<details>

<summary>2018-10-15 20:19:46 - Mobile Data Science: Towards Understanding Data-Driven Intelligent Mobile Applications</summary>

- *Iqbal H. Sarker*

- `1811.02491v1` - [abs](http://arxiv.org/abs/1811.02491v1) - [pdf](http://arxiv.org/pdf/1811.02491v1)

> Due to the popularity of smart mobile phones and context-aware technology, various contextual data relevant to users' diverse activities with mobile phones is available around us. This enables the study on mobile phone data and context-awareness in computing, for the purpose of building data-driven intelligent mobile applications, not only on a single device but also in a distributed environment for the benefit of end users. Based on the availability of mobile phone data, and the usefulness of data-driven applications, in this paper, we discuss about mobile data science that involves in collecting the mobile phone data from various sources and building data-driven models using machine learning techniques, in order to make dynamic decisions intelligently in various day-to-day situations of the users. For this, we first discuss the fundamental concepts and the potentiality of mobile data science to build intelligent applications. We also highlight the key elements and explain various key modules involving in the process of mobile data science. This article is the first in the field to draw a big picture, and thinking about mobile data science, and it's potentiality in developing various data-driven intelligent mobile applications. We believe this study will help both the researchers and application developers for building smart data-driven mobile applications, to assist the end mobile phone users in their daily activities.

</details>

<details>

<summary>2018-10-15 20:38:00 - Named-Entity Linking Using Deep Learning For Legal Documents: A Transfer Learning Approach</summary>

- *Ahmed Elnaggar, Robin Otto, Florian Matthes*

- `1810.06673v1` - [abs](http://arxiv.org/abs/1810.06673v1) - [pdf](http://arxiv.org/pdf/1810.06673v1)

> In the legal domain it is important to differentiate between words in general, and afterwards to link the occurrences of the same entities. The topic to solve these challenges is called Named-Entity Linking (NEL). Current supervised neural networks designed for NEL use publicly available datasets for training and testing. However, this paper focuses especially on the aspect of applying transfer learning approach using networks trained for NEL to legal documents. Experiments show consistent improvement in the legal datasets that were created from the European Union law in the scope of this research. Using transfer learning approach, we reached F1-score of 98.90\% and 98.01\% on the legal small and large test dataset.

</details>

<details>

<summary>2018-10-15 21:37:38 - Bringing Order to the Cognitive Fallacy Zoo</summary>

- *Ardavan S. Nobandegani, William Campoli, Thomas R. Shultz*

- `1810.06710v1` - [abs](http://arxiv.org/abs/1810.06710v1) - [pdf](http://arxiv.org/pdf/1810.06710v1)

> In the eyes of a rationalist like Descartes or Spinoza, human reasoning is flawless, marching toward uncovering ultimate truth. A few centuries later, however, culminating in the work of Kahneman and Tversky, human reasoning was portrayed as anything but flawless, filled with numerous misjudgments, biases, and cognitive fallacies. With further investigations, new cognitive fallacies continually emerged, leading to a state of affairs which can fairly be characterized as the cognitive fallacy zoo! In this largely methodological work, we formally present a principled way to bring order to this zoo. We introduce the idea of establishing implication relationships (IRs) between cognitive fallacies, formally characterizing how one fallacy implies another. IR is analogous to, and partly inspired by, the fundamental concept of reduction in computational complexity theory. We present several examples of IRs involving experimentally well-documented cognitive fallacies: base-rate neglect, availability bias, conjunction fallacy, decoy effect, framing effect, and Allais paradox. We conclude by discussing how our work: (i) allows for identifying those pivotal cognitive fallacies whose investigation would be the most rewarding research agenda, and importantly (ii) permits a systematized, guided research program on cognitive fallacies, motivating influential theoretical as well as experimental avenues of future research.

</details>

<details>

<summary>2018-10-15 23:22:10 - Assessing the Contribution of Semantic Congruency to Multisensory Integration and Conflict Resolution</summary>

- *Di Fu, Pablo Barros, German I. Parisi, Haiyan Wu, Sven Magg, Xun Liu, Stefan Wermter*

- `1810.06748v1` - [abs](http://arxiv.org/abs/1810.06748v1) - [pdf](http://arxiv.org/pdf/1810.06748v1)

> The efficient integration of multisensory observations is a key property of the brain that yields the robust interaction with the environment. However, artificial multisensory perception remains an open issue especially in situations of sensory uncertainty and conflicts. In this work, we extend previous studies on audio-visual (AV) conflict resolution in complex environments. In particular, we focus on quantitatively assessing the contribution of semantic congruency during an AV spatial localization task. In addition to conflicts in the spatial domain (i.e. spatially misaligned stimuli), we consider gender-specific conflicts with male and female avatars. Our results suggest that while semantically related stimuli affect the magnitude of the visual bias (perceptually shifting the location of the sound towards a semantically congruent visual cue), humans still strongly rely on environmental statistics to solve AV conflicts. Together with previously reported results, this work contributes to a better understanding of how multisensory integration and conflict resolution can be modelled in artificial agents and robots operating in real-world environments.

</details>

<details>

<summary>2018-10-16 00:26:39 - A survey of automatic de-identification of longitudinal clinical narratives</summary>

- *Vithya Yogarajan, Michael Mayo, Bernhard Pfahringer*

- `1810.06765v1` - [abs](http://arxiv.org/abs/1810.06765v1) - [pdf](http://arxiv.org/pdf/1810.06765v1)

> Use of medical data, also known as electronic health records, in research helps develop and advance medical science. However, protecting patient confidentiality and identity while using medical data for analysis is crucial. Medical data can be in the form of tabular structures (i.e. tables), free-form narratives, and images. This study focuses on medical data in the free form longitudinal text. De-identification of electronic health records provides the opportunity to use such data for research without it affecting patient privacy, and avoids the need for individual patient consent. In recent years there is increasing interest in developing an accurate, robust and adaptable automatic de-identification system for electronic health records. This is mainly due to the dilemma between the availability of an abundance of health data, and the inability to use such data in research due to legal and ethical restrictions. De-identification tracks in competitions such as the 2014 i2b2 UTHealth and the 2016 CEGS N-GRID shared tasks have provided a great platform to advance this area. The primary reasons for this include the open source nature of the dataset and the fact that raw psychiatric data were used for 2016 competitions. This study focuses on noticeable trend changes in the techniques used in the development of automatic de-identification for longitudinal clinical narratives. More specifically, the shift from using conditional random fields (CRF) based systems only or rules (regular expressions, dictionary or combinations) based systems only, to hybrid models (combining CRF and rules), and more recently to deep learning based systems. We review the literature and results that arose from the 2014 and the 2016 competitions and discuss the outcomes of these systems. We also provide a list of research questions that emerged from this survey.

</details>

<details>

<summary>2018-10-16 06:44:42 - Sharp Analysis of Learning with Discrete Losses</summary>

- *Alex Nowak-Vila, Francis Bach, Alessandro Rudi*

- `1810.06839v1` - [abs](http://arxiv.org/abs/1810.06839v1) - [pdf](http://arxiv.org/pdf/1810.06839v1)

> The problem of devising learning strategies for discrete losses (e.g., multilabeling, ranking) is currently addressed with methods and theoretical analyses ad-hoc for each loss. In this paper we study a least-squares framework to systematically design learning algorithms for discrete losses, with quantitative characterizations in terms of statistical and computational complexity. In particular we improve existing results by providing explicit dependence on the number of labels for a wide class of losses and faster learning rates in conditions of low-noise. Theoretical results are complemented with experiments on real datasets, showing the effectiveness of the proposed general approach.

</details>

<details>

<summary>2018-10-16 08:14:12 - Detecting and Explaining Drifts in Yearly Grant Applications</summary>

- *Stephen Pauwels, Toon Calders*

- `1809.05650v2` - [abs](http://arxiv.org/abs/1809.05650v2) - [pdf](http://arxiv.org/pdf/1809.05650v2)

> During the lifetime of a Business Process changes can be made to the workflow, the required resources, required documents, . . . . Different traces from the same Business Process within a single log file can thus differ substantially due to these changes. We propose a method that is able to detect concept drift in multivariate log files with a dozen attributes. We test our approach on the BPI Challenge 2018 data con- sisting of applications for EU direct payment from farmers in Germany where we use it to detect Concept Drift. In contrast to other methods our algorithm does not require the manual selection of the features used to detect drift. Our method first creates a model that captures the re- lations between attributes and between events of different time steps. This model is then used to score every event and trace. These scores can be used to detect outlying cases and concept drift. Thanks to the decomposability of the score we are able to perform detailed root-cause analysis.

</details>

<details>

<summary>2018-10-16 10:33:17 - Binary Matrix Guessing Problem</summary>

- *Çağrı Latifoğlu*

- `1701.06167v2` - [abs](http://arxiv.org/abs/1701.06167v2) - [pdf](http://arxiv.org/pdf/1701.06167v2)

> We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results.   reason for withdrawal: Paper will be rewritten with experiments replicated on verified and validated hardware and software.

</details>

<details>

<summary>2018-10-16 15:59:38 - Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models</summary>

- *Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, Alexander M. Rush*

- `1804.09299v2` - [abs](http://arxiv.org/abs/1804.09299v2) - [pdf](http://arxiv.org/pdf/1804.09299v2)

> Neural Sequence-to-Sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work in a five stage blackbox process that involves encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction with a trained sequence-to-sequence model through each stage of the translation process. The aim is to identify which patterns have been learned and to detect model errors. We demonstrate the utility of our tool through several real-world large-scale sequence-to-sequence use cases.

</details>

<details>

<summary>2018-10-16 16:07:08 - Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems</summary>

- *Maria-Florina Balcan, Vaishnavh Nagarajan, Ellen Vitercik, Colin White*

- `1611.04535v4` - [abs](http://arxiv.org/abs/1611.04535v4) - [pdf](http://arxiv.org/pdf/1611.04535v4)

> Max-cut, clustering, and many other partitioning problems that are of significant importance to machine learning and other scientific fields are NP-hard, a reality that has motivated researchers to develop a wealth of approximation algorithms and heuristics. Although the best algorithm to use typically depends on the specific application domain, a worst-case analysis is often used to compare algorithms. This may be misleading if worst-case instances occur infrequently, and thus there is a demand for optimization methods which return the algorithm configuration best suited for the given application's typical inputs. We address this problem for clustering, max-cut, and other partitioning problems, such as integer quadratic programming, by designing computationally efficient and sample efficient learning algorithms which receive samples from an application-specific distribution over problem instances and learn a partitioning algorithm with high expected performance. Our algorithms learn over common integer quadratic programming and clustering algorithm families: SDP rounding algorithms and agglomerative clustering algorithms with dynamic programming. For our sample complexity analysis, we provide tight bounds on the pseudodimension of these algorithm classes, and show that surprisingly, even for classes of algorithms parameterized by a single parameter, the pseudo-dimension is superconstant. In this way, our work both contributes to the foundations of algorithm configuration and pushes the boundaries of learning theory, since the algorithm classes we analyze consist of multi-stage optimization procedures and are significantly more complex than classes typically studied in learning theory.

</details>

<details>

<summary>2018-10-16 16:57:07 - Improving Data Quality through Deep Learning and Statistical Models</summary>

- *Wei Dai, Kenji Yoshigoe, William Parsley*

- `1810.07132v1` - [abs](http://arxiv.org/abs/1810.07132v1) - [pdf](http://arxiv.org/pdf/1810.07132v1)

> Traditional data quality control methods are based on users experience or previously established business rules, and this limits performance in addition to being a very time consuming process with lower than desirable accuracy. Utilizing deep learning, we can leverage computing resources and advanced techniques to overcome these challenges and provide greater value to users. In this paper, we, the authors, first review relevant works and discuss machine learning techniques, tools, and statistical quality models. Second, we offer a creative data quality framework based on deep learning and statistical model algorithm for identifying data quality. Third, we use data involving salary levels from an open dataset published by the state of Arkansas to demonstrate how to identify outlier data and how to improve data quality via deep learning. Finally, we discuss future work.

</details>

<details>

<summary>2018-10-16 17:39:53 - Packaging and Sharing Machine Learning Models via the Acumos AI Open Platform</summary>

- *Shuai Zhao, Manoop Talasila, Guy Jacobson, Cristian Borcea, Syed Anwar Aftab, John F Murray*

- `1810.07159v1` - [abs](http://arxiv.org/abs/1810.07159v1) - [pdf](http://arxiv.org/pdf/1810.07159v1)

> Applying Machine Learning (ML) to business applications for automation usually faces difficulties when integrating diverse ML dependencies and services, mainly because of the lack of a common ML framework. In most cases, the ML models are developed for applications which are targeted for specific business domain use cases, leading to duplicated effort, and making reuse impossible. This paper presents Acumos, an open platform capable of packaging ML models into portable containerized microservices which can be easily shared via the platform's catalog, and can be integrated into various business applications. We present a case study of packaging sentiment analysis and classification ML models via the Acumos platform, permitting easy sharing with others. We demonstrate that the Acumos platform reduces the technical burden on application developers when applying machine learning models to their business applications. Furthermore, the platform allows the reuse of readily available ML microservices in various business domains.

</details>

<details>

<summary>2018-10-16 17:49:43 - Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation</summary>

- *Gregory Kahn, Adam Villaflor, Pieter Abbeel, Sergey Levine*

- `1810.07167v1` - [abs](http://arxiv.org/abs/1810.07167v1) - [pdf](http://arxiv.org/pdf/1810.07167v1)

> A general-purpose intelligent robot must be able to learn autonomously and be able to accomplish multiple tasks in order to be deployed in the real world. However, standard reinforcement learning approaches learn separate task-specific policies and assume the reward function for each task is known a priori. We propose a framework that learns event cues from off-policy data, and can flexibly combine these event cues at test time to accomplish different tasks. These event cue labels are not assumed to be known a priori, but are instead labeled using learned models, such as computer vision detectors, and then `backed up' in time using an action-conditioned predictive model. We show that a simulated robotic car and a real-world RC car can gather data and train fully autonomously without any human-provided labels beyond those needed to train the detectors, and then at test-time be able to accomplish a variety of different tasks. Videos of the experiments and code can be found at https://github.com/gkahn13/CAPs

</details>

<details>

<summary>2018-10-16 18:01:57 - Reinforcement Learning Decoders for Fault-Tolerant Quantum Computation</summary>

- *Ryan Sweke, Markus S. Kesselring, Evert P. L. van Nieuwenburg, Jens Eisert*

- `1810.07207v1` - [abs](http://arxiv.org/abs/1810.07207v1) - [pdf](http://arxiv.org/pdf/1810.07207v1)

> Topological error correcting codes, and particularly the surface code, currently provide the most feasible roadmap towards large-scale fault-tolerant quantum computation. As such, obtaining fast and flexible decoding algorithms for these codes, within the experimentally relevant context of faulty syndrome measurements, is of critical importance. In this work, we show that the problem of decoding such codes, in the full fault-tolerant setting, can be naturally reformulated as a process of repeated interactions between a decoding agent and a code environment, to which the machinery of reinforcement learning can be applied to obtain decoding agents. As a demonstration, by using deepQ learning, we obtain fast decoding agents for the surface code, for a variety of noise-models.

</details>

<details>

<summary>2018-10-16 18:40:34 - Integrating kinematics and environment context into deep inverse reinforcement learning for predicting off-road vehicle trajectories</summary>

- *Yanfu Zhang, Wenshan Wang, Rogerio Bonatti, Daniel Maturana, Sebastian Scherer*

- `1810.07225v1` - [abs](http://arxiv.org/abs/1810.07225v1) - [pdf](http://arxiv.org/pdf/1810.07225v1)

> Predicting the motion of a mobile agent from a third-person perspective is an important component for many robotics applications, such as autonomous navigation and tracking. With accurate motion prediction of other agents, robots can plan for more intelligent behaviors to achieve specified objectives, instead of acting in a purely reactive way. Previous work addresses motion prediction by either only filtering kinematics, or using hand-designed and learned representations of the environment. Instead of separating kinematic and environmental context, we propose a novel approach to integrate both into an inverse reinforcement learning (IRL) framework for trajectory prediction. Instead of exponentially increasing the state-space complexity with kinematics, we propose a two-stage neural network architecture that considers motion and environment together to recover the reward function. The first-stage network learns feature representations of the environment using low-level LiDAR statistics and the second-stage network combines those learned features with kinematics data. We collected over 30 km of off-road driving data and validated experimentally that our method can effectively extract useful environmental and kinematic features. We generate accurate predictions of the distribution of future trajectories of the vehicle, encoding complex behaviors such as multi-modal distributions at road intersections, and even show different predictions at the same intersection depending on the vehicle's speed.

</details>

<details>

<summary>2018-10-16 18:56:33 - Conceptual Analysis of Hypertext</summary>

- *Robert E. Kent, Christian Neuss*

- `1810.07232v1` - [abs](http://arxiv.org/abs/1810.07232v1) - [pdf](http://arxiv.org/pdf/1810.07232v1)

> In this chapter tools and techniques from the mathematical theory of formal concept analysis are applied to hypertext systems in general, and the World Wide Web in particular. Various processes for the conceptual structuring of hypertext are discussed: summarization, conceptual scaling, and the creation of conceptual links. Well-known interchange formats for summarizing networked information resources as resource meta-information are reviewed, and two new interchange formats originating from formal concept analysis are advocated. Also reviewed is conceptual scaling, which provides a principled approach to the faceted analysis techniques in library science classification. The important notion of conceptual linkage is introduced as a generalization of a hyperlink. The automatic hyperization of the content of legacy data is described, and the composite conceptual structuring with hypertext linkage is defined. For the conceptual empowerment of the Web user, a new technique called conceptual browsing is advocated. Conceptual browsing, which browses over conceptual links, is dual mode (extensional versus intensional) and dual scope (global versus local).

</details>

<details>

<summary>2018-10-16 20:07:06 - The Concept of Criticality in Reinforcement Learning</summary>

- *Yitzhak Spielberg, Amos Azaria*

- `1810.07254v1` - [abs](http://arxiv.org/abs/1810.07254v1) - [pdf](http://arxiv.org/pdf/1810.07254v1)

> Reinforcement learning methods carry a well known bias-variance trade-off in n-step algorithms for optimal control. Unfortunately, this has rarely been addressed in current research. This trade-off principle holds independent of the choice of the algorithm, such as n-step SARSA, n-step Expected SARSA or n-step Tree backup. A small n results in a large bias, while a large n leads to large variance. The literature offers no straightforward recipe for the best choice of this value. While currently all n-step algorithms use a fixed value of n over the state space we extend the framework of n-step updates by allowing each state to have its specific n.   We propose a solution to this problem within the context of human aided reinforcement learning. Our approach is based on the observation that a human can learn more efficiently if she receives input regarding the criticality of a given state and thus the amount of attention she needs to invest into the learning in that state. This observation is related to the idea that each state of the MDP has a certain measure of criticality which indicates how much the choice of the action in that state influences the return. In our algorithm the RL agent utilizes the criticality measure, a function provided by a human trainer, in order to locally choose the best stepnumber n for the update of the Q function.

</details>

<details>

<summary>2018-10-16 20:11:52 - Automatic generation of object shapes with desired functionalities</summary>

- *Mihai Andries, Atabak Dehban, José Santos-Victor*

- `1805.11984v2` - [abs](http://arxiv.org/abs/1805.11984v2) - [pdf](http://arxiv.org/pdf/1805.11984v2)

> 3D objects (artefacts) are made to fulfill functions. Designing an object often starts with defining a list of functionalities that it should provide, also known as functional requirements. Today, the design of 3D object models is still a slow and largely artisanal activity, with few Computer-Aided Design (CAD) tools existing to aid the exploration of the design solution space. To accelerate the design process, we introduce an algorithm for generating object shapes with desired functionalities. Following the concept of form follows function, we assume that existing object shapes were rationally chosen to provide desired functionalities. First, we use an artificial neural network to learn a function-to-form mapping by analysing a dataset of objects labeled with their functionalities. Then, we combine forms providing one or more desired functions, generating an object shape that is expected to provide all of them. Finally, we verify in simulation whether the generated object possesses the desired functionalities, by defining and executing functionality tests on it.

</details>

<details>

<summary>2018-10-16 21:36:35 - At Human Speed: Deep Reinforcement Learning with Action Delay</summary>

- *Vlad Firoiu, Tina Ju, Josh Tenenbaum*

- `1810.07286v1` - [abs](http://arxiv.org/abs/1810.07286v1) - [pdf](http://arxiv.org/pdf/1810.07286v1)

> There has been a recent explosion in the capabilities of game-playing artificial intelligence. Many classes of tasks, from video games to motor control to board games, are now solvable by fairly generic algorithms, based on deep learning and reinforcement learning, that learn to play from experience with minimal prior knowledge. However, these machines often do not win through intelligence alone -- they possess vastly superior speed and precision, allowing them to act in ways a human never could. To level the playing field, we restrict the machine's reaction time to a human level, and find that standard deep reinforcement learning methods quickly drop in performance. We propose a solution to the action delay problem inspired by human perception -- to endow agents with a neural predictive model of the environment which "undoes" the delay inherent in their environment -- and demonstrate its efficacy against professional players in Super Smash Bros. Melee, a popular console fighting game.

</details>

<details>

<summary>2018-10-16 23:06:48 - Solving Tree Problems with Category Theory</summary>

- *Rafik Hadfi*

- `1810.07307v1` - [abs](http://arxiv.org/abs/1810.07307v1) - [pdf](http://arxiv.org/pdf/1810.07307v1)

> Artificial Intelligence (AI) has long pursued models, theories, and techniques to imbue machines with human-like general intelligence. Yet even the currently predominant data-driven approaches in AI seem to be lacking humans' unique ability to solve wide ranges of problems. This situation begs the question of the existence of principles that underlie general problem-solving capabilities. We approach this question through the mathematical formulation of analogies across different problems and solutions. We focus in particular on problems that could be represented as tree-like structures. Most importantly, we adopt a category-theoretic approach in formalising tree problems as categories, and in proving the existence of equivalences across apparently unrelated problem domains. We prove the existence of a functor between the category of tree problems and the category of solutions. We also provide a weaker version of the functor by quantifying equivalences of problem categories using a metric on tree problems.

</details>

<details>

<summary>2018-10-17 10:24:22 - What might matter in autonomous cars adoption: first person versus third person scenarios</summary>

- *Eva Zackova, Jan Romportl*

- `1810.07460v1` - [abs](http://arxiv.org/abs/1810.07460v1) - [pdf](http://arxiv.org/pdf/1810.07460v1)

> The discussion between the automotive industry, governments, ethicists, policy makers and general public about autonomous cars' moral agency is widening, and therefore we see the need to bring more insight into what meta-factors might actually influence the outcomes of such discussions, surveys and plebiscites. In our study, we focus on the psychological (personality traits), practical (active driving experience), gender and rhetoric/framing factors that might impact and even determine respondents' a priori preferences of autonomous cars' operation. We conducted an online survey (N=430) to collect data that show that the third person scenario is less biased than the first person scenario when presenting ethical dilemma related to autonomous cars. According to our analysis, gender bias should be explored in more extensive future studies as well. We recommend any participatory technology assessment discourse to use the third person scenario and to direct attention to the way any autonomous car related debate is introduced, especially in terms of linguistic and communication aspects and gender.

</details>

<details>

<summary>2018-10-17 11:32:15 - k-RNN: Extending NN-heuristics for the TSP</summary>

- *Nikolas Klug, Alok Chauhan, Ramesh Ragala, V Vijayakumar*

- `1810.08059v1` - [abs](http://arxiv.org/abs/1810.08059v1) - [pdf](http://arxiv.org/pdf/1810.08059v1)

> In this paper we present an extension of existing Nearest-Neighbor heuristics to an algorithm called k-Repetitive-Nearest-Neighbor. The idea is to start with a tour of k nodes and then perform a Nearest-Neighbor search from there on. After doing this for all permutations of k nodes the result gets selected as the shortest tour found. Experimental results show that for 2-RNN the solutions quality remains relatively stable between about 10% to 40% above the optimum.

</details>

<details>

<summary>2018-10-17 12:11:20 - Constructing Deep Neural Networks by Bayesian Network Structure Learning</summary>

- *Raanan Y. Rohekar, Shami Nisimov, Yaniv Gurwicz, Guy Koren, Gal Novik*

- `1806.09141v3` - [abs](http://arxiv.org/abs/1806.09141v3) - [pdf](http://arxiv.org/pdf/1806.09141v3)

> We introduce a principled approach for unsupervised structure learning of deep neural networks. We propose a new interpretation for depth and inter-layer connectivity where conditional independencies in the input distribution are encoded hierarchically in the network structure. Thus, the depth of the network is determined inherently. The proposed method casts the problem of neural network structure learning as a problem of Bayesian network structure learning. Then, instead of directly learning the discriminative structure, it learns a generative graph, constructs its stochastic inverse, and then constructs a discriminative graph. We prove that conditional-dependency relations among the latent variables in the generative graph are preserved in the class-conditional discriminative graph. We demonstrate on image classification benchmarks that the deepest layers (convolutional and dense) of common networks can be replaced by significantly smaller learned structures, while maintaining classification accuracy---state-of-the-art on tested benchmarks. Our structure learning algorithm requires a small computational cost and runs efficiently on a standard desktop CPU.

</details>

<details>

<summary>2018-10-17 13:31:41 - Machine Common Sense Concept Paper</summary>

- *David Gunning*

- `1810.07528v1` - [abs](http://arxiv.org/abs/1810.07528v1) - [pdf](http://arxiv.org/pdf/1810.07528v1)

> This paper summarizes some of the technical background, research ideas, and possible development strategies for achieving machine common sense. Machine common sense has long been a critical-but-missing component of Artificial Intelligence (AI). Recent advances in machine learning have resulted in new AI capabilities, but in all of these applications, machine reasoning is narrow and highly specialized. Developers must carefully train or program systems for every situation. General commonsense reasoning remains elusive. The absence of common sense prevents intelligent systems from understanding their world, behaving reasonably in unforeseen situations, communicating naturally with people, and learning from new experiences. Its absence is perhaps the most significant barrier between the narrowly focused AI applications we have today and the more general, human-like AI systems we would like to build in the future. Machine common sense remains a broad, potentially unbounded problem in AI. There are a wide range of strategies that could be employed to make progress on this difficult challenge. This paper discusses two diverse strategies for focusing development on two different machine commonsense services: (1) a service that learns from experience, like a child, to construct computational models that mimic the core domains of child cognition for objects (intuitive physics), agents (intentional actors), and places (spatial navigation); and (2) service that learns from reading the Web, like a research librarian, to construct a commonsense knowledge repository capable of answering natural language and image-based questions about commonsense phenomena.

</details>

<details>

<summary>2018-10-17 15:26:48 - Game-Based Video-Context Dialogue</summary>

- *Ramakanth Pasunuru, Mohit Bansal*

- `1809.04560v2` - [abs](http://arxiv.org/abs/1809.04560v2) - [pdf](http://arxiv.org/pdf/1809.04560v2)

> Current dialogue systems focus more on textual and speech context knowledge and are usually based on two speakers. Some recent work has investigated static image-based dialogue. However, several real-world human interactions also involve dynamic visual context (similar to videos) as well as dialogue exchanges among multiple speakers. To move closer towards such multimodal conversational skills and visually-situated applications, we introduce a new video-context, many-speaker dialogue dataset based on live-broadcast soccer game videos and chats from Twitch.tv. This challenging testbed allows us to develop visually-grounded dialogue models that should generate relevant temporal and spatial event language from the live video, while also being relevant to the chat history. For strong baselines, we also present several discriminative and generative models, e.g., based on tridirectional attention flow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic phrase-matching metrics, as well as human evaluation studies. We also present dataset analyses, model ablations, and visualizations to understand the contribution of different modalities and model components.

</details>

<details>

<summary>2018-10-17 17:51:36 - Relational inductive biases, deep learning, and graph networks</summary>

- *Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu*

- `1806.01261v3` - [abs](http://arxiv.org/abs/1806.01261v3) - [pdf](http://arxiv.org/pdf/1806.01261v3)

> Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI.   The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.

</details>

<details>

<summary>2018-10-17 17:59:56 - The Institutional Approach</summary>

- *Robert E. Kent*

- `1810.08074v1` - [abs](http://arxiv.org/abs/1810.08074v1) - [pdf](http://arxiv.org/pdf/1810.08074v1)

> This chapter discusses the institutional approach for organizing and maintaining ontologies. The theory of institutions was named and initially developed by Joseph Goguen and Rod Burstall. This theory, a metatheory based on category theory, regards ontologies as logical theories or local logics. The theory of institutions uses the category-theoretic ideas of fibrations and indexed categories to develop logical theories. Institutions unite the lattice approach of Formal Concept Analysis of Ganter and Wille with the distributed logic of Information Flow of Barwise and Seligman. The institutional approach incorporates locally the lattice of theories idea of Sowa from the theory of knowledge representation. The Information Flow Framework, which was initiated within the IEEE Standard Upper Ontology project, uses the institutional approach in its applied aspect for the comparison, semantic integration and maintenance of ontologies. This chapter explains the central ideas of the institutional approach to ontologies in a careful and detailed manner.

</details>

<details>

<summary>2018-10-17 20:07:08 - A Disease Diagnosis and Treatment Recommendation System Based on Big Data Mining and Cloud Computing</summary>

- *Jianguo Chen, Kenli Li, Huigui Rong, Kashif Bilal, Nan Yang, Keqin Li*

- `1810.07762v1` - [abs](http://arxiv.org/abs/1810.07762v1) - [pdf](http://arxiv.org/pdf/1810.07762v1)

> It is crucial to provide compatible treatment schemes for a disease according to various symptoms at different stages. However, most classification methods might be ineffective in accurately classifying a disease that holds the characteristics of multiple treatment stages, various symptoms, and multi-pathogenesis. Moreover, there are limited exchanges and cooperative actions in disease diagnoses and treatments between different departments and hospitals. Thus, when new diseases occur with atypical symptoms, inexperienced doctors might have difficulty in identifying them promptly and accurately. Therefore, to maximize the utilization of the advanced medical technology of developed hospitals and the rich medical knowledge of experienced doctors, a Disease Diagnosis and Treatment Recommendation System (DDTRS) is proposed in this paper. First, to effectively identify disease symptoms more accurately, a Density-Peaked Clustering Analysis (DPCA) algorithm is introduced for disease-symptom clustering. In addition, association analyses on Disease-Diagnosis (D-D) rules and Disease-Treatment (D-T) rules are conducted by the Apriori algorithm separately. The appropriate diagnosis and treatment schemes are recommended for patients and inexperienced doctors, even if they are in a limited therapeutic environment. Moreover, to reach the goals of high performance and low latency response, we implement a parallel solution for DDTRS using the Apache Spark cloud platform. Extensive experimental results demonstrate that the proposed DDTRS realizes disease-symptom clustering effectively and derives disease treatment recommendations intelligently and accurately.

</details>

<details>

<summary>2018-10-17 21:01:36 - Deep Pepper: Expert Iteration based Chess agent in the Reinforcement Learning Setting</summary>

- *Sai Krishna G. V., Kyle Goyette, Ahmad Chamseddine, Breandan Considine*

- `1806.00683v2` - [abs](http://arxiv.org/abs/1806.00683v2) - [pdf](http://arxiv.org/pdf/1806.00683v2)

> An almost-perfect chess playing agent has been a long standing challenge in the field of Artificial Intelligence. Some of the recent advances demonstrate we are approaching that goal. In this project, we provide methods for faster training of self-play style algorithms, mathematical details of the algorithm used, various potential future directions, and discuss most of the relevant work in the area of computer chess. Deep Pepper uses embedded knowledge to accelerate the training of the chess engine over a "tabula rasa" system such as Alpha Zero. We also release our code to promote further research.

</details>

<details>

<summary>2018-10-17 23:06:06 - Quality 4.0: Let's Get Digital - The many ways the fourth industrial revolution is reshaping the way we think about quality</summary>

- *Nicole M. Radziwill*

- `1810.07829v1` - [abs](http://arxiv.org/abs/1810.07829v1) - [pdf](http://arxiv.org/pdf/1810.07829v1)

> The technology landscape is richer and more promising than ever before. In many ways, cloud computing, big data, virtual reality (VR), augmented reality (AR), blockchain, additive manufacturing, artificial intelligence (AI), machine learning (ML), Internet Protocol Version 6 (IPv6), cyber-physical systems and the Internet of Things (IoT) all represent new frontiers. These technologies can help improve product and service quality, and organizational performance. In many regions, the internet is now as ubiquitous as electricity. Components are relatively cheap. A robust ecosystem of open-source software libraries means that engineers can solve problems 100 times faster than just two decades ago. This digital transformation is leading us toward connected intelligent automation: smart, hyperconnected agents deployed in environments where humans and machines cooperate, and leverage data, to achieve shared goals. This is not the worlds first industrial revolution. In fact, it is its fourth, and the disruptive changes it will bring suggest we will need a fresh perspective on quality to adapt to it.

</details>

<details>

<summary>2018-10-18 02:36:01 - Layer-compensated Pruning for Resource-constrained Convolutional Neural Networks</summary>

- *Ting-Wu Chin, Cha Zhang, Diana Marculescu*

- `1810.00518v2` - [abs](http://arxiv.org/abs/1810.00518v2) - [pdf](http://arxiv.org/pdf/1810.00518v2)

> Resource-efficient convolution neural networks enable not only the intelligence on edge devices but also opportunities in system-level optimization such as scheduling. In this work, we aim to improve the performance of resource-constrained filter pruning by merging two sub-problems commonly considered, i.e., (i) how many filters to prune for each layer and (ii) which filters to prune given a per-layer pruning budget, into a global filter ranking problem. Our framework entails a novel algorithm, dubbed layer-compensated pruning, where meta-learning is involved to determine better solutions. We show empirically that the proposed algorithm is superior to prior art in both effectiveness and efficiency. Specifically, we reduce the accuracy gap between the pruned and original networks from 0.9% to 0.7% with 8x reduction in time needed for meta-learning, i.e., from 1 hour down to 7 minutes. To this end, we demonstrate the effectiveness of our algorithm using ResNet and MobileNetV2 networks under CIFAR-10, ImageNet, and Bird-200 datasets.

</details>

<details>

<summary>2018-10-18 03:44:39 - Finding the best design parameters for optical nanostructures using reinforcement learning</summary>

- *Iman Sajedian, Trevon Badloe, Junsuk Rho*

- `1810.10964v1` - [abs](http://arxiv.org/abs/1810.10964v1) - [pdf](http://arxiv.org/pdf/1810.10964v1)

> Recently, a novel machine learning model has emerged in the field of reinforcement learning known as deep Q-learning. This model is capable of finding the best possible solution in systems consisting of millions of choices, without ever experiencing it before, and has been used to beat the best human minds at complex games such as, Go and chess, which both have a huge number of possible decisions and outcomes for each move. With a human-level intelligence, it has been solved the problems that no other machine learning model could do before. Here, we show the steps needed for implementing this model on an optical problem. We investigated the colour generation by dielectric nanostructures and show that this model can find geometrical properties that can generate a much deeper red, green and blue colours compared to the ones found by human researchers. This technique can easily be extended to predict and find the best design parameters for other optical structures.

</details>

<details>

<summary>2018-10-18 09:47:35 - An Upper Bound for Random Measurement Error in Causal Discovery</summary>

- *Tineke Blom, Anna Klimovskaia, Sara Magliacane, Joris M. Mooij*

- `1810.07973v1` - [abs](http://arxiv.org/abs/1810.07973v1) - [pdf](http://arxiv.org/pdf/1810.07973v1)

> Causal discovery algorithms infer causal relations from data based on several assumptions, including notably the absence of measurement error. However, this assumption is most likely violated in practical applications, which may result in erroneous, irreproducible results. In this work we show how to obtain an upper bound for the variance of random measurement error from the covariance matrix of measured variables and how to use this upper bound as a correction for constraint-based causal discovery. We demonstrate a practical application of our approach on both simulated data and real-world protein signaling data.

</details>

<details>

<summary>2018-10-18 14:00:48 - Visions of a generalized probability theory</summary>

- *Fabio Cuzzolin*

- `1810.10341v1` - [abs](http://arxiv.org/abs/1810.10341v1) - [pdf](http://arxiv.org/pdf/1810.10341v1)

> In this Book we argue that the fruitful interaction of computer vision and belief calculus is capable of stimulating significant advances in both fields. From a methodological point of view, novel theoretical results concerning the geometric and algebraic properties of belief functions as mathematical objects are illustrated and discussed in Part II, with a focus on both a perspective 'geometric approach' to uncertainty and an algebraic solution to the issue of conflicting evidence. In Part III we show how these theoretical developments arise from important computer vision problems (such as articulated object tracking, data association and object pose estimation) to which, in turn, the evidential formalism is able to provide interesting new solutions. Finally, some initial steps towards a generalization of the notion of total probability to belief functions are taken, in the perspective of endowing the theory of evidence with a complete battery of estimation and inference tools to the benefit of all scientists and practitioners.

</details>

<details>

<summary>2018-10-18 14:17:12 - A Training-based Identification Approach to VIN Adversarial Examples</summary>

- *Yingdi Wang, Wenjia Niu, Tong Chen, Yingxiao Xiang, Jingjing Liu, Gang Li, Jiqiang Liu*

- `1810.08070v1` - [abs](http://arxiv.org/abs/1810.08070v1) - [pdf](http://arxiv.org/pdf/1810.08070v1)

> With the rapid development of Artificial Intelligence (AI), the problem of AI security has gradually emerged. Most existing machine learning algorithms may be attacked by adversarial examples. An adversarial example is a slightly modified input sample that can lead to a false result of machine learning algorithms. The adversarial examples pose a potential security threat for many AI application areas, especially in the domain of robot path planning. In this field, the adversarial examples obstruct the algorithm by adding obstacles to the normal maps, resulting in multiple effects on the predicted path. However, there is no suitable approach to automatically identify them. To our knowledge, all previous work uses manual observation method to estimate the attack results of adversarial maps, which is time-consuming. Aiming at the existing problem, this paper explores a method to automatically identify the adversarial examples in Value Iteration Networks (VIN), which has a strong generalization ability. We analyze the possible scenarios caused by the adversarial maps. We propose a training-based identification approach to VIN adversarial examples by combing the path feature comparison and path image classification. We evaluate our method using the adversarial maps dataset, show that our method can achieve a high-accuracy and faster identification than manual observation method.

</details>

<details>

<summary>2018-10-18 15:55:54 - Procedurally Provisioned Access Control for Robotic Systems</summary>

- *Ruffin White, Gianluca Caiazza, Henrik I. Christensen, Agostino Cortesi*

- `1810.08125v1` - [abs](http://arxiv.org/abs/1810.08125v1) - [pdf](http://arxiv.org/pdf/1810.08125v1)

> Security of robotics systems, as well as of the related middleware infrastructures, is a critical issue for industrial and domestic IoT, and it needs to be continuously assessed throughout the whole development lifecycle. The next generation open source robotic software stack, ROS2, is now targeting support for Secure DDS, providing the community with valuable tools for secure real world robotic deployments. In this work, we introduce a framework for procedural provisioning access control policies for robotic software, as well as for verifying the compliance of generated transport artifacts and decision point implementations.

</details>

<details>

<summary>2018-10-18 16:31:52 - A Variable Neighborhood Search for Flying Sidekick Traveling Salesman Problem</summary>

- *Julia C. Freitas, Puca Huachi V. Penna*

- `1804.03954v2` - [abs](http://arxiv.org/abs/1804.03954v2) - [pdf](http://arxiv.org/pdf/1804.03954v2)

> The efficiency and dynamism of Unmanned Aerial Vehicles (UAVs), or drones, present substantial application opportunities in several industries in the last years. Notably, the logistic companies gave close attention to these vehicles envisioning reduce delivery time and operational cost. A variant of the Traveling Salesman Problem (TSP) called Flying Sidekick Traveling Salesman Problem (FSTSP) was introduced involving drone-assisted parcel delivery. The drone is launched from the truck, proceeds to deliver parcels to a customer and then is recovered by the truck in a third location. While the drone travels through a trip, the truck delivers parcels to other customers as long as the drone has enough battery to hover waiting for the truck. This work proposes a hybrid heuristic that the initial solution is created from the optimal TSP solution reached by a TSP solver. Next, an implementation of the General Variable Neighborhood Search is used to obtain the delivery routes of truck and drone. Computational experiments show the potential of the algorithm to improve the delivery time significantly. Furthermore, we provide a new set of instances based on well-known TSPLIB instances.

</details>

<details>

<summary>2018-10-18 17:00:20 - Fast deep reinforcement learning using online adjustments from the past</summary>

- *Steven Hansen, Pablo Sprechmann, Alexander Pritzel, André Barreto, Charles Blundell*

- `1810.08163v1` - [abs](http://arxiv.org/abs/1810.08163v1) - [pdf](http://arxiv.org/pdf/1810.08163v1)

> We propose Ephemeral Value Adjusments (EVA): a means of allowing deep reinforcement learning agents to rapidly adapt to experience in their replay buffer. EVA shifts the value predicted by a neural network with an estimate of the value function found by planning over experience tuples from the replay buffer near the current state. EVA combines a number of recent ideas around combining episodic memory-like structures into reinforcement learning agents: slot-based storage, content-based retrieval, and memory-based planning. We show that EVAis performant on a demonstration task and Atari games.

</details>

<details>

<summary>2018-10-18 17:38:57 - Gradient Agreement as an Optimization Objective for Meta-Learning</summary>

- *Amir Erfan Eshratifar, David Eigen, Massoud Pedram*

- `1810.08178v1` - [abs](http://arxiv.org/abs/1810.08178v1) - [pdf](http://arxiv.org/pdf/1810.08178v1)

> This paper presents a novel optimization method for maximizing generalization over tasks in meta-learning. The goal of meta-learning is to learn a model for an agent adapting rapidly when presented with previously unseen tasks. Tasks are sampled from a specific distribution which is assumed to be similar for both seen and unseen tasks. We focus on a family of meta-learning methods learning initial parameters of a base model which can be fine-tuned quickly on a new task, by few gradient steps (MAML). Our approach is based on pushing the parameters of the model to a direction in which tasks have more agreement upon. If the gradients of a task agree with the parameters update vector, then their inner product will be a large positive value. As a result, given a batch of tasks to be optimized for, we associate a positive (negative) weight to the loss function of a task, if the inner product between its gradients and the average of the gradients of all tasks in the batch is a positive (negative) value. Therefore, the degree of the contribution of a task to the parameter updates is controlled by introducing a set of weights on the loss function of the tasks. Our method can be easily integrated with the current meta-learning algorithms for neural networks. Our experiments demonstrate that it yields models with better generalization compared to MAML and Reptile.

</details>

<details>

<summary>2018-10-18 18:50:37 - Semantic Integration in the Information Flow Framework</summary>

- *Robert E. Kent*

- `1810.08236v1` - [abs](http://arxiv.org/abs/1810.08236v1) - [pdf](http://arxiv.org/pdf/1810.08236v1)

> The Information Flow Framework (IFF) is a descriptive category metatheory currently under development, which is being offered as the structural aspect of the Standard Upper Ontology (SUO). The architecture of the IFF is composed of metalevels, namespaces and meta-ontologies. The main application of the IFF is institutional: the notion of institutions and their morphisms are being axiomatized in the upper metalevels of the IFF, and the lower metalevel of the IFF has axiomatized various institutions in which semantic integration has a natural expression as the colimit of theories.

</details>

<details>

<summary>2018-10-18 23:16:23 - Compositional Verification for Autonomous Systems with Deep Learning Components</summary>

- *Corina S. Pasareanu, Divya Gopinath, Huafeng Yu*

- `1810.08303v1` - [abs](http://arxiv.org/abs/1810.08303v1) - [pdf](http://arxiv.org/pdf/1810.08303v1)

> As autonomy becomes prevalent in many applications, ranging from recommendation systems to fully autonomous vehicles, there is an increased need to provide safety guarantees for such systems. The problem is difficult, as these are large, complex systems which operate in uncertain environments, requiring data-driven machine-learning components. However, learning techniques such as Deep Neural Networks, widely used today, are inherently unpredictable and lack the theoretical foundations to provide strong assurance guarantees. We present a compositional approach for the scalable, formal verification of autonomous systems that contain Deep Neural Network components. The approach uses assume-guarantee reasoning whereby {\em contracts}, encoding the input-output behavior of individual components, allow the designer to model and incorporate the behavior of the learning-enabled components working side-by-side with the other components. We illustrate the approach on an example taken from the autonomous vehicles domain.

</details>

<details>

<summary>2018-10-19 02:31:26 - Crowd-Powered Data Mining</summary>

- *Chengliang Chai, Ju Fan, Guoliang Li, Jiannan Wang, Yudian Zheng*

- `1806.04968v2` - [abs](http://arxiv.org/abs/1806.04968v2) - [pdf](http://arxiv.org/pdf/1806.04968v2)

> Many data mining tasks cannot be completely addressed by auto- mated processes, such as sentiment analysis and image classification. Crowdsourcing is an effective way to harness the human cognitive ability to process these machine-hard tasks. Thanks to public crowdsourcing platforms, e.g., Amazon Mechanical Turk and Crowd- Flower, we can easily involve hundreds of thousands of ordinary workers (i.e., the crowd) to address these machine-hard tasks. In this tutorial, we will survey and synthesize a wide spectrum of existing studies on crowd-powered data mining. We first give an overview of crowdsourcing, and then summarize the fundamental techniques, including quality control, cost control, and latency control, which must be considered in crowdsourced data mining. Next we review crowd-powered data mining operations, including classification, clustering, pattern mining, machine learning using the crowd (including deep learning, transfer learning and semi-supervised learning) and knowledge discovery. Finally, we provide the emerging challenges in crowdsourced data mining.

</details>

<details>

<summary>2018-10-19 03:21:28 - Generative Adversarial Network based Autoencoder: Application to fault detection problem for closed loop dynamical systems</summary>

- *Indrasis Chakraborty, Rudrasis Chakraborty, Draguna Vrabie*

- `1804.05320v2` - [abs](http://arxiv.org/abs/1804.05320v2) - [pdf](http://arxiv.org/pdf/1804.05320v2)

> Fault detection problem for closed loop uncertain dynamical systems, is investigated in this paper, using different deep learning based methods. Traditional classifier based method does not perform well, because of the inherent difficulty of detecting system level faults for closed loop dynamical system. Specifically, acting controller in any closed loop dynamical system, works to reduce the effect of system level faults. A novel Generative Adversarial based deep Autoencoder is designed to classify datasets under normal and faulty operating conditions. This proposed network performs significantly well when compared to any available classifier based methods, and moreover, does not require labeled fault incorporated datasets for training purpose. Finally, this aforementioned network's performance is tested on a high complexity building energy system dataset.

</details>

<details>

<summary>2018-10-19 06:26:33 - Developmental Bayesian Optimization of Black-Box with Visual Similarity-Based Transfer Learning</summary>

- *Maxime Petit, Amaury Depierre, Xiaofang Wang, Emmanuel Dellandréa, Liming Chen*

- `1809.10141v7` - [abs](http://arxiv.org/abs/1809.10141v7) - [pdf](http://arxiv.org/pdf/1809.10141v7)

> We present a developmental framework based on a long-term memory and reasoning mechanisms (Vision Similarity and Bayesian Optimisation). This architecture allows a robot to optimize autonomously hyper-parameters that need to be tuned from any action and/or vision module, treated as a black-box. The learning can take advantage of past experiences (stored in the episodic and procedural memories) in order to warm-start the exploration using a set of hyper-parameters previously optimized from objects similar to the new unknown one (stored in a semantic memory). As example, the system has been used to optimized 9 continuous hyper-parameters of a professional software (Kamido) both in simulation and with a real robot (industrial robotic arm Fanuc) with a total of 13 different objects. The robot is able to find a good object-specific optimization in 68 (simulation) or 40 (real) trials. In simulation, we demonstrate the benefit of the transfer learning based on visual similarity, as opposed to an amnesic learning (i.e. learning from scratch all the time). Moreover, with the real robot, we show that the method consistently outperforms the manual optimization from an expert with less than 2 hours of training time to achieve more than 88% of success.

</details>

<details>

<summary>2018-10-19 10:26:27 - Assumption-Based Planning</summary>

- *Damien Pellier, Humbert Fiorino*

- `1810.08431v1` - [abs](http://arxiv.org/abs/1810.08431v1) - [pdf](http://arxiv.org/pdf/1810.08431v1)

> The purpose of the paper is to introduce a new approach of planning called Assumption-Based Planning. This approach is a very interesting way to devise a planner based on a multi-agent system in which the production of a global shared plan is obtained by conjecture/refutation cycles. Contrary to classical approaches, our contribution relies on the agents reasoning that leads to the production of a plan from planning domains. To take into account complex environments and the partial agents knowledge, we propose to consider the planning problem as a defeasible reasoning where the agents exchange proposals and counter-proposals and are able to reason about uncertainty. The argumentation dialogue between agents must not be viewed as a negotiation process but as an investigation process in order to build a plan. In this paper, we focus on the mechanisms that allow an agent to produce `reasonable' proposals according to its knowledge.

</details>

<details>

<summary>2018-10-19 10:53:53 - Coordinated exploration for labyrinthine environments with application to the Pursuit-Evasion problem</summary>

- *Damien Pellier, Humbert Fiorino*

- `1810.08438v1` - [abs](http://arxiv.org/abs/1810.08438v1) - [pdf](http://arxiv.org/pdf/1810.08438v1)

> This paper introduces a multirobot cooperation approach to solve the "pursuit evasion" problem for mobile robots that have omnidirectional vision sensors. The main characteristic of this approach is to implement a real cooperation between robots based on knowledge sharing and makes them work as a team. A complete algorithm for computing a motion strategy of robots is also presented. This algorithm is based on searching critical points in the environment. Finally, the deliberation protocol which distributes the exploration task among the team and takes the best possible outcome from the robots resources is presented.

</details>

<details>

<summary>2018-10-19 11:29:49 - Bilinear Attention Networks</summary>

- *Jin-Hwa Kim, Jaehyun Jun, Byoung-Tak Zhang*

- `1805.07932v2` - [abs](http://arxiv.org/abs/1805.07932v2) - [pdf](http://arxiv.org/pdf/1805.07932v2)

> Attention networks in multimodal learning provide an efficient way to utilize given visual information selectively. However, the computational cost to learn attention distributions for every pair of multimodal input channels is prohibitively expensive. To solve this problem, co-attention builds two separate attention distributions for each modality neglecting the interaction between multimodal inputs. In this paper, we propose bilinear attention networks (BAN) that find bilinear attention distributions to utilize given vision-language information seamlessly. BAN considers bilinear interactions among two groups of input channels, while low-rank bilinear pooling extracts the joint representations for each pair of channels. Furthermore, we propose a variant of multimodal residual networks to exploit eight-attention maps of the BAN efficiently. We quantitatively and qualitatively evaluate our model on visual question answering (VQA 2.0) and Flickr30k Entities datasets, showing that BAN significantly outperforms previous methods and achieves new state-of-the-arts on both datasets.

</details>

<details>

<summary>2018-10-19 12:21:47 - Planification par fusions incrémentales de graphes</summary>

- *Damien Pellier, lias. Belaidi*

- `1810.08460v1` - [abs](http://arxiv.org/abs/1810.08460v1) - [pdf](http://arxiv.org/pdf/1810.08460v1)

> In this paper, we introduce a generic and fresh model for distributed planning called "Distributed Planning Through Graph Merging" ({\sf DPGM}). This model unifies the different steps of the distributed planning process into a single step. Our approach is based on a planning graph structure for the agent reasoning and a CSP mechanism for the individual plan extraction and the coordination. We assume that no agent can reach the global goal alone. Therefore the agents must cooperate, {\it i.e.,} take in into account potential positive interactions between their activities to reach their common shared goal. The originality of our model consists in considering as soon as possible, {\it i.e.,} in the individual planning process, the positive and the negative interactions between agents activities in order to reduce the search cost of a global coordinated solution plan.

</details>

<details>

<summary>2018-10-19 13:07:57 - Wikistat 2.0: Educational Resources for Artificial Intelligence</summary>

- *Philippe Besse, Brendan Guillouet, Béatrice Laurent*

- `1810.02688v2` - [abs](http://arxiv.org/abs/1810.02688v2) - [pdf](http://arxiv.org/pdf/1810.02688v2)

> Big data, data science, deep learning, artificial intelligence are the key words of intense hype related with a job market in full evolution, that impose to adapt the contents of our university professional trainings. Which artificial intelligence is mostly concerned by the job offers? Which methodologies and technologies should be favored in the training programs? Which objectives, tools and educational resources do we needed to put in place to meet these pressing needs? We answer these questions in describing the contents and operational resources in the Data Science orientation of the specialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics training (Optimization, Probability, Statistics), associated with the practical implementation of the most performing statistical learning algorithms, with the most appropriate technologies and on real examples. Considering the huge volatility of the technologies, it is imperative to train students in seft-training, this will be their technological watch tool when they will be in professional activity. This explains the structuring of the educational site github.com/wikistat into a set of tutorials. Finally, to motivate the thorough practice of these tutorials, a serious game is organized each year in the form of a prediction contest between students of Master degrees in Applied Mathematics for IA.

</details>

<details>

<summary>2018-10-19 13:29:36 - A Framework for Robot Programming in Cobotic Environments: First user experiments</summary>

- *Ying Siu Liang, Damien Pellier, Humbert Fiorino, Sylvie Pesty*

- `1810.08492v1` - [abs](http://arxiv.org/abs/1810.08492v1) - [pdf](http://arxiv.org/pdf/1810.08492v1)

> The increasing presence of robots in industries has not gone unnoticed. Large industrial players have incorporated them into their production lines, but smaller companies hesitate due to high initial costs and the lack of programming expertise. In this work we introduce a framework that combines two disciplines, Programming by Demonstration and Automated Planning, to allow users without any programming knowledge to program a robot. The user teaches the robot atomic actions together with their semantic meaning and represents them in terms of preconditions and effects. Using these atomic actions the robot can generate action sequences autonomously to reach any goal given by the user. We evaluated the usability of our framework in terms of user experiments with a Baxter Research Robot and showed that it is well-adapted to users without any programming experience.

</details>

<details>

<summary>2018-10-19 14:16:25 - Transfer Learning versus Multi-agent Learning regarding Distributed Decision-Making in Highway Traffic</summary>

- *Mark Schutera, Niklas Goby, Dirk Neumann, Markus Reischl*

- `1810.08515v1` - [abs](http://arxiv.org/abs/1810.08515v1) - [pdf](http://arxiv.org/pdf/1810.08515v1)

> Transportation and traffic are currently undergoing a rapid increase in terms of both scale and complexity. At the same time, an increasing share of traffic participants are being transformed into agents driven or supported by artificial intelligence resulting in mixed-intelligence traffic. This work explores the implications of distributed decision-making in mixed-intelligence traffic. The investigations are carried out on the basis of an online-simulated highway scenario, namely the MIT \emph{DeepTraffic} simulation. In the first step traffic agents are trained by means of a deep reinforcement learning approach, being deployed inside an elitist evolutionary algorithm for hyperparameter search. The resulting architectures and training parameters are then utilized in order to either train a single autonomous traffic agent and transfer the learned weights onto a multi-agent scenario or else to conduct multi-agent learning directly. Both learning strategies are evaluated on different ratios of mixed-intelligence traffic. The strategies are assessed according to the average speed of all agents driven by artificial intelligence. Traffic patterns that provoke a reduction in traffic flow are analyzed with respect to the different strategies.

</details>

<details>

<summary>2018-10-19 15:12:56 - Fairness for Whom? Critically reframing fairness with Nash Welfare Product</summary>

- *Ansh Patel*

- `1810.08540v1` - [abs](http://arxiv.org/abs/1810.08540v1) - [pdf](http://arxiv.org/pdf/1810.08540v1)

> Recent studies on disparate impact in machine learning applications have sparked a debate around the concept of fairness along with attempts to formalize its different criteria. Many of these approaches focus on reducing prediction errors while maximizing sole utility of the institution. This work seeks to reconceptualize and critically frame the existing discourse on fairness by underlining the implicit biases embedded in common understandings of fairness in the literature and how they contrast with its corresponding economic and legal definitions. This paper expands the concept of utility and fairness by bringing in concepts from established literature in welfare economics and game theory. We then translate these concepts for the algorithmic prediction domain by defining a formalization of Nash Welfare Product that seeks to expand utility by collapsing that of the institution using the prediction tool and the individual subject to the prediction into one function. We then apply a modulating function that makes the fairness and welfare trade-offs explicit based on designated policy goals and then apply it to a temporal model to take into account the effects of decisions beyond the scope of one-shot predictions. We apply this on a binary classification problem and present results of a multi-epoch simulation based on the UCI Adult Income dataset and a test case analysis of the ProPublica recidivism dataset that show that expanding the concept of utility results in a fairer distribution correcting for the embedded biases in the dataset without sacrificing the classifier accuracy.

</details>

<details>

<summary>2018-10-19 16:30:48 - Supervising strong learners by amplifying weak experts</summary>

- *Paul Christiano, Buck Shlegeris, Dario Amodei*

- `1810.08575v1` - [abs](http://arxiv.org/abs/1810.08575v1) - [pdf](http://arxiv.org/pdf/1810.08575v1)

> Many real world learning tasks involve complex or hard-to-specify objectives, and using an easier-to-specify proxy can lead to poor performance or misaligned behavior. One solution is to have humans provide a training signal by demonstrating or judging performance, but this approach fails if the task is too complicated for a human to directly evaluate. We propose Iterated Amplification, an alternative training strategy which progressively builds up a training signal for difficult problems by combining solutions to easier subproblems. Iterated Amplification is closely related to Expert Iteration (Anthony et al., 2017; Silver et al., 2017), except that it uses no external reward function. We present results in algorithmic environments, showing that Iterated Amplification can efficiently learn complex behaviors.

</details>

<details>

<summary>2018-10-19 16:41:27 - Conceptual Organization is Revealed by Consumer Activity Patterns</summary>

- *Adam N. Hornsby, Thomas Evans, Peter Riefer, Rosie Prior, Bradley C. Love*

- `1810.08577v1` - [abs](http://arxiv.org/abs/1810.08577v1) - [pdf](http://arxiv.org/pdf/1810.08577v1)

> Meaning may arise from an element's role or interactions within a larger system. For example, hitting nails is more central to people's concept of a hammer than its particular material composition or other intrinsic features. Likewise, the importance of a web page may result from its links with other pages rather than solely from its content. One example of meaning arising from extrinsic relationships are approaches that extract the meaning of word concepts from co-occurrence patterns in large, text corpora. The success of these methods suggest that human activity patterns may reveal conceptual organization. However, texts do not directly reflect human activity, but instead serve a communicative function and are usually highly curated or edited to suit an audience. Here, we apply methods devised for text to a data source that directly reflects thousands of individuals' activity patterns, namely supermarket purchases. Using product co-occurrence data from nearly 1.3m shopping baskets, we trained a topic model to learn 25 high-level concepts (or "topics"). These topics were found to be comprehensible and coherent by both retail experts and consumers. Topics ranged from specific (e.g., ingredients for a stir-fry) to general (e.g., cooking from scratch). Topics tended to be goal-directed and situational, consistent with the notion that human conceptual knowledge is tailored to support action. Individual differences in the topics sampled predicted basic demographic characteristics. These results suggest that human activity patterns reveal conceptual organization and may give rise to it.

</details>

<details>

<summary>2018-10-19 19:20:17 - The Information Flow Foundation for Conceptual Knowledge Organization</summary>

- *Robert E. Kent*

- `1810.11369v1` - [abs](http://arxiv.org/abs/1810.11369v1) - [pdf](http://arxiv.org/pdf/1810.11369v1)

> The sharing of ontologies between diverse communities of discourse allows them to compare their own information structures with that of other communities that share a common terminology and semantics - ontology sharing facilitates interoperability between online knowledge organizations. This paper demonstrates how ontology sharing is formalizable within the conceptual knowledge model of Information Flow (IF). Information Flow indirectly represents sharing through a specifiable, ontology extension hierarchy augmented with synonymic type equivalencing - two ontologies share terminology and meaning through a common generic ontology that each extends. Using the paradigm of participant community ontologies formalized as IF logics, a common shared extensible ontology formalized as an IF theory, participant community specification links from the common ontology to the participating community ontology formalizable as IF theory interpretations, this paper argues that ontology sharing is concentrated in a virtual ontology of community connections, and demonstrates how this virtual ontology is computable as the fusion of the participant ontologies - the quotient of the sum of the participant ontologies modulo the ontological sharing structure.

</details>

<details>

<summary>2018-10-19 19:45:03 - A Practical Method for Solving Contextual Bandit Problems Using Decision Trees</summary>

- *Adam N. Elmachtoub, Ryan McNellis, Sechan Oh, Marek Petrik*

- `1706.04687v2` - [abs](http://arxiv.org/abs/1706.04687v2) - [pdf](http://arxiv.org/pdf/1706.04687v2)

> Many efficient algorithms with strong theoretical guarantees have been proposed for the contextual multi-armed bandit problem. However, applying these algorithms in practice can be difficult because they require domain expertise to build appropriate features and to tune their parameters. We propose a new method for the contextual bandit problem that is simple, practical, and can be applied with little or no domain expertise. Our algorithm relies on decision trees to model the context-reward relationship. Decision trees are non-parametric, interpretable, and work well without hand-crafted features. To guide the exploration-exploitation trade-off, we use a bootstrapping approach which abstracts Thompson sampling to non-Bayesian settings. We also discuss several computational heuristics and demonstrate the performance of our method on several datasets.

</details>

<details>

<summary>2018-10-19 20:22:53 - Subset Scanning Over Neural Network Activations</summary>

- *Skyler Speakman, Srihari Sridharan, Sekou Remy, Komminist Weldemariam, Edward McFowland*

- `1810.08676v1` - [abs](http://arxiv.org/abs/1810.08676v1) - [pdf](http://arxiv.org/pdf/1810.08676v1)

> This work views neural networks as data generating systems and applies anomalous pattern detection techniques on that data in order to detect when a network is processing an anomalous input. Detecting anomalies is a critical component for multiple machine learning problems including detecting adversarial noise. More broadly, this work is a step towards giving neural networks the ability to recognize an out-of-distribution sample. This is the first work to introduce "Subset Scanning" methods from the anomalous pattern detection domain to the task of detecting anomalous input of neural networks. Subset scanning treats the detection problem as a search for the most anomalous subset of node activations (i.e., highest scoring subset according to non-parametric scan statistics). Mathematical properties of these scoring functions allow the search to be completed in log-linear rather than exponential time while still guaranteeing the most anomalous subset of nodes in the network is identified for a given input. Quantitative results for detecting and characterizing adversarial noise are provided for CIFAR-10 images on a simple convolutional neural network. We observe an "interference" pattern where anomalous activations in shallow layers suppress the activation structure of the original image in deeper layers.

</details>

<details>

<summary>2018-10-19 20:32:36 - Lightweight Convolutional Approaches to Reading Comprehension on SQuAD</summary>

- *Tobin Bell, Benjamin Penchas*

- `1810.08680v1` - [abs](http://arxiv.org/abs/1810.08680v1) - [pdf](http://arxiv.org/pdf/1810.08680v1)

> Current state-of-the-art reading comprehension models rely heavily on recurrent neural networks. We explored an entirely different approach to question answering: a convolutional model. By their nature, these convolutional models are fast to train and capture local dependencies well, though they can struggle with longer-range dependencies and thus require augmentation to achieve comparable performance to RNN-based models. We conducted over two dozen controlled experiments with convolutional models and various kernel/attention/regularization schemes to determine the precise performance gains of each strategy, while maintaining a focus on speed. We ultimately ensembled three models: crossconv (0.5398 dev F1), attnconv (0.5665), and maybeconv (0.5285). The ensembled model was able to achieve a 0.6238 F1 score using the official SQuAD evaluation script. Our individual convolutional model crossconv was able to exceed the performance of the RNN-plus-attention baseline by 25% while training 6 times faster.

</details>

<details>

<summary>2018-10-19 21:41:57 - Hows and Whys of Artificial Intelligence for Public Sector Decisions: Explanation and Evaluation</summary>

- *Alun Preece, Rob Ashelford, Harry Armstrong, Dave Braines*

- `1810.02689v2` - [abs](http://arxiv.org/abs/1810.02689v2) - [pdf](http://arxiv.org/pdf/1810.02689v2)

> Evaluation has always been a key challenge in the development of artificial intelligence (AI) based software, due to the technical complexity of the software artifact and, often, its embedding in complex sociotechnical processes. Recent advances in machine learning (ML) enabled by deep neural networks has exacerbated the challenge of evaluating such software due to the opaque nature of these ML-based artifacts. A key related issue is the (in)ability of such systems to generate useful explanations of their outputs, and we argue that the explanation and evaluation problems are closely linked. The paper models the elements of a ML-based AI system in the context of public sector decision (PSD) applications involving both artificial and human intelligence, and maps these elements against issues in both evaluation and explanation, showing how the two are related. We consider a number of common PSD application patterns in the light of our model, and identify a set of key issues connected to explanation and evaluation in each case. Finally, we propose multiple strategies to promote wider adoption of AI/ML technologies in PSD, where each is distinguished by a focus on different elements of our model, allowing PSD policy makers to adopt an approach that best fits their context and concerns.

</details>

<details>

<summary>2018-10-19 22:47:52 - Mobile Sound Recognition for the Deaf and Hard of Hearing</summary>

- *Leonardo A. Fanzeres, Adriana S. Vivacqua, Luiz W. P. Biscainho*

- `1810.08707v1` - [abs](http://arxiv.org/abs/1810.08707v1) - [pdf](http://arxiv.org/pdf/1810.08707v1)

> Human perception of surrounding events is strongly dependent on audio cues. Thus, acoustic insulation can seriously impact situational awareness. We present an exploratory study in the domain of assistive computing, eliciting requirements and presenting solutions to problems found in the development of an environmental sound recognition system, which aims to assist deaf and hard of hearing people in the perception of sounds. To take advantage of smartphones computational ubiquity, we propose a system that executes all processing on the device itself, from audio features extraction to recognition and visual presentation of results. Our application also presents the confidence level of the classification to the user. A test of the system conducted with deaf users provided important and inspiring feedback from participants.

</details>

<details>

<summary>2018-10-20 05:03:42 - From Machine to Machine: An OCT-trained Deep Learning Algorithm for Objective Quantification of Glaucomatous Damage in Fundus Photographs</summary>

- *Felipe A. Medeiros, Alessandro A. Jammal, Atalie C. Thompson*

- `1810.10343v1` - [abs](http://arxiv.org/abs/1810.10343v1) - [pdf](http://arxiv.org/pdf/1810.10343v1)

> Previous approaches using deep learning algorithms to classify glaucomatous damage on fundus photographs have been limited by the requirement for human labeling of a reference training set. We propose a new approach using spectral-domain optical coherence tomography (SDOCT) data to train a deep learning algorithm to quantify glaucomatous structural damage on optic disc photographs. The dataset included 32,820 pairs of optic disc photos and SDOCT retinal nerve fiber layer (RNFL) scans from 2,312 eyes of 1,198 subjects. A deep learning convolutional neural network was trained to assess optic disc photographs and predict SDOCT average RNFL thickness. The performance of the algorithm was evaluated in an independent test sample. The mean prediction of average RNFL thickness from all 6,292 optic disc photos in the test set was 83.3$\pm$14.5 $\mu$m, whereas the mean average RNFL thickness from all corresponding SDOCT scans was 82.5$\pm$16.8 $\mu$m (P = 0.164). There was a very strong correlation between predicted and observed RNFL thickness values (r = 0.832; P<0.001), with mean absolute error of the predictions of 7.39 $\mu$m. The areas under the receiver operating characteristic curves for discriminating glaucoma from healthy eyes with the deep learning predictions and actual SDOCT measurements were 0.944 (95$\%$ CI: 0.912- 0.966) and 0.940 (95$\%$ CI: 0.902 - 0.966), respectively (P = 0.724). In conclusion, we introduced a novel deep learning approach to assess optic disc photographs and provide quantitative information about the amount of neural damage. This approach could potentially be used to diagnose and stage glaucomatous damage from optic disc photographs.

</details>

<details>

<summary>2018-10-20 06:33:30 - Design of robust H_inf fuzzy output feedback controller for affine nonlinear systems:Fuzzy Lyapunov function approach</summary>

- *Leila Rajabpour, Mokhtar Shasadeghi, Alireza Barzegar*

- `1810.08759v1` - [abs](http://arxiv.org/abs/1810.08759v1) - [pdf](http://arxiv.org/pdf/1810.08759v1)

> In this paper, we propose a new systematic approach based on nonquadratic Lyapunov function and technique of introducing slack matrices, for a class of affine nonlinear systems with disturbance. To achieve the goal, first, the affine nonlinear system is represented via Takagi-Sugeno (T-S) fuzzy bilinear model. Subsequently, the robust H_inf controller is designed based on parallel distributed compensation (PDC) scheme. Then, the stability conditions are derived in terms of linear matrix inequalities (LMIs) by utilizing Lyapunov function. Moreover, some slack matrices are proposed to reduce the conservativeness of the LMI stability conditions. Finally, for illustrating the merits and verifying the effectiveness of the proposed approach, the application of an isothermal continuous stirred tank reactor (CSTR) for Van de Vusse reactor is discussed in details.

</details>

<details>

<summary>2018-10-20 14:25:53 - Autonomous Self-Explanation of Behavior for Interactive Reinforcement Learning Agents</summary>

- *Yosuke Fukuchi, Masahiko Osawa, Hiroshi Yamakawa, Michita Imai*

- `1810.08811v1` - [abs](http://arxiv.org/abs/1810.08811v1) - [pdf](http://arxiv.org/pdf/1810.08811v1)

> In cooperation, the workers must know how co-workers behave. However, an agent's policy, which is embedded in a statistical machine learning model, is hard to understand, and requires much time and knowledge to comprehend. Therefore, it is difficult for people to predict the behavior of machine learning robots, which makes Human Robot Cooperation challenging. In this paper, we propose Instruction-based Behavior Explanation (IBE), a method to explain an autonomous agent's future behavior. In IBE, an agent can autonomously acquire the expressions to explain its own behavior by reusing the instructions given by a human expert to accelerate the learning of the agent's policy. IBE also enables a developmental agent, whose policy may change during the cooperation, to explain its own behavior with sufficient time granularity.

</details>

<details>

<summary>2018-10-20 16:58:54 - A Knowledge-Grounded Multimodal Search-Based Conversational Agent</summary>

- *Shubham Agarwal, Ondrej Dusek, Ioannis Konstas, Verena Rieser*

- `1810.11954v1` - [abs](http://arxiv.org/abs/1810.11954v1) - [pdf](http://arxiv.org/pdf/1810.11954v1)

> Multimodal search-based dialogue is a challenging new task: It extends visually grounded question answering systems into multi-turn conversations with access to an external database. We address this new challenge by learning a neural response generation system from the recently released Multimodal Dialogue (MMD) dataset (Saha et al., 2017). We introduce a knowledge-grounded multimodal conversational model where an encoded knowledge base (KB) representation is appended to the decoder input. Our model substantially outperforms strong baselines in terms of text-based similarity measures (over 9 BLEU points, 3 of which are solely due to the use of additional information from the KB.

</details>

<details>

<summary>2018-10-20 17:41:16 - Enriched Interpretation</summary>

- *Robert E. Kent*

- `1810.08831v1` - [abs](http://arxiv.org/abs/1810.08831v1) - [pdf](http://arxiv.org/pdf/1810.08831v1)

> The theory introduced, presented and developed in this paper, is concerned with an enriched extension of the theory of Rough Sets pioneered by Zdzislaw Pawlak. The enrichment discussed here is in the sense of valuated categories as developed by F.W. Lawvere. This paper relates Rough Sets to an abstraction of the theory of Fuzzy Sets pioneered by Lotfi Zadeh, and provides a natural foundation for "soft computation". To paraphrase Lotfi Zadeh, the impetus for the transition from a hard theory to a soft theory derives from the fact that both the generality of a theory and its applicability to real-world problems are substantially enhanced by replacing various hard concepts with their soft counterparts. Here we discuss the corresponding enriched notions for indiscernibility, subsets, upper/lower approximations, and rough sets. Throughout, we indicate linkages with the theory of Formal Concept Analysis pioneered by Rudolf Wille. We pay particular attention to the all-important notion of a "linguistic variable" - developing its enriched extension, comparing it with the notion of conceptual scale from Formal Concept Analysis, and discussing the pragmatic issues of its creation and use in the interpretation of data. These pragmatic issues are exemplified by the discovery, conceptual analysis, interpretation, and categorization of networked information resources in WAVE, the Web Analysis and Visualization Environment currently being developed for the management and interpretation of the universe of resource information distributed over the World-Wide Web.

</details>

<details>

<summary>2018-10-20 19:34:49 - Kernel Feature Selection via Conditional Covariance Minimization</summary>

- *Jianbo Chen, Mitchell Stern, Martin J. Wainwright, Michael I. Jordan*

- `1707.01164v2` - [abs](http://arxiv.org/abs/1707.01164v2) - [pdf](http://arxiv.org/pdf/1707.01164v2)

> We propose a method for feature selection that employs kernel-based measures of independence to find a subset of covariates that is maximally predictive of the response. Building on past work in kernel dimension reduction, we show how to perform feature selection via a constrained optimization problem involving the trace of the conditional covariance operator. We prove various consistency results for this procedure, and also demonstrate that our method compares favorably with other state-of-the-art algorithms on a variety of synthetic and real data sets.

</details>

<details>

<summary>2018-10-21 03:42:02 - Smart City Development with Urban Transfer Learning</summary>

- *Leye Wang, Bin Guo, Qiang Yang*

- `1808.01552v2` - [abs](http://arxiv.org/abs/1808.01552v2) - [pdf](http://arxiv.org/pdf/1808.01552v2)

> Nowadays, the smart city development levels of different cities are still unbalanced. For a large number of cities which just started development, the governments will face a critical cold-start problem: 'how to develop a new smart city service with limited data?'. To address this problem, transfer learning can be leveraged to accelerate the smart city development, which we term the urban transfer learning paradigm. This article investigates the common process of urban transfer learning, aiming to provide city planners and relevant practitioners with guidelines on how to apply this novel learning paradigm. Our guidelines include common transfer strategies to take, general steps to follow, and case studies in public safety, transportation management, etc. We also summarize a few research opportunities and expect this article can attract more researchers to study urban transfer learning.

</details>

<details>

<summary>2018-10-21 07:56:53 - Estimating savings in parking demand using shared vehicles for home-work commuting</summary>

- *Dániel Kondor, Hongmou Zhang, Remi Tachet, Paolo Santi, Carlo Ratti*

- `1710.04983v4` - [abs](http://arxiv.org/abs/1710.04983v4) - [pdf](http://arxiv.org/pdf/1710.04983v4)

> The increasing availability and adoption of shared vehicles as an alternative to personally-owned cars presents ample opportunities for achieving more efficient transportation in cities. With private cars spending on the average over 95\% of the time parked, one of the possible benefits of shared mobility is the reduced need for parking space. While widely discussed, a systematic quantification of these benefits as a function of mobility demand and sharing models is still mostly lacking in the literature. As a first step in this direction, this paper focuses on a type of private mobility which, although specific, is a major contributor to traffic congestion and parking needs, namely, home-work commuting. We develop a data-driven methodology for estimating commuter parking needs in different shared mobility models, including a model where self-driving vehicles are used to partially compensate flow imbalance typical of commuting, and further reduce parking infrastructure at the expense of increased traveled kilometers. We consider the city of Singapore as a case study, and produce very encouraging results showing that the gradual transition to shared mobility models will bring tangible reductions in parking infrastructure. In the future-looking, self-driving vehicle scenario, our analysis suggests that up to 50\% reduction in parking needs can be achieved at the expense of increasing total traveled kilometers of less than 2\%.

</details>

<details>

<summary>2018-10-21 08:36:37 - Label Noise Filtering Techniques to Improve Monotonic Classification</summary>

- *José-Ramón Cano, Julián Luengo, Salvador García*

- `1810.08914v1` - [abs](http://arxiv.org/abs/1810.08914v1) - [pdf](http://arxiv.org/pdf/1810.08914v1)

> The monotonic ordinal classification has increased the interest of researchers and practitioners within machine learning community in the last years. In real applications, the problems with monotonicity constraints are very frequent. To construct predictive monotone models from those problems, many classifiers require as input a data set satisfying the monotonicity relationships among all samples. Changing the class labels of the data set (relabelling) is useful for this. Relabelling is assumed to be an important building block for the construction of monotone classifiers and it is proved that it can improve the predictive performance.   In this paper, we will address the construction of monotone datasets considering as noise the cases that do not meet the monotonicity restrictions. For the first time in the specialized literature, we propose the use of noise filtering algorithms in a preprocessing stage with a double goal: to increase both the monotonicity index of the models and the accuracy of the predictions for different monotonic classifiers. The experiments are performed over 12 datasets coming from classification and regression problems and show that our scheme improves the prediction capabilities of the monotonic classifiers instead of being applied to original and relabeled datasets. In addition, we have included the analysis of noise filtering process in the particular case of wine quality classification to understand its effect in the predictive models generated.

</details>

<details>

<summary>2018-10-21 13:57:17 - BCWS: Bilingual Contextual Word Similarity</summary>

- *Ta-Chung Chi, Ching-Yen Shih, Yun-Nung Chen*

- `1810.08951v1` - [abs](http://arxiv.org/abs/1810.08951v1) - [pdf](http://arxiv.org/pdf/1810.08951v1)

> This paper introduces the first dataset for evaluating English-Chinese Bilingual Contextual Word Similarity, namely BCWS (https://github.com/MiuLab/BCWS). The dataset consists of 2,091 English-Chinese word pairs with the corresponding sentential contexts and their similarity scores annotated by the human. Our annotated dataset has higher consistency compared to other similar datasets. We establish several baselines for the bilingual embedding task to benchmark the experiments. Modeling cross-lingual sense representations as provided in this dataset has the potential of moving artificial intelligence from monolingual understanding towards multilingual understanding.

</details>

<details>

<summary>2018-10-21 18:41:52 - Mechanism Design for Social Good</summary>

- *Rediet Abebe, Kira Goldner*

- `1810.09832v1` - [abs](http://arxiv.org/abs/1810.09832v1) - [pdf](http://arxiv.org/pdf/1810.09832v1)

> Across various domains--such as health, education, and housing--improving societal welfare involves allocating resources, setting policies, targeting interventions, and regulating activities. These solutions have an immense impact on the day-to-day lives of individuals, whether in the form of access to quality healthcare, labor market outcomes, or how votes are accounted for in a democratic society. Problems that can have an out-sized impact on individuals whose opportunities have historically been limited often pose conceptual and technical challenges, requiring insights from many disciplines. Conversely, the lack of interdisciplinary approach can leave these urgent needs unaddressed and can even exacerbate underlying socioeconomic inequalities. To realize the opportunities in these domains, we need to correctly set objectives and reason about human behavior and actions. Doing so requires a deep grounding in the field of interest and collaboration with domain experts who understand the societal implications and feasibility of proposed solutions. These insights can play an instrumental role in proposing algorithmically-informed policies.   In this article, we describe the Mechanism Design for Social Good (MD4SG) research agenda, which involves using insights from algorithms, optimization, and mechanism design to improve access to opportunity. The MD4SG research community takes an interdisciplinary, multi-stakeholder approach to improve societal welfare. We discuss three exciting research avenues within MD4SG related to improving access to opportunity in the developing world, labor markets and discrimination, and housing. For each of these, we showcase ongoing work, underline new directions, and discuss potential for implementing existing work in practice.

</details>

<details>

<summary>2018-10-21 21:13:48 - Challenge AI Mind: A Crowd System for Proactive AI Testing</summary>

- *Siwei Fu, Anbang Xu, Xiaotong Liu, Huimin Zhou, Rama Akkiraju*

- `1810.09030v1` - [abs](http://arxiv.org/abs/1810.09030v1) - [pdf](http://arxiv.org/pdf/1810.09030v1)

> Artificial Intelligence (AI) has burrowed into our lives in various aspects; however, without appropriate testing, deployed AI systems are often being criticized to fail in critical and embarrassing cases. Existing testing approaches mainly depend on fixed and pre-defined datasets, providing a limited testing coverage. In this paper, we propose the concept of proactive testing to dynamically generate testing data and evaluate the performance of AI systems. We further introduce Challenge.AI, a new crowd system that features the integration of crowdsourcing and machine learning techniques in the process of error generation, error validation, error categorization, and error analysis. We present experiences and insights into a participatory design with AI developers. The evaluation shows that the crowd workflow is more effective with the help of machine learning techniques. AI developers found that our system can help them discover unknown errors made by the AI models, and engage in the process of proactive testing.

</details>

<details>

<summary>2018-10-21 22:30:17 - Soft Concept Analysis</summary>

- *Robert E. Kent*

- `1810.09036v1` - [abs](http://arxiv.org/abs/1810.09036v1) - [pdf](http://arxiv.org/pdf/1810.09036v1)

> In this chapter we discuss soft concept analysis, a study which identifies an enriched notion of "conceptual scale" as developed in formal concept analysis with an enriched notion of "linguistic variable" as discussed in fuzzy logic. The identification "enriched conceptual scale" = "enriched linguistic variable" was made in a previous paper (Enriched interpretation, Robert E. Kent). In this chapter we offer further arguments for the importance of this identification by discussing the philosophy, spirit, and practical application of conceptual scaling to the discovery, conceptual analysis, interpretation, and categorization of networked information resources. We argue that a linguistic variable, which has been defined at just the right generalization of valuated categories, provides a natural definition for the process of soft conceptual scaling. This enrichment using valuated categories models the relation of indiscernability, a notion of central importance in rough set theory. At a more fundamental level for soft concept analysis, it also models the derivation of formal concepts, a process of central importance in formal concept analysis. Soft concept analysis is synonymous with enriched concept analysis. From one viewpoint, the study of soft concept analysis that is initiated here extends formal concept analysis to soft computational structures. From another viewpoint, soft concept analysis provides a natural foundation for soft computation by unifying and explaining notions from soft computation in terms of suitably generalized notions from formal concept analysis, rough set theory and fuzzy set theory.

</details>

<details>

<summary>2018-10-22 04:52:39 - A general learning system based on neuron bursting and tonic firing</summary>

- *Hin Wai Lui*

- `1810.09084v1` - [abs](http://arxiv.org/abs/1810.09084v1) - [pdf](http://arxiv.org/pdf/1810.09084v1)

> This paper proposes a framework for the biological learning mechanism as a general learning system. The proposal is as follows. The bursting and tonic modes of firing patterns found in many neuron types in the brain correspond to two separate modes of information processing, with one mode resulting in awareness, and another mode being subliminal. In such a coding scheme, a neuron in bursting state codes for the highest level of perceptual abstraction representing a pattern of sensory stimuli, or volitional abstraction representing a pattern of muscle contraction sequences. Within the 50-250 ms minimum integration time of experience, the bursting neurons form synchrony ensembles to allow for binding of related percepts. The degree which different bursting neurons can be merged into the same synchrony ensemble depends on the underlying cortical connections that represent the degree of perceptual similarity. These synchrony ensembles compete for selective attention to remain active. The dominant synchrony ensemble triggers episodic memory recall in the hippocampus, while forming new episodic memory with current sensory stimuli, resulting in a stream of thoughts. Neuromodulation modulates both top-down selection of synchrony ensembles, and memory formation. Episodic memory stored in the hippocampus is transferred to semantic and procedural memory in the cortex during rapid eye movement sleep, by updating cortical neuron synaptic weights with spike timing dependent plasticity. With the update of synaptic weights, new neurons become bursting while previous bursting neurons become tonic, allowing bursting neurons to move up to a higher level of perceptual abstraction. Finally, the proposed learning mechanism is compared with the back-propagation algorithm used in deep neural networks, and a proposal of how the credit assignment problem can be addressed by the current proposal is presented.

</details>

<details>

<summary>2018-10-22 05:35:13 - Efficient Dependency-Guided Named Entity Recognition</summary>

- *Zhanming Jie, Aldrian Obaja Muis, Wei Lu*

- `1810.08436v2` - [abs](http://arxiv.org/abs/1810.08436v2) - [pdf](http://arxiv.org/pdf/1810.08436v2)

> Named entity recognition (NER), which focuses on the extraction of semantically meaningful named entities and their semantic classes from text, serves as an indispensable component for several down-stream natural language processing (NLP) tasks such as relation extraction and event extraction. Dependency trees, on the other hand, also convey crucial semantic-level information. It has been shown previously that such information can be used to improve the performance of NER (Sasano and Kurohashi 2008, Ling and Weld 2012). In this work, we investigate on how to better utilize the structured information conveyed by dependency trees to improve the performance of NER. Specifically, unlike existing approaches which only exploit dependency information for designing local features, we show that certain global structured information of the dependency trees can be exploited when building NER models where such information can provide guided learning and inference. Through extensive experiments, we show that our proposed novel dependency-guided NER model performs competitively with models based on conventional semi-Markov conditional random fields, while requiring significantly less running time.

</details>

<details>

<summary>2018-10-22 09:05:57 - Mining useful Macro-actions in Planning</summary>

- *Sandra Castellanos-Paez, Damien Pellier, Humbert Fiorino, Sylvie Pesty*

- `1810.09145v1` - [abs](http://arxiv.org/abs/1810.09145v1) - [pdf](http://arxiv.org/pdf/1810.09145v1)

> Planning has achieved significant progress in recent years. Among the various approaches to scale up plan synthesis, the use of macro-actions has been widely explored. As a first stage towards the development of a solution to learn on-line macro-actions, we propose an algorithm to identify useful macro-actions based on data mining techniques. The integration in the planning search of these learned macro-actions shows significant improvements over six classical planning benchmarks.

</details>

<details>

<summary>2018-10-22 09:32:55 - Mean-based Heuristic Search for Real-Time Planning</summary>

- *Damien Pellier, Bruno Bouzy, Marc Métivier*

- `1810.09150v1` - [abs](http://arxiv.org/abs/1810.09150v1) - [pdf](http://arxiv.org/pdf/1810.09150v1)

> In this paper, we introduce a new heuristic search algorithm based on mean values for real-time planning, called MHSP. It consists in associating the principles of UCT, a bandit-based algorithm which gave very good results in computer games, and especially in Computer Go, with heuristic search in order to obtain a real-time planner in the context of classical planning. MHSP is evaluated on different planning problems and compared to existing algorithms performing on-line search and learning. Besides, our results highlight the capacity of MHSP to return plans in a real-time manner which tend to an optimal plan over the time which is faster and of better quality compared to existing algorithms in the literature.

</details>

<details>

<summary>2018-10-22 10:25:01 - Planification en temps réel avec agenda de buts et sauts</summary>

- *Damien Pellier, Bruno Bouzy, Marc Métivier*

- `1810.10907v1` - [abs](http://arxiv.org/abs/1810.10907v1) - [pdf](http://arxiv.org/pdf/1810.10907v1)

> In the context of real-time planning, this paper investigates the contributions of two enhancements for selecting actions. First, the agenda-driven planning enhancement ranks relevant atomic goals and solves them incrementally in a best-first manner. Second, the committed jump enhancement commits a sequence of actions to be executed at the following time steps. To assess these two enhancements, we developed a real-time planning algorithm in which action selection can be driven by a goal-agenda, and committed jumps can be done. Experimental results, performed on classical planning problems, show that agenda-planning and committed jumps are clear advantages in the real-time context. Used simultaneously, they enable the planner to be several orders of magnitude faster and solution plans to be shorter.

</details>

<details>

<summary>2018-10-22 10:47:03 - What is an Ontology?</summary>

- *Fabian Neuhaus*

- `1810.09171v1` - [abs](http://arxiv.org/abs/1810.09171v1) - [pdf](http://arxiv.org/pdf/1810.09171v1)

> In the knowledge engineering community "ontology" is usually defined in the tradition of Gruber as an "explicit specification of a conceptualization". Several variations of this definition exist. In the paper we argue that (with one notable exception) these definitions are of no explanatory value, because they violate one of the basic rules for good definitions: The defining statement (the definiens) should be clearer than the term that is defined (the definiendum). In the paper we propose a different definition of "ontology" and discuss how it helps to explain various phenomena: the ability of ontologies to change, the role of the choice of vocabulary, the significance of annotations, the possibility of collaborative ontology development, and the relationship between ontological conceptualism and ontological realism.

</details>

<details>

<summary>2018-10-22 12:02:56 - MGP: Un algorithme de planification temps réel prenant en compte l'évolution dynamique du but</summary>

- *Damien Pellier, Mickaël Vanneufville, Humbert Fiorino, Marc Métivier, Bruno Bouzy*

- `1810.10908v1` - [abs](http://arxiv.org/abs/1810.10908v1) - [pdf](http://arxiv.org/pdf/1810.10908v1)

> Devising intelligent robots or agents that interact with humans is a major challenge for artificial intelligence. In such contexts, agents must constantly adapt their decisions according to human activities and modify their goals. In this paper, we tackle this problem by introducing a novel planning approach, called Moving Goal Planning (MGP), to adapt plans to goal evolutions. This planning algorithm draws inspiration from Moving Target Search (MTS) algorithms. In order to limit the number of search iterations and to improve its efficiency, MGP delays as much as possible triggering new searches when the goal changes over time. To this purpose, MGP uses two strategies: Open Check (OC) that checks if the new goal is still in the current search tree and Plan Follow (PF) that estimates whether executing actions of the current plan brings MGP closer to the new goal. Moreover, MGP uses a parsimonious strategy to update incrementally the search tree at each new search that reduces the number of calls to the heuristic function and speeds up the search. Finally, we show evaluation results that demonstrate the effectiveness of our approach.

</details>

<details>

<summary>2018-10-22 12:24:11 - Multi-Agent Actor-Critic with Generative Cooperative Policy Network</summary>

- *Heechang Ryu, Hayong Shin, Jinkyoo Park*

- `1810.09206v1` - [abs](http://arxiv.org/abs/1810.09206v1) - [pdf](http://arxiv.org/pdf/1810.09206v1)

> We propose an efficient multi-agent reinforcement learning approach to derive equilibrium strategies for multi-agents who are participating in a Markov game. Mainly, we are focused on obtaining decentralized policies for agents to maximize the performance of a collaborative task by all the agents, which is similar to solving a decentralized Markov decision process. We propose to use two different policy networks: (1) decentralized greedy policy network used to generate greedy action during training and execution period and (2) generative cooperative policy network (GCPN) used to generate action samples to make other agents improve their objectives during training period. We show that the samples generated by GCPN enable other agents to explore the policy space more effectively and favorably to reach a better policy in terms of achieving the collaborative tasks.

</details>

<details>

<summary>2018-10-22 13:17:28 - A Review on Learning Planning Action Models for Socio-Communicative HRI</summary>

- *Ankuj Arora, Humbert Fiorino, Damien Pellier, Sylvie Pesty*

- `1810.09245v1` - [abs](http://arxiv.org/abs/1810.09245v1) - [pdf](http://arxiv.org/pdf/1810.09245v1)

> For social robots to be brought more into widespread use in the fields of companionship, care taking and domestic help, they must be capable of demonstrating social intelligence. In order to be acceptable, they must exhibit socio-communicative skills. Classic approaches to program HRI from observed human-human interactions fails to capture the subtlety of multimodal interactions as well as the key structural differences between robots and humans. The former arises due to a difficulty in quantifying and coding multimodal behaviours, while the latter due to a difference of the degrees of liberty between a robot and a human. However, the notion of reverse engineering from multimodal HRI traces to learn the underlying behavioral blueprint of the robot given multimodal traces seems an option worth exploring. With this spirit, the entire HRI can be seen as a sequence of exchanges of speech acts between the robot and human, each act treated as an action, bearing in mind that the entire sequence is goal-driven. Thus, this entire interaction can be treated as a sequence of actions propelling the interaction from its initial to goal state, also known as a plan in the domain of AI planning. In the same domain, this action sequence that stems from plan execution can be represented as a trace. AI techniques, such as machine learning, can be used to learn behavioral models (also known as symbolic action models in AI), intended to be reusable for AI planning, from the aforementioned multimodal traces. This article reviews recent machine learning techniques for learning planning action models which can be applied to the field of HRI with the intent of rendering robots as socio-communicative.

</details>

<details>

<summary>2018-10-22 13:40:51 - Une architecture cognitive et affective orient{é}e interaction</summary>

- *Damien Pellier, Carole Adam, Wafa Johal, Humbert Fiorino, Sylvie Pesty*

- `1810.10909v1` - [abs](http://arxiv.org/abs/1810.10909v1) - [pdf](http://arxiv.org/pdf/1810.10909v1)

> In this paper, we present CAIO, a Cognitive and Affective Interaction-Oriented architecture for social human-robot interactions (HRI), allowing robots to reason on mental states (including emotions), and to act physically, emotionally and verbally. We also present a short scenario and implementation on a Nao robot.

</details>

<details>

<summary>2018-10-22 13:48:32 - Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models</summary>

- *Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun, Stefan Lee, David Crandall, Dhruv Batra*

- `1610.02424v2` - [abs](http://arxiv.org/abs/1610.02424v2) - [pdf](http://arxiv.org/pdf/1610.02424v2)

> Neural sequence models are widely used to model time-series data. Equally ubiquitous is the usage of beam search (BS) as an approximate inference algorithm to decode output sequences from these models. BS explores the search space in a greedy left-right fashion retaining only the top-B candidates - resulting in sequences that differ only slightly from each other. Producing lists of nearly identical sequences is not only computationally wasteful but also typically fails to capture the inherent ambiguity of complex AI tasks. To overcome this problem, we propose Diverse Beam Search (DBS), an alternative to BS that decodes a list of diverse outputs by optimizing for a diversity-augmented objective. We observe that our method finds better top-1 solutions by controlling for the exploration and exploitation of the search space - implying that DBS is a better search algorithm. Moreover, these gains are achieved with minimal computational or memory over- head as compared to beam search. To demonstrate the broad applicability of our method, we present results on image captioning, machine translation and visual question generation using both standard quantitative metrics and qualitative human studies. Further, we study the role of diversity for image-grounded language generation tasks as the complexity of the image changes. We observe that our method consistently outperforms BS and previously proposed techniques for diverse decoding from neural sequence models.

</details>

<details>

<summary>2018-10-22 14:06:48 - Une approche totalement instanciée pour la planification HTN</summary>

- *Abdeldjalil Ramoul, Damien Pellier, Humbert Fiorino, Sylvie Pesty*

- `1810.10910v1` - [abs](http://arxiv.org/abs/1810.10910v1) - [pdf](http://arxiv.org/pdf/1810.10910v1)

> Many planning techniques have been developed to allow autonomous systems to act and make decisions based on their perceptions of the environment. Among these techniques, HTN ({\it Hierarchical Task Network}) planning is one of the most used in practice. Unlike classical approaches of planning. HTN operates by decomposing task into sub-tasks until each of these sub-tasks can be achieved an action. This hierarchical representation provide a richer representation of planning problems and allows to better guide the plan search and provides more knowledge to the underlying algorithms. In this paper, we propose a new approach of HTN planning in which, as in conventional planning, we instantiate all planning operators before starting the search process. This approach has proven its effectiveness in classical planning and is necessary for the development of effective heuristics and encoding planning problems in other formalism such as CSP or SAT. The instantiation is actually used by most modern planners but has never been applied in an HTN based planning framework. We present in this article a generic instantiation algorithm which implements many simplification techniques to reduce the process complexity inspired from those used in classical planning. Finally we present some results obtained from an experimentation on a range of problems used in the international planning competitions with a modified version of SHOP planner using fully instantiated problems.

</details>

<details>

<summary>2018-10-22 14:12:03 - On the k-Boundedness for Existential Rules</summary>

- *Stathis Delivorias, Michel Leclere, Marie-Laure Mugnier, Federico Ulliana*

- `1810.09304v1` - [abs](http://arxiv.org/abs/1810.09304v1) - [pdf](http://arxiv.org/pdf/1810.09304v1)

> The chase is a fundamental tool for existential rules. Several chase variants are known, which differ on how they handle redundancies possibly caused by the introduction of nulls. Given a chase variant, the halting problem takes as input a set of existential rules and asks if this set of rules ensures the termination of the chase for any factbase. It is well-known that this problem is undecidable for all known chase variants. The related problem of boundedness asks if a given set of existential rules is bounded, i.e., whether there is a predefined upper bound on the number of (breadth-first) steps of the chase, independently from any factbase. This problem is already undecidable in the specific case of datalog rules. However, knowing that a set of rules is bounded for some chase variant does not help much in practice if the bound is unknown. Hence, in this paper, we investigate the decidability of the k-boundedness problem, which asks whether a given set of rules is bounded by an integer k. We prove that k-boundedness is decidable for three chase variants, namely the oblivious, semi-oblivious and restricted chase.

</details>

<details>

<summary>2018-10-22 14:23:13 - A simulated annealing approach to the student-project allocation problem</summary>

- *Abigail H. Chown, Christopher J. Cook, Nigel B. Wilding*

- `1810.11370v1` - [abs](http://arxiv.org/abs/1810.11370v1) - [pdf](http://arxiv.org/pdf/1810.11370v1)

> We describe a solution to the student-project allocation problem using simulated annealing. The problem involves assigning students to projects, where each student has ranked a fixed number of projects in order of preference. Each project is offered by a specific supervisor (or supervisors), and the goal is to find an optimal matching of students to projects taking into account the students' preferences, the constraint that only one student can be assigned to a given project, and the constraint that supervisors have a maximum workload. We show that when applied to a real dataset from a university physics department, simulated annealing allows the rapid determination of high quality solutions to this allocation problem. The quality of the solution is quantified by a satisfaction metric derived from empirical student survey data. Our approach provides high quality allocations in a matter of minutes that are as good as those found previously by the course organizer using a laborious trial-and-error approach. We investigate how the quality of the allocation is affected by the ratio of the number of projects offered to the number of students and the number of projects ranked by each student. We briefly discuss how our approach can be generalized to include other types of constraints and discuss its potential applicability to wider allocation problems.

</details>

<details>

<summary>2018-10-22 14:26:13 - Ruuh: A Deep Learning Based Conversational Social Agent</summary>

- *Sonam Damani, Nitya Raviprakash, Umang Gupta, Ankush Chatterjee, Meghana Joshi, Khyatti Gupta, Kedhar Nath Narahari, Puneet Agrawal, Manoj Kumar Chinnakotla, Sneha Magapu, Abhishek Mathur*

- `1810.12097v1` - [abs](http://arxiv.org/abs/1810.12097v1) - [pdf](http://arxiv.org/pdf/1810.12097v1)

> Dialogue systems and conversational agents are becoming increasingly popular in the modern society but building an agent capable of holding intelligent conversation with its users is a challenging problem for artificial intelligence. In this demo, we demonstrate a deep learning based conversational social agent called "Ruuh" (facebook.com/Ruuh) designed by a team at Microsoft India to converse on a wide range of topics. Ruuh needs to think beyond the utilitarian notion of merely generating "relevant" responses and meet a wider range of user social needs, like expressing happiness when user's favorite team wins, sharing a cute comment on showing the pictures of the user's pet and so on. The agent also needs to detect and respond to abusive language, sensitive topics and trolling behavior of the users. Many of these problems pose significant research challenges which will be demonstrated in our demo. Our agent has interacted with over 2 million real world users till date which has generated over 150 million user conversations.

</details>

<details>

<summary>2018-10-22 15:25:04 - The Uncertainty Bellman Equation and Exploration</summary>

- *Brendan O'Donoghue, Ian Osband, Remi Munos, Volodymyr Mnih*

- `1709.05380v4` - [abs](http://arxiv.org/abs/1709.05380v4) - [pdf](http://arxiv.org/pdf/1709.05380v4)

> We consider the exploration/exploitation problem in reinforcement learning. For exploitation, it is well known that the Bellman equation connects the value at any time-step to the expected value at subsequent time-steps. In this paper we consider a similar \textit{uncertainty} Bellman equation (UBE), which connects the uncertainty at any time-step to the expected uncertainties at subsequent time-steps, thereby extending the potential exploratory benefit of a policy beyond individual time-steps. We prove that the unique fixed point of the UBE yields an upper bound on the variance of the posterior distribution of the Q-values induced by any policy. This bound can be much tighter than traditional count-based bonuses that compound standard deviation rather than variance. Importantly, and unlike several existing approaches to optimism, this method scales naturally to large systems with complex generalization. Substituting our UBE-exploration strategy for $\epsilon$-greedy improves DQN performance on 51 out of 57 games in the Atari suite.

</details>

<details>

<summary>2018-10-22 15:35:12 - Coupled Longitudinal and Lateral Control of a Vehicle using Deep Learning</summary>

- *Guillaume Devineau, Philip Polack, Florent Altché, Fabien Moutarde*

- `1810.09365v1` - [abs](http://arxiv.org/abs/1810.09365v1) - [pdf](http://arxiv.org/pdf/1810.09365v1)

> This paper explores the capability of deep neural networks to capture key characteristics of vehicle dynamics, and their ability to perform coupled longitudinal and lateral control of a vehicle. To this extent, two different artificial neural networks are trained to compute vehicle controls corresponding to a reference trajectory, using a dataset based on high-fidelity simulations of vehicle dynamics. In this study, control inputs are chosen as the steering angle of the front wheels, and the applied torque on each wheel. The performance of both models, namely a Multi-Layer Perceptron (MLP) and a Convolutional Neural Network (CNN), is evaluated based on their ability to drive the vehicle on a challenging test track, shifting between long straight lines and tight curves. A comparison to conventional decoupled controllers on the same track is also provided.

</details>

<details>

<summary>2018-10-22 16:27:21 - A neuro-inspired architecture for unsupervised continual learning based on online clustering and hierarchical predictive coding</summary>

- *Constantine Dovrolis*

- `1810.09391v1` - [abs](http://arxiv.org/abs/1810.09391v1) - [pdf](http://arxiv.org/pdf/1810.09391v1)

> We propose that the Continual Learning desiderata can be achieved through a neuro-inspired architecture, grounded on Mountcastle's cortical column hypothesis. The proposed architecture involves a single module, called Self-Taught Associative Memory (STAM), which models the function of a cortical column. STAMs are repeated in multi-level hierarchies involving feedforward, lateral and feedback connections. STAM networks learn in an unsupervised manner, based on a combination of online clustering and hierarchical predictive coding. This short paper only presents the architecture and its connections with neuroscience. A mathematical formulation and experimental results will be presented in an extended version of this paper.

</details>

<details>

<summary>2018-10-22 17:37:07 - Addressing Function Approximation Error in Actor-Critic Methods</summary>

- *Scott Fujimoto, Herke van Hoof, David Meger*

- `1802.09477v3` - [abs](http://arxiv.org/abs/1802.09477v3) - [pdf](http://arxiv.org/pdf/1802.09477v3)

> In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.

</details>

<details>

<summary>2018-10-22 17:56:08 - Proactive Security: Embedded AI Solution for Violent and Abusive Speech Recognition</summary>

- *Christopher Dane Shulby, Leonardo Pombal, Vitor Jordão, Guilherme Ziolle, Bruno Martho, Antônio Postal, Thiago Prochnow*

- `1810.09431v1` - [abs](http://arxiv.org/abs/1810.09431v1) - [pdf](http://arxiv.org/pdf/1810.09431v1)

> Violence is an epidemic in Brazil and a problem on the rise world-wide. Mobile devices provide communication technologies which can be used to monitor and alert about violent situations. However, current solutions, like panic buttons or safe words, might increase the loss of life in violent situations. We propose an embedded artificial intelligence solution, using natural language and speech processing technology, to silently alert someone who can help in this situation. The corpus used contains 400 positive phrases and 800 negative phrases, totaling 1,200 sentences which are classified using two well-known extraction methods for natural language processing tasks: bag-of-words and word embeddings and classified with a support vector machine. We describe the proof-of-concept product in development with promising results, indicating a path towards a commercial product. More importantly we show that model improvements via word embeddings and data augmentation techniques provide an intrinsically robust model. The final embedded solution also has a small footprint of less than 10 MB.

</details>

<details>

<summary>2018-10-22 20:43:16 - Convolutional Collaborative Filter Network for Video Based Recommendation Systems</summary>

- *Cheng-Kang Hsieh, Miguel Campo, Abhinav Taliyan, Matt Nickens, Mitkumar Pandya, JJ Espinoza*

- `1810.08189v2` - [abs](http://arxiv.org/abs/1810.08189v2) - [pdf](http://arxiv.org/pdf/1810.08189v2)

> This analysis explores the temporal sequencing of objects in a movie trailer. Temporal sequencing of objects in a movie trailer (e.g., a long shot of an object vs intermittent short shots) can convey information about the type of movie, plot of the movie, role of the main characters, and the filmmakers cinematographic choices. When combined with historical customer data, sequencing analysis can be used to improve predictions of customer behavior. E.g., a customer buys tickets to a new movie and maybe the customer has seen movies in the past that contained similar sequences. To explore object sequencing in movie trailers, we propose a video convolutional network to capture actions and scenes that are predictive of customers' preferences. The model learns the specific nature of sequences for different types of objects (e.g., cars vs faces), and the role of sequences in predicting customer future behavior. We show how such a temporal-aware model outperforms simple feature pooling methods proposed in our previous works and, importantly, demonstrate the additional model explain-ability allowed by such a model.

</details>

<details>

<summary>2018-10-22 21:41:11 - Learning Probabilistic Trajectory Models of Aircraft in Terminal Airspace from Position Data</summary>

- *Shane Barratt, Mykel Kochenderfer, Stephen Boyd*

- `1810.09568v1` - [abs](http://arxiv.org/abs/1810.09568v1) - [pdf](http://arxiv.org/pdf/1810.09568v1)

> Models for predicting aircraft motion are an important component of modern aeronautical systems. These models help aircraft plan collision avoidance maneuvers and help conduct offline performance and safety analyses. In this article, we develop a method for learning a probabilistic generative model of aircraft motion in terminal airspace, the controlled airspace surrounding a given airport. The method fits the model based on a historical dataset of radar-based position measurements of aircraft landings and takeoffs at that airport. We find that the model generates realistic trajectories, provides accurate predictions, and captures the statistical properties of aircraft trajectories. Furthermore, the model trains quickly, is compact, and allows for efficient real-time inference.

</details>

<details>

<summary>2018-10-22 22:06:00 - Posterior Sampling for Large Scale Reinforcement Learning</summary>

- *Georgios Theocharous, Zheng Wen, Yasin Abbasi-Yadkori, Nikos Vlassis*

- `1711.07979v3` - [abs](http://arxiv.org/abs/1711.07979v3) - [pdf](http://arxiv.org/pdf/1711.07979v3)

> We propose a practical non-episodic PSRL algorithm that unlike recent state-of-the-art PSRL algorithms uses a deterministic, model-independent episode switching schedule. Our algorithm termed deterministic schedule PSRL (DS-PSRL) is efficient in terms of time, sample, and space complexity. We prove a Bayesian regret bound under mild assumptions. Our result is more generally applicable to multiple parameters and continuous state action problems. We compare our algorithm with state-of-the-art PSRL algorithms on standard discrete and continuous problems from the literature. Finally, we show how the assumptions of our algorithm satisfy a sensible parametrization for a large class of problems in sequential recommendations.

</details>

<details>

<summary>2018-10-22 23:04:05 - The Lives of Bots</summary>

- *R. Stuart Geiger*

- `1810.09590v1` - [abs](http://arxiv.org/abs/1810.09590v1) - [pdf](http://arxiv.org/pdf/1810.09590v1)

> Automated software agents --- or bots --- have long been an important part of how Wikipedia's volunteer community of editors write, edit, update, monitor, and moderate content. In this paper, I discuss the complex social and technical environment in which Wikipedia's bots operate. This paper focuses on the establishment and role of English Wikipedia's bot policies and the Bot Approvals Group, a volunteer committee that reviews applications for new bots and helps resolve conflicts between Wikipedians about automation. In particular, I examine an early bot controversy over the first bot in Wikipedia to automatically enforce a social norm about how Wikipedian editors ought to interact in discussion spaces. As I show, bots enforce many rules in Wikipedia, but humans produce these bots and negotiate rules around their operation. Because of the openness of Wikipedia's processes around automation, we can vividly observe the often-invisible human work involved in such algorithmic systems --- in stark contrast to most other user-generated content platforms.

</details>

<details>

<summary>2018-10-22 23:37:31 - Biomedical Document Clustering and Visualization based on the Concepts of Diseases</summary>

- *Setu Shah, Xiao Luo*

- `1810.09597v1` - [abs](http://arxiv.org/abs/1810.09597v1) - [pdf](http://arxiv.org/pdf/1810.09597v1)

> Document clustering is a text mining technique used to provide better document search and browsing in digital libraries or online corpora. A lot of research has been done on biomedical document clustering that is based on using existing ontology. But, associations and co-occurrences of the medical concepts are not well represented by using ontology. In this research, a vector representation of concepts of diseases and similarity measurement between concepts are proposed. They identify the closest concepts of diseases in the context of a corpus. Each document is represented by using the vector space model. A weight scheme is proposed to consider both local content and associations between concepts. A Self-Organizing Map is used as document clustering algorithm. The vector projection and visualization features of SOM enable visualization and analysis of the clusters distributions and relationships on the two dimensional space. The experimental results show that the proposed document clustering framework generates meaningful clusters and facilitate visualization of the clusters based on the concepts of diseases.

</details>

<details>

<summary>2018-10-22 23:40:20 - Explainable artificial intelligence (XAI), the goodness criteria and the grasp-ability test</summary>

- *Tae Wan Kim*

- `1810.09598v1` - [abs](http://arxiv.org/abs/1810.09598v1) - [pdf](http://arxiv.org/pdf/1810.09598v1)

> This paper introduces the "grasp-ability test" as a "goodness" criteria by which to compare which explanation is more or less meaningful than others for users to understand the automated algorithmic data processing.

</details>

<details>

<summary>2018-10-23 01:08:25 - Deep Neural Ranking for Crowdsourced Geopolitical Event Forecasting</summary>

- *Giuseppe Nebbione, Derek Doran, Srikanth Nadella, Brandon Minnery*

- `1810.09620v1` - [abs](http://arxiv.org/abs/1810.09620v1) - [pdf](http://arxiv.org/pdf/1810.09620v1)

> There are many examples of 'wisdom of the crowd' effects in which the large number of participants imparts confidence in the collective judgment of the crowd. But how do we form an aggregated judgment when the size of the crowd is limited? Whose judgments do we include, and whose do we accord the most weight? This paper considers this problem in the context of geopolitical event forecasting, where volunteer analysts are queried to give their expertise, confidence, and predictions about the outcome of an event. We develop a forecast aggregation model that integrates topical information about a question, meta-data about a pair of forecasters, and their predictions in a deep siamese neural network that decides which forecasters' predictions are more likely to be close to the correct response. A ranking of the forecasters is induced from a tournament of pair-wise forecaster comparisons, with the ranking used to create an aggregate forecast. Preliminary results find the aggregate prediction of the best forecasters ranked by our deep siamese network model consistently beats typical aggregation techniques by Brier score.

</details>

<details>

<summary>2018-10-23 04:51:29 - Variational Knowledge Graph Reasoning</summary>

- *Wenhu Chen, Wenhan Xiong, Xifeng Yan, William Wang*

- `1803.06581v3` - [abs](http://arxiv.org/abs/1803.06581v3) - [pdf](http://arxiv.org/pdf/1803.06581v3)

> Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying latent variable (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework (\textsc{Diva}) is composed of three modules, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using variational inference, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, \textsc{Diva} is better at handling noise and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets.

</details>

<details>

<summary>2018-10-23 04:52:53 - Hierarchical Approaches for Reinforcement Learning in Parameterized Action Space</summary>

- *Ermo Wei, Drew Wicke, Sean Luke*

- `1810.09656v1` - [abs](http://arxiv.org/abs/1810.09656v1) - [pdf](http://arxiv.org/pdf/1810.09656v1)

> We explore Deep Reinforcement Learning in a parameterized action space. Specifically, we investigate how to achieve sample-efficient end-to-end training in these tasks. We propose a new compact architecture for the tasks where the parameter policy is conditioned on the output of the discrete action policy. We also propose two new methods based on the state-of-the-art algorithms Trust Region Policy Optimization (TRPO) and Stochastic Value Gradient (SVG) to train such an architecture. We demonstrate that these methods outperform the state of the art method, Parameterized Action DDPG, on test domains.

</details>

<details>

<summary>2018-10-23 05:31:15 - RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records</summary>

- *Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, Jaegul Choo*

- `1805.10724v3` - [abs](http://arxiv.org/abs/1805.10724v3) - [pdf](http://arxiv.org/pdf/1805.10724v3)

> We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.

</details>

<details>

<summary>2018-10-23 08:19:33 - Finding Appropriate Traffic Regulations via Graph Convolutional Networks</summary>

- *Tomoharu Iwata, Takuma Otsuka, Hitoshi Shimizu, Hiroshi Sawada, Futoshi Naya, Naonori Ueda*

- `1810.09712v1` - [abs](http://arxiv.org/abs/1810.09712v1) - [pdf](http://arxiv.org/pdf/1810.09712v1)

> Appropriate traffic regulations, e.g. planned road closure, are important in congested events. Crowd simulators have been used to find appropriate regulations by simulating multiple scenarios with different regulations. However, this approach requires multiple simulation runs, which are time-consuming. In this paper, we propose a method to learn a function that outputs regulation effects given the current traffic situation as inputs. If the function is learned using the training data of many simulation runs in advance, we can obtain an appropriate regulation efficiently by bypassing simulations for the current situation. We use the graph convolutional networks for modeling the function, which enable us to find regulations even for unseen areas. With the proposed method, we construct a graph for each area, where a node represents a road, and an edge represents the road connection. By running crowd simulations with various regulations on various areas, we generate traffic situations and regulation effects. The graph convolutional networks are trained to output the regulation effects given the graph with the traffic situation information as inputs. With experiments using real-world road networks and a crowd simulator, we demonstrate that the proposed method can find a road to close that reduces the average time needed to reach the destination.

</details>

<details>

<summary>2018-10-23 08:36:19 - Intrinsic Motivation and Mental Replay enable Efficient Online Adaptation in Stochastic Recurrent Networks</summary>

- *Daniel Tanneberg, Jan Peters, Elmar Rueckert*

- `1802.08013v2` - [abs](http://arxiv.org/abs/1802.08013v2) - [pdf](http://arxiv.org/pdf/1802.08013v2)

> Autonomous robots need to interact with unknown, unstructured and changing environments, constantly facing novel challenges. Therefore, continuous online adaptation for lifelong-learning and the need of sample-efficient mechanisms to adapt to changes in the environment, the constraints, the tasks, or the robot itself are crucial. In this work, we propose a novel framework for probabilistic online motion planning with online adaptation based on a bio-inspired stochastic recurrent neural network. By using learning signals which mimic the intrinsic motivation signalcognitive dissonance in addition with a mental replay strategy to intensify experiences, the stochastic recurrent network can learn from few physical interactions and adapts to novel environments in seconds. We evaluate our online planning and adaptation framework on an anthropomorphic KUKA LWR arm. The rapid online adaptation is shown by learning unknown workspace constraints sample-efficiently from few physical interactions while following given way points.

</details>

<details>

<summary>2018-10-23 08:51:54 - Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A Comprehensive Survey, and Future Directions</summary>

- *Reza Shakeri, Mohammed Ali Al-Garadi, Ahmed Badawy, Amr Mohamed, Tamer Khattab, Abdulla Al-Ali, Khaled A. Harras, Mohsen Guizani*

- `1810.09729v1` - [abs](http://arxiv.org/abs/1810.09729v1) - [pdf](http://arxiv.org/pdf/1810.09729v1)

> Unmanned Aerial Vehicles (UAVs) have recently rapidly grown to facilitate a wide range of innovative applications that can fundamentally change the way cyber-physical systems (CPSs) are designed. CPSs are a modern generation of systems with synergic cooperation between computational and physical potentials that can interact with humans through several new mechanisms. The main advantages of using UAVs in CPS application is their exceptional features, including their mobility, dynamism, effortless deployment, adaptive altitude, agility, adjustability, and effective appraisal of real-world functions anytime and anywhere. Furthermore, from the technology perspective, UAVs are predicted to be a vital element of the development of advanced CPSs. Therefore, in this survey, we aim to pinpoint the most fundamental and important design challenges of multi-UAV systems for CPS applications. We highlight key and versatile aspects that span the coverage and tracking of targets and infrastructure objects, energy-efficient navigation, and image analysis using machine learning for fine-grained CPS applications. Key prototypes and testbeds are also investigated to show how these practical technologies can facilitate CPS applications. We present and propose state-of-the-art algorithms to address design challenges with both quantitative and qualitative methods and map these challenges with important CPS applications to draw insightful conclusions on the challenges of each application. Finally, we summarize potential new directions and ideas that could shape future research in these areas.

</details>

<details>

<summary>2018-10-23 10:22:17 - LoGAN: Generating Logos with a Generative Adversarial Neural Network Conditioned on color</summary>

- *Ajkel Mino, Gerasimos Spanakis*

- `1810.10395v1` - [abs](http://arxiv.org/abs/1810.10395v1) - [pdf](http://arxiv.org/pdf/1810.10395v1)

> Designing a logo is a long, complicated, and expensive process for any designer. However, recent advancements in generative algorithms provide models that could offer a possible solution. Logos are multi-modal, have very few categorical properties, and do not have a continuous latent space. Yet, conditional generative adversarial networks can be used to generate logos that could help designers in their creative process. We propose LoGAN: an improved auxiliary classifier Wasserstein generative adversarial neural network (with gradient penalty) that is able to generate logos conditioned on twelve different colors. In 768 generated instances (12 classes and 64 logos per class), when looking at the most prominent color, the conditional generation part of the model has an overall precision and recall of 0.8 and 0.7 respectively. LoGAN's results offer a first glance at how artificial intelligence can be used to assist designers in their creative process and open promising future directions, such as including more descriptive labels which will provide a more exhaustive and easy-to-use system.

</details>

<details>

<summary>2018-10-23 12:09:37 - PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference Resolution</summary>

- *Hong Chen, Zhenhua Fan, Hao Lu, Alan L. Yuille, Shu Rong*

- `1810.09807v1` - [abs](http://arxiv.org/abs/1810.09807v1) - [pdf](http://arxiv.org/pdf/1810.09807v1)

> We introduce PreCo, a large-scale English dataset for coreference resolution. The dataset is designed to embody the core challenges in coreference, such as entity representation, by alleviating the challenge of low overlap between training and test sets and enabling separated analysis of mention detection and mention clustering. To strengthen the training-test overlap, we collect a large corpus of about 38K documents and 12.4M words which are mostly from the vocabulary of English-speaking preschoolers. Experiments show that with higher training-test overlap, error analysis on PreCo is more efficient than the one on OntoNotes, a popular existing dataset. Furthermore, we annotate singleton mentions making it possible for the first time to quantify the influence that a mention detector makes on coreference resolution performance. The dataset is freely available at https://preschool-lab.github.io/PreCo/.

</details>

<details>

<summary>2018-10-23 13:48:53 - Deep Neural Network inference with reduced word length</summary>

- *Lukas Mauch, Bin Yang*

- `1810.09854v1` - [abs](http://arxiv.org/abs/1810.09854v1) - [pdf](http://arxiv.org/pdf/1810.09854v1)

> Deep neural networks (DNN) are powerful models for many pattern recognition tasks, yet their high computational complexity and memory requirement limit them to applications on high-performance computing platforms. In this paper, we propose a new method to evaluate DNNs trained with 32bit floating point (float32) accuracy using only low precision integer arithmetics in combination with binary shift and clipping operations. Because hardware implementation of these operations is much simpler than high precision floating point calculation, our method can be used for an efficient DNN inference on dedicated hardware. In experiments on MNIST, we demonstrate that DNNs trained with float32 can be evaluated using a combination of 2bit integer arithmetics and a few float32 calculations in each layer or only 3bit integer arithmetics in combination with binary shift and clipping without significant performance degradation.

</details>

<details>

<summary>2018-10-23 15:10:07 - Outcome-Oriented Predictive Process Monitoring: Review and Benchmark</summary>

- *Irene Teinemaa, Marlon Dumas, Marcello La Rosa, Fabrizio Maria Maggi*

- `1707.06766v4` - [abs](http://arxiv.org/abs/1707.06766v4) - [pdf](http://arxiv.org/pdf/1707.06766v4)

> Predictive business process monitoring refers to the act of making predictions about the future state of ongoing cases of a business process, based on their incomplete execution traces and logs of historical (completed) traces. Motivated by the increasingly pervasive availability of fine-grained event data about business process executions, the problem of predictive process monitoring has received substantial attention in the past years. In particular, a considerable number of methods have been put forward to address the problem of outcome-oriented predictive process monitoring, which refers to classifying each ongoing case of a process according to a given set of possible categorical outcomes - e.g., Will the customer complain or not? Will an order be delivered, canceled or withdrawn? Unfortunately, different authors have used different datasets, experimental settings, evaluation measures and baselines to assess their proposals, resulting in poor comparability and an unclear picture of the relative merits and applicability of different methods. To address this gap, this article presents a systematic review and taxonomy of outcome-oriented predictive process monitoring methods, and a comparative experimental evaluation of eleven representative methods using a benchmark covering 24 predictive process monitoring tasks based on nine real-life event logs.

</details>

<details>

<summary>2018-10-23 15:20:56 - Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising</summary>

- *Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Jian Xu, Kun Gai*

- `1802.08365v6` - [abs](http://arxiv.org/abs/1802.08365v6) - [pdf](http://arxiv.org/pdf/1802.08365v6)

> Real-time bidding (RTB) is an important mechanism in online display advertising, where a proper bid for each page view plays an essential role for good marketing results. Budget constrained bidding is a typical scenario in RTB where the advertisers hope to maximize the total value of the winning impressions under a pre-set budget constraint. However, the optimal bidding strategy is hard to be derived due to the complexity and volatility of the auction environment. To address these challenges, in this paper, we formulate budget constrained bidding as a Markov Decision Process and propose a model-free reinforcement learning framework to resolve the optimization problem. Our analysis shows that the immediate reward from environment is misleading under a critical resource constraint. Therefore, we innovate a reward function design methodology for the reinforcement learning problems with constraints. Based on the new reward design, we employ a deep neural network to learn the appropriate reward so that the optimal policy can be learned effectively. Different from the prior model-based work, which suffers from the scalability problem, our framework is easy to be deployed in large-scale industrial applications. The experimental evaluations demonstrate the effectiveness of our framework on large-scale real datasets.

</details>

<details>

<summary>2018-10-23 15:43:32 - Blockchain and Artificial Intelligence</summary>

- *Tshilidzi Marwala, Bo Xing*

- `1802.04451v2` - [abs](http://arxiv.org/abs/1802.04451v2) - [pdf](http://arxiv.org/pdf/1802.04451v2)

> It is undeniable that artificial intelligence (AI) and blockchain concepts are spreading at a phenomenal rate. Both technologies have distinct degree of technological complexity and multi-dimensional business implications. However, a common misunderstanding about blockchain concept, in particular, is that blockchain is decentralized and is not controlled by anyone. But the underlying development of a blockchain system is still attributed to a cluster of core developers. Take smart contract as an example, it is essentially a collection of codes (or functions) and data (or states) that are programmed and deployed on a blockchain (say, Ethereum) by different human programmers. It is thus, unfortunately, less likely to be free of loopholes and flaws. In this article, through a brief overview about how artificial intelligence could be used to deliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we to emphasize that the blockchain implementation can be assisted or enhanced via various AI techniques. The alliance of AI and blockchain is expected to create numerous possibilities.

</details>

<details>

<summary>2018-10-23 15:51:57 - Reconstruction of Hidden Representation for Robust Feature Extraction</summary>

- *Zeng Yu, Tianrui Li, Ning Yu, Yi Pan, Hongmei Chen, Bing Liu*

- `1710.02844v2` - [abs](http://arxiv.org/abs/1710.02844v2) - [pdf](http://arxiv.org/pdf/1710.02844v2)

> This paper aims to develop a new and robust approach to feature representation. Motivated by the success of Auto-Encoders, we first theoretical summarize the general properties of all algorithms that are based on traditional Auto-Encoders: 1) The reconstruction error of the input can not be lower than a lower bound, which can be viewed as a guiding principle for reconstructing the input. Additionally, when the input is corrupted with noises, the reconstruction error of the corrupted input also can not be lower than a lower bound. 2) The reconstruction of a hidden representation achieving its ideal situation is the necessary condition for the reconstruction of the input to reach the ideal state. 3) Minimizing the Frobenius norm of the Jacobian matrix of the hidden representation has a deficiency and may result in a much worse local optimum value. We believe that minimizing the reconstruction error of the hidden representation is more robust than minimizing the Frobenius norm of the Jacobian matrix of the hidden representation. Based on the above analysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs), which uses corruption and reconstruction on both the input and the hidden representation. We demonstrate that the proposed model is highly flexible and extensible and has a potentially better capability to learn invariant and robust feature representations. We also show that our model is more robust than Denoising Auto-Encoders (DAEs) for dealing with noises or inessential features. Furthermore, we detail how to train DDAEs with two different pre-training methods by optimizing the objective function in a combined and separate manner, respectively. Comparative experiments illustrate that the proposed model is significantly better for representation learning than the state-of-the-art models.

</details>

<details>

<summary>2018-10-23 17:43:54 - Efficient computational strategies to learn the structure of probabilistic graphical models of cumulative phenomena</summary>

- *Daniele Ramazzotti, Marco S. Nobile, Marco Antoniotti, Alex Graudenzi*

- `1703.03074v4` - [abs](http://arxiv.org/abs/1703.03074v4) - [pdf](http://arxiv.org/pdf/1703.03074v4)

> Structural learning of Bayesian Networks (BNs) is a NP-hard problem, which is further complicated by many theoretical issues, such as the I-equivalence among different structures. In this work, we focus on a specific subclass of BNs, named Suppes-Bayes Causal Networks (SBCNs), which include specific structural constraints based on Suppes' probabilistic causation to efficiently model cumulative phenomena. Here we compare the performance, via extensive simulations, of various state-of-the-art search strategies, such as local search techniques and Genetic Algorithms, as well as of distinct regularization methods. The assessment is performed on a large number of simulated datasets from topologies with distinct levels of complexity, various sample size and different rates of errors in the data. Among the main results, we show that the introduction of Suppes' constraints dramatically improve the inference accuracy, by reducing the solution space and providing a temporal ordering on the variables. We also report on trade-offs among different search techniques that can be efficiently employed in distinct experimental settings. This manuscript is an extended version of the paper "Structural Learning of Probabilistic Graphical Models of Cumulative Phenomena" presented at the 2018 International Conference on Computational Science.

</details>

<details>

<summary>2018-10-23 17:52:36 - Automated Reasoning in Normative Detachment Structures with Ideal Conditions</summary>

- *Tomer Libal, Matteo Pascucci*

- `1810.09993v1` - [abs](http://arxiv.org/abs/1810.09993v1) - [pdf](http://arxiv.org/pdf/1810.09993v1)

> Systems of deontic logic suffer either from being too expressive and therefore hard to mechanize, or from being too simple to capture relevant aspects of normative reasoning. In this article we look for a suitable way in between: the automation of a simple logic of normative ideality and sub-ideality that is not affected by many deontic paradoxes and that is expressive enough to capture contrary-to-duty reason- ing. We show that this logic is very useful to reason on normative scenarios from which one can extract a certain kind of argumentative structure, called a Normative Detachment Structure with Ideal Conditions. The theoretical analysis of the logic is accompanied by examples of automated reasoning on a concrete legal text.

</details>

<details>

<summary>2018-10-23 18:14:47 - Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial Examples Against Gradient Obfuscation Defenses</summary>

- *Mohammad Hashemi, Greg Cusack, Eric Keller*

- `1810.10031v1` - [abs](http://arxiv.org/abs/1810.10031v1) - [pdf](http://arxiv.org/pdf/1810.10031v1)

> It has been shown that adversaries can craft example inputs to neural networks which are similar to legitimate inputs but have been created to purposely cause the neural network to misclassify the input. These adversarial examples are crafted, for example, by calculating gradients of a carefully defined loss function with respect to the input. As a countermeasure, some researchers have tried to design robust models by blocking or obfuscating gradients, even in white-box settings. Another line of research proposes introducing a separate detector to attempt to detect adversarial examples. This approach also makes use of gradient obfuscation techniques, for example, to prevent the adversary from trying to fool the detector. In this paper, we introduce stochastic substitute training, a gray-box approach that can craft adversarial examples for defenses which obfuscate gradients. For those defenses that have tried to make models more robust, with our technique, an adversary can craft adversarial examples with no knowledge of the defense. For defenses that attempt to detect the adversarial examples, with our technique, an adversary only needs very limited information about the defense to craft adversarial examples. We demonstrate our technique by applying it against two defenses which make models more robust and two defenses which detect adversarial examples.

</details>

<details>

<summary>2018-10-23 18:29:02 - I Know How You Feel: Emotion Recognition with Facial Landmarks</summary>

- *Ivona Tautkute, Tomasz Trzcinski, Adam Bielski*

- `1805.00326v2` - [abs](http://arxiv.org/abs/1805.00326v2) - [pdf](http://arxiv.org/pdf/1805.00326v2)

> Classification of human emotions remains an important and challenging task for many computer vision algorithms, especially in the era of humanoid robots which coexist with humans in their everyday life. Currently proposed methods for emotion recognition solve this task using multi-layered convolutional networks that do not explicitly infer any facial features in the classification phase. In this work, we postulate a fundamentally different approach to solve emotion recognition task that relies on incorporating facial landmarks as a part of the classification loss function. To that end, we extend a recently proposed Deep Alignment Network (DAN), that achieves state-of-the-art results in the recent facial landmark recognition challenge, with a term related to facial features. Thanks to this simple modification, our model called EmotionalDAN is able to outperform state-of-the-art emotion classification methods on two challenging benchmark dataset by up to 5%.

</details>

<details>

<summary>2018-10-23 18:59:02 - Insights on representational similarity in neural networks with canonical correlation</summary>

- *Ari S. Morcos, Maithra Raghu, Samy Bengio*

- `1806.05759v3` - [abs](http://arxiv.org/abs/1806.05759v3) - [pdf](http://arxiv.org/pdf/1806.05759v3)

> Comparing different neural network representations and determining how representations evolve over time remain challenging open questions in our understanding of the function of neural networks. Comparing representations in neural networks is fundamentally difficult as the structure of representations varies greatly, even across groups of networks trained on identical tasks, and over the course of training. Here, we develop projection weighted CCA (Canonical Correlation Analysis) as a tool for understanding neural networks, building off of SVCCA, a recently proposed method (Raghu et al., 2017). We first improve the core method, showing how to differentiate between signal and noise, and then apply this technique to compare across a group of CNNs, demonstrating that networks which generalize converge to more similar representations than networks which memorize, that wider networks converge to more similar solutions than narrow networks, and that trained networks with identical topology but different learning rates converge to distinct clusters with diverse representations. We also investigate the representational dynamics of RNNs, across both training and sequential timesteps, finding that RNNs converge in a bottom-up pattern over the course of training and that the hidden state is highly variable over the course of a sequence, even when accounting for linear transforms. Together, these results provide new insights into the function of CNNs and RNNs, and demonstrate the utility of using CCA to understand representations.

</details>

<details>

<summary>2018-10-23 19:22:25 - Time-Agnostic Prediction: Predicting Predictable Video Frames</summary>

- *Dinesh Jayaraman, Frederik Ebert, Alexei A. Efros, Sergey Levine*

- `1808.07784v3` - [abs](http://arxiv.org/abs/1808.07784v3) - [pdf](http://arxiv.org/pdf/1808.07784v3)

> Prediction is arguably one of the most basic functions of an intelligent system. In general, the problem of predicting events in the future or between two waypoints is exceedingly difficult. However, most phenomena naturally pass through relatively predictable bottlenecks---while we cannot predict the precise trajectory of a robot arm between being at rest and holding an object up, we can be certain that it must have picked the object up. To exploit this, we decouple visual prediction from a rigid notion of time. While conventional approaches predict frames at regularly spaced temporal intervals, our time-agnostic predictors (TAP) are not tied to specific times so that they may instead discover predictable "bottleneck" frames no matter when they occur. We evaluate our approach for future and intermediate frame prediction across three robotic manipulation tasks. Our predictions are not only of higher visual quality, but also correspond to coherent semantic subgoals in temporally extended tasks.

</details>

<details>

<summary>2018-10-23 19:23:11 - Accelerating Deep Learning with Memcomputing</summary>

- *Haik Manukian, Fabio L. Traversa, Massimiliano Di Ventra*

- `1801.00512v3` - [abs](http://arxiv.org/abs/1801.00512v3) - [pdf](http://arxiv.org/pdf/1801.00512v3)

> Restricted Boltzmann machines (RBMs) and their extensions, called 'deep-belief networks', are powerful neural networks that have found applications in the fields of machine learning and artificial intelligence. The standard way to training these models resorts to an iterative unsupervised procedure based on Gibbs sampling, called 'contrastive divergence' (CD), and additional supervised tuning via back-propagation. However, this procedure has been shown not to follow any gradient and can lead to suboptimal solutions. In this paper, we show an efficient alternative to CD by means of simulations of digital memcomputing machines (DMMs). We test our approach on pattern recognition using a modified version of the MNIST data set. DMMs sample effectively the vast phase space given by the model distribution of the RBM, and provide a very good approximation close to the optimum. This efficient search significantly reduces the number of pretraining iterations necessary to achieve a given level of accuracy, as well as a total performance gain over CD. In fact, the acceleration of pretraining achieved by simulating DMMs is comparable to, in number of iterations, the recently reported hardware application of the quantum annealing method on the same network and data set. Notably, however, DMMs perform far better than the reported quantum annealing results in terms of quality of the training. We also compare our method to advances in supervised training, like batch-normalization and rectifiers, that work to reduce the advantage of pretraining. We find that the memcomputing method still maintains a quality advantage ($>1\%$ in accuracy, and a $20\%$ reduction in error rate) over these approaches. Furthermore, our method is agnostic about the connectivity of the network. Therefore, it can be extended to train full Boltzmann machines, and even deep networks at once.

</details>

<details>

<summary>2018-10-23 21:41:41 - Comparative Evaluation of Tree-Based Ensemble Algorithms for Short-Term Travel Time Prediction</summary>

- *Saleh Mousa, Sherif Ishak*

- `1810.10102v1` - [abs](http://arxiv.org/abs/1810.10102v1) - [pdf](http://arxiv.org/pdf/1810.10102v1)

> Disseminating accurate travel time information to road users helps achieve traffic equilibrium and reduce traffic congestion. The deployment of Connected Vehicles technology will provide unique opportunities for the implementation of travel time prediction models. The aim of this study is twofold: (1) estimate travel times in the freeway network at five-minute intervals using Basic Safety Messages (BSM); (2) develop an eXtreme Gradient Boosting (XGB) model for short-term travel time prediction on freeways. The XGB tree-based ensemble prediction model is evaluated against common tree-based ensemble algorithms and the evaluations are performed at five-minute intervals over a 30-minute horizon. BSMs generated by the Safety Pilot Model Deployment conducted in Ann Arbor, Michigan, were used. Nearly two billion messages were processed for providing travel time estimates for the entire freeway network. A Combination of grid search and five-fold cross-validation techniques using the travel time estimates were used for developing the prediction models and tuning their parameters. About 9.6 km freeway stretch was used for evaluating the XGB together with the most common tree-based ensemble algorithms. The results show that XGB is superior to all other algorithms, followed by the Gradient Boosting. XGB travel time predictions were accurate and consistent with variations during peak periods, with mean absolute percentage error in prediction about 5.9% and 7.8% for 5-minute and 30-minute horizons, respectively. Additionally, through applying the developed models to another 4.7 km stretch along the eastbound segment of M-14, the XGB demonstrated its considerable advantages in travel time prediction during congested and uncongested conditions.

</details>

<details>

<summary>2018-10-23 22:20:27 - A mathematical theory of semantic development in deep neural networks</summary>

- *Andrew M. Saxe, James L. McClelland, Surya Ganguli*

- `1810.10531v1` - [abs](http://arxiv.org/abs/1810.10531v1) - [pdf](http://arxiv.org/pdf/1810.10531v1)

> An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.

</details>

<details>

<summary>2018-10-24 02:40:14 - Automatic Identification of Indicators of Compromise using Neural-Based Sequence Labelling</summary>

- *Shengping Zhou, Zi Long, Lianzhi Tan, Hao Guo*

- `1810.10156v1` - [abs](http://arxiv.org/abs/1810.10156v1) - [pdf](http://arxiv.org/pdf/1810.10156v1)

> Indicators of Compromise (IOCs) are artifacts observed on a network or in an operating system that can be utilized to indicate a computer intrusion and detect cyber-attacks in an early stage. Thus, they exert an important role in the field of cybersecurity. However, state-of-the-art IOCs detection systems rely heavily on hand-crafted features with expert knowledge of cybersecurity, and require a large amount of supervised training corpora to train an IOC classifier. In this paper, we propose using a neural-based sequence labelling model to identify IOCs automatically from reports on cybersecurity without expert knowledge of cybersecurity. Our work is the first to apply an end-to-end sequence labelling to the task in IOCs identification. By using an attention mechanism and several token spelling features, we find that the proposed model is capable of identifying the low frequency IOCs from long sentences contained in cybersecurity reports. Experiments show that the proposed model outperforms other sequence labelling models, achieving over 88% average F1-score.

</details>

<details>

<summary>2018-10-24 03:56:07 - Data-driven Blockbuster Planning on Online Movie Knowledge Library</summary>

- *Ye Liu, Jiawei Zhang, Chenwei Zhang, Philip S. Yu*

- `1810.10175v1` - [abs](http://arxiv.org/abs/1810.10175v1) - [pdf](http://arxiv.org/pdf/1810.10175v1)

> In the era of big data, logistic planning can be made data-driven to take advantage of accumulated knowledge in the past. While in the movie industry, movie planning can also exploit the existing online movie knowledge library to achieve better results. However, it is ineffective to solely rely on conventional heuristics for movie planning, due to a large number of existing movies and various real-world factors that contribute to the success of each movie, such as the movie genre, available budget, production team (involving actor, actress, director, and writer), etc. In this paper, we study a "Blockbuster Planning" (BP) problem to learn from previous movies and plan for low budget yet high return new movies in a totally data-driven fashion. After a thorough investigation of an online movie knowledge library, a novel movie planning framework "Blockbuster Planning with Maximized Movie Configuration Acquaintance" (BigMovie) is introduced in this paper. From the investment perspective, BigMovie maximizes the estimated gross of the planned movies with a given budget. It is able to accurately estimate the movie gross with a 0.26 mean absolute percentage error (and 0.16 for budget). Meanwhile, from the production team's perspective, BigMovie is able to formulate an optimized team with people/movie genres that team members are acquainted with. Historical collaboration records are utilized to estimate acquaintance scores of movie configuration factors via an acquaintance tensor. We formulate the BP problem as a non-linear binary programming problem and prove its NP-hardness. To solve it in polynomial time, BigMovie relaxes the hard binary constraints and addresses the BP problem as a cubic programming problem. Extensive experiments conducted on IMDB movie database demonstrate the capability of BigMovie for an effective data-driven blockbuster planning.

</details>

<details>

<summary>2018-10-24 04:08:22 - Exploiting Deep Representations for Neural Machine Translation</summary>

- *Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Shuming Shi, Tong Zhang*

- `1810.10181v1` - [abs](http://arxiv.org/abs/1810.10181v1) - [pdf](http://arxiv.org/pdf/1810.10181v1)

> Advanced neural machine translation (NMT) models generally implement encoder and decoder as multiple layers, which allows systems to model complex functions and capture complicated linguistic structures. However, only the top layers of encoder and decoder are leveraged in the subsequent process, which misses the opportunity to exploit the useful information embedded in other layers. In this work, we propose to simultaneously expose all of these signals with layer aggregation and multi-layer attention mechanisms. In addition, we introduce an auxiliary regularization term to encourage different layers to capture diverse information. Experimental results on widely-used WMT14 English-German and WMT17 Chinese-English translation data demonstrate the effectiveness and universality of the proposed approach.

</details>

<details>

<summary>2018-10-24 04:08:25 - Modeling Localness for Self-Attention Networks</summary>

- *Baosong Yang, Zhaopeng Tu, Derek F. Wong, Fandong Meng, Lidia S. Chao, Tong Zhang*

- `1810.10182v1` - [abs](http://arxiv.org/abs/1810.10182v1) - [pdf](http://arxiv.org/pdf/1810.10182v1)

> Self-attention networks have proven to be of profound value for its strength of capturing global dependencies. In this work, we propose to model localness for self-attention networks, which enhances the ability of capturing useful local context. We cast localness modeling as a learnable Gaussian bias, which indicates the central and scope of the local region to be paid more attention. The bias is then incorporated into the original attention distribution to form a revised distribution. To maintain the strength of capturing long distance dependencies and enhance the ability of capturing short-range dependencies, we only apply localness modeling to lower layers of self-attention networks. Quantitative and qualitative analyses on Chinese-English and English-German translation tasks demonstrate the effectiveness and universality of the proposed approach.

</details>

<details>

<summary>2018-10-24 04:08:27 - Multi-Head Attention with Disagreement Regularization</summary>

- *Jian Li, Zhaopeng Tu, Baosong Yang, Michael R. Lyu, Tong Zhang*

- `1810.10183v1` - [abs](http://arxiv.org/abs/1810.10183v1) - [pdf](http://arxiv.org/pdf/1810.10183v1)

> Multi-head attention is appealing for the ability to jointly attend to information from different representation subspaces at different positions. In this work, we introduce a disagreement regularization to explicitly encourage the diversity among multiple attention heads. Specifically, we propose three types of disagreement regularization, which respectively encourage the subspace, the attended positions, and the output representation associated with each attention head to be different from other heads. Experimental results on widely-used WMT14 English-German and WMT17 Chinese-English translation tasks demonstrate the effectiveness and universality of the proposed approach.

</details>

<details>

<summary>2018-10-24 06:01:45 - Soft-Robust Actor-Critic Policy-Gradient</summary>

- *Esther Derman, Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor*

- `1803.04848v2` - [abs](http://arxiv.org/abs/1803.04848v2) - [pdf](http://arxiv.org/pdf/1803.04848v2)

> Robust Reinforcement Learning aims to derive optimal behavior that accounts for model uncertainty in dynamical systems. However, previous studies have shown that by considering the worst case scenario, robust policies can be overly conservative. Our soft-robust framework is an attempt to overcome this issue. In this paper, we present a novel Soft-Robust Actor-Critic algorithm (SR-AC). It learns an optimal policy with respect to a distribution over an uncertainty set and stays robust to model uncertainty but avoids the conservativeness of robust strategies. We show the convergence of SR-AC and test the efficiency of our approach on different domains by comparing it against regular learning methods and their robust formulations.

</details>

<details>

<summary>2018-10-24 08:22:01 - Multistep Speed Prediction on Traffic Networks: A Graph Convolutional Sequence-to-Sequence Learning Approach with Attention Mechanism</summary>

- *Zhengchao Zhang, Meng Li, Xi Lin, Yinhai Wang, Fang He*

- `1810.10237v1` - [abs](http://arxiv.org/abs/1810.10237v1) - [pdf](http://arxiv.org/pdf/1810.10237v1)

> Multistep traffic forecasting on road networks is a crucial task in successful intelligent transportation system applications. To capture the complex non-stationary temporal dynamics and spatial dependency in multistep traffic-condition prediction, we propose a novel deep learning framework named attention graph convolutional sequence-to-sequence model (AGC-Seq2Seq). In the proposed deep learning framework, spatial and temporal dependencies are modeled through the Seq2Seq model and graph convolution network separately, and the attention mechanism along with a newly designed training method based on the Seq2Seq architecture is proposed to overcome the difficulty in multistep prediction and further capture the temporal heterogeneity of traffic pattern. We conduct numerical tests to compare AGC-Seq2Seq with other benchmark models using a real-world dataset. The results indicate that our model yields the best prediction performance in terms of various prediction error measures. Furthermore, the variation of spatiotemporal correlation of traffic conditions under different perdition steps and road segments is revealed through sensitivity analyses.

</details>

<details>

<summary>2018-10-24 11:07:44 - Coarse-to-fine volumetric segmentation of teeth in Cone-Beam CT</summary>

- *Matvey Ezhov, Adel Zakirov, Maxim Gusarev*

- `1810.10293v1` - [abs](http://arxiv.org/abs/1810.10293v1) - [pdf](http://arxiv.org/pdf/1810.10293v1)

> We consider the problem of localizing and segmenting individual teeth inside 3D Cone-Beam Computed Tomography (CBCT) images. To handle large image sizes we approach this task with a coarse-to-fine framework, where the whole volume is first analyzed as a 33-class semantic segmentation (adults have up to 32 teeth) in coarse resolution, followed by binary semantic segmentation of the cropped region of interest in original resolution. To improve the performance of the challenging 33-class segmentation, we first train the Coarse step model on a large weakly labeled dataset, then fine-tune it on a smaller precisely labeled dataset. The Fine step model is trained with precise labels only. Experiments using our in-house dataset show significant improvement for both weakly-supervised pretraining and for the addition of the Fine step. Empirically, this framework yields precise teeth masks with low localization errors sufficient for many real-world applications.

</details>

<details>

<summary>2018-10-24 11:44:00 - A predictive processing model of perception and action for self-other distinction</summary>

- *Sebastian Kahl, Stefan Kopp*

- `1810.09879v2` - [abs](http://arxiv.org/abs/1810.09879v2) - [pdf](http://arxiv.org/pdf/1810.09879v2)

> During interaction with others, we perceive and produce social actions in close temporal distance or even simultaneously. It has been argued that the motor system is involved in perception and action, playing a fundamental role in the handling of actions produced by oneself and by others. But how does it distinguish in this processing between self and other, thus contributing to self-other distinction? In this paper we propose a hierarchical model of sensorimotor coordination based on principles of perception-action coupling and predictive processing in which self-other distinction arises during action and perception. For this we draw on mechanisms assumed for the integration of cues for a sense of agency, i.e., the sense that an action is self-generated. We report results from simulations of different scenarios, showing that the model is not only able to minimize free energy during perception and action, but also showing that the model can correctly attribute sense of agency to own actions.

</details>

<details>

<summary>2018-10-24 14:30:39 - Effective extractive summarization using frequency-filtered entity relationship graphs</summary>

- *Archit Sakhadeo, Nisheeth Srivastava*

- `1810.10419v1` - [abs](http://arxiv.org/abs/1810.10419v1) - [pdf](http://arxiv.org/pdf/1810.10419v1)

> Word frequency-based methods for extractive summarization are easy to implement and yield reasonable results across languages. However, they have significant limitations - they ignore the role of context, they offer uneven coverage of topics in a document, and sometimes are disjointed and hard to read. We use a simple premise from linguistic typology - that English sentences are complete descriptors of potential interactions between entities, usually in the order subject-verb-object - to address a subset of these difficulties. We have developed a hybrid model of extractive summarization that combines word-frequency based keyword identification with information from automatically generated entity relationship graphs to select sentences for summaries. Comparative evaluation with word-frequency and topic word-based methods shows that the proposed method is competitive by conventional ROUGE standards, and yields moderately more informative summaries on average, as assessed by a large panel (N=94) of human raters.

</details>

<details>

<summary>2018-10-24 15:57:02 - A deep material network for multiscale topology learning and accelerated nonlinear modeling of heterogeneous materials</summary>

- *Zeliang Liu, C. T. Wu, M. Koishi*

- `1807.09829v4` - [abs](http://arxiv.org/abs/1807.09829v4) - [pdf](http://arxiv.org/pdf/1807.09829v4)

> In this paper, a new data-driven multiscale material modeling method, which we refer to as deep material network, is developed based on mechanistic homogenization theory of representative volume element (RVE) and advanced machine learning techniques. We propose to use a collection of connected mechanistic building blocks with analytical homogenization solutions which avoids the loss of essential physics in generic neural networks, and this concept is demonstrated for 2-dimensional RVE problems and network depth up to 7. Based on linear elastic RVE data from offline direct numerical simulations, the material network can be effectively trained using stochastic gradient descent with backpropagation algorithm, enhanced by model compression methods. Importantly, the trained network is valid for any local material laws without the need for additional calibration or micromechanics assumption. Its extrapolations to unknown material and loading spaces for a wide range of problems are validated through numerical experiments, including linear elasticity with high contrast of phase properties, nonlinear history-dependent plasticity and finite-strain hyperelasticity under large deformations.   By discovering a proper topological representation of RVE with fewer degrees of freedom, this intelligent material model is believed to open new possibilities of high-fidelity efficient concurrent simulations for a large-scale heterogeneous structure. It also provides a mechanistic understanding of structure-property relations across material length scales and enables the development of parameterized microstructural database for material design and manufacturing.

</details>

<details>

<summary>2018-10-24 16:06:33 - Learning Negotiating Behavior Between Cars in Intersections using Deep Q-Learning</summary>

- *Tommy Tram, Anton Jansson, Robin Grönberg, Mohammad Ali, Jonas Sjöberg*

- `1810.10469v1` - [abs](http://arxiv.org/abs/1810.10469v1) - [pdf](http://arxiv.org/pdf/1810.10469v1)

> This paper concerns automated vehicles negotiating with other vehicles, typically human driven, in crossings with the goal to find a decision algorithm by learning typical behaviors of other vehicles. The vehicle observes distance and speed of vehicles on the intersecting road and use a policy that adapts its speed along its pre-defined trajectory to pass the crossing efficiently. Deep Q-learning is used on simulated traffic with different predefined driver behaviors and intentions. The results show a policy that is able to cross the intersection avoiding collision with other vehicles 98% of the time, while at the same time not being too passive. Moreover, inferring information over time is important to distinguish between different intentions and is shown by comparing the collision rate between a Deep Recurrent Q-Network at 0.85% and a Deep Q-learning at 1.75%.

</details>

<details>

<summary>2018-10-24 17:08:36 - Multi-Multi-View Learning: Multilingual and Multi-Representation Entity Typing</summary>

- *Yadollah Yaghoobzadeh, Hinrich Schütze*

- `1810.10499v1` - [abs](http://arxiv.org/abs/1810.10499v1) - [pdf](http://arxiv.org/pdf/1810.10499v1)

> Knowledge bases (KBs) are paramount in NLP. We employ multiview learning for increasing accuracy and coverage of entity type information in KBs. We rely on two metaviews: language and representation. For language, we consider high-resource and low-resource languages from Wikipedia. For representation, we consider representations based on the context distribution of the entity (i.e., on its embedding), on the entity's name (i.e., on its surface form) and on its description in Wikipedia. The two metaviews language and representation can be freely combined: each pair of language and representation (e.g., German embedding, English description, Spanish name) is a distinct view. Our experiments on entity typing with fine-grained classes demonstrate the effectiveness of multiview learning. We release MVET, a large multiview - and, in particular, multilingual - entity typing dataset we created. Mono- and multilingual fine-grained entity typing systems can be evaluated on this dataset.

</details>

<details>

<summary>2018-10-24 18:16:42 - Multimodal Polynomial Fusion for Detecting Driver Distraction</summary>

- *Yulun Du, Chirag Raman, Alan W Black, Louis-Philippe Morency, Maxine Eskenazi*

- `1810.10565v1` - [abs](http://arxiv.org/abs/1810.10565v1) - [pdf](http://arxiv.org/pdf/1810.10565v1)

> Distracted driving is deadly, claiming 3,477 lives in the U.S. in 2015 alone. Although there has been a considerable amount of research on modeling the distracted behavior of drivers under various conditions, accurate automatic detection using multiple modalities and especially the contribution of using the speech modality to improve accuracy has received little attention. This paper introduces a new multimodal dataset for distracted driving behavior and discusses automatic distraction detection using features from three modalities: facial expression, speech and car signals. Detailed multimodal feature analysis shows that adding more modalities monotonically increases the predictive accuracy of the model. Finally, a simple and effective multimodal fusion technique using a polynomial fusion layer shows superior distraction detection results compared to the baseline SVM and neural network models.

</details>

<details>

<summary>2018-10-24 18:28:03 - Applying Deep Learning To Airbnb Search</summary>

- *Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull, Brendan M. Collins, Thomas Legrand*

- `1810.09591v2` - [abs](http://arxiv.org/abs/1810.09591v2) - [pdf](http://arxiv.org/pdf/1810.09591v2)

> The application to search ranking is one of the biggest machine learning success stories at Airbnb. Much of the initial gains were driven by a gradient boosted decision tree model. The gains, however, plateaued over time. This paper discusses the work done in applying neural networks in an attempt to break out of that plateau. We present our perspective not with the intention of pushing the frontier of new modeling techniques. Instead, ours is a story of the elements we found useful in applying neural networks to a real life product. Deep learning was steep learning for us. To other teams embarking on similar journeys, we hope an account of our struggles and triumphs will provide some useful pointers. Bon voyage!

</details>

<details>

<summary>2018-10-24 20:00:50 - Inverse reinforcement learning for video games</summary>

- *Aaron Tucker, Adam Gleave, Stuart Russell*

- `1810.10593v1` - [abs](http://arxiv.org/abs/1810.10593v1) - [pdf](http://arxiv.org/pdf/1810.10593v1)

> Deep reinforcement learning achieves superhuman performance in a range of video game environments, but requires that a designer manually specify a reward function. It is often easier to provide demonstrations of a target behavior than to design a reward function describing that behavior. Inverse reinforcement learning (IRL) algorithms can infer a reward from demonstrations in low-dimensional continuous control environments, but there has been little work on applying IRL to high-dimensional video games. In our CNN-AIRL baseline, we modify the state-of-the-art adversarial IRL (AIRL) algorithm to use CNNs for the generator and discriminator. To stabilize training, we normalize the reward and increase the size of the discriminator training dataset. We additionally learn a low-dimensional state representation using a novel autoencoder architecture tuned for video game environments. This embedding is used as input to the reward network, improving the sample efficiency of expert demonstrations. Our method achieves high-level performance on the simple Catcher video game, substantially outperforming the CNN-AIRL baseline. We also score points on the Enduro Atari racing game, but do not match expert performance, highlighting the need for further work.

</details>

<details>

<summary>2018-10-24 21:36:43 - Optimizing Heuristics for Tableau-based OWL Reasoners</summary>

- *Razieh Mehri, Volker Haarslev, Hamidreza Chinaei*

- `1810.06617v2` - [abs](http://arxiv.org/abs/1810.06617v2) - [pdf](http://arxiv.org/pdf/1810.06617v2)

> Optimization techniques play a significant role in improving description logic reasoners covering the Web Ontology Language (OWL). These techniques are essential to speed up these reasoners. Many of the optimization techniques are based on heuristic choices. Optimal heuristic selection makes these techniques more effective. The FaCT++ OWL reasoner and its Java version JFact implement an optimization technique called ToDo list which is a substitute for a traditional top-down approach in tableau-based reasoners. The ToDo list mechanism allows one to arrange the order of applying different rules by giving each a priority. Compared to a top-down approach, the ToDo list technique has a better control over the application of expansion rules. Learning the proper heuristic order for applying rules in ToDo lis} will have a great impact on reasoning speed. We use a binary SVM technique to build our learning model. The model can help to choose ontology-specific order sets to speed up OWL reasoning. On average, our learning approach tested with 40 selected ontologies achieves a speedup of two orders of magnitude when compared to the worst rule ordering choice.

</details>

<details>

<summary>2018-10-24 23:49:58 - Sample-Efficient Learning of Nonprehensile Manipulation Policies via Physics-Based Informed State Distributions</summary>

- *Lerrel Pinto, Aditya Mandalika, Brian Hou, Siddhartha Srinivasa*

- `1810.10654v1` - [abs](http://arxiv.org/abs/1810.10654v1) - [pdf](http://arxiv.org/pdf/1810.10654v1)

> This paper proposes a sample-efficient yet simple approach to learning closed-loop policies for nonprehensile manipulation. Although reinforcement learning (RL) can learn closed-loop policies without requiring access to underlying physics models, it suffers from poor sample complexity on challenging tasks. To overcome this problem, we leverage rearrangement planning to provide an informative physics-based prior on the environment's optimal state-visitation distribution. Specifically, we present a new technique, Learning with Planned Episodic Resets (LeaPER), that resets the environment's state to one informed by the prior during the learning phase. We experimentally show that LeaPER significantly outperforms traditional RL approaches by a factor of up to 5X on simulated rearrangement. Further, we relax dynamics from quasi-static to welded contacts to illustrate that LeaPER is robust to the use of simpler physics models. Finally, LeaPER's closed-loop policies significantly improve task success rates relative to both open-loop controls with a planned path or simple feedback controllers that track open-loop trajectories. We demonstrate the performance and behavior of LeaPER on a physical 7-DOF manipulator in https://youtu.be/feS-zFq6J1c.

</details>

<details>

<summary>2018-10-25 00:12:44 - Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search</summary>

- *Zhuwen Li, Qifeng Chen, Vladlen Koltun*

- `1810.10659v1` - [abs](http://arxiv.org/abs/1810.10659v1) - [pdf](http://arxiv.org/pdf/1810.10659v1)

> We present a learning-based approach to computing solutions for certain NP-hard problems. Our approach combines deep learning techniques with useful algorithmic elements from classic heuristics. The central component is a graph convolutional network that is trained to estimate the likelihood, for each vertex in a graph, of whether this vertex is part of the optimal solution. The network is designed and trained to synthesize a diverse set of solutions, which enables rapid exploration of the solution space via tree search. The presented approach is evaluated on four canonical NP-hard problems and five datasets, which include benchmark satisfiability problems and real social network graphs with up to a hundred thousand nodes. Experimental results demonstrate that the presented approach substantially outperforms recent deep learning work, and performs on par with highly optimized state-of-the-art heuristic solvers for some NP-hard problems. Experiments indicate that our approach generalizes across datasets, and scales to graphs that are orders of magnitude larger than those used during training.

</details>

<details>

<summary>2018-10-25 00:51:42 - ExIt-OOS: Towards Learning from Planning in Imperfect Information Games</summary>

- *Andy Kitchen, Michela Benedetti*

- `1808.10120v2` - [abs](http://arxiv.org/abs/1808.10120v2) - [pdf](http://arxiv.org/pdf/1808.10120v2)

> The current state of the art in playing many important perfect information games, including Chess and Go, combines planning and deep reinforcement learning with self-play. We extend this approach to imperfect information games and present ExIt-OOS, a novel approach to playing imperfect information games within the Expert Iteration framework and inspired by AlphaZero. We use Online Outcome Sampling, an online search algorithm for imperfect information games in place of MCTS. While training online, our neural strategy is used to improve the accuracy of playouts in OOS, allowing a learning and planning feedback loop for imperfect information games.

</details>

<details>

<summary>2018-10-25 00:58:42 - Regret Minimization for Partially Observable Deep Reinforcement Learning</summary>

- *Peter Jin, Kurt Keutzer, Sergey Levine*

- `1710.11424v2` - [abs](http://arxiv.org/abs/1710.11424v2) - [pdf](http://arxiv.org/pdf/1710.11424v2)

> Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategies from raw image pixels. However, algorithms that estimate state and state-action value functions typically assume a fully observed state and must compensate for partial observations by using finite length observation histories or recurrent networks. In this work, we propose a new deep reinforcement learning algorithm based on counterfactual regret minimization that iteratively updates an approximation to an advantage-like function and is robust to partially observed state. We demonstrate that this new algorithm can substantially outperform strong baseline methods on several partially observed reinforcement learning tasks: learning first-person 3D navigation in Doom and Minecraft, and acting in the presence of partially observed objects in Doom and Pong.

</details>

<details>

<summary>2018-10-25 01:19:21 - Solving Poisson's Equation using Deep Learning in Particle Simulation of PN Junction</summary>

- *Zhongyang Zhang, Ling Zhang, Ze Sun, Nicholas Erickson, Ryan From, Jun Fan*

- `1810.10192v2` - [abs](http://arxiv.org/abs/1810.10192v2) - [pdf](http://arxiv.org/pdf/1810.10192v2)

> Simulating the dynamic characteristics of a PN junction at the microscopic level requires solving the Poisson's equation at every time step. Solving at every time step is a necessary but time-consuming process when using the traditional finite difference (FDM) approach. Deep learning is a powerful technique to fit complex functions. In this work, deep learning is utilized to accelerate solving Poisson's equation in a PN junction. The role of the boundary condition is emphasized in the loss function to ensure a better fitting. The resulting I-V curve for the PN junction, using the deep learning solver presented in this work, shows a perfect match to the I-V curve obtained using the finite difference method, with the advantage of being 10 times faster at every time step.

</details>

<details>

<summary>2018-10-25 05:28:35 - Urban Healthcare Big Data System Based on Crowdsourced and Cloud-Based Air Quality Indicators</summary>

- *Min Chen, Jun Yang, Long Hu, M. Shamim Hossain, Ghulam Muhammad*

- `1810.10723v1` - [abs](http://arxiv.org/abs/1810.10723v1) - [pdf](http://arxiv.org/pdf/1810.10723v1)

> The ever-accelerating process of globalization enables more than half the population to live in cities. Thus, the air quality in cities exerts critical influence on the health status of more and more urban residents. In this article, based on urban air quality data collected through meteorological sites, mobile crowdsourcing, and IoT sensing, along with users' body signals, we propose an urban healthcare big data system named UH-BigDataSys. In this article, we first introduce a method of integrating multi-source air quality data for the data preparation of artificial-intelligence-based smart urban services. Then a testbed of UH-BigDataSys is set up with the deployment of air-quality-aware healthcare applications. Finally, we provide health guidance for urban residents in aspects of respiratory diseases, outdoor travel, sleep quality, and so on. The ultimate goal of UH-BigDataSys is for urban residents to lead healthier lives.

</details>

<details>

<summary>2018-10-25 09:19:11 - Statistical Piano Reduction Controlling Performance Difficulty</summary>

- *Eita Nakamura, Kazuyoshi Yoshii*

- `1808.05006v2` - [abs](http://arxiv.org/abs/1808.05006v2) - [pdf](http://arxiv.org/pdf/1808.05006v2)

> We present a statistical-modelling method for piano reduction, i.e. converting an ensemble score into piano scores, that can control performance difficulty. While previous studies have focused on describing the condition for playable piano scores, it depends on player's skill and can change continuously with the tempo. We thus computationally quantify performance difficulty as well as musical fidelity to the original score, and formulate the problem as optimization of musical fidelity under constraints on difficulty values. First, performance difficulty measures are developed by means of probabilistic generative models for piano scores and the relation to the rate of performance errors is studied. Second, to describe musical fidelity, we construct a probabilistic model integrating a prior piano-score model and a model representing how ensemble scores are likely to be edited. An iterative optimization algorithm for piano reduction is developed based on statistical inference of the model. We confirm the effect of the iterative procedure; we find that subjective difficulty and musical fidelity monotonically increase with controlled difficulty values; and we show that incorporating sequential dependence of pitches and fingering motion in the piano-score model improves the quality of reduction scores in high-difficulty cases.

</details>

<details>

<summary>2018-10-25 09:24:13 - Tackling Sequence to Sequence Mapping Problems with Neural Networks</summary>

- *Lei Yu*

- `1810.10802v1` - [abs](http://arxiv.org/abs/1810.10802v1) - [pdf](http://arxiv.org/pdf/1810.10802v1)

> In Natural Language Processing (NLP), it is important to detect the relationship between two sequences or to generate a sequence of tokens given another observed sequence. We call the type of problems on modelling sequence pairs as sequence to sequence (seq2seq) mapping problems. A lot of research has been devoted to finding ways of tackling these problems, with traditional approaches relying on a combination of hand-crafted features, alignment models, segmentation heuristics, and external linguistic resources. Although great progress has been made, these traditional approaches suffer from various drawbacks, such as complicated pipeline, laborious feature engineering, and the difficulty for domain adaptation. Recently, neural networks emerged as a promising solution to many problems in NLP, speech recognition, and computer vision. Neural models are powerful because they can be trained end to end, generalise well to unseen examples, and the same framework can be easily adapted to a new domain.   The aim of this thesis is to advance the state-of-the-art in seq2seq mapping problems with neural networks. We explore solutions from three major aspects: investigating neural models for representing sequences, modelling interactions between sequences, and using unpaired data to boost the performance of neural models. For each aspect, we propose novel models and evaluate their efficacy on various tasks of seq2seq mapping.

</details>

<details>

<summary>2018-10-25 11:59:36 - Replay spoofing detection system for automatic speaker verification using multi-task learning of noise classes</summary>

- *Hye-Jin Shim, Jee-weon Jung, Hee-Soo Heo, Sunghyun Yoon, Ha-Jin Yu*

- `1808.09638v4` - [abs](http://arxiv.org/abs/1808.09638v4) - [pdf](http://arxiv.org/pdf/1808.09638v4)

> In this paper, we propose a replay attack spoofing detection system for automatic speaker verification using multitask learning of noise classes. We define the noise that is caused by the replay attack as replay noise. We explore the effectiveness of training a deep neural network simultaneously for replay attack spoofing detection and replay noise classification. The multi-task learning includes classifying the noise of playback devices, recording environments, and recording devices as well as the spoofing detection. Each of the three types of the noise classes also includes a genuine class. The experiment results on the ASVspoof2017 datasets demonstrate that the performance of our proposed system is improved by 30% relatively on the evaluation set.

</details>

<details>

<summary>2018-10-25 13:33:53 - Playing With Danger: A Taxonomy and Evaluation of Threats to Smart Toys</summary>

- *Sharon Shasha, Moustafa Mahmoud, Mohammad Mannan, Amr Youssef*

- `1809.05556v2` - [abs](http://arxiv.org/abs/1809.05556v2) - [pdf](http://arxiv.org/pdf/1809.05556v2)

> Smart toys have captured an increasing share of the toy market, and are growing ubiquitous in households with children. Smart toys are a subset of Internet of Things (IoT) devices, containing sensors, actuators, and/or artificial intelligence capabilities. They frequently have internet connectivity, directly or indirectly through companion apps, and collect information about their users and environments. Recent studies have found security flaws in many smart toys that have led to serious privacy leaks, or allowed tracking a child's physical location. Some well-publicized discoveries of this nature have prompted actions from governments around the world to ban some of these toys. Compared to other IoT devices, smart toys pose unique risks because of their easily-vulnerable user base, and our work is intended to define these risks and assess a subset of toys against them. We provide a classification of threats specific to smart toys in order to unite and complement existing adhoc analyses, and help comprehensive evaluation of other smart toys. Our threat classification framework addresses the potential security and privacy flaws that can lead to leakage of private information or allow an adversary to control the toy to lure, harm, or distress a child. Using this framework, we perform a thorough experimental analysis of eleven smart toys and their companion apps. Our systematic analysis has uncovered that several current toys still expose children to multiple threats for attackers with physical, nearby, or remote access to the toy.

</details>

<details>

<summary>2018-10-25 13:38:34 - Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record</summary>

- *Jinghe Zhang, Kamran Kowsari, James H. Harrison, Jennifer M. Lobo, Laura E. Barnes*

- `1810.04793v3` - [abs](http://arxiv.org/abs/1810.04793v3) - [pdf](http://arxiv.org/pdf/1810.04793v3)

> The wide implementation of electronic health record (EHR) systems facilitates the collection of large-scale health data from real clinical settings. Despite the significant increase in adoption of EHR systems, this data remains largely unexplored, but presents a rich data source for knowledge discovery from patient health histories in tasks such as understanding disease correlations and predicting health outcomes. However, the heterogeneity, sparsity, noise, and bias in this data present many complex challenges. This complexity makes it difficult to translate potentially relevant information into machine learning algorithms. In this paper, we propose a computational framework, Patient2Vec, to learn an interpretable deep representation of longitudinal EHR data which is personalized for each patient. To evaluate this approach, we apply it to the prediction of future hospitalizations using real EHR data and compare its predictive performance with baseline methods. Patient2Vec produces a vector space with meaningful structure and it achieves an AUC around 0.799 outperforming baseline methods. In the end, the learned feature importance can be visualized and interpreted at both the individual and population levels to bring clinical insights.

</details>

<details>

<summary>2018-10-25 15:30:07 - HAR-Net:Fusing Deep Representation and Hand-crafted Features for Human Activity Recognition</summary>

- *Mingtao Dong, Jindong Han*

- `1810.10929v1` - [abs](http://arxiv.org/abs/1810.10929v1) - [pdf](http://arxiv.org/pdf/1810.10929v1)

> Wearable computing and context awareness are the focuses of study in the field of artificial intelligence recently. One of the most appealing as well as challenging applications is the Human Activity Recognition (HAR) utilizing smart phones. Conventional HAR based on Support Vector Machine relies on subjective manually extracted features. This approach is time and energy consuming as well as immature in prediction due to the partial view toward which features to be extracted by human. With the rise of deep learning, artificial intelligence has been making progress toward being a mature technology. This paper proposes a new approach based on deep learning and traditional feature engineering called HAR-Net to address the issue related to HAR. The study used the data collected by gyroscopes and acceleration sensors in android smart phones. The raw sensor data was put into the HAR-Net proposed. The HAR-Net fusing the hand-crafted features and high-level features extracted from convolutional network to make prediction. The performance of the proposed method was proved to be 0.9% higher than the original MC-SVM approach. The experimental results on the UCI dataset demonstrate that fusing the two kinds of features can make up for the shortage of traditional feature engineering and deep learning techniques.

</details>

<details>

<summary>2018-10-25 16:11:29 - Differential Variable Speed Limits Control for Freeway Recurrent Bottlenecks via Deep Reinforcement learning</summary>

- *Yuankai Wu, Huachun Tan, Bin Ran*

- `1810.10952v1` - [abs](http://arxiv.org/abs/1810.10952v1) - [pdf](http://arxiv.org/pdf/1810.10952v1)

> Variable speed limits (VSL) control is a flexible way to improve traffic condition,increase safety and reduce emission. There is an emerging trend of using reinforcement learning technique for VSL control and recent studies have shown promising results. Currently, deep learning is enabling reinforcement learning to develope autonomous control agents for problems that were previously intractable. In this paper, we propose a more effective deep reinforcement learning (DRL) model for differential variable speed limits (DVSL) control, in which the dynamic and different speed limits among lanes can be imposed. The proposed DRL models use a novel actor-critic architecture which can learn a large number of discrete speed limits in a continues action space. Different reward signals, e.g. total travel time, bottleneck speed, emergency braking, and vehicular emission are used to train the DVSL controller, and comparison between these reward signals are conducted. We test proposed DRL baased DVSL controllers on a simulated freeway recurrent bottleneck. Results show that the efficiency, safety and emissions can be improved by the proposed method. We also show some interesting findings through the visulization of the control policies generated from DRL models.

</details>

<details>

<summary>2018-10-25 17:23:11 - Particle Filter Networks with Application to Visual Localization</summary>

- *Peter Karkus, David Hsu, Wee Sun Lee*

- `1805.08975v3` - [abs](http://arxiv.org/abs/1805.08975v3) - [pdf](http://arxiv.org/pdf/1805.08975v3)

> Particle filtering is a powerful approach to sequential state estimation and finds application in many domains, including robot localization, object tracking, etc. To apply particle filtering in practice, a critical challenge is to construct probabilistic system models, especially for systems with complex dynamics or rich sensory inputs such as camera images. This paper introduces the Particle Filter Network (PFnet), which encodes both a system model and a particle filter algorithm in a single neural network. The PF-net is fully differentiable and trained end-to-end from data. Instead of learning a generic system model, it learns a model optimized for the particle filter algorithm. We apply the PF-net to a visual localization task, in which a robot must localize in a rich 3-D world, using only a schematic 2-D floor map. In simulation experiments, PF-net consistently outperforms alternative learning architectures, as well as a traditional model-based method, under a variety of sensor inputs. Further, PF-net generalizes well to new, unseen environments.

</details>

<details>

<summary>2018-10-25 17:34:51 - q-Space Novelty Detection with Variational Autoencoders</summary>

- *Aleksei Vasilev, Vladimir Golkov, Marc Meissner, Ilona Lipp, Eleonora Sgarlata, Valentina Tomassini, Derek K. Jones, Daniel Cremers*

- `1806.02997v2` - [abs](http://arxiv.org/abs/1806.02997v2) - [pdf](http://arxiv.org/pdf/1806.02997v2)

> In machine learning, novelty detection is the task of identifying novel unseen data. During training, only samples from the normal class are available. Test samples are classified as normal or abnormal by assignment of a novelty score. Here we propose novelty detection methods based on training variational autoencoders (VAEs) on normal data. Since abnormal samples are not used during training, we define novelty metrics based on the (partially complementary) assumptions that the VAE is less capable of reconstructing abnormal samples well; that abnormal samples more strongly violate the VAE regularizer; and that abnormal samples differ from normal samples not only in input-feature space, but also in the VAE latent space and VAE output. These approaches, combined with various possibilities of using (e.g. sampling) the probabilistic VAE to obtain scalar novelty scores, yield a large family of methods. We apply these methods to magnetic resonance imaging, namely to the detection of diffusion-space (q-space) abnormalities in diffusion MRI scans of multiple sclerosis patients, i.e. to detect multiple sclerosis lesions without using any lesion labels for training. Many of our methods outperform previously proposed q-space novelty detection methods. We also evaluate the proposed methods on the MNIST handwritten digits dataset and show that many of them are able to outperform the state of the art.

</details>

<details>

<summary>2018-10-25 18:05:08 - One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks</summary>

- *Tianhe Yu, Pieter Abbeel, Sergey Levine, Chelsea Finn*

- `1810.11043v1` - [abs](http://arxiv.org/abs/1810.11043v1) - [pdf](http://arxiv.org/pdf/1810.11043v1)

> We consider the problem of learning multi-stage vision-based tasks on a real robot from a single video of a human performing the task, while leveraging demonstration data of subtasks with other objects. This problem presents a number of major challenges. Video demonstrations without teleoperation are easy for humans to provide, but do not provide any direct supervision. Learning policies from raw pixels enables full generality but calls for large function approximators with many parameters to be learned. Finally, compound tasks can require impractical amounts of demonstration data, when treated as a monolithic skill. To address these challenges, we propose a method that learns both how to learn primitive behaviors from video demonstrations and how to dynamically compose these behaviors to perform multi-stage tasks by "watching" a human demonstrator. Our results on a simulated Sawyer robot and real PR2 robot illustrate our method for learning a variety of order fulfillment and kitchen serving tasks with novel objects and raw pixel inputs.

</details>

<details>

<summary>2018-10-25 18:32:36 - Loss Functions for Multiset Prediction</summary>

- *Sean Welleck, Zixin Yao, Yu Gai, Jialin Mao, Zheng Zhang, Kyunghyun Cho*

- `1711.05246v2` - [abs](http://arxiv.org/abs/1711.05246v2) - [pdf](http://arxiv.org/pdf/1711.05246v2)

> We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.

</details>

<details>

<summary>2018-10-25 18:42:01 - Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering</summary>

- *Adam Trowbridge, Jessica Westbrook, Filipo Sharevski*

- `1810.11063v1` - [abs](http://arxiv.org/abs/1810.11063v1) - [pdf](http://arxiv.org/pdf/1810.11063v1)

> In this paper we argue, drawing from the perspectives of cybersecurity and social psychology, that Internet-based manipulation of an individual or group reality using ambient tactical deception is possible using only software and changing words in a web browser. We call this attack Ambient Tactical Deception (ATD). Ambient, in artificial intelligence, describes software that is "unobtrusive," and completely integrated into a user's life. Tactical deception is an information warfare term for the use of deception on an opposing force. We suggest that an ATD attack could change the sentiment of text in a web browser. This could alter the victim's perception of reality by providing disinformation. Within the limit of online communication, even a pause in replying to a text can affect how people perceive each other. The outcomes of an ATD attack could include alienation, upsetting a victim, and influencing their feelings about an election, a spouse, or a corporation.

</details>

<details>

<summary>2018-10-25 19:05:16 - RELF: Robust Regression Extended with Ensemble Loss Function</summary>

- *Hamideh Hajiabadi, Reza Monsefi, Hadi Sadoghi Yazdi*

- `1810.11071v1` - [abs](http://arxiv.org/abs/1810.11071v1) - [pdf](http://arxiv.org/pdf/1810.11071v1)

> Ensemble techniques are powerful approaches that combine several weak learners to build a stronger one. As a meta-learning framework, ensemble techniques can easily be applied to many machine learning methods. Inspired by ensemble techniques, in this paper we propose an ensemble loss functions applied to a simple regressor. We then propose a half-quadratic learning algorithm in order to find the parameter of the regressor and the optimal weights associated with each loss function. Moreover, we show that our proposed loss function is robust in noisy environments. For a particular class of loss functions, we show that our proposed ensemble loss function is Bayes consistent and robust. Experimental evaluations on several datasets demonstrate that our proposed ensemble loss function significantly improves the performance of a simple regressor in comparison with state-of-the-art methods.

</details>

<details>

<summary>2018-10-25 19:25:59 - Quantum Entanglement in Corpuses of Documents</summary>

- *Lester Beltran, Suzette Geriente*

- `1810.12114v1` - [abs](http://arxiv.org/abs/1810.12114v1) - [pdf](http://arxiv.org/pdf/1810.12114v1)

> We show that data collected from corpuses of documents violate the Clauser-Horne-Shimony-Holt version of Bell's inequality (CHSH inequality) and therefore indicate the presence of quantum entanglement in their structure. We obtain this result by considering two concepts and their combination and coincidence operations consisting of searches of co-occurrences of exemplars of these concepts in specific corpuses of documents. Measuring the frequencies of these co-occurrences and calculating the relative frequencies as approximate probabilities entering in the CHSH inequality, we obtain manifest violations of the latter for all considered corpuses of documents. In comparing these violations with those analogously obtained in an earlier work for the same combined concepts in psychological coincidence experiments with human participants, also violating the CHSH inequality, we identify the entanglement as being carried by the meaning connection between the two considered concepts within the combination they form. We explain the stronger violation for the corpuses of documents, as compared to the violation in the psychology experiments, as being due to the superior meaning domain of the human mind and, on the other side, to the latter reaching a broader domain of meaning and being possibly also actively influenced during the experimentation. We mention some of the issues to be analyzed in future work such as the violations of the CHSH inequality being larger than the `Cirel'son bound' for all of the considered corpuses of documents.

</details>

<details>

<summary>2018-10-25 19:29:46 - Generalised framework for multi-criteria method selection</summary>

- *Jarosław Wątróbski, Jarosław Jankowski, Paweł Ziemba, Artur Karczmarczyk, Magdalena Zioło*

- `1810.11078v1` - [abs](http://arxiv.org/abs/1810.11078v1) - [pdf](http://arxiv.org/pdf/1810.11078v1)

> Multi-Criteria Decision Analysis (MCDA) methods are widely used in various fields and disciplines. While most of the research has been focused on the development and improvement of new MCDA methods, relatively limited attention has been paid to their appropriate selection for the given decision problem. Their improper application decreases the quality of recommendations, as different MCDA methods deliver inconsistent results. The current paper presents a methodological and practical framework for selecting suitable MCDA methods for a particular decision situation. A set of 56 available MCDA methods was analyzed and, based on that, a hierarchical set of methods characteristics and the rule base were obtained. This analysis, rules and modelling of the uncertainty in the decision problem description allowed to build a framework supporting the selection of a MCDA method for a given decision-making situation. The practical studies indicate consistency between the methods recommended with the proposed approach and those used by the experts in reference cases. The results of the research also showed that the proposed approach can be used as a general framework for selecting an appropriate MCDA method for a given area of decision support, even in cases of data gaps in the decision-making problem description. The proposed framework was implemented within a web platform available for public use at www.mcda.it.

</details>

<details>

<summary>2018-10-25 20:33:55 - SyntaxSQLNet: Syntax Tree Networks for Complex and Cross-DomainText-to-SQL Task</summary>

- *Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan Li, Dragomir Radev*

- `1810.05237v2` - [abs](http://arxiv.org/abs/1810.05237v2) - [pdf](http://arxiv.org/pdf/1810.05237v2)

> Most existing studies in text-to-SQL tasks do not require generating complex SQL queries with multiple clauses or sub-queries, and generalizing to new, unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network to address the complex and cross-domain text-to-SQL generation task. SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL generation path history and table-aware column attention encoders. We evaluate SyntaxSQLNet on the Spider text-to-SQL task, which contains databases with multiple tables and complex SQL queries with multiple SQL clauses and nested queries. We use a database split setting where databases in the test set are unseen during training. Experimental results show that SyntaxSQLNet can handle a significantly greater number of complex SQL examples than prior work, outperforming the previous state-of-the-art model by 7.3% in exact matching accuracy. We also show that SyntaxSQLNet can further improve the performance by an additional 7.5% using a cross-domain augmentation method, resulting in a 14.8% improvement in total. To our knowledge, we are the first to study this complex and cross-domain text-to-SQL task.

</details>

<details>

<summary>2018-10-25 21:34:21 - Mimetic vs Anchored Value Alignment in Artificial Intelligence</summary>

- *Tae Wan Kim, Thomas Donaldson, John Hooker*

- `1810.11116v1` - [abs](http://arxiv.org/abs/1810.11116v1) - [pdf](http://arxiv.org/pdf/1810.11116v1)

> "Value alignment" (VA) is considered as one of the top priorities in AI research. Much of the existing research focuses on the "A" part and not the "V" part of "value alignment." This paper corrects that neglect by emphasizing the "value" side of VA and analyzes VA from the vantage point of requirements in value theory, in particular, of avoiding the "naturalistic fallacy"--a major epistemic caveat. The paper begins by isolating two distinct forms of VA: "mimetic" and "anchored." Then it discusses which VA approach better avoids the naturalistic fallacy. The discussion reveals stumbling blocks for VA approaches that neglect implications of the naturalistic fallacy. Such problems are more serious in mimetic VA since the mimetic process imitates human behavior that may or may not rise to the level of correct ethical behavior. Anchored VA, including hybrid VA, in contrast, holds more promise for future VA since it anchors alignment by normative concepts of intrinsic value.

</details>

<details>

<summary>2018-10-26 00:55:45 - Reimplementation and Reinterpretation of the Copycat Project</summary>

- *Hongyi Huang*

- `1811.04747v1` - [abs](http://arxiv.org/abs/1811.04747v1) - [pdf](http://arxiv.org/pdf/1811.04747v1)

> We present the reinterpreted and reimplemented Copycat project, an architecture solving letter analogy domain problems. To support a flexible implementation change and rigor testing process, we propose a implementation method in DrRacket by using functional abstraction, naming system, initialization, and structural reference. Finally, benefits and limitations are analyzed for cognitive architectures along the lines of Copycat.

</details>

<details>

<summary>2018-10-26 03:45:22 - Learning sparse relational transition models</summary>

- *Victoria Xia, Zi Wang, Leslie Pack Kaelbling*

- `1810.11177v1` - [abs](http://arxiv.org/abs/1810.11177v1) - [pdf](http://arxiv.org/pdf/1810.11177v1)

> We present a representation for describing transition models in complex uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state. Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties. This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.

</details>

<details>

<summary>2018-10-26 03:51:27 - Tree-to-tree Neural Networks for Program Translation</summary>

- *Xinyun Chen, Chang Liu, Dawn Song*

- `1802.03691v3` - [abs](http://arxiv.org/abs/1802.03691v3) - [pdf](http://arxiv.org/pdf/1802.03691v3)

> Program translation is an important tool to migrate legacy code in one language into an ecosystem built in a different language. In this work, we are the first to employ deep neural networks toward tackling this problem. We observe that program translation is a modular procedure, in which a sub-tree of the source tree is translated into the corresponding target sub-tree at each step. To capture this intuition, we design a tree-to-tree neural network to translate a source tree into a target one. Meanwhile, we develop an attention mechanism for the tree-to-tree model, so that when the decoder expands one non-terminal in the target tree, the attention mechanism locates the corresponding sub-tree in the source tree to guide the expansion of the decoder. We evaluate the program translation capability of our tree-to-tree model against several state-of-the-art approaches. Compared against other neural translation models, we observe that our approach is consistently better than the baselines with a margin of up to 15 points. Further, our approach can improve the previous state-of-the-art program translation approaches by a margin of 20 points on the translation of real-world projects.

</details>

<details>

<summary>2018-10-26 05:04:07 - Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package</summary>

- *Ajay Patel, Alexander Sands, Chris Callison-Burch, Marianna Apidianaki*

- `1810.11190v1` - [abs](http://arxiv.org/abs/1810.11190v1) - [pdf](http://arxiv.org/pdf/1810.11190v1)

> Vector space embedding models like word2vec, GloVe, fastText, and ELMo are extremely popular representations in natural language processing (NLP) applications. We present Magnitude, a fast, lightweight tool for utilizing and processing embeddings. Magnitude is an open source Python package with a compact vector storage file format that allows for efficient manipulation of huge numbers of embeddings. Magnitude performs common operations up to 60 to 6,000 times faster than Gensim. Magnitude introduces several novel features for improved robustness like out-of-vocabulary lookups.

</details>

<details>

<summary>2018-10-26 05:21:19 - Learning under Misspecified Objective Spaces</summary>

- *Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Anca D. Dragan*

- `1810.05157v4` - [abs](http://arxiv.org/abs/1810.05157v4) - [pdf](http://arxiv.org/pdf/1810.05157v4)

> Learning robot objective functions from human input has become increasingly important, but state-of-the-art techniques assume that the human's desired objective lies within the robot's hypothesis space. When this is not true, even methods that keep track of uncertainty over the objective fail because they reason about which hypothesis might be correct, and not whether any of the hypotheses are correct. We focus specifically on learning from physical human corrections during the robot's task execution, where not having a rich enough hypothesis space leads to the robot updating its objective in ways that the person did not actually intend. We observe that such corrections appear irrelevant to the robot, because they are not the best way of achieving any of the candidate objectives. Instead of naively trusting and learning from every human interaction, we propose robots learn conservatively by reasoning in real time about how relevant the human's correction is for the robot's hypothesis space. We test our inference method in an experiment with human interaction data, and demonstrate that this alleviates unintended learning in an in-person user study with a 7DoF robot manipulator.

</details>

<details>

<summary>2018-10-26 05:44:01 - Integrating Transformer and Paraphrase Rules for Sentence Simplification</summary>

- *Sanqiang Zhao, Rui Meng, Daqing He, Saptono Andi, Parmanto Bambang*

- `1810.11193v1` - [abs](http://arxiv.org/abs/1810.11193v1) - [pdf](http://arxiv.org/pdf/1810.11193v1)

> Sentence simplification aims to reduce the complexity of a sentence while retaining its original meaning. Current models for sentence simplification adopted ideas from ma- chine translation studies and implicitly learned simplification mapping rules from normal- simple sentence pairs. In this paper, we explore a novel model based on a multi-layer and multi-head attention architecture and we pro- pose two innovative approaches to integrate the Simple PPDB (A Paraphrase Database for Simplification), an external paraphrase knowledge base for simplification that covers a wide range of real-world simplification rules. The experiments show that the integration provides two major benefits: (1) the integrated model outperforms multiple state- of-the-art baseline models for sentence simplification in the literature (2) through analysis of the rule utilization, the model seeks to select more accurate simplification rules. The code and models used in the paper are available at https://github.com/ Sanqiang/text_simplification.

</details>

<details>

<summary>2018-10-26 07:51:06 - Classification of cyber-physical production systems applications: Proposition of an analysis framework</summary>

- *Olivier Cardin*

- `1811.03122v1` - [abs](http://arxiv.org/abs/1811.03122v1) - [pdf](http://arxiv.org/pdf/1811.03122v1)

> Cyber-physical systems have encountered a huge success in the past decade in several scientific communities, and specifically in production topics. The main attraction of the concept relies in the fact that it encompasses many scientific topics that were distinct before. The downside is the lack of readability of the current developments about cyber-physical production systems (CPPS). Indeed, the large scientific area of CPPS makes it difficult to identify clearly and rapidly, in the various applications that were made of CPPS, what are the choices, best practices and methodology that are suggested and that could be used for a new application. This work intends to introduce an analysis framework able to classify those developments. An extensive study of literature enabled to extract the major criteria that are to be used in the framework, namely: Development Extent; Research Axis; Instrumenting; Communication standards; Intelligence deposit; Cognition level; Human factor. Several recent examples of CPPS developments in literature are used to illustrate the use of the framework and brief conclusions are drawn from the comparative analysis of those examples.

</details>

<details>

<summary>2018-10-26 08:44:50 - From the EM Algorithm to the CM-EM Algorithm for Global Convergence of Mixture Models</summary>

- *Chenguang Lu*

- `1810.11227v1` - [abs](http://arxiv.org/abs/1810.11227v1) - [pdf](http://arxiv.org/pdf/1810.11227v1)

> The Expectation-Maximization (EM) algorithm for mixture models often results in slow or invalid convergence. The popular convergence proof affirms that the likelihood increases with Q; Q is increasing in the M -step and non-decreasing in the E-step. The author found that (1) Q may and should decrease in some E-steps; (2) The Shannon channel from the E-step is improper and hence the expectation is improper. The author proposed the CM-EM algorithm (CM means Channel's Matching), which adds a step to optimize the mixture ratios for the proper Shannon channel and maximizes G, average log-normalized-likelihood, in the M-step. Neal and Hinton's Maximization-Maximization (MM) algorithm use F instead of Q to speed the convergence. Maximizing G is similar to maximizing F. The new convergence proof is similar to Beal's proof with the variational method. It first proves that the minimum relative entropy equals the minimum R-G (R is mutual information), then uses variational and iterative methods that Shannon et al. use for rate-distortion functions to prove the global convergence. Some examples show that Q and F should and may decrease in some E-steps. For the same example, the EM, MM, and CM-EM algorithms need about 36, 18, and 9 iterations respectively.

</details>

<details>

<summary>2018-10-26 09:34:36 - From Word to Sense Embeddings: A Survey on Vector Representations of Meaning</summary>

- *Jose Camacho-Collados, Mohammad Taher Pilehvar*

- `1805.04032v3` - [abs](http://arxiv.org/abs/1805.04032v3) - [pdf](http://arxiv.org/pdf/1805.04032v3)

> Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.

</details>

<details>

<summary>2018-10-26 12:10:05 - Neural Guided Constraint Logic Programming for Program Synthesis</summary>

- *Lisa Zhang, Gregory Rosenblatt, Ethan Fetaya, Renjie Liao, William E. Byrd, Matthew Might, Raquel Urtasun, Richard Zemel*

- `1809.02840v3` - [abs](http://arxiv.org/abs/1809.02840v3) - [pdf](http://arxiv.org/pdf/1809.02840v3)

> Synthesizing programs using example input/outputs is a classic problem in artificial intelligence. We present a method for solving Programming By Example (PBE) problems by using a neural model to guide the search of a constraint logic programming system called miniKanren. Crucially, the neural model uses miniKanren's internal representation as input; miniKanren represents a PBE problem as recursive constraints imposed by the provided examples. We explore Recurrent Neural Network and Graph Neural Network models. We contribute a modified miniKanren, drivable by an external agent, available at https://github.com/xuexue/neuralkanren. We show that our neural-guided approach using constraints can synthesize programs faster in many cases, and importantly, can generalize to larger problems.

</details>

<details>

<summary>2018-10-26 12:34:21 - Finding Answers from the Word of God: Domain Adaptation for Neural Networks in Biblical Question Answering</summary>

- *Helen Jiahe Zhao, Jiamou Liu*

- `1810.12118v1` - [abs](http://arxiv.org/abs/1810.12118v1) - [pdf](http://arxiv.org/pdf/1810.12118v1)

> Question answering (QA) has significantly benefitted from deep learning techniques in recent years. However, domain-specific QA remains a challenge due to the significant amount of data required to train a neural network. This paper studies the answer sentence selection task in the Bible domain and answer questions by selecting relevant verses from the Bible. For this purpose, we create a new dataset BibleQA based on bible trivia questions and propose three neural network models for our task. We pre-train our models on a large-scale QA dataset, SQuAD, and investigate the effect of transferring weights on model accuracy. Furthermore, we also measure the model accuracies with different answer context lengths and different Bible translations. We affirm that transfer learning has a noticeable improvement in the model accuracy. We achieve relatively good results with shorter context lengths, whereas longer context lengths decreased model accuracy. We also find that using a more modern Bible translation in the dataset has a positive effect on the task.

</details>

<details>

<summary>2018-10-26 12:35:58 - Interruptible Algorithms for Multiproblem Solving</summary>

- *Spyros Angelopoulos, Alejandro Lopez-Ortiz*

- `1810.11291v1` - [abs](http://arxiv.org/abs/1810.11291v1) - [pdf](http://arxiv.org/pdf/1810.11291v1)

> In this paper we address the problem of designing an interruptible system in a setting in which $n$ problem instances, all equally important, must be solved concurrently. The system involves scheduling executions of contract algorithms (which offer a trade-off between allowable computation time and quality of the solution) in m identical parallel processors. When an interruption occurs, the system must report a solution to each of the $n$ problem instances. The quality of this output is then compared to the best-possible algorithm that has foreknowledge of the interruption time and must, likewise, produce solutions to all $n$ problem instances. This extends the well-studied setting in which only one problem instance is queried at interruption time.   In this work we first introduce new measures for evaluating the performance of interruptible systems in this setting. In particular, we propose the deficiency of a schedule as a performance measure that meets the requirements of the problem at hand. We then present a schedule whose performance we prove that is within a small factor from optimal in the general, multiprocessor setting. We also show several lower bounds on the deficiency of schedules on a single processor. More precisely, we prove a general lower bound of (n+1)/n, an improved lower bound for the two-problem setting (n=2), and a tight lower bound for the class of round-robin schedules. Our techniques can also yield a simpler, alternative proof of the main result of [Bernstein et al, IJCAI 2003] concerning the performance of cyclic schedules in multiprocessor environments.

</details>

<details>

<summary>2018-10-26 18:28:42 - Transfer of Deep Reactive Policies for MDP Planning</summary>

- *Aniket Bajpai, Sankalp Garg, Mausam*

- `1810.11488v1` - [abs](http://arxiv.org/abs/1810.11488v1) - [pdf](http://arxiv.org/pdf/1810.11488v1)

> Domain-independent probabilistic planners input an MDP description in a factored representation language such as PPDDL or RDDL, and exploit the specifics of the representation for faster planning. Traditional algorithms operate on each problem instance independently, and good methods for transferring experience from policies of other instances of a domain to a new instance do not exist. Recently, researchers have begun exploring the use of deep reactive policies, trained via deep reinforcement learning (RL), for MDP planning domains. One advantage of deep reactive policies is that they are more amenable to transfer learning.   In this paper, we present the first domain-independent transfer algorithm for MDP planning domains expressed in an RDDL representation. Our architecture exploits the symbolic state configuration and transition function of the domain (available via RDDL) to learn a shared embedding space for states and state-action pairs for all problem instances of a domain. We then learn an RL agent in the embedding space, making a near zero-shot transfer possible, i.e., without much training on the new instance, and without using the domain simulator at all. Experiments on three different benchmark domains underscore the value of our transfer algorithm. Compared against planning from scratch, and a state-of-the-art RL transfer algorithm, our transfer solution has significantly superior learning curves.

</details>

<details>

<summary>2018-10-26 18:40:59 - An Approximation Algorithm for Risk-averse Submodular Optimization</summary>

- *Lifeng Zhou, Pratap Tokekar*

- `1807.09358v2` - [abs](http://arxiv.org/abs/1807.09358v2) - [pdf](http://arxiv.org/pdf/1807.09358v2)

> We study the problem of incorporating risk while making combinatorial decisions under uncertainty. We formulate a discrete submodular maximization problem for selecting a set using Conditional-Value-at-Risk (CVaR), a risk metric commonly used in financial analysis. While CVaR has recently been used in optimization of linear cost functions in robotics, we take the first stages towards extending this to discrete submodular optimization and provide several positive results. Specifically, we propose the Sequential Greedy Algorithm that provides an approximation guarantee on finding the maxima of the CVaR cost function under a matroidal constraint. The approximation guarantee shows that the solution produced by our algorithm is within a constant factor of the optimal and an additive term that depends on the optimal. Our analysis uses the curvature of the submodular set function, and proves that the algorithm runs in polynomial time. This formulates a number of combinatorial optimization problems that appear in robotics. We use two such problems, vehicle assignment under uncertainty for mobility-on-demand and sensor selection with failures for environmental monitoring, as case studies to demonstrate the efficacy of our formulation.

</details>

<details>

<summary>2018-10-26 19:42:23 - Adapting control policies from simulation to reality using a pairwise loss</summary>

- *Ulrich Viereck, Xingchao Peng, Kate Saenko, Robert Platt*

- `1807.10413v2` - [abs](http://arxiv.org/abs/1807.10413v2) - [pdf](http://arxiv.org/pdf/1807.10413v2)

> This paper proposes an approach to domain transfer based on a pairwise loss function that helps transfer control policies learned in simulation onto a real robot. We explore the idea in the context of a 'category level' manipulation task where a control policy is learned that enables a robot to perform a mating task involving novel objects. We explore the case where depth images are used as the main form of sensor input. Our experimental results demonstrate that proposed method consistently outperforms baseline methods that train only in simulation or that combine real and simulated data in a naive way.

</details>

<details>

<summary>2018-10-26 20:12:20 - An Acceleration Scheme to The Local Directional Pattern</summary>

- *Yasin Musa Ayami, Aboubayda Shabat*

- `1810.11518v1` - [abs](http://arxiv.org/abs/1810.11518v1) - [pdf](http://arxiv.org/pdf/1810.11518v1)

> This study seeks to improve the running time of the Local Directional Pattern (LDP) during feature extraction using a newly proposed acceleration scheme to LDP. LDP is considered to be computationally expensive. To confirm this, the running time of the LDP to gray level co-occurrence matrix (GLCM) were it was established that the running time for LDP was two orders of magnitude higher than that of the GLCM. In this study, the performance of the newly proposed acceleration scheme was evaluated against LDP and Local Binary patter (LBP) using images from the publicly available extended Cohn-Kanade (CK+) dataset. Based on our findings, the proposed acceleration scheme significantly improves the running time of the LDP by almost 3 times during feature extraction

</details>

<details>

<summary>2018-10-26 21:41:46 - FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation</summary>

- *Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, Maosong Sun*

- `1810.10147v2` - [abs](http://arxiv.org/abs/1810.10147v2) - [pdf](http://arxiv.org/pdf/1810.10147v2)

> We present a Few-Shot Relation Classification Dataset (FewRel), consisting of 70, 000 sentences on 100 relations derived from Wikipedia and annotated by crowdworkers. The relation of each sentence is first recognized by distant supervision methods, and then filtered by crowdworkers. We adapt the most recent state-of-the-art few-shot learning methods for relation classification and conduct a thorough evaluation of these methods. Empirical results show that even the most competitive few-shot learning models struggle on this task, especially as compared with humans. We also show that a range of different reasoning skills are needed to solve our task. These results indicate that few-shot relation classification remains an open problem and still requires further research. Our detailed analysis points multiple directions for future research. All details and resources about the dataset and baselines are released on http://zhuhao.me/fewrel.

</details>

<details>

<summary>2018-10-26 22:39:45 - Learning to Infer Graphics Programs from Hand-Drawn Images</summary>

- *Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Joshua B. Tenenbaum*

- `1707.09627v5` - [abs](http://arxiv.org/abs/1707.09627v5) - [pdf](http://arxiv.org/pdf/1707.09627v5)

> We introduce a model that learns to convert simple hand drawings into graphics programs written in a subset of \LaTeX. The model combines techniques from deep learning and program synthesis. We learn a convolutional neural network that proposes plausible drawing primitives that explain an image. These drawing primitives are like a trace of the set of primitive commands issued by a graphics program. We learn a model that uses program synthesis techniques to recover a graphics program from that trace. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network, measure similarity between drawings by use of similar high-level geometric structures, and extrapolate drawings. Taken together these results are a step towards agents that induce useful, human-readable programs from perceptual input.

</details>

<details>

<summary>2018-10-26 22:59:52 - Adaptive Matching for Expert Systems with Uncertain Task Types</summary>

- *Virag Shah, Lennart Gulikers, Laurent Massoulie, Milan Vojnovic*

- `1703.00674v3` - [abs](http://arxiv.org/abs/1703.00674v3) - [pdf](http://arxiv.org/pdf/1703.00674v3)

> A matching in a two-sided market often incurs an externality: a matched resource may become unavailable to the other side of the market, at least for a while. This is especially an issue in online platforms involving human experts as the expert resources are often scarce. The efficient utilization of experts in these platforms is made challenging by the fact that the information available about the parties involved is usually limited.   To address this challenge, we develop a model of a task-expert matching system where a task is matched to an expert using not only the prior information about the task but also the feedback obtained from the past matches. In our model the tasks arrive online while the experts are fixed and constrained by a finite service capacity. For this model, we characterize the maximum task resolution throughput a platform can achieve. We show that the natural greedy approaches where each expert is assigned a task most suitable to her skill is suboptimal, as it does not internalize the above externality. We develop a throughput optimal backpressure algorithm which does so by accounting for the `congestion' among different task types. Finally, we validate our model and confirm our theoretical findings with data-driven simulations via logs of Math.StackExchange, a StackOverflow forum dedicated to mathematics.

</details>

<details>

<summary>2018-10-26 23:46:21 - Estimating scale-invariant future in continuous time</summary>

- *Zoran Tiganj, Samuel J. Gershman, Per B. Sederberg, Marc W. Howard*

- `1802.06426v3` - [abs](http://arxiv.org/abs/1802.06426v3) - [pdf](http://arxiv.org/pdf/1802.06426v3)

> Natural learners must compute an estimate of future outcomes that follow from a stimulus in continuous time. Widely used reinforcement learning algorithms discretize continuous time and estimate either transition functions from one step to the next (model-based algorithms) or a scalar value of exponentially-discounted future reward using the Bellman equation (model-free algorithms). An important drawback of model-based algorithms is that computational cost grows linearly with the amount of time to be simulated. On the other hand, an important drawback of model-free algorithms is the need to select a time-scale required for exponential discounting. We present a computational mechanism, developed based on work in psychology and neuroscience, for computing a scale-invariant timeline of future outcomes. This mechanism efficiently computes an estimate of inputs as a function of future time on a logarithmically-compressed scale, and can be used to generate a scale-invariant power-law-discounted estimate of expected future reward. The representation of future time retains information about what will happen when. The entire timeline can be constructed in a single parallel operation which generates concrete behavioral and neural predictions. This computational mechanism could be incorporated into future reinforcement learning algorithms.

</details>

<details>

<summary>2018-10-27 02:32:32 - Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples</summary>

- *Guanhong Tao, Shiqing Ma, Yingqi Liu, Xiangyu Zhang*

- `1810.11580v1` - [abs](http://arxiv.org/abs/1810.11580v1) - [pdf](http://arxiv.org/pdf/1810.11580v1)

> Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors. Recent research has demonstrated the widespread presence and the devastating consequences of such attacks. Existing defense techniques either assume prior knowledge of specific attacks or may not work well on complex models due to their underlying assumptions. We argue that adversarial sample attacks are deeply entangled with interpretability of DNN models: while classification results on benign inputs can be reasoned based on the human perceptible features/attributes, results on adversarial samples can hardly be explained. Therefore, we propose a novel adversarial sample detection technique for face recognition models, based on interpretability. It features a novel bi-directional correspondence inference between attributes and internal neurons to identify neurons critical for individual attributes. The activation values of critical neurons are enhanced to amplify the reasoning part of the computation and the values of other neurons are weakened to suppress the uninterpretable part. The classification results after such transformation are compared with those of the original model to detect adversaries. Results show that our technique can achieve 94% detection accuracy for 7 different kinds of attacks with 9.91% false positives on benign inputs. In contrast, a state-of-the-art feature squeezing technique can only achieve 55% accuracy with 23.3% false positives.

</details>

<details>

<summary>2018-10-27 03:49:01 - Task-Driven Convolutional Recurrent Models of the Visual System</summary>

- *Aran Nayebi, Daniel Bear, Jonas Kubilius, Kohitij Kar, Surya Ganguli, David Sussillo, James J. DiCarlo, Daniel L. K. Yamins*

- `1807.00053v2` - [abs](http://arxiv.org/abs/1807.00053v2) - [pdf](http://arxiv.org/pdf/1807.00053v2)

> Feed-forward convolutional neural networks (CNNs) are currently state-of-the-art for object classification tasks such as ImageNet. Further, they are quantitatively accurate models of temporally-averaged responses of neurons in the primate brain's visual system. However, biological visual systems have two ubiquitous architectural features not shared with typical CNNs: local recurrence within cortical areas, and long-range feedback from downstream areas to upstream areas. Here we explored the role of recurrence in improving classification performance. We found that standard forms of recurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the ImageNet task. In contrast, novel cells that incorporated two structural features, bypassing and gating, were able to boost task accuracy substantially. We extended these design principles in an automated search over thousands of model architectures, which identified novel local recurrent cells and long-range feedback connections useful for object recognition. Moreover, these task-optimized ConvRNNs matched the dynamics of neural activity in the primate visual system better than feedforward networks, suggesting a role for the brain's recurrent connections in performing difficult visual behaviors.

</details>

<details>

<summary>2018-10-27 05:28:48 - Flexible Neural Representation for Physics Prediction</summary>

- *Damian Mrowca, Chengxu Zhuang, Elias Wang, Nick Haber, Li Fei-Fei, Joshua B. Tenenbaum, Daniel L. K. Yamins*

- `1806.08047v2` - [abs](http://arxiv.org/abs/1806.08047v2) - [pdf](http://arxiv.org/pdf/1806.08047v2)

> Humans have a remarkable capacity to understand the physical dynamics of objects in their environment, flexibly capturing complex structures and interactions at multiple levels of detail. Inspired by this ability, we propose a hierarchical particle-based object representation that covers a wide variety of types of three-dimensional objects, including both arbitrary rigid geometrical shapes and deformable materials. We then describe the Hierarchical Relation Network (HRN), an end-to-end differentiable neural network based on hierarchical graph convolution, that learns to predict physical dynamics in this representation. Compared to other neural network baselines, the HRN accurately handles complex collisions and nonrigid deformations, generating plausible dynamics predictions at long time scales in novel settings, and scaling to large scene configurations. These results demonstrate an architecture with the potential to form the basis of next-generation physics predictors for use in computer vision, robotics, and quantitative cognitive science.

</details>

<details>

<summary>2018-10-27 05:58:36 - A Miniaturized Semantic Segmentation Method for Remote Sensing Image</summary>

- *Shou-Yu Chen, Guang-Sheng Chen, Wei-Peng Jing*

- `1810.11603v1` - [abs](http://arxiv.org/abs/1810.11603v1) - [pdf](http://arxiv.org/pdf/1810.11603v1)

> In order to save the memory, we propose a miniaturization method for neural network to reduce the parameter quantity existed in remote sensing (RS) image semantic segmentation model. The compact convolution optimization method is first used for standard U-Net to reduce the weights quantity. With the purpose of decreasing model performance loss caused by miniaturization and based on the characteristics of remote sensing image, fewer down-samplings and improved cascade atrous convolution are then used to improve the performance of the miniaturized U-Net. Compared with U-Net, our proposed Micro-Net not only achieves 29.26 times model compression, but also basically maintains the performance unchanged on the public dataset. We provide a Keras and Tensorflow hybrid programming implementation for our model: https://github.com/Isnot2bad/Micro-Net

</details>

<details>

<summary>2018-10-27 09:10:37 - On a Formal Model of Safe and Scalable Self-driving Cars</summary>

- *Shai Shalev-Shwartz, Shaked Shammah, Amnon Shashua*

- `1708.06374v6` - [abs](http://arxiv.org/abs/1708.06374v6) - [pdf](http://arxiv.org/pdf/1708.06374v6)

> In recent years, car makers and tech companies have been racing towards self driving cars. It seems that the main parameter in this race is who will have the first car on the road. The goal of this paper is to add to the equation two additional crucial parameters. The first is standardization of safety assurance --- what are the minimal requirements that every self-driving car must satisfy, and how can we verify these requirements. The second parameter is scalability --- engineering solutions that lead to unleashed costs will not scale to millions of cars, which will push interest in this field into a niche academic corner, and drive the entire field into a "winter of autonomous driving". In the first part of the paper we propose a white-box, interpretable, mathematical model for safety assurance, which we call Responsibility-Sensitive Safety (RSS). In the second part we describe a design of a system that adheres to our safety assurance requirements and is scalable to millions of cars.

</details>

<details>

<summary>2018-10-27 14:23:38 - Fabrik: An Online Collaborative Neural Network Editor</summary>

- *Utsav Garg, Viraj Prabhu, Deshraj Yadav, Ram Ramrakhya, Harsh Agrawal, Dhruv Batra*

- `1810.11649v1` - [abs](http://arxiv.org/abs/1810.11649v1) - [pdf](http://arxiv.org/pdf/1810.11649v1)

> We present Fabrik, an online neural network editor that provides tools to visualize, edit, and share neural networks from within a browser. Fabrik provides a simple and intuitive GUI to import neural networks written in popular deep learning frameworks such as Caffe, Keras, and TensorFlow, and allows users to interact with, build, and edit models via simple drag and drop. Fabrik is designed to be framework agnostic and support high interoperability, and can be used to export models back to any supported framework. Finally, it provides powerful collaborative features to enable users to iterate over model design remotely and at scale.

</details>

<details>

<summary>2018-10-27 15:39:18 - Towards Smart City Innovation Under the Perspective of Software-Defined Networking, Artificial Intelligence and Big Data</summary>

- *Joberto S. B. Martins*

- `1810.11665v1` - [abs](http://arxiv.org/abs/1810.11665v1) - [pdf](http://arxiv.org/pdf/1810.11665v1)

> Smart city projects address many of the current problems afflicting high populated areas and cities and, as such, are a target for government, institutions and private organizations that plan to explore its foreseen advantages. In technical terms, smart city projects present a complex set of requirements including a large number users with highly different and heterogeneous requirements. In this scenario, this paper proposes and analyses the impact and perspectives on adopting software-defined networking and artificial intelligence as innovative approaches for smart city project development and deployment. Big data is also considered as an inherent element of most smart city project that must be tackled. A framework layered view is proposed with a discussion about software-defined networking and machine learning impacts on innovation followed by a use case that demonstrates the potential benefits of cognitive learning for smart cities. It is argued that the complexity of smart city projects do require new innovative approaches that potentially result in more efficient and intelligent systems.

</details>

<details>

<summary>2018-10-27 16:49:13 - Learning Task Specifications from Demonstrations</summary>

- *Marcell Vazquez-Chanlatte, Susmit Jha, Ashish Tiwari, Mark K. Ho, Sanjit A. Seshia*

- `1710.03875v5` - [abs](http://arxiv.org/abs/1710.03875v5) - [pdf](http://arxiv.org/pdf/1710.03875v5)

> Real world applications often naturally decompose into several sub-tasks. In many settings (e.g., robotics) demonstrations provide a natural way to specify the sub-tasks. However, most methods for learning from demonstrations either do not provide guarantees that the artifacts learned for the sub-tasks can be safely recombined or limit the types of composition available. Motivated by this deficit, we consider the problem of inferring Boolean non-Markovian rewards (also known as logical trace properties or specifications) from demonstrations provided by an agent operating in an uncertain, stochastic environment. Crucially, specifications admit well-defined composition rules that are typically easy to interpret. In this paper, we formulate the specification inference task as a maximum a posteriori (MAP) probability inference problem, apply the principle of maximum entropy to derive an analytic demonstration likelihood model and give an efficient approach to search for the most likely specification in a large candidate pool of specifications. In our experiments, we demonstrate how learning specifications can help avoid common problems that often arise due to ad-hoc reward composition.

</details>

<details>

<summary>2018-10-27 19:57:47 - Uploading Brain into Computer: Whom to Upload First?</summary>

- *Yana B. Feygin, Kelly Morris, Roman V. Yampolskiy*

- `1811.03009v1` - [abs](http://arxiv.org/abs/1811.03009v1) - [pdf](http://arxiv.org/pdf/1811.03009v1)

> The final goal of the intelligence augmentation process is a complete merger of biological brains and computers allowing for integration and mutual enhancement between computer's speed and memory and human's intelligence. This process, known as uploading, analyzes human brain in detail sufficient to understand its working patterns and makes it possible to simulate said brain on a computer. As it is likely that such simulations would quickly evolve or be modified to achieve superintelligence it is very important to make sure that the first brain chosen for such a procedure is a suitable one. In this paper, we attempt to answer the question: Whom to upload first?

</details>

<details>

<summary>2018-10-27 23:47:39 - Post-prognostics decision in Cyber-Physical Systems</summary>

- *Safa Meraghni, Labib Sadek Terrissa, Soheyb Ayad, Noureddine Zerhouni, Christophe Varnier*

- `1810.11732v1` - [abs](http://arxiv.org/abs/1810.11732v1) - [pdf](http://arxiv.org/pdf/1810.11732v1)

> Prognostics and Health Management (PHM) offers several benefits for predictive maintenance. It predicts the future behavior of a system as well as its Remaining Useful Life (RUL). This RUL is used to planned the maintenance operation to avoid the failure, the stop time and optimize the cost of the maintenance and failure. However, with the development of the industry the assets are nowadays distributed this is why the PHM needs to be developed using the new IT. In our work we propose a PHM solution based on Cyber physical system where the physical side is connected to the analyze process of the PHM which are developed in the cloud to be shared and to benefit of the cloud characteristics

</details>

<details>

<summary>2018-10-28 03:19:07 - Iterative Local Voting for Collective Decision-making in Continuous Spaces</summary>

- *Nikhil Garg, Vijay Kamble, Ashish Goel, David Marn, Kamesh Munagala*

- `1702.07984v3` - [abs](http://arxiv.org/abs/1702.07984v3) - [pdf](http://arxiv.org/pdf/1702.07984v3)

> Many societal decision problems lie in high-dimensional continuous spaces not amenable to the voting techniques common for their discrete or single-dimensional counterparts. These problems are typically discretized before running an election or decided upon through negotiation by representatives. We propose a algorithm called {\sc Iterative Local Voting} for collective decision-making in this setting. In this algorithm, voters are sequentially sampled and asked to modify a candidate solution within some local neighborhood of its current value, as defined by a ball in some chosen norm, with the size of the ball shrinking at a specified rate.   We first prove the convergence of this algorithm under appropriate choices of neighborhoods to Pareto optimal solutions with desirable fairness properties in certain natural settings: when the voters' utilities can be expressed in terms of some form of distance from their ideal solution, and when these utilities are additively decomposable across dimensions. In many of these cases, we obtain convergence to the societal welfare maximizing solution.   We then describe an experiment in which we test our algorithm for the decision of the U.S. Federal Budget on Mechanical Turk with over 2,000 workers, employing neighborhoods defined by $\mathcal{L}^1, \mathcal{L}^2$ and $\mathcal{L}^\infty$ balls. We make several observations that inform future implementations of such a procedure.

</details>

<details>

<summary>2018-10-28 04:47:56 - Diversity-Driven Exploration Strategy for Deep Reinforcement Learning</summary>

- *Zhang-Wei Hong, Tzu-Yun Shann, Shih-Yang Su, Yi-Hsiang Chang, Chun-Yi Lee*

- `1802.04564v2` - [abs](http://arxiv.org/abs/1802.04564v2) - [pdf](http://arxiv.org/pdf/1802.04564v2)

> Efficient exploration remains a challenging research problem in reinforcement learning, especially when an environment contains large state spaces, deceptive local optima, or sparse rewards. To tackle this problem, we present a diversity-driven approach for exploration, which can be easily combined with both off- and on-policy reinforcement learning algorithms. We show that by simply adding a distance measure to the loss function, the proposed methodology significantly enhances an agent's exploratory behaviors, and thus preventing the policy from being trapped in local optima. We further propose an adaptive scaling method for stabilizing the learning process. Our experimental results in Atari 2600 show that our method outperforms baseline approaches in several tasks in terms of mean scores and exploration efficiency.

</details>

<details>

<summary>2018-10-28 09:37:47 - A Hitchhiker's Guide On Distributed Training of Deep Neural Networks</summary>

- *Karanbir Chahal, Manraj Singh Grover, Kuntal Dey*

- `1810.11787v1` - [abs](http://arxiv.org/abs/1810.11787v1) - [pdf](http://arxiv.org/pdf/1810.11787v1)

> Deep learning has led to tremendous advancements in the field of Artificial Intelligence. One caveat however is the substantial amount of compute needed to train these deep learning models. Training a benchmark dataset like ImageNet on a single machine with a modern GPU can take upto a week, distributing training on multiple machines has been observed to drastically bring this time down. Recent work has brought down ImageNet training time to a time as low as 4 minutes by using a cluster of 2048 GPUs. This paper surveys the various algorithms and techniques used to distribute training and presents the current state of the art for a modern distributed training framework. More specifically, we explore the synchronous and asynchronous variants of distributed Stochastic Gradient Descent, various All Reduce gradient aggregation strategies and best practices for obtaining higher throughout and lower latency over a cluster such as mixed precision training, large batch training and gradient compression.

</details>

<details>

<summary>2018-10-28 12:17:27 - Robots Learning to Say `No': Prohibition and Rejective Mechanisms in Acquisition of Linguistic Negation</summary>

- *Frank Förster, Joe Saunders, Hagen Lehmann, Chrystopher L. Nehaniv*

- `1810.11804v1` - [abs](http://arxiv.org/abs/1810.11804v1) - [pdf](http://arxiv.org/pdf/1810.11804v1)

> `No' belongs to the first ten words used by children and embodies the first active form of linguistic negation. Despite its early occurrence the details of its acquisition process remain largely unknown. The circumstance that `no' cannot be construed as a label for perceptible objects or events puts it outside of the scope of most modern accounts of language acquisition. Moreover, most symbol grounding architectures will struggle to ground the word due to its non-referential character. In an experimental study involving the child-like humanoid robot iCub that was designed to illuminate the acquisition process of negation words, the robot is deployed in several rounds of speech-wise unconstrained interaction with na\"ive participants acting as its language teachers. The results corroborate the hypothesis that affect or volition plays a pivotal role in the socially distributed acquisition process. Negation words are prosodically salient within prohibitive utterances and negative intent interpretations such that they can be easily isolated from the teacher's speech signal. These words subsequently may be grounded in negative affective states. However, observations of the nature of prohibitive acts and the temporal relationships between its linguistic and extra-linguistic components raise serious questions over the suitability of Hebbian-type algorithms for language grounding.

</details>

<details>

<summary>2018-10-29 03:34:56 - An approach to predictively securing critical cloud infrastructures through probabilistic modeling</summary>

- *Satvik Jain, Arun Balaji Buduru, Anshuman Chhabra*

- `1810.11937v1` - [abs](http://arxiv.org/abs/1810.11937v1) - [pdf](http://arxiv.org/pdf/1810.11937v1)

> Cloud infrastructures are being increasingly utilized in critical infrastructures such as banking/finance, transportation and utility management. Sophistication and resources used in recent security breaches including those on critical infrastructures show that attackers are no longer limited by monetary/computational constraints. In fact, they may be aided by entities with large financial and human resources. Hence there is urgent need to develop predictive approaches for cyber defense to strengthen cloud infrastructures specifically utilized by critical infrastructures. Extensive research has been done in the past on applying techniques such as Game Theory, Machine Learning and Bayesian Networks among others for the predictive defense of critical infrastructures. However a major drawback of these approaches is that they do not incorporate probabilistic human behavior which limits their predictive ability. In this paper, a stochastic approach is proposed to predict less secure states in critical cloud systems which might lead to potential security breaches. These less-secure states are deemed as `risky' states in our approach. Markov Decision Process (MDP) is used to accurately incorporate user behavior(s) as well as operational behavior of the cloud infrastructure through a set of features. The developed reward/cost mechanism is then used to select appropriate `actions' to identify risky states at future time steps by learning an optimal policy. Experimental results show that the proposed framework performs well in identifying future `risky' states. Through this work we demonstrate the effectiveness of using probabilistic modeling (MDP) to predictively secure critical cloud infrastructures.

</details>

<details>

<summary>2018-10-29 04:14:05 - Vehicle Tracking Using Surveillance with Multimodal Data Fusion</summary>

- *Yue Zhang, Bin Song, Xiaojiang Du, Mohsen Guizani*

- `1811.02627v1` - [abs](http://arxiv.org/abs/1811.02627v1) - [pdf](http://arxiv.org/pdf/1811.02627v1)

> Vehicle location prediction or vehicle tracking is a significant topic within connected vehicles. This task, however, is difficult if only a single modal data is available, probably causing bias and impeding the accuracy. With the development of sensor networks in connected vehicles, multimodal data are becoming accessible. Therefore, we propose a framework for vehicle tracking with multimodal data fusion. Specifically, we fuse the results of two modalities, images and velocity, in our vehicle-tracking task. Images, being processed in the module of vehicle detection, provide direct information about the features of vehicles, whereas velocity estimation can further evaluate the possible location of the target vehicles, which reduces the number of features being compared, and decreases the time consumption and computational cost. Vehicle detection is designed with a color-faster R-CNN, which takes both the shape and color of the vehicles into consideration. Meanwhile, velocity estimation is through the Kalman filter, which is a classical method for tracking. Finally, a multimodal data fusion method is applied to integrate these outcomes so that vehicle-tracking tasks can be achieved. Experimental results suggest the efficiency of our methods, which can track vehicles using a series of surveillance cameras in urban areas.

</details>

<details>

<summary>2018-10-29 04:14:17 - Social Vehicle Swarms: A Novel Perspective on Social-aware Vehicular Communication Architecture</summary>

- *Yue Zhang, Fang Tian, Bin Song, Xiaojiang Du*

- `1810.11947v1` - [abs](http://arxiv.org/abs/1810.11947v1) - [pdf](http://arxiv.org/pdf/1810.11947v1)

> Internet of vehicles is a promising area related to D2D communication and internet of things. We present a novel perspective for vehicular communications, social vehicle swarms, to study and analyze socially aware internet of vehicles with the assistance of an agent-based model intended to reveal hidden patterns behind superficial data. After discussing its components, namely its agents, environments, and rules, we introduce supportive technology and methods, deep reinforcement learning, privacy preserving data mining and sub-cloud computing, in order to detect the most significant and interesting information for each individual effectively, which is the key desire. Finally, several relevant research topics and challenges are discussed.

</details>

<details>

<summary>2018-10-29 05:31:52 - Robust Learning of Fixed-Structure Bayesian Networks</summary>

- *Yu Cheng, Ilias Diakonikolas, Daniel Kane, Alistair Stewart*

- `1606.07384v2` - [abs](http://arxiv.org/abs/1606.07384v2) - [pdf](http://arxiv.org/pdf/1606.07384v2)

> We investigate the problem of learning Bayesian networks in a robust model where an $\epsilon$-fraction of the samples are adversarially corrupted. In this work, we study the fully observable discrete case where the structure of the network is given. Even in this basic setting, previous learning algorithms either run in exponential time or lose dimension-dependent factors in their error guarantees. We provide the first computationally efficient robust learning algorithm for this problem with dimension-independent error guarantees. Our algorithm has near-optimal sample complexity, runs in polynomial time, and achieves error that scales nearly-linearly with the fraction of adversarially corrupted samples. Finally, we show on both synthetic and semi-synthetic data that our algorithm performs well in practice.

</details>

<details>

<summary>2018-10-29 05:41:55 - SD-WAN Internet Census</summary>

- *Sergey Gordeychik, Denis Kolegov, Antony Nikolaev*

- `1808.09027v2` - [abs](http://arxiv.org/abs/1808.09027v2) - [pdf](http://arxiv.org/pdf/1808.09027v2)

> The concept of software defined wide area network (SD-WAN or SDWAN) is central to modern computer networking, particularly in enterprise networks. By definition, these systems form network perimeter and connect Internet, WAN, extranet, and branches that makes them crucial from cybersecurity point of view. The goal of this paper is to provide the results of passive and active fingerprinting for SD-WAN systems using a common threat intelligence approach. We explore Internet-based and cloud-based publicly available SD-WAN systems using well-known Shodan and Censys search engines and custom developed automation tools and show that most of the SD-WAN systems have known vulnerabilities related to outdated software and insecure configuration.

</details>

<details>

<summary>2018-10-29 10:05:37 - Software Engineering Challenges of Deep Learning</summary>

- *Anders Arpteg, Björn Brinne, Luka Crnkovic-Friis, Jan Bosch*

- `1810.12034v1` - [abs](http://arxiv.org/abs/1810.12034v1) - [pdf](http://arxiv.org/pdf/1810.12034v1)

> Surprisingly promising results have been achieved by deep learning (DL) systems in recent years. Many of these achievements have been reached in academic settings, or by large technology companies with highly skilled research groups and advanced supporting infrastructure. For companies without large research groups or advanced infrastructure, building high-quality production-ready systems with DL components has proven challenging. There is a clear lack of well-functioning tools and best practices for building DL systems. It is the goal of this research to identify what the main challenges are, by applying an interpretive research approach in close collaboration with companies of varying size and type.   A set of seven projects have been selected to describe the potential with this new technology and to identify associated main challenges. A set of 12 main challenges has been identified and categorized into the three areas of development, production, and organizational challenges. Furthermore, a mapping between the challenges and the projects is defined, together with selected motivating descriptions of how and why the challenges apply to specific projects.   Compared to other areas such as software engineering or database technologies, it is clear that DL is still rather immature and in need of further work to facilitate development of high-quality systems. The challenges identified in this paper can be used to guide future research by the software engineering and DL communities. Together, we could enable a large number of companies to start taking advantage of the high potential of the DL technology.

</details>

<details>

<summary>2018-10-29 12:27:02 - Generalisation of structural knowledge in the hippocampal-entorhinal system</summary>

- *James C. R. Whittington, Timothy H. Muller, Shirley Mark, Caswell Barry, Timothy E. J. Behrens*

- `1805.09042v2` - [abs](http://arxiv.org/abs/1805.09042v2) - [pdf](http://arxiv.org/pdf/1805.09042v2)

> A central problem to understanding intelligence is the concept of generalisation. This allows previously learnt structure to be exploited to solve tasks in novel situations differing in their particularities. We take inspiration from neuroscience, specifically the hippocampal-entorhinal system known to be important for generalisation. We propose that to generalise structural knowledge, the representations of the structure of the world, i.e. how entities in the world relate to each other, need to be separated from representations of the entities themselves. We show, under these principles, artificial neural networks embedded with hierarchy and fast Hebbian memory, can learn the statistics of memories and generalise structural knowledge. Spatial neuronal representations mirroring those found in the brain emerge, suggesting spatial cognition is an instance of more general organising principles. We further unify many entorhinal cell types as basis functions for constructing transition graphs, and show these representations effectively utilise memories. We experimentally support model assumptions, showing a preserved relationship between entorhinal grid and hippocampal place cells across environments.

</details>

<details>

<summary>2018-10-29 12:29:51 - Quantum Structures in Human Decision-making: Towards Quantum Expected Utility</summary>

- *Sandro Sozzo*

- `1811.00875v1` - [abs](http://arxiv.org/abs/1811.00875v1) - [pdf](http://arxiv.org/pdf/1811.00875v1)

> {\it Ellsberg thought experiments} and empirical confirmation of Ellsberg preferences pose serious challenges to {\it subjective expected utility theory} (SEUT). We have recently elaborated a quantum-theoretic framework for human decisions under uncertainty which satisfactorily copes with the Ellsberg paradox and other puzzles of SEUT. We apply here the quantum-theoretic framework to the {\it Ellsberg two-urn example}, showing that the paradox can be explained by assuming a state change of the conceptual entity that is the object of the decision ({\it decision-making}, or {\it DM}, {\it entity}) and representing subjective probabilities by quantum probabilities. We also model the empirical data we collected in a DM test on human participants within the theoretic framework above. The obtained results are relevant, as they provide a line to model real life, e.g., financial and medical, decisions that show the same empirical patterns as the two-urn experiment.

</details>

<details>

<summary>2018-10-29 13:03:38 - Learning to Teach with Dynamic Loss Functions</summary>

- *Lijun Wu, Fei Tian, Yingce Xia, Yang Fan, Tao Qin, Jianhuang Lai, Tie-Yan Liu*

- `1810.12081v1` - [abs](http://arxiv.org/abs/1810.12081v1) - [pdf](http://arxiv.org/pdf/1810.12081v1)

> Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g., textbooks), but also sets up appropriate learning objectives (e.g., course projects and exams) considering different situations of a student. When it comes to artificial intelligence, treating machine learning models as students, the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work, we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed, in our framework, the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible, exempt of the ineffective solutions such as policy optimization. We name our method as "learning to teach with dynamic loss functions" (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models.

</details>

<details>

<summary>2018-10-29 15:28:20 - Adversarial Attacks on Stochastic Bandits</summary>

- *Kwang-Sung Jun, Lihong Li, Yuzhe Ma, Xiaojin Zhu*

- `1810.12188v1` - [abs](http://arxiv.org/abs/1810.12188v1) - [pdf](http://arxiv.org/pdf/1810.12188v1)

> We study adversarial attacks that manipulate the reward signals to control the actions chosen by a stochastic multi-armed bandit algorithm. We propose the first attack against two popular bandit algorithms: $\epsilon$-greedy and UCB, \emph{without} knowledge of the mean rewards. The attacker is able to spend only logarithmic effort, multiplied by a problem-specific parameter that becomes smaller as the bandit problem gets easier to attack. The result means the attacker can easily hijack the behavior of the bandit algorithm to promote or obstruct certain actions, say, a particular medical treatment. As bandits are seeing increasingly wide use in practice, our study exposes a significant security threat.

</details>

<details>

<summary>2018-10-29 15:32:56 - Staff dimensioning in homecare services with uncertain demands</summary>

- *C. Rodriguez, Thierry Garaix, X. Xie, V. Augusto*

- `1811.06363v1` - [abs](http://arxiv.org/abs/1811.06363v1) - [pdf](http://arxiv.org/pdf/1811.06363v1)

> The problem addressed in this paper is how to calculate the amount of personnel required to ensure the activity of a home health care (HHC) center on a tactical horizon. Design of quantitative approaches for this question is challenging. The number of caregivers has to be determined for each profession in order to balance the coverage of patients in a region and the workforce cost over several months. Unknown demand in care and spatial dimensions, combination of skills to cover a care and individual trips visiting patients make the underlaying optimization problem very hard. Few studies are dedicated to staff dimensioning for HHC compared to patient to nurses assignment/sequencing and centers location problems. We propose an original two-stage approach based on integer linear stochastic programming, that exploits historical medical data. The first stage calculates (near-)optimal levels of resources for possible demand scenarios , while the second stage computes the optimal number of caregiver for each profession to meet a target coverage indicator. For decision-makers, our algorithm gives the number of employees for each category required to satisfy the demand without any recourse (overtime, external resources) with fixed probability and confidence interval. The approach has been tested on various instances built from data of the French agency of hospitalization data (ATIH).

</details>

<details>

<summary>2018-10-29 15:49:37 - TIP: Typifying the Interpretability of Procedures</summary>

- *Amit Dhurandhar, Vijay Iyengar, Ronny Luss, Karthikeyan Shanmugam*

- `1706.02952v3` - [abs](http://arxiv.org/abs/1706.02952v3) - [pdf](http://arxiv.org/pdf/1706.02952v3)

> We provide a novel notion of what it means to be interpretable, looking past the usual association with human understanding. Our key insight is that interpretability is not an absolute concept and so we define it relative to a target model, which may or may not be a human. We define a framework that allows for comparing interpretable procedures by linking them to important practical aspects such as accuracy and robustness. We characterize many of the current state-of-the-art interpretable methods in our framework portraying its general applicability. Finally, principled interpretable strategies are proposed and empirically evaluated on synthetic data, as well as on the largest public olfaction dataset that was made recently available \cite{olfs}. We also experiment on MNIST with a simple target model and different oracle models of varying complexity. This leads to the insight that the improvement in the target model is not only a function of the oracle model's performance, but also its relative complexity with respect to the target model. Further experiments on CIFAR-10, a real manufacturing dataset and FICO dataset showcase the benefit of our methods over Knowledge Distillation when the target models are simple and the complex model is a neural network.

</details>

<details>

<summary>2018-10-29 16:08:36 - Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives</summary>

- *Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Paishun Ting, Karthikeyan Shanmugam, Payel Das*

- `1802.07623v2` - [abs](http://arxiv.org/abs/1802.07623v2) - [pdf](http://arxiv.org/pdf/1802.07623v2)

> In this paper we propose a novel method that provides contrastive explanations justifying the classification of an input by a black box classifier such as a deep neural network. Given an input we find what should be %necessarily and minimally and sufficiently present (viz. important object pixels in an image) to justify its classification and analogously what should be minimally and necessarily \emph{absent} (viz. certain background pixels). We argue that such explanations are natural for humans and are used commonly in domains such as health care and criminology. What is minimally but critically \emph{absent} is an important part of an explanation, which to the best of our knowledge, has not been explicitly identified by current explanation methods that explain predictions of neural networks. We validate our approach on three real datasets obtained from diverse domains; namely, a handwritten digits dataset MNIST, a large procurement fraud dataset and a brain activity strength dataset. In all three cases, we witness the power of our approach in generating precise explanations that are also easy for human experts to understand and evaluate.

</details>

<details>

<summary>2018-10-29 17:51:54 - Scaling Gaussian Process Regression with Derivatives</summary>

- *David Eriksson, Kun Dong, Eric Hans Lee, David Bindel, Andrew Gordon Wilson*

- `1810.12283v1` - [abs](http://arxiv.org/abs/1810.12283v1) - [pdf](http://arxiv.org/pdf/1810.12283v1)

> Gaussian processes (GPs) with derivatives are useful in many applications, including Bayesian optimization, implicit surface reconstruction, and terrain reconstruction. Fitting a GP to function values and derivatives at $n$ points in $d$ dimensions requires linear solves and log determinants with an ${n(d+1) \times n(d+1)}$ positive definite matrix -- leading to prohibitive $\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose iterative solvers using fast $\mathcal{O}(nd)$ matrix-vector multiplications (MVMs), together with pivoted Cholesky preconditioning that cuts the iterations to convergence by several orders of magnitude, allowing for fast kernel learning and prediction. Our approaches, together with dimensionality reduction, enables Bayesian optimization with derivatives to scale to high-dimensional problems and large evaluation budgets.

</details>

<details>

<summary>2018-10-29 18:02:53 - Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents</summary>

- *Edoardo Conti, Vashisht Madhavan, Felipe Petroski Such, Joel Lehman, Kenneth O. Stanley, Jeff Clune*

- `1712.06560v3` - [abs](http://arxiv.org/abs/1712.06560v3) - [pdf](http://arxiv.org/pdf/1712.06560v3)

> Evolution strategies (ES) are a family of black-box optimization algorithms able to train deep neural networks roughly as well as Q-learning and policy gradient methods on challenging deep reinforcement learning (RL) problems, but are much faster (e.g. hours vs. days) because they parallelize better. However, many RL problems require directed exploration because they have reward functions that are sparse or deceptive (i.e. contain local optima), and it is unknown how to encourage such exploration with ES. Here we show that algorithms that have been invented to promote directed exploration in small-scale evolved neural networks via populations of exploring agents, specifically novelty search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to improve its performance on sparse or deceptive deep RL tasks, while retaining scalability. Our experiments confirm that the resultant new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES to achieve higher performance on Atari and simulated robots learning to walk around a deceptive trap. This paper thus introduces a family of fast, scalable algorithms for reinforcement learning that are capable of directed exploration. It also adds this new family of exploration algorithms to the RL toolbox and raises the interesting possibility that analogous algorithms with multiple simultaneous paths of exploration might also combine well with existing RL algorithms outside ES.

</details>

<details>

<summary>2018-10-29 19:14:26 - Do Explanations make VQA Models more Predictable to a Human?</summary>

- *Arjun Chandrasekaran, Viraj Prabhu, Deshraj Yadav, Prithvijit Chattopadhyay, Devi Parikh*

- `1810.12366v1` - [abs](http://arxiv.org/abs/1810.12366v1) - [pdf](http://arxiv.org/pdf/1810.12366v1)

> A rich line of research attempts to make deep neural networks more transparent by generating human-interpretable 'explanations' of their decision process, especially for interactive tasks like Visual Question Answering (VQA). In this work, we analyze if existing explanations indeed make a VQA model -- its responses as well as failures -- more predictable to a human. Surprisingly, we find that they do not. On the other hand, we find that human-in-the-loop approaches that treat the model as a black-box do.

</details>

<details>

<summary>2018-10-29 20:41:47 - Big Data Meet Cyber-Physical Systems: A Panoramic Survey</summary>

- *Rachad Atat, Lingjia Liu, Jinsong Wu, Guangyu Li, Chunxuan Ye, Yang Yi*

- `1810.12399v1` - [abs](http://arxiv.org/abs/1810.12399v1) - [pdf](http://arxiv.org/pdf/1810.12399v1)

> The world is witnessing an unprecedented growth of cyber-physical systems (CPS), which are foreseen to revolutionize our world {via} creating new services and applications in a variety of sectors such as environmental monitoring, mobile-health systems, intelligent transportation systems and so on. The {information and communication technology }(ICT) sector is experiencing a significant growth in { data} traffic, driven by the widespread usage of smartphones, tablets and video streaming, along with the significant growth of sensors deployments that are anticipated in the near future. {It} is expected to outstandingly increase the growth rate of raw sensed data. In this paper, we present the CPS taxonomy {via} providing a broad overview of data collection, storage, access, processing and analysis. Compared with other survey papers, this is the first panoramic survey on big data for CPS, where our objective is to provide a panoramic summary of different CPS aspects. Furthermore, CPS {require} cybersecurity to protect {them} against malicious attacks and unauthorized intrusion, which {become} a challenge with the enormous amount of data that is continuously being generated in the network. {Thus, we also} provide an overview of the different security solutions proposed for CPS big data storage, access and analytics. We also discuss big data meeting green challenges in the contexts of CPS.

</details>

<details>

<summary>2018-10-29 21:58:13 - Parallel Attention Mechanisms in Neural Machine Translation</summary>

- *Julian Richard Medina, Jugal Kalita*

- `1810.12427v1` - [abs](http://arxiv.org/abs/1810.12427v1) - [pdf](http://arxiv.org/pdf/1810.12427v1)

> Recent papers in neural machine translation have proposed the strict use of attention mechanisms over previous standards such as recurrent and convolutional neural networks (RNNs and CNNs). We propose that by running traditionally stacked encoding branches from encoder-decoder attention- focused architectures in parallel, that even more sequential operations can be removed from the model and thereby decrease training time. In particular, we modify the recently published attention-based architecture called Transformer by Google, by replacing sequential attention modules with parallel ones, reducing the amount of training time and substantially improving BLEU scores at the same time. Experiments over the English to German and English to French translation tasks show that our model establishes a new state of the art.

</details>

<details>

<summary>2018-10-29 22:03:58 - Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation</summary>

- *Qiang Liu, Lihong Li, Ziyang Tang, Dengyong Zhou*

- `1810.12429v1` - [abs](http://arxiv.org/abs/1810.12429v1) - [pdf](http://arxiv.org/pdf/1810.12429v1)

> We consider the off-policy estimation problem of estimating the expected reward of a target policy using samples collected by a different behavior policy. Importance sampling (IS) has been a key technique to derive (nearly) unbiased estimators, but is known to suffer from an excessively high variance in long-horizon problems. In the extreme case of in infinite-horizon problems, the variance of an IS-based estimator may even be unbounded. In this paper, we propose a new off-policy estimation method that applies IS directly on the stationary state-visitation distributions to avoid the exploding variance issue faced by existing estimators.Our key contribution is a novel approach to estimating the density ratio of two stationary distributions, with trajectories sampled from only the behavior distribution. We develop a mini-max loss function for the estimation problem, and derive a closed-form solution for the case of RKHS. We support our method with both theoretical and empirical analyses.

</details>

<details>

<summary>2018-10-29 22:21:33 - Object Detection based on LIDAR Temporal Pulses using Spiking Neural Networks</summary>

- *Shibo Zhou, Wei Wang*

- `1810.12436v1` - [abs](http://arxiv.org/abs/1810.12436v1) - [pdf](http://arxiv.org/pdf/1810.12436v1)

> Neural networks has been successfully used in the processing of Lidar data, especially in the scenario of autonomous driving. However, existing methods heavily rely on pre-processing of the pulse signals derived from Lidar sensors and therefore result in high computational overhead and considerable latency. In this paper, we proposed an approach utilizing Spiking Neural Network (SNN) to address the object recognition problem directly with raw temporal pulses. To help with the evaluation and benchmarking, a comprehensive temporal pulses data-set was created to simulate Lidar reflection in different road scenarios. Being tested with regard to recognition accuracy and time efficiency under different noise conditions, our proposed method shows remarkable performance with the inference accuracy up to 99.83% (with 10% noise) and the average recognition delay as low as 265 ns. It highlights the potential of SNN in autonomous driving and some related applications. In particular, to our best knowledge, this is the first attempt to use SNN to directly perform object recognition on raw Lidar temporal pulses.

</details>

<details>

<summary>2018-10-29 23:33:30 - Faster quantum mixing for slowly evolving sequences of Markov chains</summary>

- *Davide Orsucci, Hans J. Briegel, Vedran Dunjko*

- `1503.01334v4` - [abs](http://arxiv.org/abs/1503.01334v4) - [pdf](http://arxiv.org/pdf/1503.01334v4)

> Markov chain methods are remarkably successful in computational physics, machine learning, and combinatorial optimization. The cost of such methods often reduces to the mixing time, i.e., the time required to reach the steady state of the Markov chain, which scales as $\delta^{-1}$, the inverse of the spectral gap. It has long been conjectured that quantum computers offer nearly generic quadratic improvements for mixing problems. However, except in special cases, quantum algorithms achieve a run-time of $\mathcal{O}(\sqrt{\delta^{-1}} \sqrt{N})$, which introduces a costly dependence on the Markov chain size $N,$ not present in the classical case. Here, we re-address the problem of mixing of Markov chains when these form a slowly evolving sequence. This setting is akin to the simulated annealing setting and is commonly encountered in physics, material sciences and machine learning. We provide a quantum memory-efficient algorithm with a run-time of $\mathcal{O}(\sqrt{\delta^{-1}} \sqrt[4]{N})$, neglecting logarithmic terms, which is an important improvement for large state spaces. Moreover, our algorithms output quantum encodings of distributions, which has advantages over classical outputs. Finally, we discuss the run-time bounds of mixing algorithms and show that, under certain assumptions, our algorithms are optimal.

</details>

<details>

<summary>2018-10-30 02:21:46 - DARKMENTION: A Deployed System to Predict Enterprise-Targeted External Cyberattacks</summary>

- *Mohammed Almukaynizi, Ericsson Marin, Eric Nunes, Paulo Shakarian, Gerardo I. Simari, Dipsy Kapoor, Timothy Siedlecki*

- `1810.12492v1` - [abs](http://arxiv.org/abs/1810.12492v1) - [pdf](http://arxiv.org/pdf/1810.12492v1)

> Recent incidents of data breaches call for organizations to proactively identify cyber attacks on their systems. Darkweb/Deepweb (D2web) forums and marketplaces provide environments where hackers anonymously discuss existing vulnerabilities and commercialize malicious software to exploit those vulnerabilities. These platforms offer security practitioners a threat intelligence environment that allows to mine for patterns related to organization-targeted cyber attacks. In this paper, we describe a system (called DARKMENTION) that learns association rules correlating indicators of attacks from D2web to real-world cyber incidents. Using the learned rules, DARKMENTION generates and submits warnings to a Security Operations Center (SOC) prior to attacks. Our goal was to design a system that automatically generates enterprise-targeted warnings that are timely, actionable, accurate, and transparent. We show that DARKMENTION meets our goal. In particular, we show that it outperforms baseline systems that attempt to generate warnings of cyber attacks related to two enterprises with an average increase in F1 score of about 45% and 57%. Additionally, DARKMENTION was deployed as part of a larger system that is built under a contract with the IARPA Cyber-attack Automated Unconventional Sensor Environment (CAUSE) program. It is actively producing warnings that precede attacks by an average of 3 days.

</details>

<details>

<summary>2018-10-30 02:35:54 - Finding Cryptocurrency Attack Indicators Using Temporal Logic and Darkweb Data</summary>

- *Mohammed Almukaynizi, Vivin Paliath, Malay Shah, Malav Shah, Paulo Shakarian*

- `1810.12906v1` - [abs](http://arxiv.org/abs/1810.12906v1) - [pdf](http://arxiv.org/pdf/1810.12906v1)

> With the recent prevalence of darkweb/deepweb (D2web) sites specializing in the trade of exploit kits and malware, malicious actors have easy-access to a wide-range of tools that can empower their offensive capability. In this study, we apply concepts from causal reasoning, itemset mining, and logic programming on historical cryptocurrency-related cyber incidents with intelligence collected from over 400 D2web hacker forums. Our goal was to find indicators of cyber threats targeting cryptocurrency traders and exchange platforms from hacker activity. Our approach found interesting activities that, when observed together in the D2web, subsequent cryptocurrency-related incidents are at least twice as likely to occur than they would if no activity was observed. We also present an algorithmic extension to a previously-introduced algorithm called APT-Extract that allows to model new semantic structures that are specific to our application.

</details>

<details>

<summary>2018-10-30 03:04:45 - A Framework for Probabilistic Generic Traffic Scene Prediction</summary>

- *Yeping Hu, Wei Zhan, Masayoshi Tomizuka*

- `1810.12506v1` - [abs](http://arxiv.org/abs/1810.12506v1) - [pdf](http://arxiv.org/pdf/1810.12506v1)

> In a given scenario, simultaneously and accurately predicting every possible interaction of traffic participants is an important capability for autonomous vehicles. The majority of current researches focused on the prediction of an single entity without incorporating the environment information. Although some approaches aimed to predict multiple vehicles, they either predicted each vehicle independently with no considerations on possible interaction with surrounding entities or generated discretized joint motions which cannot be directly used in decision making and motion planning for autonomous vehicle. In this paper, we present a probabilistic framework that is able to jointly predict continuous motions for multiple interacting road participants under any driving scenarios and is capable of forecasting the duration of each interaction, which can enhance the prediction performance and efficiency. The proposed traffic scene prediction framework contains two hierarchical modules: the upper module and the lower module. The upper module forecasts the intention of the predicted vehicle, while the lower module predicts motions for interacting scene entities. An exemplar real-world scenario is used to implement and examine the proposed framework.

</details>

<details>

<summary>2018-10-30 04:31:48 - Gated Transfer Network for Transfer Learning</summary>

- *Yi Zhu, Jia Xue, Shawn Newsam*

- `1810.12521v1` - [abs](http://arxiv.org/abs/1810.12521v1) - [pdf](http://arxiv.org/pdf/1810.12521v1)

> Deep neural networks have led to a series of breakthroughs in computer vision given sufficient annotated training datasets. For novel tasks with limited labeled data, the prevalent approach is to transfer the knowledge learned in the pre-trained models to the new tasks by fine-tuning. Classic model fine-tuning utilizes the fact that well trained neural networks appear to learn cross domain features. These features are treated equally during transfer learning. In this paper, we explore the impact of feature selection in model fine-tuning by introducing a transfer module, which assigns weights to features extracted from pre-trained models. The proposed transfer module proves the importance of feature selection for transferring models from source to target domains. It is shown to significantly improve upon fine-tuning results with only marginal extra computational cost. We also incorporate an auxiliary classifier as an extra regularizer to avoid over-fitting. Finally, we build a Gated Transfer Network (GTN) based on our transfer module and achieve state-of-the-art results on six different tasks.

</details>

<details>

<summary>2018-10-30 04:35:43 - Random Temporal Skipping for Multirate Video Analysis</summary>

- *Yi Zhu, Shawn Newsam*

- `1810.12522v1` - [abs](http://arxiv.org/abs/1810.12522v1) - [pdf](http://arxiv.org/pdf/1810.12522v1)

> Current state-of-the-art approaches to video understanding adopt temporal jittering to simulate analyzing the video at varying frame rates. However, this does not work well for multirate videos, in which actions or subactions occur at different speeds. The frame sampling rate should vary in accordance with the different motion speeds. In this work, we propose a simple yet effective strategy, termed random temporal skipping, to address this situation. This strategy effectively handles multirate videos by randomizing the sampling rate during training. It is an exhaustive approach, which can potentially cover all motion speed variations. Furthermore, due to the large temporal skipping, our network can see video clips that originally cover over 100 frames. Such a time range is enough to analyze most actions/events. We also introduce an occlusion-aware optical flow learning method that generates improved motion maps for human action recognition. Our framework is end-to-end trainable, runs in real-time, and achieves state-of-the-art performance on six widely adopted video benchmarks.

</details>

<details>

<summary>2018-10-30 05:39:08 - Object-Oriented Dynamics Predictor</summary>

- *Guangxiang Zhu, Zhiao Huang, Chongjie Zhang*

- `1806.07371v3` - [abs](http://arxiv.org/abs/1806.07371v3) - [pdf](http://arxiv.org/pdf/1806.07371v3)

> Generalization has been one of the major challenges for learning dynamics models in model-based reinforcement learning. However, previous work on action-conditioned dynamics prediction focuses on learning the pixel-level motion and thus does not generalize well to novel environments with different object layouts. In this paper, we present a novel object-oriented framework, called object-oriented dynamics predictor (OODP), which decomposes the environment into objects and predicts the dynamics of objects conditioned on both actions and object-to-object relations. It is an end-to-end neural network and can be trained in an unsupervised manner. To enable the generalization ability of dynamics learning, we design a novel CNN-based relation mechanism that is class-specific (rather than object-specific) and exploits the locality principle. Empirical results show that OODP significantly outperforms previous methods in terms of generalization over novel environments with various object layouts. OODP is able to learn from very few environments and accurately predict dynamics in a large number of unseen environments. In addition, OODP learns semantically and visually interpretable dynamics models.

</details>

<details>

<summary>2018-10-30 09:45:07 - code2vec: Learning Distributed Representations of Code</summary>

- *Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav*

- `1803.09473v5` - [abs](http://arxiv.org/abs/1803.09473v5) - [pdf](http://arxiv.org/pdf/1803.09473v5)

> We present a neural model for representing snippets of code as continuous distributed vectors ("code embeddings"). The main idea is to represent a code snippet as a single fixed-length $\textit{code vector}$, which can be used to predict semantic properties of the snippet. This is performed by decomposing code to a collection of paths in its abstract syntax tree, and learning the atomic representation of each path $\textit{simultaneously}$ with learning how to aggregate a set of them. We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 14M methods. We show that code vectors trained on this dataset can predict method names from files that were completely unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies. Comparing previous techniques over the same data set, our approach obtains a relative improvement of over 75%, being the first to successfully predict method names based on a large, cross-project, corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data, and trained models are available at https://github.com/tech-srl/code2vec.

</details>

<details>

<summary>2018-10-30 10:14:57 - Evaluation of Session-based Recommendation Algorithms</summary>

- *Malte Ludewig, Dietmar Jannach*

- `1803.09587v2` - [abs](http://arxiv.org/abs/1803.09587v2) - [pdf](http://arxiv.org/pdf/1803.09587v2)

> Recommender systems help users find relevant items of interest, for example on e-commerce or media streaming sites. Most academic research is concerned with approaches that personalize the recommendations according to long-term user profiles. In many real-world applications, however, such long-term profiles often do not exist and recommendations therefore have to be made solely based on the observed behavior of a user during an ongoing session. Given the high practical relevance of the problem, an increased interest in this problem can be observed in recent years, leading to a number of proposals for session-based recommendation algorithms that typically aim to predict the user's immediate next actions. In this work, we present the results of an in-depth performance comparison of a number of such algorithms, using a variety of datasets and evaluation measures. Our comparison includes the most recent approaches based on recurrent neural networks like GRU4REC, factorized Markov model approaches such as FISM or FOSSIL, as well as simpler methods based, e.g., on nearest neighbor schemes. Our experiments reveal that algorithms of this latter class, despite their sometimes almost trivial nature, often perform equally well or significantly better than today's more complex approaches based on deep neural networks. Our results therefore suggest that there is substantial room for improvement regarding the development of more sophisticated session-based recommendation algorithms.

</details>

<details>

<summary>2018-10-30 10:35:07 - Neuromorphic hardware as a self-organizing computing system</summary>

- *Lyes Khacef, Bernard Girau, Nicolas Rougier, Andres Upegui, Benoit Miramond*

- `1810.12640v1` - [abs](http://arxiv.org/abs/1810.12640v1) - [pdf](http://arxiv.org/pdf/1810.12640v1)

> This paper presents the self-organized neuromorphic architecture named SOMA. The objective is to study neural-based self-organization in computing systems and to prove the feasibility of a self-organizing hardware structure. Considering that these properties emerge from large scale and fully connected neural maps, we will focus on the definition of a self-organizing hardware architecture based on digital spiking neurons that offer hardware efficiency. From a biological point of view, this corresponds to a combination of the so-called synaptic and structural plasticities. We intend to define computational models able to simultaneously self-organize at both computation and communication levels, and we want these models to be hardware-compliant, fault tolerant and scalable by means of a neuro-cellular structure.

</details>

<details>

<summary>2018-10-30 11:39:49 - Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs</summary>

- *Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry Vetrov, Andrew Gordon Wilson*

- `1802.10026v4` - [abs](http://arxiv.org/abs/1802.10026v4) - [pdf](http://arxiv.org/pdf/1802.10026v4)

> The loss functions of deep neural networks are complex and their geometric properties are not well understood. We show that the optima of these complex loss functions are in fact connected by simple curves over which training and test accuracy are nearly constant. We introduce a training procedure to discover these high-accuracy pathways between modes. Inspired by this new geometric insight, we also propose a new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we can train high-performing ensembles in the time required to train a single model. We achieve improved performance compared to the recent state-of-the-art Snapshot Ensembles, on CIFAR-10, CIFAR-100, and ImageNet.

</details>

<details>

<summary>2018-10-30 11:56:42 - Change Surfaces for Expressive Multidimensional Changepoints and Counterfactual Prediction</summary>

- *William Herlands, Daniel B. Neill, Hannes Nickisch, Andrew Gordon Wilson*

- `1810.11861v2` - [abs](http://arxiv.org/abs/1810.11861v2) - [pdf](http://arxiv.org/pdf/1810.11861v2)

> Identifying changes in model parameters is fundamental in machine learning and statistics. However, standard changepoint models are limited in expressiveness, often addressing unidimensional problems and assuming instantaneous changes. We introduce change surfaces as a multidimensional and highly expressive generalization of changepoints. We provide a model-agnostic formalization of change surfaces, illustrating how they can provide variable, heterogeneous, and non-monotonic rates of change across multiple dimensions. Additionally, we show how change surfaces can be used for counterfactual prediction. As a concrete instantiation of the change surface framework, we develop Gaussian Process Change Surfaces (GPCS). We demonstrate counterfactual prediction with Bayesian posterior mean and credible sets, as well as massive scalability by introducing novel methods for additive non-separable kernels. Using two large spatio-temporal datasets we employ GPCS to discover and characterize complex changes that can provide scientific and policy relevant insights. Specifically, we analyze twentieth century measles incidence across the United States and discover previously unknown heterogeneous changes after the introduction of the measles vaccine. Additionally, we apply the model to requests for lead testing kits in New York City, discovering distinct spatial and demographic patterns.

</details>

<details>

<summary>2018-10-30 12:10:43 - Research Issues in Mining User Behavioral Rules for Context-Aware Intelligent Mobile Applications</summary>

- *Iqbal H. Sarker*

- `1810.12692v1` - [abs](http://arxiv.org/abs/1810.12692v1) - [pdf](http://arxiv.org/pdf/1810.12692v1)

> Context-awareness in smart mobile applications is a growing area of study, because of it's intelligence in the applications. In order to build context-aware intelligent applications, mining contextual behavioral rules of individual smartphone users utilizing their phone log data is the key. However, to mine these rules, a number of issues, such as the quality of smartphone data, understanding the relevancy of contexts, discretization of continuous contextual data, discovery of useful behavioral rules of individuals and their ordering, knowledge-based interactive post-mining for semantic understanding, and dynamic updating and management of rules according to their present behavior, are investigated. In this paper, we briefly discuss these issues and their potential solution directions for mining individuals' behavioral rules, for the purpose of building various context-aware intelligent mobile applications. We also summarize a number of real-life rule-based applications that intelligently assist individual smartphone users according to their behavioral rules in their daily activities.

</details>

<details>

<summary>2018-10-30 12:23:35 - Compositional Attention Networks for Interpretability in Natural Language Question Answering</summary>

- *Muru Selvakumar, Suriyadeepan Ramamoorthy, Vaidheeswaran Archana, Malaikannan Sankarasubbu*

- `1810.12698v1` - [abs](http://arxiv.org/abs/1810.12698v1) - [pdf](http://arxiv.org/pdf/1810.12698v1)

> MAC Net is a compositional attention network designed for Visual Question Answering. We propose a modified MAC net architecture for Natural Language Question Answering. Question Answering typically requires Language Understanding and multi-step Reasoning. MAC net's unique architecture - the separation between memory and control, facilitates data-driven iterative reasoning. This makes it an ideal candidate for solving tasks that involve logical reasoning. Our experiments with 20 bAbI tasks demonstrate the value of MAC net as a data-efficient and interpretable architecture for Natural Language Question Answering. The transparent nature of MAC net provides a highly granular view of the reasoning steps taken by the network in answering a query.

</details>

<details>

<summary>2018-10-30 13:24:03 - OptStream: Releasing Time Series Privately</summary>

- *Ferdinando Fioretto, Pascal Van Hentenryck*

- `1808.01949v2` - [abs](http://arxiv.org/abs/1808.01949v2) - [pdf](http://arxiv.org/pdf/1808.01949v2)

> Many applications of machine learning and optimization operate on data streams. While these datasets are fundamental to fuel decision-making algorithms, often they contain sensitive information about individuals and their usage poses significant privacy risks. Motivated by an application in energy systems, this paper presents OPTSTREAM, a novel algorithm for releasing differentially private data streams under the w-event model of privacy. OPTSTREAM is a 4-step procedure consisting of sampling, perturbation, reconstruction, and post-processing modules. First, the sampling module selects a small set of points to access in each period of interest. Then, the perturbation module adds noise to the sampled data points to guarantee privacy. Next, the reconstruction module reassembles non-sampled data points from the perturbed sample points. Finally, the post-processing module uses convex optimization over the private output of the previous modules, as well as the private answers of additional queries on the data stream, to improve accuracy by redistributing the added noise. OPTSTREAM is evaluated on a test case involving the release of a real data stream from the largest European transmission operator. Experimental results show that OPTSTREAM may not only improve the accuracy of state-of-the-art methods by at least one order of magnitude but also supports accurate load forecasting on the private data.

</details>

<details>

<summary>2018-10-30 13:31:44 - Quantum Statistics-Inspired Neural Attention</summary>

- *Aristotelis Charalampous, Sotirios Chatzis*

- `1809.06205v2` - [abs](http://arxiv.org/abs/1809.06205v2) - [pdf](http://arxiv.org/pdf/1809.06205v2)

> Sequence-to-sequence (encoder-decoder) models with attention constitute a cornerstone of deep learning research, as they have enabled unprecedented sequential data modeling capabilities. This effectiveness largely stems from the capacity of these models to infer salient temporal dynamics over long horizons; these are encoded into the obtained neural attention (NA) distributions. However, existing NA formulations essentially constitute point-wise selection mechanisms over the observed source sequences; that is, attention weights computation relies on the assumption that each source sequence element is independent of the rest. Unfortunately, although convenient, this assumption fails to account for higher-order dependencies which might be prevalent in real-world data. This paper addresses these limitations by leveraging Quantum-Statistical modeling arguments. Specifically, our work broadens the notion of NA, by attempting to account for the case that the NA model becomes inherently incapable of discerning between individual source elements; this is assumed to be the case due to higher-order temporal dynamics. On the contrary, we postulate that in some cases selection may be feasible only at the level of pairs of source sequence elements. To this end, we cast NA into inference of an attention density matrix (ADM) approximation. We derive effective training and inference algorithms, and evaluate our approach in the context of a machine translation (MT) application. We perform experiments with challenging benchmark datasets. As we show, our approach yields favorable outcomes in terms of several evaluation metrics.

</details>

<details>

<summary>2018-10-30 14:43:36 - Reinforcement Learning and Deep Learning based Lateral Control for Autonomous Driving</summary>

- *Dong Li, Dongbin Zhao, Qichao Zhang, Yaran Chen*

- `1810.12778v1` - [abs](http://arxiv.org/abs/1810.12778v1) - [pdf](http://arxiv.org/pdf/1810.12778v1)

> This paper investigates the vision-based autonomous driving with deep learning and reinforcement learning methods. Different from the end-to-end learning method, our method breaks the vision-based lateral control system down into a perception module and a control module. The perception module which is based on a multi-task learning neural network first takes a driver-view image as its input and predicts the track features. The control module which is based on reinforcement learning then makes a control decision based on these features. In order to improve the data efficiency, we propose visual TORCS (VTORCS), a deep reinforcement learning environment which is based on the open racing car simulator (TORCS). By means of the provided functions, one can train an agent with the input of an image or various physical sensor measurement, or evaluate the perception algorithm on this simulator. The trained reinforcement learning controller outperforms the linear quadratic regulator (LQR) controller and model predictive control (MPC) controller on different tracks. The experiments demonstrate that the perception module shows promising performance and the controller is capable of controlling the vehicle drive well along the track center with visual input.

</details>

<details>

<summary>2018-10-30 16:46:08 - Computational Intelligence in Sports: A Systematic Literature Review</summary>

- *Robson P. Bonidia, Luiz A. L. Rodrigues, Anderson P. Avila-Santos, Danilo S. Sanches, Jacques D. Brancher*

- `1810.12850v1` - [abs](http://arxiv.org/abs/1810.12850v1) - [pdf](http://arxiv.org/pdf/1810.12850v1)

> Recently, data mining studies are being successfully conducted to estimate several parameters in a variety of domains. Data mining techniques have attracted the attention of the information industry and society as a whole, due to a large amount of data and the imminent need to turn it into useful knowledge. However, the effective use of data in some areas is still under development, as is the case in sports, which in recent years, has presented a slight growth; consequently, many sports organizations have begun to see that there is a wealth of unexplored knowledge in the data extracted by them. Therefore, this article presents a systematic review of sports data mining. Regarding years 2010 to 2018, 31 types of research were found in this topic. Based on these studies, we present the current panorama, themes, the database used, proposals, algorithms, and research opportunities. Our findings provide a better understanding of the sports data mining potentials, besides motivating the scientific community to explore this timely and interesting topic.

</details>

<details>

<summary>2018-10-30 17:44:42 - Exploration by Random Network Distillation</summary>

- *Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov*

- `1810.12894v1` - [abs](http://arxiv.org/abs/1810.12894v1) - [pdf](http://arxiv.org/pdf/1810.12894v1)

> We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.

</details>

<details>

<summary>2018-10-30 18:03:12 - NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc Information Retrieval</summary>

- *Canjia Li, Yingfei Sun, Ben He, Le Wang, Kai Hui, Andrew Yates, Le Sun, Jungang Xu*

- `1810.12936v1` - [abs](http://arxiv.org/abs/1810.12936v1) - [pdf](http://arxiv.org/pdf/1810.12936v1)

> Pseudo-relevance feedback (PRF) is commonly used to boost the performance of traditional information retrieval (IR) models by using top-ranked documents to identify and weight new query terms, thereby reducing the effect of query-document vocabulary mismatches. While neural retrieval models have recently demonstrated strong results for ad-hoc retrieval, combining them with PRF is not straightforward due to incompatibilities between existing PRF approaches and neural architectures. To bridge this gap, we propose an end-to-end neural PRF framework that can be used with existing neural IR models by embedding different neural models as building blocks. Extensive experiments on two standard test collections confirm the effectiveness of the proposed NPRF framework in improving the performance of two state-of-the-art neural IR models.

</details>

<details>

<summary>2018-10-30 19:43:17 - Word Mover's Embedding: From Word2Vec to Document Embedding</summary>

- *Lingfei Wu, Ian E. H. Yen, Kun Xu, Fangli Xu, Avinash Balakrishnan, Pin-Yu Chen, Pradeep Ravikumar, Michael J. Witbrock*

- `1811.01713v1` - [abs](http://arxiv.org/abs/1811.01713v1) - [pdf](http://arxiv.org/pdf/1811.01713v1)

> While the celebrated Word2Vec technique yields semantically rich representations for individual words, there has been relatively less success in extending to generate unsupervised sentences or documents embeddings. Recent work has demonstrated that a distance measure between documents called \emph{Word Mover's Distance} (WMD) that aligns semantically similar words, yields unprecedented KNN classification accuracy. However, WMD is expensive to compute, and it is hard to extend its use beyond a KNN classifier. In this paper, we propose the \emph{Word Mover's Embedding } (WME), a novel approach to building an unsupervised document (sentence) embedding from pre-trained word embeddings. In our experiments on 9 benchmark text classification datasets and 22 textual similarity tasks, the proposed technique consistently matches or outperforms state-of-the-art techniques, with significantly higher accuracy on problems of short length.

</details>

<details>

<summary>2018-10-30 20:08:46 - Learning to Play with Intrinsically-Motivated Self-Aware Agents</summary>

- *Nick Haber, Damian Mrowca, Li Fei-Fei, Daniel L. K. Yamins*

- `1802.07442v2` - [abs](http://arxiv.org/abs/1802.07442v2) - [pdf](http://arxiv.org/pdf/1802.07442v2)

> Infants are experts at playing, with an amazing ability to generate novel structured behaviors in unstructured environments that lack clear extrinsic reward signals. We seek to mathematically formalize these abilities using a neural network that implements curiosity-driven intrinsic motivation. Using a simple but ecologically naturalistic simulated environment in which an agent can move and interact with objects it sees, we propose a "world-model" network that learns to predict the dynamic consequences of the agent's actions. Simultaneously, we train a separate explicit "self-model" that allows the agent to track the error map of its own world-model, and then uses the self-model to adversarially challenge the developing world-model. We demonstrate that this policy causes the agent to explore novel and informative interactions with its environment, leading to the generation of a spectrum of complex behaviors, including ego-motion prediction, object attention, and object gathering. Moreover, the world-model that the agent learns supports improved performance on object dynamics prediction, detection, localization and recognition tasks. Taken together, our results are initial steps toward creating flexible autonomous agents that self-supervise in complex novel physical environments.

</details>

<details>

<summary>2018-10-30 22:26:39 - ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning</summary>

- *Rana Hanocka, Noa Fish, Zhenhua Wang, Raja Giryes, Shachar Fleishman, Daniel Cohen-Or*

- `1804.08497v2` - [abs](http://arxiv.org/abs/1804.08497v2) - [pdf](http://arxiv.org/pdf/1804.08497v2)

> The process of aligning a pair of shapes is a fundamental operation in computer graphics. Traditional approaches rely heavily on matching corresponding points or features to guide the alignment, a paradigm that falters when significant shape portions are missing. These techniques generally do not incorporate prior knowledge about expected shape characteristics, which can help compensate for any misleading cues left by inaccuracies exhibited in the input shapes. We present an approach based on a deep neural network, leveraging shape datasets to learn a shape-aware prior for source-to-target alignment that is robust to shape incompleteness. In the absence of ground truth alignments for supervision, we train a network on the task of shape alignment using incomplete shapes generated from full shapes for self-supervision. Our network, called ALIGNet, is trained to warp complete source shapes to incomplete targets, as if the target shapes were complete, thus essentially rendering the alignment partial-shape agnostic. We aim for the network to develop specialized expertise over the common characteristics of the shapes in each dataset, thereby achieving a higher-level understanding of the expected shape space to which a local approach would be oblivious. We constrain ALIGNet through an anisotropic total variation identity regularization to promote piecewise smooth deformation fields, facilitating both partial-shape agnosticism and post-deformation applications. We demonstrate that ALIGNet learns to align geometrically distinct shapes, and is able to infer plausible mappings even when the target shape is significantly incomplete. We show that our network learns the common expected characteristics of shape collections, without over-fitting or memorization, enabling it to produce plausible deformations on unseen data during test time.

</details>

<details>

<summary>2018-10-30 23:49:21 - A study on speech enhancement using exponent-only floating point quantized neural network (EOFP-QNN)</summary>

- *Yi-Te Hsu, Yu-Chen Lin, Szu-Wei Fu, Yu Tsao, Tei-Wei Kuo*

- `1808.06474v4` - [abs](http://arxiv.org/abs/1808.06474v4) - [pdf](http://arxiv.org/pdf/1808.06474v4)

> Numerous studies have investigated the effectiveness of neural network quantization on pattern classification tasks. The present study, for the first time, investigated the performance of speech enhancement (a regression task in speech processing) using a novel exponent-only floating-point quantized neural network (EOFP-QNN). The proposed EOFP-QNN consists of two stages: mantissa-quantization and exponent-quantization. In the mantissa-quantization stage, EOFP-QNN learns how to quantize the mantissa bits of the model parameters while preserving the regression accuracy using the least mantissa precision. In the exponent-quantization stage, the exponent part of the parameters is further quantized without causing any additional performance degradation. We evaluated the proposed EOFP quantization technique on two types of neural networks, namely, bidirectional long short-term memory (BLSTM) and fully convolutional neural network (FCN), on a speech enhancement task. Experimental results showed that the model sizes can be significantly reduced (the model sizes of the quantized BLSTM and FCN models were only 18.75% and 21.89%, respectively, compared to those of the original models) while maintaining satisfactory speech-enhancement performance.

</details>

<details>

<summary>2018-10-31 02:10:14 - Formal Verification of Neural Network Controlled Autonomous Systems</summary>

- *Xiaowu Sun, Haitham Khedr, Yasser Shoukry*

- `1810.13072v1` - [abs](http://arxiv.org/abs/1810.13072v1) - [pdf](http://arxiv.org/pdf/1810.13072v1)

> In this paper, we consider the problem of formally verifying the safety of an autonomous robot equipped with a Neural Network (NN) controller that processes LiDAR images to produce control actions. Given a workspace that is characterized by a set of polytopic obstacles, our objective is to compute the set of safe initial conditions such that a robot trajectory starting from these initial conditions is guaranteed to avoid the obstacles. Our approach is to construct a finite state abstraction of the system and use standard reachability analysis over the finite state abstraction to compute the set of the safe initial states. The first technical problem in computing the finite state abstraction is to mathematically model the imaging function that maps the robot position to the LiDAR image. To that end, we introduce the notion of imaging-adapted sets as partitions of the workspace in which the imaging function is guaranteed to be affine. We develop a polynomial-time algorithm to partition the workspace into imaging-adapted sets along with computing the corresponding affine imaging functions. Given this workspace partitioning, a discrete-time linear dynamics of the robot, and a pre-trained NN controller with Rectified Linear Unit (ReLU) nonlinearity, the second technical challenge is to analyze the behavior of the neural network. To that end, we utilize a Satisfiability Modulo Convex (SMC) encoding to enumerate all the possible segments of different ReLUs. SMC solvers then use a Boolean satisfiability solver and a convex programming solver and decompose the problem into smaller subproblems. To accelerate this process, we develop a pre-processing algorithm that could rapidly prune the space feasible ReLU segments. Finally, we demonstrate the efficiency of the proposed algorithms using numerical simulations with increasing complexity of the neural network controller.

</details>

<details>

<summary>2018-10-31 03:22:25 - WaveGlow: A Flow-based Generative Network for Speech Synthesis</summary>

- *Ryan Prenger, Rafael Valle, Bryan Catanzaro*

- `1811.00002v1` - [abs](http://arxiv.org/abs/1811.00002v1) - [pdf](http://arxiv.org/pdf/1811.00002v1)

> In this paper we propose WaveGlow: a flow-based network capable of generating high quality speech from mel-spectrograms. WaveGlow combines insights from Glow and WaveNet in order to provide fast, efficient and high-quality audio synthesis, without the need for auto-regression. WaveGlow is implemented using only a single network, trained using only a single cost function: maximizing the likelihood of the training data, which makes the training procedure simple and stable. Our PyTorch implementation produces audio samples at a rate of more than 500 kHz on an NVIDIA V100 GPU. Mean Opinion Scores show that it delivers audio quality as good as the best publicly available WaveNet implementation. All code will be made publicly available online.

</details>

<details>

<summary>2018-10-31 04:44:41 - Gated Hierarchical Attention for Image Captioning</summary>

- *Qingzhong Wang, Antoni B. Chan*

- `1810.12535v2` - [abs](http://arxiv.org/abs/1810.12535v2) - [pdf](http://arxiv.org/pdf/1810.12535v2)

> Attention modules connecting encoder and decoders have been widely applied in the field of object recognition, image captioning, visual question answering and neural machine translation, and significantly improves the performance. In this paper, we propose a bottom-up gated hierarchical attention (GHA) mechanism for image captioning. Our proposed model employs a CNN as the decoder which is able to learn different concepts at different layers, and apparently, different concepts correspond to different areas of an image. Therefore, we develop the GHA in which low-level concepts are merged into high-level concepts and simultaneously low-level attended features pass to the top to make predictions. Our GHA significantly improves the performance of the model that only applies one level attention, for example, the CIDEr score increases from 0.923 to 0.999, which is comparable to the state-of-the-art models that employ attributes boosting and reinforcement learning (RL). We also conduct extensive experiments to analyze the CNN decoder and our proposed GHA, and we find that deeper decoders cannot obtain better performance, and when the convolutional decoder becomes deeper the model is likely to collapse during training.

</details>

<details>

<summary>2018-10-31 07:31:08 - Adaptive Extreme Learning Machine for Recurrent Beta-basis Function Neural Network Training</summary>

- *Naima Chouikhi, Adel M. Alimi*

- `1810.13135v1` - [abs](http://arxiv.org/abs/1810.13135v1) - [pdf](http://arxiv.org/pdf/1810.13135v1)

> Beta Basis Function Neural Network (BBFNN) is a special kind of kernel basis neural networks. It is a feedforward network typified by the use of beta function as a hidden activation function. Beta is a flexible transfer function representing richer forms than the common existing functions. As in every network, the architecture setting as well as the learning method are two main gauntlets faced by BBFNN. In this paper, new architecture and training algorithm are proposed for the BBFNN. An Extreme Learning Machine (ELM) is used as a training approach of BBFNN with the aim of quickening the training process. The peculiarity of ELM is permitting a certain decrement of the computing time and complexity regarding the already used BBFNN learning algorithms such as backpropagation, OLS, etc. For the architectural design, a recurrent structure is added to the common BBFNN architecture in order to make it more able to deal with complex, non linear and time varying problems. Throughout this paper, the conceived recurrent ELM-trained BBFNN is tested on a number of tasks related to time series prediction, classification and regression. Experimental results show noticeable achievements of the proposed network compared to common feedforward and recurrent networks trained by ELM and using hyperbolic tangent as activation function. These achievements are in terms of accuracy and robustness against data breakdowns such as noise signals.

</details>

<details>

<summary>2018-10-31 07:59:07 - Towards a more efficient use of process and product traceability data for continuous improvement of industrial performances</summary>

- *Thierno Diallo, Sébastien Henry, Yacine Ouzrout*

- `1810.13141v1` - [abs](http://arxiv.org/abs/1810.13141v1) - [pdf](http://arxiv.org/pdf/1810.13141v1)

> Nowadays all industrial sectors are increasingly faced with the explosion in the amount of data. Therefore, it raises the question of the efficient use of this large amount of data. In this research work, we are concerned with process and product traceability data. In some sectors (e.g. pharmaceutical and agro-food), the collection and storage of these data are required. Beyond this constraint (regulatory and / or contractual), we are interested in the use of these data for continuous improvements of industrial performances. Two research axes were identified: product recall and responsiveness towards production hazards. For the first axis, a procedure for product recall exploiting traceability data will be propose. The development of detection and prognosis functions combining process and product data is envisaged for the second axis.

</details>

<details>

<summary>2018-10-31 08:00:32 - ANS: Adaptive Network Scaling for Deep Rectifier Reinforcement Learning Models</summary>

- *Yueh-Hua Wu, Fan-Yun Sun, Yen-Yu Chang, Shou-De Lin*

- `1809.02112v3` - [abs](http://arxiv.org/abs/1809.02112v3) - [pdf](http://arxiv.org/pdf/1809.02112v3)

> This work provides a thorough study on how reward scaling can affect performance of deep reinforcement learning agents. In particular, we would like to answer the question that how does reward scaling affect non-saturating ReLU networks in RL? This question matters because ReLU is one of the most effective activation functions for deep learning models. We also propose an Adaptive Network Scaling framework to find a suitable scale of the rewards during learning for better performance. We conducted empirical studies to justify the solution.

</details>

<details>

<summary>2018-10-31 09:15:02 - Don't forget, there is more than forgetting: new metrics for Continual Learning</summary>

- *Natalia Díaz-Rodríguez, Vincenzo Lomonaco, David Filliat, Davide Maltoni*

- `1810.13166v1` - [abs](http://arxiv.org/abs/1810.13166v1) - [pdf](http://arxiv.org/pdf/1810.13166v1)

> Continual learning consists of algorithms that learn from a stream of data/tasks continuously and adaptively thought time, enabling the incremental development of ever more complex knowledge and skills. The lack of consensus in evaluating continual learning algorithms and the almost exclusive focus on forgetting motivate us to propose a more comprehensive set of implementation independent metrics accounting for several factors we believe have practical implications worth considering in the deployment of real AI systems that learn continually: accuracy or performance over time, backward and forward knowledge transfer, memory overhead as well as computational efficiency. Drawing inspiration from the standard Multi-Attribute Value Theory (MAVT) we further propose to fuse these metrics into a single score for ranking purposes and we evaluate our proposal with five continual learning strategies on the iCIFAR-100 continual learning benchmark.

</details>

<details>

<summary>2018-10-31 10:07:47 - Infrastructure for the representation and electronic exchange of design knowledge</summary>

- *Laurent Buzon, Abdelaziz Bouras, Yacine Ouzrout*

- `1810.13191v1` - [abs](http://arxiv.org/abs/1810.13191v1) - [pdf](http://arxiv.org/pdf/1810.13191v1)

> This paper develops the concept of knowledge and its exchange using Semantic Web technologies. It points out that knowledge is more than information because it embodies the meaning, that is to say semantic and context. These characteristics will influence our approach to represent and to treat the knowledge. In order to be adopted, the developed system needs to be simple and to use standards. The goal of the paper is to find standards to model knowledge and exchange it with an other person. Therefore, we propose to model knowledge using UML models to show a graphical representation and to exchange it with XML to ensure the portability at low cost. We introduce the concept of ontology for organizing knowledge and for facilitating the knowledge exchange. Proposals have been tested by implementing an application on the design knowledge of a pen.

</details>

<details>

<summary>2018-10-31 10:24:08 - The Many Moods of Emotion</summary>

- *Valentin Vielzeuf, Corentin Kervadec, Stéphane Pateux, Frédéric Jurie*

- `1810.13197v1` - [abs](http://arxiv.org/abs/1810.13197v1) - [pdf](http://arxiv.org/pdf/1810.13197v1)

> This paper presents a novel approach to the facial expression generation problem. Building upon the assumption of the psychological community that emotion is intrinsically continuous, we first design our own continuous emotion representation with a 3-dimensional latent space issued from a neural network trained on discrete emotion classification. The so-obtained representation can be used to annotate large in the wild datasets and later used to trained a Generative Adversarial Network. We first show that our model is able to map back to discrete emotion classes with a objectively and subjectively better quality of the images than usual discrete approaches. But also that we are able to pave the larger space of possible facial expressions, generating the many moods of emotion. Moreover, two axis in this space may be found to generate similar expression changes as in traditional continuous representations such as arousal-valence. Finally we show from visual interpretation, that the third remaining dimension is highly related to the well-known dominance dimension from psychology.

</details>

<details>

<summary>2018-10-31 10:47:21 - Policy Optimization via Importance Sampling</summary>

- *Alberto Maria Metelli, Matteo Papini, Francesco Faccio, Marcello Restelli*

- `1809.06098v2` - [abs](http://arxiv.org/abs/1809.06098v2) - [pdf](http://arxiv.org/pdf/1809.06098v2)

> Policy optimization is an effective reinforcement learning approach to solve continuous control tasks. Recent achievements have shown that alternating online and offline optimization is a successful choice for efficient trajectory reuse. However, deciding when to stop optimizing and collect new trajectories is non-trivial, as it requires to account for the variance of the objective function estimate. In this paper, we propose a novel, model-free, policy search algorithm, POIS, applicable in both action-based and parameter-based settings. We first derive a high-confidence bound for importance sampling estimation; then we define a surrogate objective function, which is optimized offline whenever a new batch of trajectories is collected. Finally, the algorithm is tested on a selection of continuous control tasks, with both linear and deep policies, and compared with state-of-the-art policy optimization methods.

</details>

<details>

<summary>2018-10-31 12:22:14 - MDFS - MultiDimensional Feature Selection</summary>

- *Radosław Piliszek, Krzysztof Mnich, Szymon Migacz, Paweł Tabaszewski, Andrzej Sułecki, Aneta Polewko-Klim, Witold Rudnicki*

- `1811.00631v1` - [abs](http://arxiv.org/abs/1811.00631v1) - [pdf](http://arxiv.org/pdf/1811.00631v1)

> Identification of informative variables in an information system is often performed using simple one-dimensional filtering procedures that discard information about interactions between variables. Such approach may result in removing some relevant variables from consideration. Here we present an R package MDFS (MultiDimensional Feature Selection) that performs identification of informative variables taking into account synergistic interactions between multiple descriptors and the decision variable. MDFS is an implementation of an algorithm based on information theory. Computational kernel of the package is implemented in C++. A high-performance version implemented in CUDA C is also available. The applications of MDFS are demonstrated using the well-known Madelon dataset that has synergistic variables by design. The dataset comes from the UCI Machine Learning Repository. It is shown that multidimensional analysis is more sensitive than one-dimensional tests and returns more reliable rankings of importance.

</details>

<details>

<summary>2018-10-31 14:52:02 - Text-mining and ontologies: new approaches to knowledge discovery of microbial diversity</summary>

- *Claire Nédellec, Robert Bossy, Estelle Chaix, Louise Deléger*

- `1805.04107v2` - [abs](http://arxiv.org/abs/1805.04107v2) - [pdf](http://arxiv.org/pdf/1805.04107v2)

> Microbiology research has access to a very large amount of public information on the habitats of microorganisms. Many areas of microbiology research uses this information, primarily in biodiversity studies. However the habitat information is expressed in unstructured natural language form, which hinders its exploitation at large-scale. It is very common for similar habitats to be described by different terms, which makes them hard to compare automatically, e.g. intestine and gut. The use of a common reference to standardize these habitat descriptions as claimed by (Ivana et al., 2010) is a necessity. We propose the ontology called OntoBiotope that we have been developing since 2010. The OntoBiotope ontology is in a formal machine-readable representation that enables indexing of information as well as conceptualization and reasoning.

</details>

<details>

<summary>2018-10-31 15:17:05 - Convolutional Neural Network Quantization using Generalized Gamma Distribution</summary>

- *Doyun Kim, Han Young Yim, Sanghyuck Ha, Changgwun Lee, Inyup Kang*

- `1810.13329v1` - [abs](http://arxiv.org/abs/1810.13329v1) - [pdf](http://arxiv.org/pdf/1810.13329v1)

> As edge applications using convolutional neural networks (CNN) models grow, it is becoming necessary to introduce dedicated hardware accelerators in which network parameters and feature-map data are represented with limited precision. In this paper we propose a novel quantization algorithm for energy-efficient deployment of the hardware accelerators. For weights and biases, the optimal bit length of the fractional part is determined so that the quantization error is minimized over their distribution. For feature-map data, meanwhile, their sample distribution is well approximated with the generalized gamma distribution (GGD), and accordingly the optimal quantization step size can be obtained through the asymptotical closed form solution of GGD. The proposed quantization algorithm has a higher signal-to-quantization-noise ratio (SQNR) than other quantization schemes previously proposed for CNNs, and even can be more improved by tuning the quantization parameters, resulting in efficient implementation of the hardware accelerators for CNNs in terms of power consumption and memory bandwidth.

</details>

<details>

<summary>2018-10-31 15:30:00 - MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval</summary>

- *Helena Peic Tukuljac, Antoine Deleforge, Rémi Gribonval*

- `1810.13338v1` - [abs](http://arxiv.org/abs/1810.13338v1) - [pdf](http://arxiv.org/pdf/1810.13338v1)

> This paper addresses the general problem of blind echo retrieval, i.e., given M sensors measuring in the discrete-time domain M mixtures of K delayed and attenuated copies of an unknown source signal, can the echo locations and weights be recovered? This problem has broad applications in fields such as sonars, seismol-ogy, ultrasounds or room acoustics. It belongs to the broader class of blind channel identification problems, which have been intensively studied in signal processing. Existing methods in the literature proceed in two steps: (i) blind estimation of sparse discrete-time filters and (ii) echo information retrieval by peak-picking on filters. The precision of these methods is fundamentally limited by the rate at which the signals are sampled: estimated echo locations are necessary on-grid, and since true locations never match the sampling grid, the weight estimation precision is impacted. This is the so-called basis-mismatch problem in compressed sensing. We propose a radically different approach to the problem, building on the framework of finite-rate-of-innovation sampling. The approach operates directly in the parameter-space of echo locations and weights, and enables near-exact blind and off-grid echo retrieval from discrete-time measurements. It is shown to outperform conventional methods by several orders of magnitude in precision.

</details>

<details>

<summary>2018-10-31 15:41:22 - dAIrector: Automatic Story Beat Generation through Knowledge Synthesis</summary>

- *Markus Eger, Kory W. Mathewson*

- `1811.03423v1` - [abs](http://arxiv.org/abs/1811.03423v1) - [pdf](http://arxiv.org/pdf/1811.03423v1)

> dAIrector is an automated director which collaborates with humans storytellers for live improvisational performances and writing assistance. dAIrector can be used to create short narrative arcs through contextual plot generation. In this work, we present the system architecture, a quantitative evaluation of design choices, and a case-study usage of the system which provides qualitative feedback from a professional improvisational performer. We present relevant metrics for the understudied domain of human-machine creative generation, specifically long-form narrative creation. We include, alongside publication, open-source code so that others may test, evaluate, and run the dAIrector.

</details>

<details>

<summary>2018-10-31 16:09:44 - Analyzing biological and artificial neural networks: challenges with opportunities for synergy?</summary>

- *David G. T. Barrett, Ari S. Morcos, Jakob H. Macke*

- `1810.13373v1` - [abs](http://arxiv.org/abs/1810.13373v1) - [pdf](http://arxiv.org/pdf/1810.13373v1)

> Deep neural networks (DNNs) transform stimuli across multiple processing stages to produce representations that can be used to solve complex tasks, such as object recognition in images. However, a full understanding of how they achieve this remains elusive. The complexity of biological neural networks substantially exceeds the complexity of DNNs, making it even more challenging to understand the representations that they learn. Thus, both machine learning and computational neuroscience are faced with a shared challenge: how can we analyze their representations in order to understand how they solve complex tasks?   We review how data-analysis concepts and techniques developed by computational neuroscientists can be useful for analyzing representations in DNNs, and in turn, how recently developed techniques for analysis of DNNs can be useful for understanding representations in biological neural networks. We explore opportunities for synergy between the two fields, such as the use of DNNs as in-silico model systems for neuroscience, and how this synergy can lead to new hypotheses about the operating principles of biological neural networks.

</details>

<details>

<summary>2018-10-31 18:07:40 - Autonomous Driving without a Burden: View from Outside with Elevated LiDAR</summary>

- *Nalin Jayaweera, Nandana Rajatheva, Matti Latva-aho*

- `1808.08617v2` - [abs](http://arxiv.org/abs/1808.08617v2) - [pdf](http://arxiv.org/pdf/1808.08617v2)

> The current autonomous driving architecture places a heavy burden in signal processing for the graphics processing units (GPUs) in the car. This directly translates into battery drain and lower energy efficiency, crucial factors in electric vehicles. This is due to the high bit rate of the captured video and other sensing inputs, mainly due to Light Detection and Ranging (LiDAR) sensor at the top of the car which is an essential feature in autonomous vehicles. LiDAR is needed to obtain a high precision map for the vehicle AI to make relevant decisions. However, this is still a quite restricted view from the car. This is the same even in the case of cars without a LiDAR such as Tesla. The existing LiDARs and the cameras have limited horizontal and vertical fields of visions. In all cases it can be argued that precision is lower, given the smaller map generated. This also results in the accumulation of a large amount of data in the order of several TBs in a day, the storage of which becomes challenging. If we are to reduce the effort for the processing units inside the car, we need to uplink the data to edge or an appropriately placed cloud. However, the required data rates in the order of several Gbps are difficult to be met even with the advent of 5G. Therefore, we propose to have a coordinated set of LiDAR's outside at an elevation which can provide an integrated view with a much larger field of vision (FoV) to a centralized decision making body which then sends the required control actions to the vehicles with a lower bit rate in the downlink and with the required latency. The calculations we have based on industry standard equipment from several manufacturers show that this is not just a concept but a feasible system which can be implemented.The proposed system can play a supportive role with existing autonomous vehicle architecture and it is easily applicable in an urban area.

</details>

<details>

<summary>2018-10-31 20:11:05 - TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow</summary>

- *Danijar Hafner, James Davidson, Vincent Vanhoucke*

- `1709.02878v2` - [abs](http://arxiv.org/abs/1709.02878v2) - [pdf](http://arxiv.org/pdf/1709.02878v2)

> We introduce TensorFlow Agents, an efficient infrastructure paradigm for building parallel reinforcement learning algorithms in TensorFlow. We simulate multiple environments in parallel, and group them to perform the neural network computation on a batch rather than individual observations. This allows the TensorFlow execution engine to parallelize computation, without the need for manual synchronization. Environments are stepped in separate Python processes to progress them in parallel without interference of the global interpreter lock. As part of this project, we introduce BatchPPO, an efficient implementation of the proximal policy optimization algorithm. By open sourcing TensorFlow Agents, we hope to provide a flexible starting point for future projects that accelerates future research in the field.

</details>

<details>

<summary>2018-10-31 21:31:59 - Towards a Simple Approach to Multi-step Model-based Reinforcement Learning</summary>

- *Kavosh Asadi, Evan Cater, Dipendra Misra, Michael L. Littman*

- `1811.00128v1` - [abs](http://arxiv.org/abs/1811.00128v1) - [pdf](http://arxiv.org/pdf/1811.00128v1)

> When environmental interaction is expensive, model-based reinforcement learning offers a solution by planning ahead and avoiding costly mistakes. Model-based agents typically learn a single-step transition model. In this paper, we propose a multi-step model that predicts the outcome of an action sequence with variable length. We show that this model is easy to learn, and that the model can make policy-conditional predictions. We report preliminary results that show a clear advantage for the multi-step model compared to its one-step counterpart.

</details>

<details>

<summary>2018-10-31 22:04:22 - Dirichlet Variational Autoencoder for Text Modeling</summary>

- *Yijun Xiao, Tiancheng Zhao, William Yang Wang*

- `1811.00135v1` - [abs](http://arxiv.org/abs/1811.00135v1) - [pdf](http://arxiv.org/pdf/1811.00135v1)

> We introduce an improved variational autoencoder (VAE) for text modeling with topic information explicitly modeled as a Dirichlet latent variable. By providing the proposed model topic awareness, it is more superior at reconstructing input texts. Furthermore, due to the inherent interactions between the newly introduced Dirichlet variable and the conventional multivariate Gaussian variable, the model is less prone to KL divergence vanishing. We derive the variational lower bound for the new model and conduct experiments on four different data sets. The results show that the proposed model is superior at text reconstruction across the latent space and classifications on learned representations have higher test accuracies.

</details>

<details>

<summary>2018-10-31 22:59:57 - DOLORES: Deep Contextualized Knowledge Graph Embeddings</summary>

- *Haoyu Wang, Vivek Kulkarni, William Yang Wang*

- `1811.00147v1` - [abs](http://arxiv.org/abs/1811.00147v1) - [pdf](http://arxiv.org/pdf/1811.00147v1)

> We introduce a new method DOLORES for learning knowledge graph embeddings that effectively captures contextual cues and dependencies among entities and relations. First, we note that short paths on knowledge graphs comprising of chains of entities and relations can encode valuable information regarding their contextual usage. We operationalize this notion by representing knowledge graphs not as a collection of triples but as a collection of entity-relation chains, and learn embeddings for entities and relations using deep neural models that capture such contextual usage. In particular, our model is based on Bi-Directional LSTMs and learn deep representations of entities and relations from constructed entity-relation chains. We show that these representations can very easily be incorporated into existing models to significantly advance the state of the art on several knowledge graph prediction tasks like link prediction, triple classification, and missing relation type prediction (in some cases by at least 9.5%).

</details>

<details>

<summary>2018-10-31 23:59:04 - Modeling Melodic Feature Dependency with Modularized Variational Auto-Encoder</summary>

- *Yu-An Wang, Yu-Kai Huang, Tzu-Chuan Lin, Shang-Yu Su, Yun-Nung Chen*

- `1811.00162v1` - [abs](http://arxiv.org/abs/1811.00162v1) - [pdf](http://arxiv.org/pdf/1811.00162v1)

> Automatic melody generation has been a long-time aspiration for both AI researchers and musicians. However, learning to generate euphonious melodies has turned out to be highly challenging. This paper introduces 1) a new variant of variational autoencoder (VAE), where the model structure is designed in a modularized manner in order to model polyphonic and dynamic music with domain knowledge, and 2) a hierarchical encoding/decoding strategy, which explicitly models the dependency between melodic features. The proposed framework is capable of generating distinct melodies that sounds natural, and the experiments for evaluating generated music clips show that the proposed model outperforms the baselines in human evaluation.

</details>


## 2018-11

<details>

<summary>2018-11-01 00:29:16 - PerceptionNet: A Deep Convolutional Neural Network for Late Sensor Fusion</summary>

- *Panagiotis Kasnesis, Charalampos Z. Patrikakis, Iakovos S. Venieris*

- `1811.00170v1` - [abs](http://arxiv.org/abs/1811.00170v1) - [pdf](http://arxiv.org/pdf/1811.00170v1)

> Human Activity Recognition (HAR) based on motion sensors has drawn a lot of attention over the last few years, since perceiving the human status enables context-aware applications to adapt their services on users' needs. However, motion sensor fusion and feature extraction have not reached their full potentials, remaining still an open issue. In this paper, we introduce PerceptionNet, a deep Convolutional Neural Network (CNN) that applies a late 2D convolution to multimodal time-series sensor data, in order to extract automatically efficient features for HAR. We evaluate our approach on two public available HAR datasets to demonstrate that the proposed model fuses effectively multimodal sensors and improves the performance of HAR. In particular, PerceptionNet surpasses the performance of state-of-the-art HAR methods based on: (i) features extracted from humans, (ii) deep CNNs exploiting early fusion approaches, and (iii) Long Short-Term Memory (LSTM), by an average accuracy of more than 3%.

</details>

<details>

<summary>2018-11-01 02:35:47 - BRIEF: Backward Reduction of CNNs with Information Flow Analysis</summary>

- *Yu-Hsun Lin, Chun-Nan Chou, Edward Y. Chang*

- `1807.05726v3` - [abs](http://arxiv.org/abs/1807.05726v3) - [pdf](http://arxiv.org/pdf/1807.05726v3)

> This paper proposes BRIEF, a backward reduction algorithm that explores compact CNN-model designs from the information flow perspective. This algorithm can remove substantial non-zero weighting parameters (redundant neural channels) of a network by considering its dynamic behavior, which traditional model-compaction techniques cannot achieve. With the aid of our proposed algorithm, we achieve significant model reduction on ResNet-34 in the ImageNet scale (32.3% reduction), which is 3X better than the previous result (10.8%). Even for highly optimized models such as SqueezeNet and MobileNet, we can achieve additional 10.81% and 37.56% reduction, respectively, with negligible performance degradation.

</details>

<details>

<summary>2018-11-01 03:04:09 - MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via Network Infused Embeddings</summary>

- *Hao Yu, Vivek Kulkarni, William Wang*

- `1811.00198v1` - [abs](http://arxiv.org/abs/1811.00198v1) - [pdf](http://arxiv.org/pdf/1811.00198v1)

> Many knowledge graph embedding methods operate on triples and are therefore implicitly limited by a very local view of the entire knowledge graph. We present a new framework MOHONE to effectively model higher order network effects in knowledge-graphs, thus enabling one to capture varying degrees of network connectivity (from the local to the global). Our framework is generic, explicitly models the network scale, and captures two different aspects of similarity in networks: (a) shared local neighborhood and (b) structural role-based similarity. First, we introduce methods that learn network representations of entities in the knowledge graph capturing these varied aspects of similarity. We then propose a fast, efficient method to incorporate the information captured by these network representations into existing knowledge graph embeddings. We show that our method consistently and significantly improves the performance on link prediction of several different knowledge-graph embedding methods including TRANSE, TRANSD, DISTMULT, and COMPLEX(by at least 4 points or 17% in some cases).

</details>

<details>

<summary>2018-11-01 03:50:45 - Multi-Label Robust Factorization Autoencoder and its Application in Predicting Drug-Drug Interactions</summary>

- *Xu Chu, Yang Lin, Jingyue Gao, Jiangtao Wang, Yasha Wang, Leye Wang*

- `1811.00208v1` - [abs](http://arxiv.org/abs/1811.00208v1) - [pdf](http://arxiv.org/pdf/1811.00208v1)

> Drug-drug interactions (DDIs) are a major cause of preventable hospitalizations and deaths. Predicting the occurrence of DDIs helps drug safety professionals allocate investigative resources and take appropriate regulatory action promptly. Traditional DDI prediction methods predict DDIs based on the similarity between drugs. Recently, researchers revealed that predictive performance can be improved by better modeling the interactions between drug pairs with bilinear forms. However, the shallow models leveraging bilinear forms suffer from limitations on capturing complicated nonlinear interactions between drug pairs. To this end, we propose Multi-Label Robust Factorization Autoencoder (abbreviated to MuLFA) for DDI prediction, which learns a representation of interactions between drug pairs and has the capability of characterizing complicated nonlinear interactions more precisely. Moreover, a novel loss called CuXCov is designed to effectively learn the parameters of MuLFA. Furthermore, the decoder is able to generate high-risk chemical structures of drug pairs for specific DDIs, assisting pharmacists to better understand the relationship between drug chemistry and DDI. Experimental results on real-world datasets demonstrate that MuLFA consistently outperforms state-of-the-art methods; particularly, it increases 21:3% predictive performance compared to the best baseline for top 50 frequent DDIs.We also illustrate various case studies to demonstrate the efficacy of the chemical structures generated by MuLFA in DDI diagnosis.

</details>

<details>

<summary>2018-11-01 05:14:18 - Attentive Tensor Product Learning</summary>

- *Qiuyuan Huang, Li Deng, Dapeng Wu, Chang Liu, Xiaodong He*

- `1802.07089v2` - [abs](http://arxiv.org/abs/1802.07089v2) - [pdf](http://arxiv.org/pdf/1802.07089v2)

> This paper proposes a new architecture - Attentive Tensor Product Learning (ATPL) - to represent grammatical structures in deep learning models. ATPL is a new architecture to bridge this gap by exploiting Tensor Product Representations (TPR), a structured neural-symbolic model developed in cognitive science, aiming to integrate deep learning with explicit language structures and rules. The key ideas of ATPL are: 1) unsupervised learning of role-unbinding vectors of words via TPR-based deep neural network; 2) employing attention modules to compute TPR; and 3) integration of TPR with typical deep learning architectures including Long Short-Term Memory (LSTM) and Feedforward Neural Network (FFNN). The novelty of our approach lies in its ability to extract the grammatical structure of a sentence by using role-unbinding vectors, which are obtained in an unsupervised manner. This ATPL approach is applied to 1) image captioning, 2) part of speech (POS) tagging, and 3) constituency parsing of a sentence. Experimental results demonstrate the effectiveness of the proposed approach.

</details>

<details>

<summary>2018-11-01 10:24:06 - Privacy Preserving Multi-Agent Planning with Provable Guarantees</summary>

- *Amos Beimel, Ronen I. Brafman*

- `1810.13354v2` - [abs](http://arxiv.org/abs/1810.13354v2) - [pdf](http://arxiv.org/pdf/1810.13354v2)

> In privacy-preserving multi-agent planning, a group of agents attempt to cooperatively solve a multi-agent planning problem while maintaining private their data and actions. Although much work was carried out in this area in past years, its theoretical foundations have not been fully worked out. Specifically, although algorithms with precise privacy guarantees exist, even their most efficient implementations are not fast enough on realistic instances, whereas for practical algorithms no meaningful privacy guarantees exist. Secure-MAFS, a variant of the multi-agent forward search algorithm (MAFS) is the only practical algorithm to attempt to offer more precise guarantees, but only in very limited settings and with proof sketches only. In this paper we formulate a precise notion of secure computation for search-based algorithms and prove that Secure MAFS has this property in all domains.

</details>

<details>

<summary>2018-11-01 11:39:49 - Taylor-based Optimized Recursive Extended Exponential Smoothed Neural Networks Forecasting Method</summary>

- *Emna Krichene, Wael Ouarda, Habib Chabchoub, Adel M. Alimi*

- `1811.00323v1` - [abs](http://arxiv.org/abs/1811.00323v1) - [pdf](http://arxiv.org/pdf/1811.00323v1)

> A newly introduced method called Taylor-based Optimized Recursive Extended Exponential Smoothed Neural Networks Forecasting method is applied and extended in this study to forecast numerical values. Unlike traditional forecasting techniques which forecast only future values, our proposed method provides a new extension to correct the predicted values which is done by forecasting the estimated error. Experimental results demonstrated that the proposed method has a high accuracy both in training and testing data and outperform the state-of-the-art RNN models on Mackey-Glass, NARMA, Lorenz and Henon map datasets.

</details>

<details>

<summary>2018-11-01 12:05:50 - Optimal Errors and Phase Transitions in High-Dimensional Generalized Linear Models</summary>

- *Jean Barbier, Florent Krzakala, Nicolas Macris, Léo Miolane, Lenka Zdeborová*

- `1708.03395v3` - [abs](http://arxiv.org/abs/1708.03395v3) - [pdf](http://arxiv.org/pdf/1708.03395v3)

> Generalized linear models (GLMs) arise in high-dimensional machine learning, statistics, communications and signal processing. In this paper we analyze GLMs when the data matrix is random, as relevant in problems such as compressed sensing, error-correcting codes or benchmark models in neural networks. We evaluate the mutual information (or "free entropy") from which we deduce the Bayes-optimal estimation and generalization errors. Our analysis applies to the high-dimensional limit where both the number of samples and the dimension are large and their ratio is fixed. Non-rigorous predictions for the optimal errors existed for special cases of GLMs, e.g. for the perceptron, in the field of statistical physics based on the so-called replica method. Our present paper rigorously establishes those decades old conjectures and brings forward their algorithmic interpretation in terms of performance of the generalized approximate message-passing algorithm. Furthermore, we tightly characterize, for many learning problems, regions of parameters for which this algorithm achieves the optimal performance, and locate the associated sharp phase transitions separating learnable and non-learnable regions. We believe that this random version of GLMs can serve as a challenging benchmark for multi-purpose algorithms. This paper is divided in two parts that can be read independently: The first part (main part) presents the model and main results, discusses some applications and sketches the main ideas of the proof. The second part (supplementary informations) is much more detailed and provides more examples as well as all the proofs.

</details>

<details>

<summary>2018-11-01 12:34:32 - AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing</summary>

- *Bettina Berendt*

- `1810.12847v2` - [abs](http://arxiv.org/abs/1810.12847v2) - [pdf](http://arxiv.org/pdf/1810.12847v2)

> Recently, many AI researchers and practitioners have embarked on research visions that involve doing AI for "Good". This is part of a general drive towards infusing AI research and practice with ethical thinking. One frequent theme in current ethical guidelines is the requirement that AI be good for all, or: contribute to the Common Good. But what is the Common Good, and is it enough to want to be good? Via four lead questions, I will illustrate challenges and pitfalls when determining, from an AI point of view, what the Common Good is and how it can be enhanced by AI. The questions are: What is the problem / What is a problem?, Who defines the problem?, What is the role of knowledge?, and What are important side effects and dynamics? The illustration will use an example from the domain of "AI for Social Good", more specifically "Data Science for Social Good". Even if the importance of these questions may be known at an abstract level, they do not get asked sufficiently in practice, as shown by an exploratory study of 99 contributions to recent conferences in the field. Turning these challenges and pitfalls into a positive recommendation, as a conclusion I will draw on another characteristic of computer-science thinking and practice to make these impediments visible and attenuate them: "attacks" as a method for improving design. This results in the proposal of ethics pen-testing as a method for helping AI designs to better contribute to the Common Good.

</details>

<details>

<summary>2018-11-01 12:47:40 - Exploiting Unintended Feature Leakage in Collaborative Learning</summary>

- *Luca Melis, Congzheng Song, Emiliano De Cristofaro, Vitaly Shmatikov*

- `1805.04049v3` - [abs](http://arxiv.org/abs/1805.04049v3) - [pdf](http://arxiv.org/pdf/1805.04049v3)

> Collaborative machine learning and related techniques such as federated learning allow multiple participants, each with his own training dataset, to build a joint model by training locally and periodically exchanging model updates. We demonstrate that these updates leak unintended information about participants' training data and develop passive and active inference attacks to exploit this leakage. First, we show that an adversarial participant can infer the presence of exact data points -- for example, specific locations -- in others' training data (i.e., membership inference). Then, we show how this adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. For example, he can infer when a specific person first appears in the photos used to train a binary gender classifier. We evaluate our attacks on a variety of tasks, datasets, and learning configurations, analyze their limitations, and discuss possible defenses.

</details>

<details>

<summary>2018-11-01 12:58:37 - Algorithms for Runtime Generation of Homogeneous Classes of Objects</summary>

- *Dmytro O. Terletskyi*

- `1811.07694v1` - [abs](http://arxiv.org/abs/1811.07694v1) - [pdf](http://arxiv.org/pdf/1811.07694v1)

> This paper contains analysis of main modern approaches to dynamic code generation, in particular generation of new classes of objects during program execution. The main attention was paid to universal exploiters of homogeneous classes of objects, which were proposed as a part of such knowledge representation model as object-oriented dynamic networks, as the tools for generation of new classes of objects in program runtime. As the result, algorithms for implementation of such universal exploiters of classes of objects as union, intersection, difference and symmetric difference were developed. These algorithms can be used knowledge-based intelligent systems, which are based on object-oriented dynamic networks, and they can be adapted for some object-oriented programming languages with powerful metaprogramming opportunities.

</details>

<details>

<summary>2018-11-01 15:13:49 - Improving the Modularity of AUV Control Systems using Behaviour Trees</summary>

- *Christopher Iliffe Sprague, Özer Özkahraman, Andrea Munafo, Rachel Marlow, Alexander Phillips, Petter Ögren*

- `1811.00426v1` - [abs](http://arxiv.org/abs/1811.00426v1) - [pdf](http://arxiv.org/pdf/1811.00426v1)

> In this paper, we show how behaviour trees (BTs) can be used to design modular, versatile, and robust control architectures for mission-critical systems. In particular, we show this in the context of autonomous underwater vehicles (AUVs). Robustness, in terms of system safety, is important since manual recovery of AUVs is often extremely difficult. Further more, versatility is important to be able to execute many different kinds of missions. Finally, modularity is needed to achieve a combination of robustness and versatility, as the complexity of a versatile systems needs to be encapsulated in modules, in order to create a simple overall structure enabling robustness analysis. The proposed design is illustrated using a typical AUV mission.

</details>

<details>

<summary>2018-11-01 15:18:22 - Automated Speed and Lane Change Decision Making using Deep Reinforcement Learning</summary>

- *Carl-Johan Hoel, Krister Wolff, Leo Laine*

- `1803.10056v2` - [abs](http://arxiv.org/abs/1803.10056v2) - [pdf](http://arxiv.org/pdf/1803.10056v2)

> This paper introduces a method, based on deep reinforcement learning, for automatically generating a general purpose decision making function. A Deep Q-Network agent was trained in a simulated environment to handle speed and lane change decisions for a truck-trailer combination. In a highway driving case, it is shown that the method produced an agent that matched or surpassed the performance of a commonly used reference model. To demonstrate the generality of the method, the exact same algorithm was also tested by training it for an overtaking case on a road with oncoming traffic. Furthermore, a novel way of applying a convolutional neural network to high level input that represents interchangeable objects is also introduced.

</details>

<details>

<summary>2018-11-01 16:24:50 - Hybrid Pruning: Thinner Sparse Networks for Fast Inference on Edge Devices</summary>

- *Xiaofan Xu, Mi Sun Park, Cormac Brick*

- `1811.00482v1` - [abs](http://arxiv.org/abs/1811.00482v1) - [pdf](http://arxiv.org/pdf/1811.00482v1)

> We introduce hybrid pruning which combines both coarse-grained channel and fine-grained weight pruning to reduce model size, computation and power demands with no to little loss in accuracy for enabling modern networks deployment on resource-constrained devices, such as always-on security cameras and drones. Additionally, to effectively perform channel pruning, we propose a fast sensitivity test that helps us quickly identify the sensitivity of within and across layers of a network to the output accuracy for target multiplier accumulators (MACs) or accuracy tolerance. Our experiment shows significantly better results on ResNet50 on ImageNet compared to existing work, even with an additional constraint of channels be hardware-friendly number.

</details>

<details>

<summary>2018-11-01 18:07:51 - Accelerated Labeling of Discrete Abstractions for Autonomous Driving Subject to LTL Specifications</summary>

- *Brian Paden, Peng Liu, Schuyler Cullen*

- `1810.02612v2` - [abs](http://arxiv.org/abs/1810.02612v2) - [pdf](http://arxiv.org/pdf/1810.02612v2)

> Linear temporal logic and automaton-based run-time verification provide a powerful framework for designing task and motion planning algorithms for autonomous agents. The drawback to this approach is the computational cost of operating on high resolution discrete abstractions of continuous dynamical systems. In particular, the computational bottleneck that arises is converting perceived environment variables into a labeling function on the states of a Kripke structure or analogously the transitions of a labeled transition system. This paper presents the design and empirical evaluation of an approach to constructing the labeling function that exposes a large degree of parallelism in the operation as well as efficient memory access patterns. The approach is implemented on a commodity GPU and empirical results demonstrate the efficacy of the labeling technique for real-time planning and decision-making.

</details>

<details>

<summary>2018-11-01 19:06:35 - Existence versus Exploitation: The Opacity of Backbones and Backdoors Under a Weak Assumption</summary>

- *Lane A. Hemaspaandra, David E. Narváez*

- `1706.04582v8` - [abs](http://arxiv.org/abs/1706.04582v8) - [pdf](http://arxiv.org/pdf/1706.04582v8)

> Backdoors and backbones of Boolean formulas are hidden structural properties. A natural goal, already in part realized, is that solver algorithms seek to obtain substantially better performance by exploiting these structures.   However, the present paper is not intended to improve the performance of SAT solvers, but rather is a cautionary paper. In particular, the theme of this paper is that there is a potential chasm between the existence of such structures in the Boolean formula and being able to effectively exploit them. This does not mean that these structures are not useful to solvers. It does mean that one must be very careful not to assume that it is computationally easy to go from the existence of a structure to being able to get one's hands on it and/or being able to exploit the structure.   For example, in this paper we show that, under the assumption that P $\neq$ NP, there are easily recognizable families of Boolean formulas with strong backdoors that are easy to find, yet for which it is hard (in fact, NP-complete) to determine whether the formulas are satisfiable. We also show that, also under the assumption P $\neq$ NP, there are easily recognizable sets of Boolean formulas for which it is hard (in fact, NP-complete) to determine whether they have a large backbone.

</details>

<details>

<summary>2018-11-01 19:59:06 - Exploring Semantic Incrementality with Dynamic Syntax and Vector Space Semantics</summary>

- *Mehrnoosh Sadrzadeh, Matthew Purver, Julian Hough, Ruth Kempson*

- `1811.00614v1` - [abs](http://arxiv.org/abs/1811.00614v1) - [pdf](http://arxiv.org/pdf/1811.00614v1)

> One of the fundamental requirements for models of semantic processing in dialogue is incrementality: a model must reflect how people interpret and generate language at least on a word-by-word basis, and handle phenomena such as fragments, incomplete and jointly-produced utterances. We show that the incremental word-by-word parsing process of Dynamic Syntax (DS) can be assigned a compositional distributional semantics, with the composition operator of DS corresponding to the general operation of tensor contraction from multilinear algebra. We provide abstract semantic decorations for the nodes of DS trees, in terms of vectors, tensors, and sums thereof; using the latter to model the underspecified elements crucial to assigning partial representations during incremental processing. As a working example, we give an instantiation of this theory using plausibility tensors of compositional distributional semantics, and show how our framework can incrementally assign a semantic plausibility measure as it parses phrases and sentences.

</details>

<details>

<summary>2018-11-01 20:14:49 - Efficient Online Hyperparameter Optimization for Kernel Ridge Regression with Applications to Traffic Time Series Prediction</summary>

- *Hongyuan Zhan, Gabriel Gomes, Xiaoye S. Li, Kamesh Madduri, Kesheng Wu*

- `1811.00620v1` - [abs](http://arxiv.org/abs/1811.00620v1) - [pdf](http://arxiv.org/pdf/1811.00620v1)

> Computational efficiency is an important consideration for deploying machine learning models for time series prediction in an online setting. Machine learning algorithms adjust model parameters automatically based on the data, but often require users to set additional parameters, known as hyperparameters. Hyperparameters can significantly impact prediction accuracy. Traffic measurements, typically collected online by sensors, are serially correlated. Moreover, the data distribution may change gradually. A typical adaptation strategy is periodically re-tuning the model hyperparameters, at the cost of computational burden. In this work, we present an efficient and principled online hyperparameter optimization algorithm for Kernel Ridge regression applied to traffic prediction problems. In tests with real traffic measurement data, our approach requires as little as one-seventh of the computation time of other tuning methods, while achieving better or similar prediction accuracy.

</details>

<details>

<summary>2018-11-01 21:38:18 - Online Embedding Compression for Text Classification using Low Rank Matrix Factorization</summary>

- *Anish Acharya, Rahul Goel, Angeliki Metallinou, Inderjit Dhillon*

- `1811.00641v1` - [abs](http://arxiv.org/abs/1811.00641v1) - [pdf](http://arxiv.org/pdf/1811.00641v1)

> Deep learning models have become state of the art for natural language processing (NLP) tasks, however deploying these models in production system poses significant memory constraints. Existing compression methods are either lossy or introduce significant latency. We propose a compression method that leverages low rank matrix factorization during training,to compress the word embedding layer which represents the size bottleneck for most NLP models. Our models are trained, compressed and then further re-trained on the downstream task to recover accuracy while maintaining the reduced size. Empirically, we show that the proposed method can achieve 90% compression with minimal impact in accuracy for sentence classification tasks, and outperforms alternative methods like fixed-point quantization or offline word embedding compression. We also analyze the inference time and storage space for our method through FLOP calculations, showing that we can compress DNN models by a configurable ratio and regain accuracy loss without introducing additional latency compared to fixed point quantization. Finally, we introduce a novel learning rate schedule, the Cyclically Annealed Learning Rate (CALR), which we empirically demonstrate to outperform other popular adaptive learning rate algorithms on a sentence classification benchmark.

</details>

<details>

<summary>2018-11-01 21:48:19 - Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction</summary>

- *Roei Herzig, Moshiko Raboh, Gal Chechik, Jonathan Berant, Amir Globerson*

- `1802.05451v4` - [abs](http://arxiv.org/abs/1802.05451v4) - [pdf](http://arxiv.org/pdf/1802.05451v4)

> Machine understanding of complex images is a key goal of artificial intelligence. One challenge underlying this task is that visual scenes contain multiple inter-related objects, and that global context plays an important role in interpreting the scene. A natural modeling framework for capturing such effects is structured prediction, which optimizes over complex labels, while modeling within-label interactions. However, it is unclear what principles should guide the design of a structured prediction model that utilizes the power of deep learning components. Here we propose a design principle for such architectures that follows from a natural requirement of permutation invariance. We prove a necessary and sufficient characterization for architectures that follow this invariance, and discuss its implication on model design. Finally, we show that the resulting model achieves new state of the art results on the Visual Genome scene graph labeling benchmark, outperforming all recent approaches.

</details>

<details>

<summary>2018-11-01 23:13:38 - On Meta-Learning for Dynamic Ensemble Selection</summary>

- *Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti*

- `1811.01743v1` - [abs](http://arxiv.org/abs/1811.01743v1) - [pdf](http://arxiv.org/pdf/1811.01743v1)

> In this paper, we propose a novel dynamic ensemble selection framework using meta-learning. The framework is divided into three steps. In the first step, the pool of classifiers is generated from the training data. The second phase is responsible to extract the meta-features and train the meta-classifier. Five distinct sets of meta-features are proposed, each one corresponding to a different criterion to measure the level of competence of a classifier for the classification of a given query sample. The meta-features are computed using the training data and used to train a meta-classifier that is able to predict whether or not a base classifier from the pool is competent enough to classify an input instance. Three different training scenarios for the training of the meta-classifier are considered: problem-dependent, problem-independent and hybrid. Experimental results show that the problem-dependent scenario provides the best result. In addition, the performance of the problem-dependent scenario is strongly correlated with the recognition rate of the system. A comparison with state-of-the-art techniques shows that the proposed-dependent approach outperforms current dynamic ensemble selection techniques.

</details>

<details>

<summary>2018-11-01 23:28:01 - META-DES.H: a dynamic ensemble selection technique using meta-learning and a dynamic weighting approach</summary>

- *Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti*

- `1811.01742v1` - [abs](http://arxiv.org/abs/1811.01742v1) - [pdf](http://arxiv.org/pdf/1811.01742v1)

> In Dynamic Ensemble Selection (DES) techniques, only the most competent classifiers are selected to classify a given query sample. Hence, the key issue in DES is how to estimate the competence of each classifier in a pool to select the most competent ones. In order to deal with this issue, we proposed a novel dynamic ensemble selection framework using meta-learning, called META-DES. The framework is divided into three steps. In the first step, the pool of classifiers is generated from the training data. In the second phase the meta-features are computed using the training data and used to train a meta-classifier that is able to predict whether or not a base classifier from the pool is competent enough to classify an input instance. In this paper, we propose improvements to the training and generalization phase of the META-DES framework. In the training phase, we evaluate four different algorithms for the training of the meta-classifier. For the generalization phase, three combination approaches are evaluated: Dynamic selection, where only the classifiers that attain a certain competence level are selected; Dynamic weighting, where the meta-classifier estimates the competence of each classifier in the pool, and the outputs of all classifiers in the pool are weighted based on their level of competence; and a hybrid approach, in which first an ensemble with the most competent classifiers is selected, after which the weights of the selected classifiers are estimated in order to be used in a weighted majority voting scheme. Experiments are carried out on 30 classification datasets. Experimental results demonstrate that the changes proposed in this paper significantly improve the recognition accuracy of the system in several datasets.

</details>

<details>

<summary>2018-11-02 01:02:49 - Zero-Shot Transfer VQA Dataset</summary>

- *Yuanpeng Li, Yi Yang, Jianyu Wang, Wei Xu*

- `1811.00692v1` - [abs](http://arxiv.org/abs/1811.00692v1) - [pdf](http://arxiv.org/pdf/1811.00692v1)

> Acquiring a large vocabulary is an important aspect of human intelligence. Onecommon approach for human to populating vocabulary is to learn words duringreading or listening, and then use them in writing or speaking. This ability totransfer from input to output is natural for human, but it is difficult for machines.Human spontaneously performs this knowledge transfer in complicated multimodaltasks, such as Visual Question Answering (VQA). In order to approach human-levelArtificial Intelligence, we hope to equip machines with such ability. Therefore, toaccelerate this research, we propose a newzero-shot transfer VQA(ZST-VQA)dataset by reorganizing the existing VQA v1.0 dataset in the way that duringtraining, some words appear only in one module (i.e. questions) but not in theother (i.e. answers). In this setting, an intelligent model should understand andlearn the concepts from one module (i.e. questions), and at test time, transfer themto the other (i.e. predict the concepts as answers). We conduct evaluation on thisnew dataset using three existing state-of-the-art VQA neural models. Experimentalresults show a significant drop in performance on this dataset, indicating existingmethods do not address the zero-shot transfer problem. Besides, our analysis findsthat this may be caused by the implicit bias learned during training.

</details>

<details>

<summary>2018-11-02 03:47:13 - CariGANs: Unpaired Photo-to-Caricature Translation</summary>

- *Kaidi Cao, Jing Liao, Lu Yuan*

- `1811.00222v2` - [abs](http://arxiv.org/abs/1811.00222v2) - [pdf](http://arxiv.org/pdf/1811.00222v2)

> Facial caricature is an art form of drawing faces in an exaggerated way to convey humor or sarcasm. In this paper, we propose the first Generative Adversarial Network (GAN) for unpaired photo-to-caricature translation, which we call "CariGANs". It explicitly models geometric exaggeration and appearance stylization using two components: CariGeoGAN, which only models the geometry-to-geometry transformation from face photos to caricatures, and CariStyGAN, which transfers the style appearance from caricatures to face photos without any geometry deformation. In this way, a difficult cross-domain translation problem is decoupled into two easier tasks. The perceptual study shows that caricatures generated by our CariGANs are closer to the hand-drawn ones, and at the same time better persevere the identity, compared to state-of-the-art methods. Moreover, our CariGANs allow users to control the shape exaggeration degree and change the color/texture style by tuning the parameters or giving an example caricature.

</details>

<details>

<summary>2018-11-02 05:08:40 - Efficient Metropolitan Traffic Prediction Based on Graph Recurrent Neural Network</summary>

- *Xiaoyu Wang, Cailian Chen, Yang Min, Jianping He, Bo Yang, Yang Zhang*

- `1811.00740v1` - [abs](http://arxiv.org/abs/1811.00740v1) - [pdf](http://arxiv.org/pdf/1811.00740v1)

> Traffic prediction is a fundamental and vital task in Intelligence Transportation System (ITS), but it is very challenging to get high accuracy while containing low computational complexity due to the spatiotemporal characteristics of traffic flow, especially under the metropolitan circumstances. In this work, a new topological framework, called Linkage Network, is proposed to model the road networks and present the propagation patterns of traffic flow. Based on the Linkage Network model, a novel online predictor, named Graph Recurrent Neural Network (GRNN), is designed to learn the propagation patterns in the graph. It could simultaneously predict traffic flow for all road segments based on the information gathered from the whole graph, which thus reduces the computational complexity significantly from O(nm) to O(n+m), while keeping the high accuracy. Moreover, it can also predict the variations of traffic trends. Experiments based on real-world data demonstrate that the proposed method outperforms the existing prediction methods.

</details>

<details>

<summary>2018-11-02 05:50:39 - Confiding in and Listening to Virtual Agents: The Effect of Personality</summary>

- *Jingyi Li, Michelle X. Zhou, Huahai Yang, Gloria Mark*

- `1811.00746v1` - [abs](http://arxiv.org/abs/1811.00746v1) - [pdf](http://arxiv.org/pdf/1811.00746v1)

> We present an intelligent virtual interviewer that engages with a user in a text-based conversation and automatically infers the user's psychological traits, such as personality. We investigate how the personality of a virtual interviewer influences a user's behavior from two perspectives: the user's willingness to confide in, and listen to, a virtual interviewer. We have developed two virtual interviewers with distinct personalities and deployed them in a real-world recruiting event. We present findings from completed interviews with 316 actual job applicants. Notably, users are more willing to confide in and listen to a virtual interviewer with a serious, assertive personality. Moreover, users' personality traits, inferred from their chat text, influence their perception of a virtual interviewer, and their willingness to confide in and listen to a virtual interviewer. Finally, we discuss the implications of our work on building hyper-personalized, intelligent agents based on user traits.

</details>

<details>

<summary>2018-11-02 06:36:13 - A General Framework for Multi-fidelity Bayesian Optimization with Gaussian Processes</summary>

- *Jialin Song, Yuxin Chen, Yisong Yue*

- `1811.00755v1` - [abs](http://arxiv.org/abs/1811.00755v1) - [pdf](http://arxiv.org/pdf/1811.00755v1)

> How can we efficiently gather information to optimize an unknown function, when presented with multiple, mutually dependent information sources with different costs? For example, when optimizing a robotic system, intelligently trading off computer simulations and real robot testings can lead to significant savings. Existing methods, such as multi-fidelity GP-UCB or Entropy Search-based approaches, either make simplistic assumptions on the interaction among different fidelities or use simple heuristics that lack theoretical guarantees. In this paper, we study multi-fidelity Bayesian optimization with complex structural dependencies among multiple outputs, and propose MF-MI-Greedy, a principled algorithmic framework for addressing this problem. In particular, we model different fidelities using additive Gaussian processes based on shared latent structures with the target function. Then we use cost-sensitive mutual information gain for efficient Bayesian global optimization. We propose a simple notion of regret which incorporates the cost of different fidelities, and prove that MF-MI-Greedy achieves low regret. We demonstrate the strong empirical performance of our algorithm on both synthetic and real-world datasets.

</details>

<details>

<summary>2018-11-02 07:27:51 - Should Algorithms for Random SAT and Max-SAT be Different?</summary>

- *Sixue Liu, Gerard de Melo*

- `1610.00442v2` - [abs](http://arxiv.org/abs/1610.00442v2) - [pdf](http://arxiv.org/pdf/1610.00442v2)

> We analyze to what extent the random SAT and Max-SAT problems differ in their properties. Our findings suggest that for random $k$-CNF with ratio in a certain range, Max-SAT can be solved by any SAT algorithm with subexponential slowdown, while for formulae with ratios greater than some constant, algorithms under the random walk framework require substantially different heuristics. In light of these results, we propose a novel probabilistic approach for random Max-SAT called ProMS. Experimental results illustrate that ProMS outperforms many state-of-the-art local search solvers on random Max-SAT benchmarks.

</details>

<details>

<summary>2018-11-02 09:49:18 - Automated Theorem Proving in Intuitionistic Propositional Logic by Deep Reinforcement Learning</summary>

- *Mitsuru Kusumoto, Keisuke Yahata, Masahiro Sakai*

- `1811.00796v1` - [abs](http://arxiv.org/abs/1811.00796v1) - [pdf](http://arxiv.org/pdf/1811.00796v1)

> The problem-solving in automated theorem proving (ATP) can be interpreted as a search problem where the prover constructs a proof tree step by step. In this paper, we propose a deep reinforcement learning algorithm for proof search in intuitionistic propositional logic. The most significant challenge in the application of deep learning to the ATP is the absence of large, public theorem database. We, however, overcame this issue by applying a novel data augmentation procedure at each iteration of the reinforcement learning. We also improve the efficiency of the algorithm by representing the syntactic structure of formulas by a novel compact graph representation. Using the large volume of augmented data, we train highly accurate graph neural networks that approximate the value function for the set of the syntactic structures of formulas. Our method is also cost-efficient in terms of computational time. We will show that our prover outperforms Coq's $\texttt{tauto}$ tactic, a prover based on human-engineered heuristics. Within the specified time limit, our prover solved 84% of the theorems in a benchmark library, while $\texttt{tauto}$ was able to solve only 52%.

</details>

<details>

<summary>2018-11-02 09:54:35 - eLIAN: Enhanced Algorithm for Angle-constrained Path Finding</summary>

- *Anton Andreychuk, Natalia Soboleva, Konstantin Yakovlev*

- `1811.00797v1` - [abs](http://arxiv.org/abs/1811.00797v1) - [pdf](http://arxiv.org/pdf/1811.00797v1)

> Problem of finding 2D paths of special shape, e.g. paths comprised of line segments having the property that the angle between any two consecutive segments does not exceed the predefined threshold, is considered in the paper. This problem is harder to solve than the one when shortest paths of any shape are sought, since the planer's search space is substantially bigger as multiple search nodes corresponding to the same location need to be considered. One way to reduce the search effort is to fix the length of the path's segment and to prune the nodes that violate the imposed constraint. This leads to incompleteness and to the sensitivity of the 's performance to chosen parameter value. In this work we introduce a novel technique that reduces this sensitivity by automatically adjusting the length of the path's segment on-the-fly, e.g. during the search. Embedding this technique into the known grid-based angle-constrained path finding algorithm - LIAN, leads to notable increase of the planner's effectiveness, e.g. success rate, while keeping efficiency, e.g. runtime, overhead at reasonable level. Experimental evaluation shows that LIAN with the suggested enhancements, dubbed eLIAN, solves up to 20\% of tasks more compared to the predecessor. Meanwhile, the solution quality of eLIAN is nearly the same as the one of LIAN.

</details>

<details>

<summary>2018-11-02 10:56:03 - Optimal DNN Primitive Selection with Partitioned Boolean Quadratic Programming</summary>

- *Andrew Anderson, David Gregg*

- `1710.01079v2` - [abs](http://arxiv.org/abs/1710.01079v2) - [pdf](http://arxiv.org/pdf/1710.01079v2)

> Deep Neural Networks (DNNs) require very large amounts of computation both for training and for inference when deployed in the field. Many different algorithms have been proposed to implement the most computationally expensive layers of DNNs. Further, each of these algorithms has a large number of variants, which offer different trade-offs of parallelism, data locality, memory footprint, and execution time. In addition, specific algorithms operate much more efficiently on specialized data layouts and formats.   We state the problem of optimal primitive selection in the presence of data format transformations, and show that it is NP-hard by demonstrating an embedding in the Partitioned Boolean Quadratic Assignment problem (PBQP).   We propose an analytic solution via a PBQP solver, and evaluate our approach experimentally by optimizing several popular DNNs using a library of more than 70 DNN primitives, on an embedded platform and a general purpose platform. We show experimentally that significant gains are possible versus the state of the art vendor libraries by using a principled analytic solution to the problem of layout selection in the presence of data format transformations.

</details>

<details>

<summary>2018-11-02 16:15:14 - Dantzig Selector with an Approximately Optimal Denoising Matrix and its Application to Reinforcement Learning</summary>

- *Bo Liu, Luwan Zhang, Ji Liu*

- `1811.00958v1` - [abs](http://arxiv.org/abs/1811.00958v1) - [pdf](http://arxiv.org/pdf/1811.00958v1)

> Dantzig Selector (DS) is widely used in compressed sensing and sparse learning for feature selection and sparse signal recovery. Since the DS formulation is essentially a linear programming optimization, many existing linear programming solvers can be simply applied for scaling up. The DS formulation can be explained as a basis pursuit denoising problem, wherein the data matrix (or measurement matrix) is employed as the denoising matrix to eliminate the observation noise. However, we notice that the data matrix may not be the optimal denoising matrix, as shown by a simple counter-example. This motivates us to pursue a better denoising matrix for defining a general DS formulation. We first define the optimal denoising matrix through a minimax optimization, which turns out to be an NPhard problem. To make the problem computationally tractable, we propose a novel algorithm, termed as Optimal Denoising Dantzig Selector (ODDS), to approximately estimate the optimal denoising matrix. Empirical experiments validate the proposed method. Finally, a novel sparse reinforcement learning algorithm is formulated by extending the proposed ODDS algorithm to temporal difference learning, and empirical experimental results demonstrate to outperform the conventional vanilla DS-TD algorithm.

</details>

<details>

<summary>2018-11-02 17:19:02 - Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models</summary>

- *Kurtland Chua, Roberto Calandra, Rowan McAllister, Sergey Levine*

- `1805.12114v2` - [abs](http://arxiv.org/abs/1805.12114v2) - [pdf](http://arxiv.org/pdf/1805.12114v2)

> Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).

</details>

<details>

<summary>2018-11-02 17:37:39 - On Evaluating the Generalization of LSTM Models in Formal Languages</summary>

- *Mirac Suzgun, Yonatan Belinkov, Stuart M. Shieber*

- `1811.01001v1` - [abs](http://arxiv.org/abs/1811.01001v1) - [pdf](http://arxiv.org/pdf/1811.01001v1)

> Recurrent Neural Networks (RNNs) are theoretically Turing-complete and established themselves as a dominant model for language processing. Yet, there still remains an uncertainty regarding their language learning capabilities. In this paper, we empirically evaluate the inductive learning capabilities of Long Short-Term Memory networks, a popular extension of simple RNNs, to learn simple formal languages, in particular $a^nb^n$, $a^nb^nc^n$, and $a^nb^nc^nd^n$. We investigate the influence of various aspects of learning, such as training data regimes and model capacity, on the generalization to unobserved samples. We find striking differences in model performances under different training settings and highlight the need for careful analysis and assessment when making claims about the learning capabilities of neural network models.

</details>

<details>

<summary>2018-11-02 17:56:23 - Unsupervised Learning of Interpretable Dialog Models</summary>

- *Dhiraj Madan, Dinesh Raghu, Gaurav Pandey, Sachindra Joshi*

- `1811.01012v1` - [abs](http://arxiv.org/abs/1811.01012v1) - [pdf](http://arxiv.org/pdf/1811.01012v1)

> Recently several deep learning based models have been proposed for end-to-end learning of dialogs. While these models can be trained from data without the need for any additional annotations, it is hard to interpret them. On the other hand, there exist traditional state based dialog systems, where the states of the dialog are discrete and hence easy to interpret. However these states need to be handcrafted and annotated in the data. To achieve the best of both worlds, we propose Latent State Tracking Network (LSTN) using which we learn an interpretable model in unsupervised manner. The model defines a discrete latent variable at each turn of the conversation which can take a finite set of values. Since these discrete variables are not present in the training data, we use EM algorithm to train our model in unsupervised manner. In the experiments, we show that LSTN can help achieve interpretability in dialog models without much decrease in performance compared to end-to-end approaches.

</details>

<details>

<summary>2018-11-02 20:55:20 - Ischemic Stroke Lesion Segmentation in CT Perfusion Scans using Pyramid Pooling and Focal Loss</summary>

- *S. Mazdak Abulnaga, Jonathan Rubin*

- `1811.01085v1` - [abs](http://arxiv.org/abs/1811.01085v1) - [pdf](http://arxiv.org/pdf/1811.01085v1)

> We present a fully convolutional neural network for segmenting ischemic stroke lesions in CT perfusion images for the ISLES 2018 challenge. Treatment of stroke is time sensitive and current standards for lesion identification require manual segmentation, a time consuming and challenging process. Automatic segmentation methods present the possibility of accurately identifying lesions and improving treatment planning. Our model is based on the PSPNet, a network architecture that makes use of pyramid pooling to provide global and local contextual information. To learn the varying shapes of the lesions, we train our network using focal loss, a loss function designed for the network to focus on learning the more difficult samples. We compare our model to networks trained using the U-Net and V-Net architectures. Our approach demonstrates effective performance in lesion segmentation and ranked among the top performers at the challenge conclusion.

</details>

<details>

<summary>2018-11-02 22:02:37 - Data2Vis: Automatic Generation of Data Visualizations Using Sequence to Sequence Recurrent Neural Networks</summary>

- *Victor Dibia, Çağatay Demiralp*

- `1804.03126v3` - [abs](http://arxiv.org/abs/1804.03126v3) - [pdf](http://arxiv.org/pdf/1804.03126v3)

> Rapidly creating effective visualizations using expressive grammars is challenging for users who have limited time and limited skills in statistics and data visualization. Even high-level, dedicated visualization tools often require users to manually select among data attributes, decide which transformations to apply, and specify mappings between visual encoding variables and raw or transformed attributes.   In this paper we introduce Data2Vis, a neural translation model for automatically generating visualizations from given datasets. We formulate visualization generation as a sequence to sequence translation problem where data specifications are mapped to visualization specifications in a declarative language (Vega-Lite). To this end, we train a multilayered attention-based recurrent neural network (RNN) with long short-term memory (LSTM) units on a corpus of visualization specifications.   Qualitative results show that our model learns the vocabulary and syntax for a valid visualization specification, appropriate transformations (count, bins, mean) and how to use common data selection patterns that occur within data visualizations. Data2Vis generates visualizations that are comparable to manually-created visualizations in a fraction of the time, with potential to learn more complex visualization strategies at scale.

</details>

<details>

<summary>2018-11-02 22:02:40 - Machine learning architectures to predict motion sickness using a Virtual Reality rollercoaster simulation tool</summary>

- *Stefan Hell, Vasileios Argyriou*

- `1811.01106v1` - [abs](http://arxiv.org/abs/1811.01106v1) - [pdf](http://arxiv.org/pdf/1811.01106v1)

> Virtual Reality (VR) can cause an unprecedented immersion and feeling of presence yet a lot of users experience motion sickness when moving through a virtual environment. Rollercoaster rides are popular in Virtual Reality but have to be well designed to limit the amount of nausea the user may feel. This paper describes a novel framework to get automated ratings on motion sickness using Neural Networks. An application that lets users create rollercoasters directly in VR, share them with other users and ride and rate them is used to gather real-time data related to the in-game behaviour of the player, the track itself and users' ratings based on a Simulator Sickness Questionnaire (SSQ) integrated into the application. Machine learning architectures based on deep neural networks are trained using this data aiming to predict motion sickness levels. While this paper focuses on rollercoasters this framework could help to rate any VR application on motion sickness and intensity that involves camera movement. A new well defined dataset is provided in this paper and the performance of the proposed architectures are evaluated in a comparative study.

</details>

<details>

<summary>2018-11-02 22:59:31 - Learning to Rank Query Graphs for Complex Question Answering over Knowledge Graphs</summary>

- *Gaurav Maheshwari, Priyansh Trivedi, Denis Lukovnikov, Nilesh Chakraborty, Asja Fischer, Jens Lehmann*

- `1811.01118v1` - [abs](http://arxiv.org/abs/1811.01118v1) - [pdf](http://arxiv.org/pdf/1811.01118v1)

> In this paper, we conduct an empirical investigation of neural query graph ranking approaches for the task of complex question answering over knowledge graphs. We experiment with six different ranking models and propose a novel self-attention based slot matching model which exploits the inherent structure of query graphs, our logical form of choice. Our proposed model generally outperforms the other models on two QA datasets over the DBpedia knowledge graph, evaluated in different settings. In addition, we show that transfer learning from the larger of those QA datasets to the smaller dataset yields substantial improvements, effectively offsetting the general lack of training data.

</details>

<details>

<summary>2018-11-02 23:18:03 - Topological Approaches to Deep Learning</summary>

- *Gunnar Carlsson, Rickard Brüel Gabrielsson*

- `1811.01122v1` - [abs](http://arxiv.org/abs/1811.01122v1) - [pdf](http://arxiv.org/pdf/1811.01122v1)

> We perform topological data analysis on the internal states of convolutional deep neural networks to develop an understanding of the computations that they perform. We apply this understanding to modify the computations so as to (a) speed up computations and (b) improve generalization from one data set of digits to another. One byproduct of the analysis is the production of a geometry on new sets of features on data sets of images, and use this observation to develop a methodology for constructing analogues of CNN's for many other geometries, including the graph structures constructed by topological data analysis.

</details>

<details>

<summary>2018-11-03 00:19:36 - Non-Asymptotic Uniform Rates of Consistency for k-NN Regression</summary>

- *Heinrich Jiang*

- `1707.06261v2` - [abs](http://arxiv.org/abs/1707.06261v2) - [pdf](http://arxiv.org/pdf/1707.06261v2)

> We derive high-probability finite-sample uniform rates of consistency for $k$-NN regression that are optimal up to logarithmic factors under mild assumptions. We moreover show that $k$-NN regression adapts to an unknown lower intrinsic dimension automatically. We then apply the $k$-NN regression rates to establish new results about estimating the level sets and global maxima of a function from noisy observations.

</details>

<details>

<summary>2018-11-03 01:29:29 - DAGs with NO TEARS: Continuous Optimization for Structure Learning</summary>

- *Xun Zheng, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing*

- `1803.01422v2` - [abs](http://arxiv.org/abs/1803.01422v2) - [pdf](http://arxiv.org/pdf/1803.01422v2)

> Estimating the structure of directed acyclic graphs (DAGs, also known as Bayesian networks) is a challenging problem since the search space of DAGs is combinatorial and scales superexponentially with the number of nodes. Existing approaches rely on various local heuristics for enforcing the acyclicity constraint. In this paper, we introduce a fundamentally different strategy: We formulate the structure learning problem as a purely \emph{continuous} optimization problem over real matrices that avoids this combinatorial constraint entirely. This is achieved by a novel characterization of acyclicity that is not only smooth but also exact. The resulting problem can be efficiently solved by standard numerical algorithms, which also makes implementation effortless. The proposed method outperforms existing ones, without imposing any structural assumptions on the graph such as bounded treewidth or in-degree. Code implementing the proposed algorithm is open-source and publicly available at https://github.com/xunzheng/notears.

</details>

<details>

<summary>2018-11-03 03:16:11 - SafeRoute: Learning to Navigate Streets Safely in an Urban Environment</summary>

- *Sharon Levy, Wenhan Xiong, Elizabeth Belding, William Yang Wang*

- `1811.01147v1` - [abs](http://arxiv.org/abs/1811.01147v1) - [pdf](http://arxiv.org/pdf/1811.01147v1)

> Recent studies show that 85% of women have changed their traveled route to avoid harassment and assault. Despite this, current mapping tools do not empower users with information to take charge of their personal safety. We propose SafeRoute, a novel solution to the problem of navigating cities and avoiding street harassment and crime. Unlike other street navigation applications, SafeRoute introduces a new type of path generation via deep reinforcement learning. This enables us to successfully optimize for multi-criteria path-finding and incorporate representation learning within our framework. Our agent learns to pick favorable streets to create a safe and short path with a reward function that incorporates safety and efficiency. Given access to recent crime reports in many urban cities, we train our model for experiments in Boston, New York, and San Francisco. We test our model on areas of these cities, specifically the populated downtown regions where tourists and those unfamiliar with the streets walk. We evaluate SafeRoute and successfully improve over state-of-the-art methods by up to 17% in local average distance from crimes while decreasing path length by up to 7%.

</details>

<details>

<summary>2018-11-03 09:39:02 - Active Uncertainty Calibration in Bayesian ODE Solvers</summary>

- *Hans Kersting, Philipp Hennig*

- `1605.03364v3` - [abs](http://arxiv.org/abs/1605.03364v3) - [pdf](http://arxiv.org/pdf/1605.03364v3)

> There is resurging interest, in statistics and machine learning, in solvers for ordinary differential equations (ODEs) that return probability measures instead of point estimates. Recently, Conrad et al. introduced a sampling-based class of methods that are 'well-calibrated' in a specific sense. But the computational cost of these methods is significantly above that of classic methods. On the other hand, Schober et al. pointed out a precise connection between classic Runge-Kutta ODE solvers and Gaussian filters, which gives only a rough probabilistic calibration, but at negligible cost overhead. By formulating the solution of ODEs as approximate inference in linear Gaussian SDEs, we investigate a range of probabilistic ODE solvers, that bridge the trade-off between computational cost and probabilistic calibration, and identify the inaccurate gradient measurement as the crucial source of uncertainty. We propose the novel filtering-based method Bayesian Quadrature filtering (BQF) which uses Bayesian quadrature to actively learn the imprecision in the gradient measurement by collecting multiple gradient evaluations.

</details>

<details>

<summary>2018-11-03 14:04:35 - Sharp worst-case evaluation complexity bounds for arbitrary-order nonconvex optimization with inexpensive constraints</summary>

- *Coralia Cartis, Nick I. M. Gould, Philippe L. Toint*

- `1811.01220v1` - [abs](http://arxiv.org/abs/1811.01220v1) - [pdf](http://arxiv.org/pdf/1811.01220v1)

> We provide sharp worst-case evaluation complexity bounds for nonconvex minimization problems with general inexpensive constraints, i.e.\ problems where the cost of evaluating/enforcing of the (possibly nonconvex or even disconnected) constraints, if any, is negligible compared to that of evaluating the objective function. These bounds unify, extend or improve all known upper and lower complexity bounds for unconstrained and convexly-constrained problems. It is shown that, given an accuracy level $\epsilon$, a degree of highest available Lipschitz continuous derivatives $p$ and a desired optimality order $q$ between one and $p$, a conceptual regularization algorithm requires no more than $O(\epsilon^{-\frac{p+1}{p-q+1}})$ evaluations of the objective function and its derivatives to compute a suitably approximate $q$-th order minimizer. With an appropriate choice of the regularization, a similar result also holds if the $p$-th derivative is merely H\"older rather than Lipschitz continuous. We provide an example that shows that the above complexity bound is sharp for unconstrained and a wide class of constrained problems, we also give reasons for the optimality of regularization methods from a worst-case complexity point of view, within a large class of algorithms that use the same derivative information.

</details>

<details>

<summary>2018-11-03 15:50:27 - Relation Mention Extraction from Noisy Data with Hierarchical Reinforcement Learning</summary>

- *Jun Feng, Minlie Huang, Yijie Zhang, Yang Yang, Xiaoyan Zhu*

- `1811.01237v1` - [abs](http://arxiv.org/abs/1811.01237v1) - [pdf](http://arxiv.org/pdf/1811.01237v1)

> In this paper we address a task of relation mention extraction from noisy data: extracting representative phrases for a particular relation from noisy sentences that are collected via distant supervision. Despite its significance and value in many downstream applications, this task is less studied on noisy data. The major challenges exists in 1) the lack of annotation on mention phrases, and more severely, 2) handling noisy sentences which do not express a relation at all. To address the two challenges, we formulate the task as a semi-Markov decision process and propose a novel hierarchical reinforcement learning model. Our model consists of a top-level sentence selector to remove noisy sentences, a low-level mention extractor to extract relation mentions, and a reward estimator to provide signals to guide data denoising and mention extraction without explicit annotations. Experimental results show that our model is effective to extract relation mentions from noisy data.

</details>

<details>

<summary>2018-11-03 16:42:07 - Training neural audio classifiers with few data</summary>

- *Jordi Pons, Joan Serrà, Xavier Serra*

- `1810.10274v3` - [abs](http://arxiv.org/abs/1810.10274v3) - [pdf](http://arxiv.org/pdf/1810.10274v3)

> We investigate supervised learning strategies that improve the training of neural network audio classifiers on small annotated collections. In particular, we study whether (i) a naive regularization of the solution space, (ii) prototypical networks, (iii) transfer learning, or (iv) their combination, can foster deep learning models to better leverage a small amount of training examples. To this end, we evaluate (i-iv) for the tasks of acoustic event recognition and acoustic scene classification, considering from 1 to 100 labeled examples per class. Results indicate that transfer learning is a powerful strategy in such scenarios, but prototypical networks show promising results when one does not count with external or validation data.

</details>

<details>

<summary>2018-11-03 17:39:14 - Minimizing Close-k Aggregate Loss Improves Classification</summary>

- *Bryan He, James Zou*

- `1811.00521v2` - [abs](http://arxiv.org/abs/1811.00521v2) - [pdf](http://arxiv.org/pdf/1811.00521v2)

> In classification, the de facto method for aggregating individual losses is the average loss. When the actual metric of interest is 0-1 loss, it is common to minimize the average surrogate loss for some well-behaved (e.g. convex) surrogate. Recently, several other aggregate losses such as the maximal loss and average top-$k$ loss were proposed as alternative objectives to address shortcomings of the average loss. However, we identify common classification settings, e.g. the data is imbalanced, has too many easy or ambiguous examples, etc., when average, maximal and average top-$k$ all suffer from suboptimal decision boundaries, even on an infinitely large training set. To address this problem, we propose a new classification objective called the close-$k$ aggregate loss, where we adaptively minimize the loss for points close to the decision boundary. We provide theoretical guarantees for the 0-1 accuracy when we optimize close-$k$ aggregate loss. We also conduct systematic experiments across the PMLB and OpenML benchmark datasets. Close-$k$ achieves significant gains in 0-1 test accuracy, improvements of $\geq 2$% and $p<0.05$, in over 25% of the datasets compared to average, maximal and average top-$k$. In contrast, the previous aggregate losses outperformed close-$k$ in less than 2% of the datasets.

</details>

<details>

<summary>2018-11-03 18:36:57 - LAPRAN: A Scalable Laplacian Pyramid Reconstructive Adversarial Network for Flexible Compressive Sensing Reconstruction</summary>

- *Kai Xu, Zhikang Zhang, Fengbo Ren*

- `1807.09388v3` - [abs](http://arxiv.org/abs/1807.09388v3) - [pdf](http://arxiv.org/pdf/1807.09388v3)

> This paper addresses the single-image compressive sensing (CS) and reconstruction problem. We propose a scalable Laplacian pyramid reconstructive adversarial network (LAPRAN) that enables high-fidelity, flexible and fast CS images reconstruction. LAPRAN progressively reconstructs an image following the concept of Laplacian pyramid through multiple stages of reconstructive adversarial networks (RANs). At each pyramid level, CS measurements are fused with a contextual latent vector to generate a high-frequency image residual. Consequently, LAPRAN can produce hierarchies of reconstructed images and each with an incremental resolution and improved quality. The scalable pyramid structure of LAPRAN enables high-fidelity CS reconstruction with a flexible resolution that is adaptive to a wide range of compression ratios (CRs), which is infeasible with existing methods. Experimental results on multiple public datasets show that LAPRAN offers an average 7.47dB and 5.98dB PSNR, and an average 57.93% and 33.20% SSIM improvement compared to model-based and data-driven baselines, respectively.

</details>

<details>

<summary>2018-11-03 19:09:18 - Legible Normativity for AI Alignment: The Value of Silly Rules</summary>

- *Dylan Hadfield-Menell, McKane Andrus, Gillian K. Hadfield*

- `1811.01267v1` - [abs](http://arxiv.org/abs/1811.01267v1) - [pdf](http://arxiv.org/pdf/1811.01267v1)

> It has become commonplace to assert that autonomous agents will have to be built to follow human rules of behavior--social norms and laws. But human laws and norms are complex and culturally varied systems, in many cases agents will have to learn the rules. This requires autonomous agents to have models of how human rule systems work so that they can make reliable predictions about rules. In this paper we contribute to the building of such models by analyzing an overlooked distinction between important rules and what we call silly rules--rules with no discernible direct impact on welfare. We show that silly rules render a normative system both more robust and more adaptable in response to shocks to perceived stability. They make normativity more legible for humans, and can increase legibility for AI systems as well. For AI systems to integrate into human normative systems, we suggest, it may be important for them to have models that include representations of silly rules.

</details>

<details>

<summary>2018-11-03 21:39:43 - Towards Sparse Hierarchical Graph Classifiers</summary>

- *Cătălina Cangea, Petar Veličković, Nikola Jovanović, Thomas Kipf, Pietro Liò*

- `1811.01287v1` - [abs](http://arxiv.org/abs/1811.01287v1) - [pdf](http://arxiv.org/pdf/1811.01287v1)

> Recent advances in representation learning on graphs, mainly leveraging graph convolutional networks, have brought a substantial improvement on many graph-based benchmark tasks. While novel approaches to learning node embeddings are highly suitable for node classification and link prediction, their application to graph classification (predicting a single label for the entire graph) remains mostly rudimentary, typically using a single global pooling step to aggregate node features or a hand-designed, fixed heuristic for hierarchical coarsening of the graph structure. An important step towards ameliorating this is differentiable graph coarsening---the ability to reduce the size of the graph in an adaptive, data-dependent manner within a graph neural network pipeline, analogous to image downsampling within CNNs. However, the previous prominent approach to pooling has quadratic memory requirements during training and is therefore not scalable to large graphs. Here we combine several recent advances in graph neural network design to demonstrate that competitive hierarchical graph classification results are possible without sacrificing sparsity. Our results are verified on several established graph classification benchmarks, and highlight an important direction for future research in graph-based neural networks.

</details>

<details>

<summary>2018-11-03 23:43:38 - SimplerVoice: A Key Message & Visual Description Generator System for Illiteracy</summary>

- *Minh N. B. Nguyen, Samuel Thomas, Anne E. Gattiker, Sujatha Kashyap, Kush R. Varshney*

- `1811.01299v1` - [abs](http://arxiv.org/abs/1811.01299v1) - [pdf](http://arxiv.org/pdf/1811.01299v1)

> We introduce SimplerVoice: a key message and visual description generator system to help low-literate adults navigate the information-dense world with confidence, on their own. SimplerVoice can automatically generate sensible sentences describing an unknown object, extract semantic meanings of the object usage in the form of a query string, then, represent the string as multiple types of visual guidance (pictures, pictographs, etc.). We demonstrate SimplerVoice system in a case study of generating grocery products' manuals through a mobile application. To evaluate, we conducted a user study on SimplerVoice's generated description in comparison to the information interpreted by users from other methods: the original product package and search engines' top result, in which SimplerVoice achieved the highest performance score: 4.82 on 5-point mean opinion score scale. Our result shows that SimplerVoice is able to provide low-literate end-users with simple yet informative components to help them understand how to use the grocery products, and that the system may potentially provide benefits in other real-world use cases

</details>

<details>

<summary>2018-11-04 16:36:39 - Curiosity Driven Exploration of Learned Disentangled Goal Spaces</summary>

- *Adrien Laversanne-Finot, Alexandre Péré, Pierre-Yves Oudeyer*

- `1807.01521v3` - [abs](http://arxiv.org/abs/1807.01521v3) - [pdf](http://arxiv.org/pdf/1807.01521v3)

> Intrinsically motivated goal exploration processes enable agents to autonomously sample goals to explore efficiently complex environments with high-dimensional continuous actions. They have been applied successfully to real world robots to discover repertoires of policies producing a wide diversity of effects. Often these algorithms relied on engineered goal spaces but it was recently shown that one can use deep representation learning algorithms to learn an adequate goal space in simple environments. However, in the case of more complex environments containing multiple objects or distractors, an efficient exploration requires that the structure of the goal space reflects the one of the environment. In this paper we show that using a disentangled goal space leads to better exploration performances than an entangled goal space. We further show that when the representation is disentangled, one can leverage it by sampling goals that maximize learning progress in a modular manner. Finally, we show that the measure of learning progress, used to drive curiosity-driven exploration, can be used simultaneously to discover abstract independently controllable features of the environment.

</details>

<details>

<summary>2018-11-04 17:57:07 - Semantic Role Labeling for Knowledge Graph Extraction from Text</summary>

- *Mehwish Alam, Aldo Gangemi, Valentina Presutti, Diego Reforgiato Recupero*

- `1811.01409v1` - [abs](http://arxiv.org/abs/1811.01409v1) - [pdf](http://arxiv.org/pdf/1811.01409v1)

> This paper introduces TakeFive, a new semantic role labeling method that transforms a text into a frame-oriented knowledge graph. It performs dependency parsing, identifies the words that evoke lexical frames, locates the roles and fillers for each frame, runs coercion techniques, and formalises the results as a knowledge graph. This formal representation complies with the frame semantics used in Framester, a factual-linguistic linked data resource. The obtained precision, recall and F1 values indicate that TakeFive is competitive with other existing methods such as SEMAFOR, Pikes, PathLSTM and FRED. We finally discuss how to combine TakeFive and FRED, obtaining higher values of precision, recall and F1.

</details>

<details>

<summary>2018-11-04 21:35:16 - Explaining Explanations in AI</summary>

- *Brent Mittelstadt, Chris Russell, Sandra Wachter*

- `1811.01439v1` - [abs](http://arxiv.org/abs/1811.01439v1) - [pdf](http://arxiv.org/pdf/1811.01439v1)

> Recent work on interpretability in machine learning and AI has focused on the building of simplified models that approximate the true criteria used to make decisions. These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break. However, when considering any such model it's important to remember Box's maxim that "All models are wrong but some are useful." We focus on the distinction between these models and explanations in philosophy and sociology. These models can be understood as a "do it yourself kit" for explanations, allowing a practitioner to directly answer "what if questions" or generate contrastive explanations without external assistance. Although a valuable ability, giving these models as explanations appears more difficult than necessary, and other forms of explanation may not have the same trade-offs. We contrast the different schools of thought on what makes an explanation, and suggest that machine learning might benefit from viewing the problem more broadly.

</details>

<details>

<summary>2018-11-05 00:54:03 - Medical code prediction with multi-view convolution and description-regularized label-dependent attention</summary>

- *Najmeh Sadoughi, Greg P. Finley, James Fone, Vignesh Murali, Maxim Korenevski, Slava Baryshnikov, Nico Axtmann, Mark Miller, David Suendermann-Oeft*

- `1811.01468v1` - [abs](http://arxiv.org/abs/1811.01468v1) - [pdf](http://arxiv.org/pdf/1811.01468v1)

> A ubiquitous task in processing electronic medical data is the assignment of standardized codes representing diagnoses and/or procedures to free-text documents such as medical reports. This is a difficult natural language processing task that requires parsing long, heterogeneous documents and selecting a set of appropriate codes from tens of thousands of possibilities---many of which have very few positive training samples. We present a deep learning system that advances the state of the art for the MIMIC-III dataset, achieving a new best micro F1-measure of 55.85\%, significantly outperforming the previous best result (Mullenbach et al. 2018). We achieve this through a number of enhancements, including two major novel contributions: multi-view convolutional channels, which effectively learn to adjust kernel sizes throughout the input; and attention regularization, mediated by natural-language code descriptions, which helps overcome sparsity for thousands of uncommon codes. These and other modifications are selected to address difficulties inherent to both automated coding specifically and deep learning generally. Finally, we investigate our accuracy results in detail to individually measure the impact of these contributions and point the way towards future algorithmic improvements.

</details>

<details>

<summary>2018-11-05 02:07:03 - FairMod - Making Predictive Models Discrimination Aware</summary>

- *Jixue Liu, Jiuyong Li, Lin Liu, Thuc Duy Le, Feiyue Ye, Gefei Li*

- `1811.01480v1` - [abs](http://arxiv.org/abs/1811.01480v1) - [pdf](http://arxiv.org/pdf/1811.01480v1)

> Predictive models such as decision trees and neural networks may produce discrimination in their predictions. This paper proposes a method to post-process the predictions of a predictive model to make the processed predictions non-discriminatory. The method considers multiple protected variables together. Multiple protected variables make the problem more challenging than a simple protected variable. The method uses a well-cited discrimination metric and adapts it to allow the specification of explanatory variables, such as position, profession, education, that describe the contexts of the applications. It models the post-processing of predictions problem as a nonlinear optimization problem to find best adjustments to the predictions so that the discrimination constraints of all protected variables are all met at the same time. The proposed method is independent of classification methods. It can handle the cases that existing methods cannot handle: satisfying multiple protected attributes at the same time, allowing multiple explanatory attributes, and being independent of classification model types. An evaluation using four real world data sets shows that the proposed method is as effectively as existing methods, in addition to its extra power.

</details>

<details>

<summary>2018-11-05 03:33:24 - Lifted Proximal Operator Machines</summary>

- *Jia Li, Cong Fang, Zhouchen Lin*

- `1811.01501v1` - [abs](http://arxiv.org/abs/1811.01501v1) - [pdf](http://arxiv.org/pdf/1811.01501v1)

> We propose a new optimization method for training feed-forward neural networks. By rewriting the activation function as an equivalent proximal operator, we approximate a feed-forward neural network by adding the proximal operators to the objective function as penalties, hence we call the lifted proximal operator machine (LPOM). LPOM is block multi-convex in all layer-wise weights and activations. This allows us to use block coordinate descent to update the layer-wise weights and activations in parallel. Most notably, we only use the mapping of the activation function itself, rather than its derivatives, thus avoiding the gradient vanishing or blow-up issues in gradient based training methods. So our method is applicable to various non-decreasing Lipschitz continuous activation functions, which can be saturating and non-differentiable. LPOM does not require more auxiliary variables than the layer-wise activations, thus using roughly the same amount of memory as stochastic gradient descent (SGD) does. We further prove the convergence of updating the layer-wise weights and activations. Experiments on MNIST and CIFAR-10 datasets testify to the advantages of LPOM.

</details>

<details>

<summary>2018-11-05 05:17:08 - Toward Efficient Breast Cancer Diagnosis and Survival Prediction Using L-Perceptron</summary>

- *Hadi Mansourifar, Weidong Shi*

- `1811.03016v1` - [abs](http://arxiv.org/abs/1811.03016v1) - [pdf](http://arxiv.org/pdf/1811.03016v1)

> Breast cancer is the most frequently reported cancer type among the women around the globe and beyond that it has the second highest female fatality rate among all cancer types. Despite all the progresses made in prevention and early intervention, early prognosis and survival prediction rates are still unsatisfactory. In this paper, we propose a novel type of perceptron called L-Perceptron which outperforms all the previous supervised learning methods by reaching 97.42 \% and 98.73 \% in terms of accuracy and sensitivity, respectively in Wisconsin Breast Cancer dataset. Experimental results on Haberman's Breast Cancer Survival dataset, show the superiority of proposed method by reaching 75.18 \% and 83.86 \% in terms of accuracy and F1 score, respectively. The results are the best reported ones obtained in 10-fold cross validation in absence of any preprocessing or feature selection.

</details>

<details>

<summary>2018-11-05 07:06:32 - Transfer learning for time series classification</summary>

- *Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller*

- `1811.01533v1` - [abs](http://arxiv.org/abs/1811.01533v1) - [pdf](http://arxiv.org/pdf/1811.01533v1)

> Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network's weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network's generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the model's predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.

</details>

<details>

<summary>2018-11-05 09:31:45 - PointCNN: Convolution On $\mathcal{X}$-Transformed Points</summary>

- *Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di, Baoquan Chen*

- `1801.07791v5` - [abs](http://arxiv.org/abs/1801.07791v5) - [pdf](http://arxiv.org/pdf/1801.07791v5)

> We present a simple and general framework for feature learning from point clouds. The key to the success of CNNs is the convolution operator that is capable of leveraging spatially-local correlation in data represented densely in grids (e.g. images). However, point clouds are irregular and unordered, thus directly convolving kernels against features associated with the points, will result in desertion of shape information and variance to point ordering. To address these problems, we propose to learn an $\mathcal{X}$-transformation from the input points, to simultaneously promote two causes. The first is the weighting of the input features associated with the points, and the second is the permutation of the points into a latent and potentially canonical order. Element-wise product and sum operations of the typical convolution operator are subsequently applied on the $\mathcal{X}$-transformed features. The proposed method is a generalization of typical CNNs to feature learning from point clouds, thus we call it PointCNN. Experiments show that PointCNN achieves on par or better performance than state-of-the-art methods on multiple challenging benchmark datasets and tasks.

</details>

<details>

<summary>2018-11-05 10:11:29 - Improving Response Selection in Multi-Turn Dialogue Systems by Incorporating Domain Knowledge</summary>

- *Debanjan Chaudhuri, Agustinus Kristiadi, Jens Lehmann, Asja Fischer*

- `1809.03194v3` - [abs](http://arxiv.org/abs/1809.03194v3) - [pdf](http://arxiv.org/pdf/1809.03194v3)

> Building systems that can communicate with humans is a core problem in Artificial Intelligence. This work proposes a novel neural network architecture for response selection in an end-to-end multi-turn conversational dialogue setting. The architecture applies context level attention and incorporates additional external knowledge provided by descriptions of domain-specific words. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context and responses and learns to attend over the context words given the latent response representation and vice versa.In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions. This allows better representation of domain-specific keywords in responses and hence improves the overall performance. Experimental results show that our model outperforms all other state-of-the-art methods for response selection in multi-turn conversations.

</details>

<details>

<summary>2018-11-05 12:18:25 - The Complexity of Splitting Necklaces and Bisecting Ham Sandwiches</summary>

- *Aris Filos-Ratsikas, Paul W. Goldberg*

- `1805.12559v2` - [abs](http://arxiv.org/abs/1805.12559v2) - [pdf](http://arxiv.org/pdf/1805.12559v2)

> We resolve the computational complexity of two problems known as NECKLACE-SPLITTING and DISCRETE HAM SANDWICH, showing that they are PPA-complete. For NECKLACE SPLITTING, this result is specific to the important special case in which two thieves share the necklace. We do this via a PPA-completeness result for an approximate version of the CONSENSUS-HALVING problem, strengthening our recent result that the problem is PPA-complete for inverse-exponential precision. At the heart of our construction is a smooth embedding of the high-dimensional M\"obius strip in the CONSENSUS-HALVING problem. These results settle the status of PPA as a class that captures the complexity of "natural" problems whose definitions do not incorporate a circuit.

</details>

<details>

<summary>2018-11-05 13:18:32 - Matrix Completion With Variational Graph Autoencoders: Application in Hyperlocal Air Quality Inference</summary>

- *Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Angel Lopez Aguirre, Valerio Panzica La Manna, Frank Pasveer, Wilfried Philips, Nikos Deligiannis*

- `1811.01662v1` - [abs](http://arxiv.org/abs/1811.01662v1) - [pdf](http://arxiv.org/pdf/1811.01662v1)

> Inferring air quality from a limited number of observations is an essential task for monitoring and controlling air pollution. Existing inference methods typically use low spatial resolution data collected by fixed monitoring stations and infer the concentration of air pollutants using additional types of data, e.g., meteorological and traffic information. In this work, we focus on street-level air quality inference by utilizing data collected by mobile stations. We formulate air quality inference in this setting as a graph-based matrix completion problem and propose a novel variational model based on graph convolutional autoencoders. Our model captures effectively the spatio-temporal correlation of the measurements and does not depend on the availability of additional information apart from the street-network topology. Experiments on a real air quality dataset, collected with mobile stations, shows that the proposed model outperforms state-of-the-art approaches.

</details>

<details>

<summary>2018-11-05 13:54:48 - Convolutional neural networks on irregular domains based on approximate vertex-domain translations</summary>

- *Bastien Pasdeloup, Vincent Gripon, Jean-Charles Vialatte, Dominique Pastor, Pascal Frossard*

- `1710.10035v2` - [abs](http://arxiv.org/abs/1710.10035v2) - [pdf](http://arxiv.org/pdf/1710.10035v2)

> We propose a generalization of convolutional neural networks (CNNs) to irregular domains, through the use of a translation operator on a graph structure. In regular settings such as images, convolutional layers are designed by translating a convolutional kernel over all pixels, thus enforcing translation equivariance. In the case of general graphs however, translation is not a well-defined operation, which makes shifting a convolutional kernel not straightforward. In this article, we introduce a methodology to allow the design of convolutional layers that are adapted to signals evolving on irregular topologies, even in the absence of a natural translation. Using the designed layers, we build a CNN that we train using the initial set of signals. Contrary to other approaches that aim at extending CNNs to irregular domains, we incorporate the classical settings of CNNs for 2D signals as a particular case of our approach. Designing convolutional layers in the vertex domain directly implies weight sharing, which in other approaches is generally estimated a posteriori using heuristics.

</details>

<details>

<summary>2018-11-05 14:12:14 - Combining Subgoal Graphs with Reinforcement Learning to Build a Rational Pathfinder</summary>

- *Junjie Zeng, Long Qin, Yue Hu, Cong Hu, Quanjun Yin*

- `1811.01700v1` - [abs](http://arxiv.org/abs/1811.01700v1) - [pdf](http://arxiv.org/pdf/1811.01700v1)

> In this paper, we present a hierarchical path planning framework called SG-RL (subgoal graphs-reinforcement learning), to plan rational paths for agents maneuvering in continuous and uncertain environments. By "rational", we mean (1) efficient path planning to eliminate first-move lags; (2) collision-free and smooth for agents with kinematic constraints satisfied. SG-RL works in a two-level manner. At the first level, SG-RL uses a geometric path-planning method, i.e., Simple Subgoal Graphs (SSG), to efficiently find optimal abstract paths, also called subgoal sequences. At the second level, SG-RL uses an RL method, i.e., Least-Squares Policy Iteration (LSPI), to learn near-optimal motion-planning policies which can generate kinematically feasible and collision-free trajectories between adjacent subgoals. The first advantage of the proposed method is that SSG can solve the limitations of sparse reward and local minima trap for RL agents; thus, LSPI can be used to generate paths in complex environments. The second advantage is that, when the environment changes slightly (i.e., unexpected obstacles appearing), SG-RL does not need to reconstruct subgoal graphs and replan subgoal sequences using SSG, since LSPI can deal with uncertainties by exploiting its generalization ability to handle changes in environments. Simulation experiments in representative scenarios demonstrate that, compared with existing methods, SG-RL can work well on large-scale maps with relatively low action-switching frequencies and shorter path lengths, and SG-RL can deal with small changes in environments. We further demonstrate that the design of reward functions and the types of training environments are important factors for learning feasible policies.

</details>

<details>

<summary>2018-11-05 14:12:23 - Role of Awareness and Universal Context in a Spiking Conscious Neural Network (SCNN): A New Perspective and Future Directions</summary>

- *Ahsan Adeel*

- `1811.01701v1` - [abs](http://arxiv.org/abs/1811.01701v1) - [pdf](http://arxiv.org/pdf/1811.01701v1)

> Awareness plays a major role in human cognition and adaptive behaviour, though mechanisms involved remain unknown. Awareness is not an objectively established fact, therefore, despite extensive research, scientists have not been able to fully interpret its contribution in multisensory integration and precise neural firing, hence, questions remain: (1) How the biological neuron integrates the incoming multisensory signals with respect to different situations? (2) How are the roles of incoming multisensory signals defined (selective amplification/attenuation) that help neuron(s) to originate a precise neural firing complying with the anticipated behavioural-constraint of the environment? (3) How are the external environment and anticipated behaviour integrated? Recently, scientists have exploited deep learning to integrate multimodal cues and capture context-dependent meanings. Yet, these methods suffer from imprecise behavioural representation. In this research, we introduce a new theory on the role of awareness and universal context that can help answering the aforementioned crucial neuroscience questions. Specifically, we propose a class of spiking conscious neuron in which the output depends on three functionally distinctive integrated input variables: receptive field (RF), local contextual field (LCF), and universal contextual field (UCF). The RF defines the incoming ambiguous sensory signal, LCF defines the modulatory signal coming from other parts of the brain, and UCF defines the awareness. It is believed that the conscious neuron inherently contains enough knowledge about the situation in which the problem is to be solved based on past learning and reasoning and it defines the precise role of incoming multisensory signals to originate a precise neural firing (exhibiting switch-like behaviour). It is shown that the conscious neuron helps modelling a more precise human behaviour.

</details>

<details>

<summary>2018-11-05 14:38:45 - Learning Shared Dynamics with Meta-World Models</summary>

- *Lisheng Wu, Minne Li, Jun Wang*

- `1811.01741v1` - [abs](http://arxiv.org/abs/1811.01741v1) - [pdf](http://arxiv.org/pdf/1811.01741v1)

> Humans have consciousness as the ability to perceive events and objects: a mental model of the world developed from the most impoverished of visual stimuli, enabling humans to make rapid decisions and take actions. Although spatial and temporal aspects of different scenes are generally diverse, the underlying physics among environments still work the same way, thus learning an abstract description of shared physical dynamics helps human to understand the world. In this paper, we explore building this mental world with neural network models through multi-task learning, namely the meta-world model. We show through extensive experiments that our proposed meta-world models successfully capture the common dynamics over the compact representations of visually different environments from Atari Games. We also demonstrate that agents equipped with our meta-world model possess the ability of visual self-recognition, i.e., recognize themselves from the reflected mirrored environment derived from the classic mirror self-recognition test (MSR).

</details>

<details>

<summary>2018-11-05 15:21:59 - Optimal Convergence for Distributed Learning with Stochastic Gradient Methods and Spectral Algorithms</summary>

- *Junhong Lin, Volkan Cevher*

- `1801.07226v2` - [abs](http://arxiv.org/abs/1801.07226v2) - [pdf](http://arxiv.org/pdf/1801.07226v2)

> We study generalization properties of distributed algorithms in the setting of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We first investigate distributed stochastic gradient methods (SGM), with mini-batches and multi-passes over the data. We show that optimal generalization error bounds can be retained for distributed SGM provided that the partition level is not too large. We then extend our results to spectral-regularization algorithms (SRA), including kernel ridge regression (KRR), kernel principal component analysis, and gradient methods. Our results are superior to the state-of-the-art theory. Particularly, our results show that distributed SGM has a smaller theoretical computational complexity, compared with distributed KRR and classic SGM. Moreover, even for non-distributed SRA, they provide the first optimal, capacity-dependent convergence rates, considering the case that the regression function may not be in the RKHS.

</details>

<details>

<summary>2018-11-05 16:06:57 - All You Need is "Love": Evading Hate-speech Detection</summary>

- *Tommi Gröndahl, Luca Pajola, Mika Juuti, Mauro Conti, N. Asokan*

- `1808.09115v3` - [abs](http://arxiv.org/abs/1808.09115v3) - [pdf](http://arxiv.org/pdf/1808.09115v3)

> With the spread of social networks and their unfortunate use for hate speech, automatic detection of the latter has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are brittle against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective -- a cutting-edge solution from industry. Our experiments demonstrate that adversarial training does not completely mitigate the attacks, and using character-level features makes the models systematically more attack-resistant than using word-level features.

</details>

<details>

<summary>2018-11-05 16:34:49 - Whispered-to-voiced Alaryngeal Speech Conversion with Generative Adversarial Networks</summary>

- *Santiago Pascual, Antonio Bonafonte, Joan Serrà, Jose A. Gonzalez*

- `1808.10687v2` - [abs](http://arxiv.org/abs/1808.10687v2) - [pdf](http://arxiv.org/pdf/1808.10687v2)

> Most methods of voice restoration for patients suffering from aphonia either produce whispered or monotone speech. Apart from intelligibility, this type of speech lacks expressiveness and naturalness due to the absence of pitch (whispered speech) or artificial generation of it (monotone speech). Existing techniques to restore prosodic information typically combine a vocoder, which parameterises the speech signal, with machine learning techniques that predict prosodic information. In contrast, this paper describes an end-to-end neural approach for estimating a fully-voiced speech waveform from whispered alaryngeal speech. By adapting our previous work in speech enhancement with generative adversarial networks, we develop a speaker-dependent model to perform whispered-to-voiced speech conversion. Preliminary qualitative results show effectiveness in re-generating voiced speech, with the creation of realistic pitch contours.

</details>

<details>

<summary>2018-11-05 17:04:35 - Reinforcement Learning based Dynamic Model Selection for Short-Term Load Forecasting</summary>

- *Cong Feng, Jie Zhang*

- `1811.01846v1` - [abs](http://arxiv.org/abs/1811.01846v1) - [pdf](http://arxiv.org/pdf/1811.01846v1)

> With the growing prevalence of smart grid technology, short-term load forecasting (STLF) becomes particularly important in power system operations. There is a large collection of methods developed for STLF, but selecting a suitable method under varying conditions is still challenging. This paper develops a novel reinforcement learning based dynamic model selection (DMS) method for STLF. A forecasting model pool is first built, including ten state-of-the-art machine learning based forecasting models. Then a Q-learning agent learns the optimal policy of selecting the best forecasting model for the next time step, based on the model performance. The optimal DMS policy is applied to select the best model at each time step with a moving window. Numerical simulations on two-year load and weather data show that the Q-learning algorithm converges fast, resulting in effective and efficient DMS. The developed STLF model with Q-learning based DMS improves the forecasting accuracy by approximately 50%, compared to the state-of-the-art machine learning based STLF models.

</details>

<details>

<summary>2018-11-06 02:20:40 - Bootstrapping single-channel source separation via unsupervised spatial clustering on stereo mixtures</summary>

- *Prem Seetharaman, Gordon Wichern, Jonathan Le Roux, Bryan Pardo*

- `1811.02130v1` - [abs](http://arxiv.org/abs/1811.02130v1) - [pdf](http://arxiv.org/pdf/1811.02130v1)

> Separating an audio scene into isolated sources is a fundamental problem in computer audition, analogous to image segmentation in visual scene analysis. Source separation systems based on deep learning are currently the most successful approaches for solving the underdetermined separation problem, where there are more sources than channels. Traditionally, such systems are trained on sound mixtures where the ground truth decomposition is already known. Since most real-world recordings do not have such a decomposition available, this limits the range of mixtures one can train on, and the range of mixtures the learned models may successfully separate. In this work, we use a simple blind spatial source separation algorithm to generate estimated decompositions of stereo mixtures. These estimates, together with a weighting scheme in the time-frequency domain, based on confidence in the separation quality, are used to train a deep learning model that can be used for single-channel separation, where no source direction information is available. This demonstrates how a simple cue such as the direction of origin of source can be used to bootstrap a model for source separation that can be used in situations where that cue is not available.

</details>

<details>

<summary>2018-11-06 04:52:16 - Graph based Entropy for Detecting Explanatory Signs of Changes in Market</summary>

- *Yukio Ohsawa*

- `1811.12165v1` - [abs](http://arxiv.org/abs/1811.12165v1) - [pdf](http://arxiv.org/pdf/1811.12165v1)

> Graph based entropy, an index of the diversity of events in their distribution to parts of a co-occurrence graph, is proposed for detecting signs of structural changes in the data that are informative in explaining latent dynamics of consumers behavior. For obtaining graph-based entropy, connected subgraphs are first obtained from the graph of co-occurrences of items in the data. Then, the distribution of items occurring in events in the data to these sub-graphs is reflected on the value of graph-based entropy. For the data on the position of sale, a change in this value is regarded as a sign of the appearance, the separation, the disappearance, or the uniting of consumers interests. These phenomena are regarded as the signs of dynamic changes in consumers behavior that may be the effects of external events and information. Experiments show that graph-based entropy outperforms baseline methods that can be used for change detection, in explaining substantial changes and their signs in consumers preference of items in supermarket stores.

</details>

<details>

<summary>2018-11-06 06:07:09 - Fast OBDD Reordering using Neural Message Passing on Hypergraph</summary>

- *Feifan Xu, Fei He, Enze Xie, Liang Li*

- `1811.02178v1` - [abs](http://arxiv.org/abs/1811.02178v1) - [pdf](http://arxiv.org/pdf/1811.02178v1)

> Ordered binary decision diagrams (OBDDs) are an efficient data structure for representing and manipulating Boolean formulas. With respect to different variable orders, the OBDDs' sizes may vary from linear to exponential in the number of the Boolean variables. Finding the optimal variable order has been proved a NP-complete problem. Many heuristics have been proposed to find a near-optimal solution of this problem. In this paper, we propose a neural network-based method to predict near-optimal variable orders for unknown formulas. Viewing these formulas as hypergraphs, and lifting the message passing neural network into 3-hypergraph (MPNN3), we are able to learn the patterns of Boolean formula. Compared to the traditional methods, our method can find a near-the-best solution with an extremely shorter time, even for some hard examples.To the best of our knowledge, this is the first work on applying neural network to OBDD reordering.

</details>

<details>

<summary>2018-11-06 06:31:16 - Representation Learning by Reconstructing Neighborhoods</summary>

- *Chin-Chia Michael Yeh, Yan Zhu, Evangelos E. Papalexakis, Abdullah Mueen, Eamonn Keogh*

- `1811.01557v2` - [abs](http://arxiv.org/abs/1811.01557v2) - [pdf](http://arxiv.org/pdf/1811.01557v2)

> Since its introduction, unsupervised representation learning has attracted a lot of attention from the research community, as it is demonstrated to be highly effective and easy-to-apply in tasks such as dimension reduction, clustering, visualization, information retrieval, and semi-supervised learning. In this work, we propose a novel unsupervised representation learning framework called neighbor-encoder, in which domain knowledge can be easily incorporated into the learning process without modifying the general encoder-decoder architecture of the classic autoencoder.In contrast to autoencoder, which reconstructs the input data itself, neighbor-encoder reconstructs the input data's neighbors. As the proposed representation learning problem is essentially a neighbor reconstruction problem, domain knowledge can be easily incorporated in the form of an appropriate definition of similarity between objects. Based on that observation, our framework can leverage any off-the-shelf similarity search algorithms or side information to find the neighbor of an input object. Applications of other algorithms (e.g., association rule mining) in our framework are also possible, given that the appropriate definition of neighbor can vary in different contexts. We have demonstrated the effectiveness of our framework in many diverse domains, including images, text, and time series, and for various data mining tasks including classification, clustering, and visualization. Experimental results show that neighbor-encoder not only outperforms autoencoder in most of the scenarios we consider, but also achieves the state-of-the-art performance on text document clustering.

</details>

<details>

<summary>2018-11-06 06:49:13 - Graph Bayesian Optimization: Algorithms, Evaluations and Applications</summary>

- *Jiaxu Cui, Bo Yang*

- `1805.01157v4` - [abs](http://arxiv.org/abs/1805.01157v4) - [pdf](http://arxiv.org/pdf/1805.01157v4)

> Network structure optimization is a fundamental task in complex network analysis. However, almost all the research on Bayesian optimization is aimed at optimizing the objective functions with vectorial inputs. In this work, we first present a flexible framework, denoted graph Bayesian optimization, to handle arbitrary graphs in the Bayesian optimization community. By combining the proposed framework with graph kernels, it can take full advantage of implicit graph structural features to supplement explicit features guessed according to the experience, such as tags of nodes and any attributes of graphs. The proposed framework can identify which features are more important during the optimization process. We apply the framework to solve four problems including two evaluations and two applications to demonstrate its efficacy and potential applications.

</details>

<details>

<summary>2018-11-06 08:14:01 - Day-ahead time series forecasting: application to capacity planning</summary>

- *Colin Leverger, Vincent Lemaire, Simon Malinowski, Thomas Guyet, Laurence Rozé*

- `1811.02215v1` - [abs](http://arxiv.org/abs/1811.02215v1) - [pdf](http://arxiv.org/pdf/1811.02215v1)

> In the context of capacity planning, forecasting the evolution of informatics servers usage enables companies to better manage their computational resources. We address this problem by collecting key indicator time series and propose to forecast their evolution a day-ahead. Our method assumes that data is structured by a daily seasonality, but also that there is typical evolution of indicators within a day. Then, it uses the combination of a clustering algorithm and Markov Models to produce day-ahead forecasts. Our experiments on real datasets show that the data satisfies our assumption and that, in the case study, our method outperforms classical approaches (AR, Holt-Winters).

</details>

<details>

<summary>2018-11-06 08:24:58 - An Optimal Itinerary Generation in a Configuration Space of Large Intellectual Agent Groups with Linear Logic</summary>

- *Dmitry Maximov*

- `1811.02216v1` - [abs](http://arxiv.org/abs/1811.02216v1) - [pdf](http://arxiv.org/pdf/1811.02216v1)

> A group of intelligent agents which fulfill a set of tasks in parallel is represented first by the tensor multiplication of corresponding processes in a linear logic game category. An optimal itinerary in the configuration space of the group states is defined as a play with maximal total reward in the category. New moments also are: the reward is represented as a degree of certainty (visibility) of an agent goal, and the system goals are chosen by the greatest value corresponding to these processes in the system goal lattice.

</details>

<details>

<summary>2018-11-06 09:01:02 - Semantic bottleneck for computer vision tasks</summary>

- *Maxime Bucher, Stéphane Herbin, Frédéric Jurie*

- `1811.02234v1` - [abs](http://arxiv.org/abs/1811.02234v1) - [pdf](http://arxiv.org/pdf/1811.02234v1)

> This paper introduces a novel method for the representation of images that is semantic by nature, addressing the question of computation intelligibility in computer vision tasks. More specifically, our proposition is to introduce what we call a semantic bottleneck in the processing pipeline, which is a crossing point in which the representation of the image is entirely expressed with natural language , while retaining the efficiency of numerical representations. We show that our approach is able to generate semantic representations that give state-of-the-art results on semantic content-based image retrieval and also perform very well on image classification tasks. Intelligibility is evaluated through user centered experiments for failure detection.

</details>

<details>

<summary>2018-11-06 09:58:31 - The External Interface for Extending WASP</summary>

- *Carmine Dodaro, Francesco Ricca*

- `1811.01692v2` - [abs](http://arxiv.org/abs/1811.01692v2) - [pdf](http://arxiv.org/pdf/1811.01692v2)

> Answer set programming (ASP) is a successful declarative formalism for knowledge representation and reasoning. The evaluation of ASP programs is nowadays based on the Conflict-Driven Clause Learning (CDCL) backtracking search algorithm. Recent work suggested that the performance of CDCL-based implementations can be considerably improved on specific benchmarks by extending their solving capabilities with custom heuristics and propagators. However, embedding such algorithms into existing systems requires expert knowledge of the internals of ASP implementations. The development of effective solver extensions can be made easier by providing suitable programming interfaces. In this paper, we present the interface for extending the CDCL-based ASP solver WASP. The interface is both general, i.e. it can be used for providing either new branching heuristics and propagators, and external, i.e. the implementation of new algorithms requires no internal modifications of WASP. Moreover, we review the applications of the interface witnessing it can be successfully used to extend WASP for solving effectively hard instances of both real-world and synthetic problems. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>

<details>

<summary>2018-11-06 14:20:44 - Symmetrization for Embedding Directed Graphs</summary>

- *Jiankai Sun, Srinivasan Parthasarathy*

- `1811.12164v1` - [abs](http://arxiv.org/abs/1811.12164v1) - [pdf](http://arxiv.org/pdf/1811.12164v1)

> Recently, one has seen a surge of interest in developing such methods including ones for learning such representations for (undirected) graphs (while preserving important properties). However, most of the work to date on embedding graphs has targeted undirected networks and very little has focused on the thorny issue of embedding directed networks. In this paper, we instead propose to solve the directed graph embedding problem via a two-stage approach: in the first stage, the graph is symmetrized in one of several possible ways, and in the second stage, the so-obtained symmetrized graph is embedded using any state-of-the-art (undirected) graph embedding algorithm. Note that it is not the objective of this paper to propose a new (undirected) graph embedding algorithm or discuss the strengths and weaknesses of existing ones; all we are saying is that whichever be the suitable graph embedding algorithm, it will fit in the above proposed symmetrization framework.

</details>

<details>

<summary>2018-11-06 14:25:49 - ATP: Directed Graph Embedding with Asymmetric Transitivity Preservation</summary>

- *Jiankai Sun, Bortik Bandyopadhyay, Armin Bashizade, Jiongqian Liang, P. Sadayappan, Srinivasan Parthasarathy*

- `1811.00839v2` - [abs](http://arxiv.org/abs/1811.00839v2) - [pdf](http://arxiv.org/pdf/1811.00839v2)

> Directed graphs have been widely used in Community Question Answering services (CQAs) to model asymmetric relationships among different types of nodes in CQA graphs, e.g., question, answer, user. Asymmetric transitivity is an essential property of directed graphs, since it can play an important role in downstream graph inference and analysis. Question difficulty and user expertise follow the characteristic of asymmetric transitivity. Maintaining such properties, while reducing the graph to a lower dimensional vector embedding space, has been the focus of much recent research. In this paper, we tackle the challenge of directed graph embedding with asymmetric transitivity preservation and then leverage the proposed embedding method to solve a fundamental task in CQAs: how to appropriately route and assign newly posted questions to users with the suitable expertise and interest in CQAs. The technique incorporates graph hierarchy and reachability information naturally by relying on a non-linear transformation that operates on the core reachability and implicit hierarchy within such graphs. Subsequently, the methodology levers a factorization-based approach to generate two embedding vectors for each node within the graph, to capture the asymmetric transitivity. Extensive experiments show that our framework consistently and significantly outperforms the state-of-the-art baselines on two diverse real-world tasks: link prediction, and question difficulty estimation and expert finding in online forums like Stack Exchange. Particularly, our framework can support inductive embedding learning for newly posted questions (unseen nodes during training), and therefore can properly route and assign these kinds of questions to experts in CQAs.

</details>

<details>

<summary>2018-11-06 15:08:08 - Quantum Reasoning using Lie Algebra for Everyday Life (and AI perhaps...)</summary>

- *Steven Gratton*

- `1811.04760v1` - [abs](http://arxiv.org/abs/1811.04760v1) - [pdf](http://arxiv.org/pdf/1811.04760v1)

> We investigate the applicability of the formalism of quantum mechanics to everyday life. It seems to be directly relevant for situations in which the very act of coming to a conclusion or decision on one issue affects one's confidence about conclusions or decisions on another issue. Lie algebra theory is argued to be a very useful tool in guiding the construction of quantum descriptions of such situations. Tests, extensions and speculative applications and implications, including for the encoding of thoughts in neural networks, are discussed. It is suggested that the recognition and incorporation of such mathematical structure into machine learning and artificial intelligence might lead to significant efficiency and generality gains in addition to ensuring probabilistic reasoning at a fundamental level.

</details>

<details>

<summary>2018-11-06 16:06:49 - Synaptic Strength For Convolutional Neural Network</summary>

- *Chen Lin, Zhao Zhong, Wei Wu, Junjie Yan*

- `1811.02454v1` - [abs](http://arxiv.org/abs/1811.02454v1) - [pdf](http://arxiv.org/pdf/1811.02454v1)

> Convolutional Neural Networks(CNNs) are both computation and memory intensive which hindered their deployment in mobile devices. Inspired by the relevant concept in neural science literature, we propose Synaptic Pruning: a data-driven method to prune connections between input and output feature maps with a newly proposed class of parameters called Synaptic Strength. Synaptic Strength is designed to capture the importance of a connection based on the amount of information it transports. Experiment results show the effectiveness of our approach. On CIFAR-10, we prune connections for various CNN models with up to 96% , which results in significant size reduction and computation saving. Further evaluation on ImageNet demonstrates that synaptic pruning is able to discover efficient models which is competitive to state-of-the-art compact CNNs such as MobileNet-V2 and NasNet-Mobile. Our contribution is summarized as following: (1) We introduce Synaptic Strength, a new class of parameters for CNNs to indicate the importance of each connections. (2) Our approach can prune various CNNs with high compression without compromising accuracy. (3) Further investigation shows, the proposed Synaptic Strength is a better indicator for kernel pruning compared with the previous approach in both empirical result and theoretical analysis.

</details>

<details>

<summary>2018-11-06 16:12:00 - Parser Extraction of Triples in Unstructured Text</summary>

- *Shaun D'Souza*

- `1811.05768v1` - [abs](http://arxiv.org/abs/1811.05768v1) - [pdf](http://arxiv.org/pdf/1811.05768v1)

> The web contains vast repositories of unstructured text. We investigate the opportunity for building a knowledge graph from these text sources. We generate a set of triples which can be used in knowledge gathering and integration. We define the architecture of a language compiler for processing subject-predicate-object triples using the OpenNLP parser. We implement a depth-first search traversal on the POS tagged syntactic tree appending predicate and object information. A parser enables higher precision and higher recall extractions of syntactic relationships across conjunction boundaries. We are able to extract 2-2.5 times the correct extractions of ReVerb. The extractions are used in a variety of semantic web applications and question answering. We verify extraction of 50,000 triples on the ClueWeb dataset.

</details>

<details>

<summary>2018-11-06 16:27:27 - Modeling Multi-turn Conversation with Deep Utterance Aggregation</summary>

- *Zhuosheng Zhang, Jiangtong Li, Pengfei Zhu, Hai Zhao, Gongshen Liu*

- `1806.09102v2` - [abs](http://arxiv.org/abs/1806.09102v2) - [pdf](http://arxiv.org/pdf/1806.09102v2)

> Multi-turn conversation understanding is a major challenge for building intelligent dialogue systems. This work focuses on retrieval-based response matching for multi-turn conversation whose related work simply concatenates the conversation utterances, ignoring the interactions among previous utterances for context modeling. In this paper, we formulate previous utterances into context using a proposed deep utterance aggregation model to form a fine-grained context representation. In detail, a self-matching attention is first introduced to route the vital information in each utterance. Then the model matches a response with each refined utterance and the final matching score is obtained after attentive turns aggregation. Experimental results show our model outperforms the state-of-the-art methods on three multi-turn conversation benchmarks, including a newly introduced e-commerce dialogue corpus.

</details>

<details>

<summary>2018-11-06 16:43:47 - Deep Reinforcement Learning for Green Security Games with Real-Time Information</summary>

- *Yufei Wang, Zheyuan Ryan Shi, Lantao Yu, Yi Wu, Rohit Singh, Lucas Joppa, Fei Fang*

- `1811.02483v1` - [abs](http://arxiv.org/abs/1811.02483v1) - [pdf](http://arxiv.org/pdf/1811.02483v1)

> Green Security Games (GSGs) have been proposed and applied to optimize patrols conducted by law enforcement agencies in green security domains such as combating poaching, illegal logging and overfishing. However, real-time information such as footprints and agents' subsequent actions upon receiving the information, e.g., rangers following the footprints to chase the poacher, have been neglected in previous work. To fill the gap, we first propose a new game model GSG-I which augments GSGs with sequential movement and the vital element of real-time information. Second, we design a novel deep reinforcement learning-based algorithm, DeDOL, to compute a patrolling strategy that adapts to the real-time information against a best-responding attacker. DeDOL is built upon the double oracle framework and the policy-space response oracle, solving a restricted game and iteratively adding best response strategies to it through training deep Q-networks. Exploring the game structure, DeDOL uses domain-specific heuristic strategies as initial strategies and constructs several local modes for efficient and parallelized training. To our knowledge, this is the first attempt to use Deep Q-Learning for security games.

</details>

<details>

<summary>2018-11-06 16:52:20 - Concept Learning with Energy-Based Models</summary>

- *Igor Mordatch*

- `1811.02486v1` - [abs](http://arxiv.org/abs/1811.02486v1) - [pdf](http://arxiv.org/pdf/1811.02486v1)

> Many hallmarks of human intelligence, such as generalizing from limited experience, abstract reasoning and planning, analogical reasoning, creative problem solving, and capacity for language require the ability to consolidate experience into concepts, which act as basic building blocks of understanding and reasoning. We present a framework that defines a concept by an energy function over events in the environment, as well as an attention mask over entities participating in the event. Given few demonstration events, our method uses inference-time optimization procedure to generate events involving similar concepts or identify entities involved in the concept. We evaluate our framework on learning visual, quantitative, relational, temporal concepts from demonstration events in an unsupervised manner. Our approach is able to successfully generate and identify concepts in a few-shot setting and resulting learned concepts can be reused across environments. Example videos of our results are available at sites.google.com/site/energyconceptmodels

</details>

<details>

<summary>2018-11-06 17:00:40 - Artificial Intelligence Enabled Software Defined Networking: A Comprehensive Overview</summary>

- *Majd Latah, Levent Toker*

- `1803.06818v3` - [abs](http://arxiv.org/abs/1803.06818v3) - [pdf](http://arxiv.org/pdf/1803.06818v3)

> Software defined networking (SDN) represents a promising networking architecture that combines central management and network programmability. SDN separates the control plane from the data plane and moves the network management to a central point, called the controller, that can be programmed and used as the brain of the network. Recently, the research community has showed an increased tendency to benefit from the recent advancements in the artificial intelligence (AI) field to provide learning abilities and better decision making in SDN. In this study, we provide a detailed overview of the recent efforts to include AI in SDN. Our study showed that the research efforts focused on three main sub-fields of AI namely: machine learning, meta-heuristics and fuzzy inference systems. Accordingly, in this work we investigate their different application areas and potential use, as well as the improvements achieved by including AI-based techniques in the SDN paradigm.

</details>

<details>

<summary>2018-11-06 19:09:04 - Online Off-policy Prediction</summary>

- *Sina Ghiassian, Andrew Patterson, Martha White, Richard S. Sutton, Adam White*

- `1811.02597v1` - [abs](http://arxiv.org/abs/1811.02597v1) - [pdf](http://arxiv.org/pdf/1811.02597v1)

> This paper investigates the problem of online prediction learning, where learning proceeds continuously as the agent interacts with an environment. The predictions made by the agent are contingent on a particular way of behaving, represented as a value function. However, the behavior used to select actions and generate the behavior data might be different from the one used to define the predictions, and thus the samples are generated off-policy. The ability to learn behavior-contingent predictions online and off-policy has long been advocated as a key capability of predictive-knowledge learning systems but remained an open algorithmic challenge for decades. The issue lies with the temporal difference (TD) learning update at the heart of most prediction algorithms: combining bootstrapping, off-policy sampling and function approximation may cause the value estimate to diverge. A breakthrough came with the development of a new objective function that admitted stochastic gradient descent variants of TD. Since then, many sound online off-policy prediction algorithms have been developed, but there has been limited empirical work investigating the relative merits of all the variants. This paper aims to fill these empirical gaps and provide clarity on the key ideas behind each method. We summarize the large body of literature on off-policy learning, focusing on 1- methods that use computation linear in the number of features and are convergent under off-policy sampling, and 2- other methods which have proven useful with non-fixed, nonlinear function approximation. We provide an empirical study of off-policy prediction methods in two challenging microworlds. We report each method's parameter sensitivity, empirical convergence rate, and final performance, providing new insights that should enable practitioners to successfully extend these new methods to large-scale applications.[Abridged abstract]

</details>

<details>

<summary>2018-11-06 19:53:52 - Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization</summary>

- *Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett, Bill Dolan*

- `1809.05972v5` - [abs](http://arxiv.org/abs/1809.05972v5) - [pdf](http://arxiv.org/pdf/1809.05972v5)

> Responses generated by neural conversational models tend to lack informativeness and diversity. We present Adversarial Information Maximization (AIM), an adversarial learning strategy that addresses these two related but distinct problems. To foster response diversity, we leverage adversarial training that allows distributional matching of synthetic and real responses. To improve informativeness, our framework explicitly optimizes a variational lower bound on pairwise mutual information between query and response. Empirical results from automatic and human evaluations demonstrate that our methods significantly boost informativeness and diversity.

</details>

<details>

<summary>2018-11-06 22:32:55 - ACE: An Actor Ensemble Algorithm for Continuous Control with Tree Search</summary>

- *Shangtong Zhang, Hao Chen, Hengshuai Yao*

- `1811.02696v1` - [abs](http://arxiv.org/abs/1811.02696v1) - [pdf](http://arxiv.org/pdf/1811.02696v1)

> In this paper, we propose an actor ensemble algorithm, named ACE, for continuous control with a deterministic policy in reinforcement learning. In ACE, we use actor ensemble (i.e., multiple actors) to search the global maxima of the critic. Besides the ensemble perspective, we also formulate ACE in the option framework by extending the option-critic architecture with deterministic intra-option policies, revealing a relationship between ensemble and options. Furthermore, we perform a look-ahead tree search with those actors and a learned value prediction model, resulting in a refined value estimation. We demonstrate a significant performance boost of ACE over DDPG and its variants in challenging physical robot simulators.

</details>

<details>

<summary>2018-11-06 23:21:14 - A Comparison of Techniques for Language Model Integration in Encoder-Decoder Speech Recognition</summary>

- *Shubham Toshniwal, Anjuli Kannan, Chung-Cheng Chiu, Yonghui Wu, Tara N Sainath, Karen Livescu*

- `1807.10857v2` - [abs](http://arxiv.org/abs/1807.10857v2) - [pdf](http://arxiv.org/pdf/1807.10857v2)

> Attention-based recurrent neural encoder-decoder models present an elegant solution to the automatic speech recognition problem. This approach folds the acoustic model, pronunciation model, and language model into a single network and requires only a parallel corpus of speech and text for training. However, unlike in conventional approaches that combine separate acoustic and language models, it is not clear how to use additional (unpaired) text. While there has been previous work on methods addressing this problem, a thorough comparison among methods is still lacking. In this paper, we compare a suite of past methods and some of our own proposed methods for using unpaired text data to improve encoder-decoder models. For evaluation, we use the medium-sized Switchboard data set and the large-scale Google voice search and dictation data sets. Our results confirm the benefits of using unpaired text across a range of methods and data sets. Surprisingly, for first-pass decoding, the rather simple approach of shallow fusion performs best across data sets. However, for Google data sets we find that cold fusion has a lower oracle error rate and outperforms other approaches after second-pass rescoring on the Google voice search data set.

</details>

<details>

<summary>2018-11-06 23:25:45 - Proceedings of the 2018 Workshop on Compositional Approaches in Physics, NLP, and Social Sciences</summary>

- *Martha Lewis, Bob Coecke, Jules Hedges, Dimitri Kartsaklis, Dan Marsden*

- `1811.02701v1` - [abs](http://arxiv.org/abs/1811.02701v1) - [pdf](http://arxiv.org/pdf/1811.02701v1)

> The ability to compose parts to form a more complex whole, and to analyze a whole as a combination of elements, is desirable across disciplines. This workshop bring together researchers applying compositional approaches to physics, NLP, cognitive science, and game theory. Within NLP, a long-standing aim is to represent how words can combine to form phrases and sentences. Within the framework of distributional semantics, words are represented as vectors in vector spaces. The categorical model of Coecke et al. [2010], inspired by quantum protocols, has provided a convincing account of compositionality in vector space models of NLP. There is furthermore a history of vector space models in cognitive science. Theories of categorization such as those developed by Nosofsky [1986] and Smith et al. [1988] utilise notions of distance between feature vectors. More recently G\"ardenfors [2004, 2014] has developed a model of concepts in which conceptual spaces provide geometric structures, and information is represented by points, vectors and regions in vector spaces. The same compositional approach has been applied to this formalism, giving conceptual spaces theory a richer model of compositionality than previously [Bolt et al., 2018]. Compositional approaches have also been applied in the study of strategic games and Nash equilibria. In contrast to classical game theory, where games are studied monolithically as one global object, compositional game theory works bottom-up by building large and complex games from smaller components. Such an approach is inherently difficult since the interaction between games has to be considered. Research into categorical compositional methods for this field have recently begun [Ghani et al., 2018]. Moreover, the interaction between the three disciplines of cognitive science, linguistics and game theory is a fertile ground for research. Game theory in cognitive science is a well-established area [Camerer, 2011]. Similarly game theoretic approaches have been applied in linguistics [J\"ager, 2008]. Lastly, the study of linguistics and cognitive science is intimately intertwined [Smolensky and Legendre, 2006, Jackendoff, 2007]. Physics supplies compositional approaches via vector spaces and categorical quantum theory, allowing the interplay between the three disciplines to be examined.

</details>

<details>

<summary>2018-11-07 01:49:14 - Optimal Number of Choices in Rating Contexts</summary>

- *Sam Ganzfried, Farzana Yusuf*

- `1605.06588v9` - [abs](http://arxiv.org/abs/1605.06588v9) - [pdf](http://arxiv.org/pdf/1605.06588v9)

> In many settings people must give numerical scores to entities from a small discrete set. For instance, rating physical attractiveness from 1--5 on dating sites, or papers from 1--10 for conference reviewing. We study the problem of understanding when using a different number of options is optimal. We consider the case when scores are uniform random and Gaussian. We study computationally when using 2, 3, 4, 5, and 10 options out of a total of 100 is optimal in these models (though our theoretical analysis is for a more general setting with $k$ choices from $n$ total options as well as a continuous underlying space). One may expect that using more options would always improve performance in this model, but we show that this is not necessarily the case, and that using fewer choices---even just two---can surprisingly be optimal in certain situations. While in theory for this setting it would be optimal to use all 100 options, in practice this is prohibitive, and it is preferable to utilize a smaller number of options due to humans' limited computational resources. Our results could have many potential applications, as settings requiring entities to be ranked by humans are ubiquitous. There could also be applications to other fields such as signal or image processing where input values from a large set must be mapped to output values in a smaller set.

</details>

<details>

<summary>2018-11-07 02:18:32 - Distributionally Robust Graphical Models</summary>

- *Rizal Fathony, Ashkan Rezaei, Mohammad Ali Bashiri, Xinhua Zhang, Brian D. Ziebart*

- `1811.02728v1` - [abs](http://arxiv.org/abs/1811.02728v1) - [pdf](http://arxiv.org/pdf/1811.02728v1)

> In many structured prediction problems, complex relationships between variables are compactly defined using graphical structures. The most prevalent graphical prediction methods---probabilistic graphical models and large margin methods---have their own distinct strengths but also possess significant drawbacks. Conditional random fields (CRFs) are Fisher consistent, but they do not permit integration of customized loss metrics into their learning process. Large-margin models, such as structured support vector machines (SSVMs), have the flexibility to incorporate customized loss metrics, but lack Fisher consistency guarantees. We present adversarial graphical models (AGM), a distributionally robust approach for constructing a predictor that performs robustly for a class of data distributions defined using a graphical structure. Our approach enjoys both the flexibility of incorporating customized loss metrics into its design as well as the statistical guarantee of Fisher consistency. We present exact learning and prediction algorithms for AGM with time complexity similar to existing graphical models and show the practical benefits of our approach with experiments.

</details>

<details>

<summary>2018-11-07 02:35:24 - A Probabilistic Model of the Bitcoin Blockchain</summary>

- *Marc Jourdan, Sebastien Blandin, Laura Wynter, Pralhad Deshpande*

- `1812.05451v1` - [abs](http://arxiv.org/abs/1812.05451v1) - [pdf](http://arxiv.org/pdf/1812.05451v1)

> The Bitcoin transaction graph is a public data structure organized as transactions between addresses, each associated with a logical entity. In this work, we introduce a complete probabilistic model of the Bitcoin Blockchain. We first formulate a set of conditional dependencies induced by the Bitcoin protocol at the block level and derive a corresponding fully observed graphical model of a Bitcoin block. We then extend the model to include hidden entity attributes such as the functional category of the associated logical agent and derive asymptotic bounds on the privacy properties implied by this model. At the network level, we show evidence of complex transaction-to-transaction behavior and present a relevant discriminative model of the agent categories. Performance of both the block-based graphical model and the network-level discriminative model is evaluated on a subset of the public Bitcoin Blockchain.

</details>

<details>

<summary>2018-11-07 07:34:23 - Uncertainty in Quantum Rule-Based Systems</summary>

- *Vicente Moret-Bonillo, Isaac Fernández-Varela, Diego Alvarez-Estevez*

- `1811.02782v1` - [abs](http://arxiv.org/abs/1811.02782v1) - [pdf](http://arxiv.org/pdf/1811.02782v1)

> This article deals with the problem of the uncertainty in rule-based systems (RBS), but from the perspective of quantum computing (QC). In this work we first remember the characteristics of Quantum Rule-Based Systems (QRBS), a concept defined in a previous article by one of the authors of this paper, and we introduce the problem of quantum uncertainty. We assume that the subjective uncertainty that affects the facts of classical RBSs can be treated as a direct consequence of the probabilistic nature of quantum mechanics (QM), and we also assume that the uncertainty associated with a given hypothesis is a consequence of the propagation of the imprecision through the inferential circuits of RBSs. This article does not intend to contribute anything new to the QM field: it is a work of artificial intelligence (AI) that uses QC techniques to solve the problem of uncertainty in RBSs. Bearing the above arguments in mind a quantum model is proposed. This model has been applied to a problem already defined by one of the authors of this work in a previous publication and which is briefly described in this article. Then the model is generalized, and it is thoroughly evaluated. The results obtained show that QC is a valid, effective and efficient method to deal with the inherent uncertainty of RBSs

</details>

<details>

<summary>2018-11-07 08:01:21 - RoboTurk: A Crowdsourcing Platform for Robotic Skill Learning through Imitation</summary>

- *Ajay Mandlekar, Yuke Zhu, Animesh Garg, Jonathan Booher, Max Spero, Albert Tung, Julian Gao, John Emmons, Anchit Gupta, Emre Orbay, Silvio Savarese, Li Fei-Fei*

- `1811.02790v1` - [abs](http://arxiv.org/abs/1811.02790v1) - [pdf](http://arxiv.org/pdf/1811.02790v1)

> Imitation Learning has empowered recent advances in learning robotic manipulation tasks by addressing shortcomings of Reinforcement Learning such as exploration and reward specification. However, research in this area has been limited to modest-sized datasets due to the difficulty of collecting large quantities of task demonstrations through existing mechanisms. This work introduces RoboTurk to address this challenge. RoboTurk is a crowdsourcing platform for high quality 6-DoF trajectory based teleoperation through the use of widely available mobile devices (e.g. iPhone). We evaluate RoboTurk on three manipulation tasks of varying timescales (15-120s) and observe that our user interface is statistically similar to special purpose hardware such as virtual reality controllers in terms of task completion times. Furthermore, we observe that poor network conditions, such as low bandwidth and high delay links, do not substantially affect the remote users' ability to perform task demonstrations successfully on RoboTurk. Lastly, we demonstrate the efficacy of RoboTurk through the collection of a pilot dataset; using RoboTurk, we collected 137.5 hours of manipulation data from remote workers, amounting to over 2200 successful task demonstrations in 22 hours of total system usage. We show that the data obtained through RoboTurk enables policy learning on multi-step manipulation tasks with sparse rewards and that using larger quantities of demonstrations during policy learning provides benefits in terms of both learning consistency and final performance. For additional results, videos, and to download our pilot dataset, visit $\href{http://roboturk.stanford.edu/}{\texttt{roboturk.stanford.edu}}$

</details>

<details>

<summary>2018-11-07 08:28:40 - Abstract Argumentation / Persuasion / Dynamics</summary>

- *Ryuta Arisaka, Ken Satoh*

- `1705.10044v3` - [abs](http://arxiv.org/abs/1705.10044v3) - [pdf](http://arxiv.org/pdf/1705.10044v3)

> The act of persuasion, a key component in rhetoric argumentation, may be viewed as a dynamics modifier. We extend Dung's frameworks with acts of persuasion among agents, and consider interactions among attack, persuasion and defence that have been largely unheeded so far. We characterise basic notions of admissibilities in this framework, and show a way of enriching them through, effectively, CTL (computation tree logic) encoding, which also permits importation of the theoretical results known to the logic into our argumentation frameworks. Our aim is to complement the growing interest in coordination of static and dynamic argumentation.

</details>

<details>

<summary>2018-11-07 09:42:21 - Towards Realizing the Smart Product Traceability System</summary>

- *Dharmendra Kumar Mishra, Aicha Sekhari, Sébastien Henry, Dharmendra Mishra, Yacine Ouzrout, Ajay Shrestha, Abdelaziz Bouras*

- `1811.09693v1` - [abs](http://arxiv.org/abs/1811.09693v1) - [pdf](http://arxiv.org/pdf/1811.09693v1)

> The rapid technological enhancement and innovations in current days have changed people's thought. The use of Information Technology tools in people's daily life has changed their life style completely. The advent of various innovative smart products in the market has tremendous impact on people's lifestyle. They want to know their heart beat while they run, they need a smart car which makes them alert when they become sleepy while driving, and they need an IT tool which can make their home safer when they are out. These quests of people to the very extent have been fulfilled by development of many Meta products like wearables, smart phones, smart car etc. The concept of Meta product is based on the fact that they need to offer intelligent services to the users. In present day's Meta products market, the manufacturers have their own cloud based platform which is used by the products for which it is developed. The other products cannot use the common platform. In this paper, we propose a common cloud based platform that will be used by any Meta product's user to get different services.

</details>

<details>

<summary>2018-11-07 11:08:25 - Learning-based Model Predictive Control for Safe Exploration</summary>

- *Torsten Koller, Felix Berkenkamp, Matteo Turchetta, Andreas Krause*

- `1803.08287v3` - [abs](http://arxiv.org/abs/1803.08287v3) - [pdf](http://arxiv.org/pdf/1803.08287v3)

> Learning-based methods have been successful in solving complex control tasks without significant prior knowledge about the system. However, these methods typically do not provide any safety guarantees, which prevents their use in safety-critical, real-world applications. In this paper, we present a learning-based model predictive control scheme that can provide provable high-probability safety guarantees. To this end, we exploit regularity assumptions on the dynamics in terms of a Gaussian process prior to construct provably accurate confidence intervals on predicted trajectories. Unlike previous approaches, we do not assume that model uncertainties are independent. Based on these predictions, we guarantee that trajectories satisfy safety constraints. Moreover, we use a terminal set constraint to recursively guarantee the existence of safe control actions at every iteration. In our experiments, we show that the resulting algorithm can be used to safely and efficiently explore and learn about dynamic systems.

</details>

<details>

<summary>2018-11-07 13:45:19 - Deep Learning can Replicate Adaptive Traders in a Limit-Order-Book Financial Market</summary>

- *Arthur le Calvez, Dave Cliff*

- `1811.02880v1` - [abs](http://arxiv.org/abs/1811.02880v1) - [pdf](http://arxiv.org/pdf/1811.02880v1)

> We report successful results from using deep learning neural networks (DLNNs) to learn, purely by observation, the behavior of profitable traders in an electronic market closely modelled on the limit-order-book (LOB) market mechanisms that are commonly found in the real-world global financial markets for equities (stocks & shares), currencies, bonds, commodities, and derivatives. Successful real human traders, and advanced automated algorithmic trading systems, learn from experience and adapt over time as market conditions change; our DLNN learns to copy this adaptive trading behavior. A novel aspect of our work is that we do not involve the conventional approach of attempting to predict time-series of prices of tradeable securities. Instead, we collect large volumes of training data by observing only the quotes issued by a successful sales-trader in the market, details of the orders that trader is executing, and the data available on the LOB (as would usually be provided by a centralized exchange) over the period that the trader is active. In this paper we demonstrate that suitably configured DLNNs can learn to replicate the trading behavior of a successful adaptive automated trader, an algorithmic system previously demonstrated to outperform human traders. We also demonstrate that DLNNs can learn to perform better (i.e., more profitably) than the trader that provided the training data. We believe that this is the first ever demonstration that DLNNs can successfully replicate a human-like, or super-human, adaptive trader operating in a realistic emulation of a real-world financial market. Our results can be considered as proof-of-concept that a DLNN could, in principle, observe the actions of a human trader in a real financial market and over time learn to trade equally as well as that human trader, and possibly better.

</details>

<details>

<summary>2018-11-07 13:55:01 - Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals</summary>

- *Ellie Birbeck, Dave Cliff*

- `1811.02886v1` - [abs](http://arxiv.org/abs/1811.02886v1) - [pdf](http://arxiv.org/pdf/1811.02886v1)

> The increasing availability of "big" (large volume) social media data has motivated a great deal of research in applying sentiment analysis to predict the movement of prices within financial markets. Previous work in this field investigates how the true sentiment of text (i.e. positive or negative opinions) can be used for financial predictions, based on the assumption that sentiments expressed online are representative of the true market sentiment. Here we consider the converse idea, that using the stock price as the ground-truth in the system may be a better indication of sentiment. Tweets are labelled as Buy or Sell dependent on whether the stock price discussed rose or fell over the following hour, and from this, stock-specific dictionaries are built for individual companies. A Bayesian classifier is used to generate stock predictions, which are input to an automated trading algorithm. Placing 468 trades over a 1 month period yields a return rate of 5.18%, which annualises to approximately 83% per annum. This approach performs significantly better than random chance and outperforms two baseline sentiment analysis methods tested.

</details>

<details>

<summary>2018-11-07 14:21:14 - Cycle Consistent Adversarial Denoising Network for Multiphase Coronary CT Angiography</summary>

- *Eunhee Kang, Hyun Jung Koo, Dong Hyun Yang, Joon Bum Seo, Jong Chul Ye*

- `1806.09748v3` - [abs](http://arxiv.org/abs/1806.09748v3) - [pdf](http://arxiv.org/pdf/1806.09748v3)

> In coronary CT angiography, a series of CT images are taken at different levels of radiation dose during the examination. Although this reduces the total radiation dose, the image quality during the low-dose phases is significantly degraded. To address this problem, here we propose a novel semi-supervised learning technique that can remove the noises of the CT images obtained in the low-dose phases by learning from the CT images in the routine dose phases. Although a supervised learning approach is not possible due to the differences in the underlying heart structure in two phases, the images in the two phases are closely related so that we propose a cycle-consistent adversarial denoising network to learn the non-degenerate mapping between the low and high dose cardiac phases. Experimental results showed that the proposed method effectively reduces the noise in the low-dose CT image while the preserving detailed texture and edge information. Moreover, thanks to the cyclic consistency and identity loss, the proposed network does not create any artificial features that are not present in the input images. Visual grading and quality evaluation also confirm that the proposed method provides significant improvement in diagnostic quality.

</details>

<details>

<summary>2018-11-07 14:57:18 - Analysis of visitors' mobility patterns through random walk in the Louvre museum</summary>

- *Yuji Yoshimura, Roberta Sinatra, Anne Krebs, Carlo Ratti*

- `1811.02918v1` - [abs](http://arxiv.org/abs/1811.02918v1) - [pdf](http://arxiv.org/pdf/1811.02918v1)

> This paper proposes a random walk model to analyze visitors' mobility patterns in a large museum. Visitors' available time makes their visiting styles different, resulting in dissimilarity in the order and number of visited places and in path sequence length. We analyze all this by comparing a simulation model and observed data, which provide us the strength of the visitors' mobility patterns. The obtained results indicate that shorter stay-type visitors exhibit stronger patterns than those with the longer stay-type, confirming that the former are more selective than the latter in terms of their visitation type.

</details>

<details>

<summary>2018-11-07 16:30:08 - Instantly Deployable Expert Knowledge - Networks of Knowledge Engines</summary>

- *Bernhard Bergmair, Thomas Buchegger, Johann Hoffelner, Gerald Schatz, Siegfried Silber, Johannes Klinglmayr*

- `1811.02964v1` - [abs](http://arxiv.org/abs/1811.02964v1) - [pdf](http://arxiv.org/pdf/1811.02964v1)

> Knowledge and information are becoming the primary resources of the emerging information society. To exploit the potential of available expert knowledge, comprehension and application skills (i.e. expert competences) are necessary. The ability to acquire these skills is limited for any individual human. Consequently, the capacities to solve problems based on human knowledge in a manual (i.e. mental) way are strongly limited. We envision a new systemic approach to enable scalable knowledge deployment without expert competences. Eventually, the system is meant to instantly deploy humanity's total knowledge in full depth for every individual challenge. To this end, we propose a socio-technical framework that transforms expert knowledge into a solution creation system. Knowledge is represented by automated algorithms (knowledge engines). Executable compositions of knowledge engines (networks of knowledge engines) generate requested individual information at runtime. We outline how these knowledge representations could yield legal, ethical and social challenges and nurture new business and remuneration models on knowledge. We identify major technological and economic concepts that are already pushing the boundaries in knowledge utilisation: e.g. in artificial intelligence, knowledge bases, ontologies, advanced search tools, automation of knowledge work, the API economy. We indicate impacts on society, economy and labour. Existing developments are linked, including a specific use case in engineering design.

</details>

<details>

<summary>2018-11-07 16:42:51 - Active Fairness in Algorithmic Decision Making</summary>

- *Alejandro Noriega-Campero, Michiel A. Bakker, Bernardo Garcia-Bulle, Alex Pentland*

- `1810.00031v2` - [abs](http://arxiv.org/abs/1810.00031v2) - [pdf](http://arxiv.org/pdf/1810.00031v2)

> Society increasingly relies on machine learning models for automated decision making. Yet, efficiency gains from automation have come paired with concern for algorithmic discrimination that can systematize inequality. Recent work has proposed optimal post-processing methods that randomize classification decisions for a fraction of individuals, in order to achieve fairness measures related to parity in errors and calibration. These methods, however, have raised concern due to the information inefficiency, intra-group unfairness, and Pareto sub-optimality they entail. The present work proposes an alternative active framework for fair classification, where, in deployment, a decision-maker adaptively acquires information according to the needs of different groups or individuals, towards balancing disparities in classification performance. We propose two such methods, where information collection is adapted to group- and individual-level needs respectively. We show on real-world datasets that these can achieve: 1) calibration and single error parity (e.g., equal opportunity); and 2) parity in both false positive and false negative rates (i.e., equal odds). Moreover, we show that by leveraging their additional degree of freedom, active approaches can substantially outperform randomization-based classifiers previously considered optimal, while avoiding limitations such as intra-group unfairness.

</details>

<details>

<summary>2018-11-07 17:20:05 - A Generative Model for Dynamic Networks with Applications</summary>

- *Shubham Gupta, Gaurav Sharma, Ambedkar Dukkipati*

- `1802.03725v2` - [abs](http://arxiv.org/abs/1802.03725v2) - [pdf](http://arxiv.org/pdf/1802.03725v2)

> Networks observed in real world like social networks, collaboration networks etc., exhibit temporal dynamics, i.e. nodes and edges appear and/or disappear over time. In this paper, we propose a generative, latent space based, statistical model for such networks (called dynamic networks). We consider the case where the number of nodes is fixed, but the presence of edges can vary over time. Our model allows the number of communities in the network to be different at different time steps. We use a neural network based methodology to perform approximate inference in the proposed model and its simplified version. Experiments done on synthetic and real world networks for the task of community detection and link prediction demonstrate the utility and effectiveness of our model as compared to other similar existing approaches.

</details>

<details>

<summary>2018-11-07 17:39:24 - Computing the Value of Computation for Planning</summary>

- *Can Eren Sezener*

- `1811.03035v1` - [abs](http://arxiv.org/abs/1811.03035v1) - [pdf](http://arxiv.org/pdf/1811.03035v1)

> An intelligent agent performs actions in order to achieve its goals. Such actions can either be externally directed, such as opening a door, or internally directed, such as writing data to a memory location or strengthening a synaptic connection. Some internal actions, to which we refer as computations, potentially help the agent choose better actions. Considering that (external) actions and computations might draw upon the same resources, such as time and energy, deciding when to act or compute, as well as what to compute, are detrimental to the performance of an agent.   In an environment that provides rewards depending on an agent's behavior, an action's value is typically defined as the sum of expected long-term rewards succeeding the action (itself a complex quantity that depends on what the agent goes on to do after the action in question). However, defining the value of a computation is not as straightforward, as computations are only valuable in a higher order way, through the alteration of actions.   This thesis offers a principled way of computing the value of a computation in a planning setting formalized as a Markov decision process. We present two different definitions of computation values: static and dynamic. They address two extreme cases of the computation budget: affording calculation of zero or infinitely many steps in the future. We show that these values have desirable properties, such as temporal consistency and asymptotic convergence.   Furthermore, we propose methods for efficiently computing and approximating the static and dynamic computation values. We describe a sense in which the policies that greedily maximize these values can be optimal. We utilize these principles to construct Monte Carlo tree search algorithms that outperform most of the state-of-the-art in terms of finding higher quality actions given the same simulation resources.

</details>

<details>

<summary>2018-11-07 18:27:41 - Prototypical Clustering Networks for Dermatological Disease Diagnosis</summary>

- *Viraj Prabhu, Anitha Kannan, Murali Ravuri, Manish Chablani, David Sontag, Xavier Amatriain*

- `1811.03066v1` - [abs](http://arxiv.org/abs/1811.03066v1) - [pdf](http://arxiv.org/pdf/1811.03066v1)

> We consider the problem of image classification for the purpose of aiding doctors in dermatological diagnosis. Dermatological diagnosis poses two major challenges for standard off-the-shelf techniques: First, the data distribution is typically extremely long tailed. Second, intra-class variability is often large. To address the first issue, we formulate the problem as low-shot learning, where once deployed, a base classifier must rapidly generalize to diagnose novel conditions given very few labeled examples. To model diverse classes effectively, we propose Prototypical Clustering Networks (PCN), an extension to Prototypical Networks that learns a mixture of prototypes for each class. Prototypes are initialized for each class via clustering and refined via an online update scheme. Classification is performed by measuring similarity to a weighted combination of prototypes within a class, where the weights are the inferred cluster responsibilities. We demonstrate the strengths of our approach in effective diagnosis on a realistic dataset of dermatological conditions.

</details>

<details>

<summary>2018-11-07 19:52:47 - QUOTA: The Quantile Option Architecture for Reinforcement Learning</summary>

- *Shangtong Zhang, Borislav Mavrin, Linglong Kong, Bo Liu, Hengshuai Yao*

- `1811.02073v2` - [abs](http://arxiv.org/abs/1811.02073v2) - [pdf](http://arxiv.org/pdf/1811.02073v2)

> In this paper, we propose the Quantile Option Architecture (QUOTA) for exploration based on recent advances in distributional reinforcement learning (RL). In QUOTA, decision making is based on quantiles of a value distribution, not only the mean. QUOTA provides a new dimension for exploration via making use of both optimism and pessimism of a value distribution. We demonstrate the performance advantage of QUOTA in both challenging video games and physical robot simulators.

</details>

<details>

<summary>2018-11-07 20:36:53 - Reward Estimation for Variance Reduction in Deep Reinforcement Learning</summary>

- *Joshua Romoff, Peter Henderson, Alexandre Piché, Vincent Francois-Lavet, Joelle Pineau*

- `1805.03359v2` - [abs](http://arxiv.org/abs/1805.03359v2) - [pdf](http://arxiv.org/pdf/1805.03359v2)

> Reinforcement Learning (RL) agents require the specification of a reward signal for learning behaviours. However, introduction of corrupt or stochastic rewards can yield high variance in learning. Such corruption may be a direct result of goal misspecification, randomness in the reward signal, or correlation of the reward with external factors that are not known to the agent. Corruption or stochasticity of the reward signal can be especially problematic in robotics, where goal specification can be particularly difficult for complex tasks. While many variance reduction techniques have been studied to improve the robustness of the RL process, handling such stochastic or corrupted reward structures remains difficult. As an alternative for handling this scenario in model-free RL methods, we suggest using an estimator for both rewards and value functions. We demonstrate that this improves performance under corrupted stochastic rewards in both the tabular and non-linear function approximation settings for a variety of noise types and environments. The use of reward estimation is a robust and easy-to-implement improvement for handling corrupted reward signals in model-free RL.

</details>

<details>

<summary>2018-11-07 21:49:00 - Election with Bribed Voter Uncertainty: Hardness and Approximation Algorithm</summary>

- *Lin Chen, Lei Xu, Shouhuai Xu, Zhimin Gao, Weidong Shi*

- `1811.03158v1` - [abs](http://arxiv.org/abs/1811.03158v1) - [pdf](http://arxiv.org/pdf/1811.03158v1)

> Bribery in election (or computational social choice in general) is an important problem that has received a considerable amount of attention. In the classic bribery problem, the briber (or attacker) bribes some voters in attempting to make the briber's designated candidate win an election. In this paper, we introduce a novel variant of the bribery problem, "Election with Bribed Voter Uncertainty" or BVU for short, accommodating the uncertainty that the vote of a bribed voter may or may not be counted. This uncertainty occurs either because a bribed voter may not cast its vote in fear of being caught, or because a bribed voter is indeed caught and therefore its vote is discarded. As a first step towards ultimately understanding and addressing this important problem, we show that it does not admit any multiplicative $O(1)$-approximation algorithm modulo standard complexity assumptions. We further show that there is an approximation algorithm that returns a solution with an additive-$\epsilon$ error in FPT time for any fixed $\epsilon$.

</details>

<details>

<summary>2018-11-07 22:30:38 - Efficient Formal Safety Analysis of Neural Networks</summary>

- *Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana*

- `1809.08098v3` - [abs](http://arxiv.org/abs/1809.08098v3) - [pdf](http://arxiv.org/pdf/1809.08098v3)

> Neural networks are increasingly deployed in real-world safety-critical domains such as autonomous driving, aircraft collision avoidance, and malware detection. However, these networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations. Consequences of such errors can be disastrous and even potentially fatal as shown by the recent Tesla autopilot crash. Thus, there is an urgent need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations within a certain $L$-norm of a given image. An effective safety analysis system for a neural network must be able to either ensure that a safety property is satisfied by the network or find a counterexample, i.e., an input for which the network will violate the property. Unfortunately, most existing techniques for performing such analysis struggle to scale beyond very small networks and the ones that can scale to larger networks suffer from high false positives and cannot produce concrete counterexamples in case of a property violation. In this paper, we present a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperforms existing approaches by multiple orders of magnitude. Our approach can check different safety properties and find concrete counterexamples for networks that are 10$\times$ larger than the ones supported by existing analysis techniques. We believe that our approach to estimating tight output bounds of a network for a given input range can also help improve the explainability of neural networks and guide the training process of more robust neural networks.

</details>

<details>

<summary>2018-11-08 01:07:17 - Robustness of Conditional GANs to Noisy Labels</summary>

- *Kiran Koshy Thekumparampil, Ashish Khetan, Zinan Lin, Sewoong Oh*

- `1811.03205v1` - [abs](http://arxiv.org/abs/1811.03205v1) - [pdf](http://arxiv.org/pdf/1811.03205v1)

> We study the problem of learning conditional generators from noisy labeled samples, where the labels are corrupted by random noise. A standard training of conditional GANs will not only produce samples with wrong labels, but also generate poor quality samples. We consider two scenarios, depending on whether the noise model is known or not. When the distribution of the noise is known, we introduce a novel architecture which we call Robust Conditional GAN (RCGAN). The main idea is to corrupt the label of the generated sample before feeding to the adversarial discriminator, forcing the generator to produce samples with clean labels. This approach of passing through a matching noisy channel is justified by corresponding multiplicative approximation bounds between the loss of the RCGAN and the distance between the clean real distribution and the generator distribution. This shows that the proposed approach is robust, when used with a carefully chosen discriminator architecture, known as projection discriminator. When the distribution of the noise is not known, we provide an extension of our architecture, which we call RCGAN-U, that learns the noise model simultaneously while training the generator. We show experimentally on MNIST and CIFAR-10 datasets that both the approaches consistently improve upon baseline approaches, and RCGAN-U closely matches the performance of RCGAN.

</details>

<details>

<summary>2018-11-08 01:53:22 - Advanced machine learning informatics modeling using clinical and radiological imaging metrics for characterizing breast tumor characteristics with the OncotypeDX gene array</summary>

- *Michael A. Jacobs, Christopher Umbricht, Vishwa Parekh, Riham El Khouli, Leslie Cope, Katarzyna J. Macura, Susan Harvey, Antonio C. Wolff*

- `1811.03218v1` - [abs](http://arxiv.org/abs/1811.03218v1) - [pdf](http://arxiv.org/pdf/1811.03218v1)

> Purpose-Optimal use of established and imaging methods, such as multiparametric magnetic resonance imaging(mpMRI) can simultaneously identify key functional parameters and provide unique imaging phenotypes of breast cancer. Therefore, we have developed and implemented a new machine-learning informatic system that integrates clinical variables, derived from imaging and clinical health records, to compare with the 21-gene array assay, OncotypeDX. Materials and methods-We tested our informatics modeling in a subset of patients (n=81) who had ER+ disease and underwent OncotypeDX gene expression and breast mpMRI testing. The machine-learning informatic method is termed Integrated Radiomic Informatic System-IRIS was applied to the mpMRI, clinical and pathologic descriptors, as well as a gene array analysis. The IRIS method using an advanced graph theoretic model and quantitative metrics. Summary statistics (mean and standard deviations) for the quantitative imaging parameters were obtained. Sensitivity and specificity and Area Under the Curve were calculated for the classification of the patients. Results-The OncotypeDX classification by IRIS model had sensitivity of 95% and specificity of 89% with AUC of 0.92. The breast lesion size was larger for the high-risk groups and lower for both low risk and intermediate risk groups. There were significant differences in PK-DCE and ADC map values in each group. The ADC map values for high- and intermediate-risk groups were significantly lower than the low-risk group. Conclusion-These initial studies provide deeper understandings of imaging features and molecular gene array OncotypeDX score. This insight provides the foundation to relate these imaging features to the assessment of treatment response for improved personalized medicine.

</details>

<details>

<summary>2018-11-08 02:32:05 - Compositional Language Understanding with Text-based Relational Reasoning</summary>

- *Koustuv Sinha, Shagun Sodhani, William L. Hamilton, Joelle Pineau*

- `1811.02959v2` - [abs](http://arxiv.org/abs/1811.02959v2) - [pdf](http://arxiv.org/pdf/1811.02959v2)

> Neural networks for natural language reasoning have largely focused on extractive, fact-based question-answering (QA) and common-sense inference. However, it is also crucial to understand the extent to which neural networks can perform relational reasoning and combinatorial generalization from natural language---abilities that are often obscured by annotation artifacts and the dominance of language modeling in standard QA benchmarks. In this work, we present a novel benchmark dataset for language understanding that isolates performance on relational reasoning. We also present a neural message-passing baseline and show that this model, which incorporates a relational inductive bias, is superior at combinatorial generalization compared to a traditional recurrent neural network approach.

</details>

<details>

<summary>2018-11-08 03:04:20 - An Efficient Anonymous Authentication Scheme for Internet of Vehicles</summary>

- *Jingwei Liu, Qingqing Li, Rong Sun, Xiaojiang Du, Mohsen Guizani*

- `1811.03239v1` - [abs](http://arxiv.org/abs/1811.03239v1) - [pdf](http://arxiv.org/pdf/1811.03239v1)

> Internet of Vehicles (IoV) is an intelligent application of IoT in smart transportation, which can make intelligent decisions for passengers. It has drawn extensive attention to improve traffic safety and efficiency and create a more comfortable driving and riding environment. Vehicular cloud computing is a variant of mobile cloud computing, which can process local information quickly. The cooperation of the Internet and vehicular cloud can make the communication more efficient in IoV. In this paper, we mainly focus on the secure communication between vehicles and roadside units. We first propose a new certificateless short signature scheme (CLSS) and prove the unforgeability of it in random oracle model. Then, by combining CLSS and a regional management strategy we design an efficient anonymous mutual quick authentication scheme for IoV. Additionally, the quantitative performance analysis shows that the proposed scheme achieves higher efficiency in terms of interaction between vehicles and roadside units compared with other existing schemes.

</details>

<details>

<summary>2018-11-08 05:11:18 - Translating and Evolving: Towards a Model of Language Change in DisCoCat</summary>

- *Tai-Danae Bradley, Martha Lewis, Jade Master, Brad Theilman*

- `1811.11041v1` - [abs](http://arxiv.org/abs/1811.11041v1) - [pdf](http://arxiv.org/pdf/1811.11041v1)

> The categorical compositional distributional (DisCoCat) model of meaning developed by Coecke et al. (2010) has been successful in modeling various aspects of meaning. However, it fails to model the fact that language can change. We give an approach to DisCoCat that allows us to represent language models and translations between them, enabling us to describe translations from one language to another, or changes within the same language. We unify the product space representation given in (Coecke et al., 2010) and the functorial description in (Kartsaklis et al., 2013), in a way that allows us to view a language as a catalogue of meanings. We formalize the notion of a lexicon in DisCoCat, and define a dictionary of meanings between two lexicons. All this is done within the framework of monoidal categories. We give examples of how to apply our methods, and give a concrete suggestion for compositional translation in corpora.

</details>

<details>

<summary>2018-11-08 05:11:59 - Internal Wiring of Cartesian Verbs and Prepositions</summary>

- *Bob Coecke, Martha Lewis, Dan Marsden*

- `1811.05770v1` - [abs](http://arxiv.org/abs/1811.05770v1) - [pdf](http://arxiv.org/pdf/1811.05770v1)

> Categorical compositional distributional semantics (CCDS) allows one to compute the meaning of phrases and sentences from the meaning of their constituent words. A type-structure carried over from the traditional categorial model of grammar a la Lambek becomes a 'wire-structure' that mediates the interaction of word meanings. However, CCDS has a much richer logical structure than plain categorical semantics in that certain words can also be given an 'internal wiring' that either provides their entire meaning or reduces the size their meaning space. Previous examples of internal wiring include relative pronouns and intersective adjectives. Here we establish the same for a large class of well-behaved transitive verbs to which we refer as Cartesian verbs, and reduce the meaning space from a ternary tensor to a unary one. Some experimental evidence is also provided.

</details>

<details>

<summary>2018-11-08 05:12:46 - Classical Copying versus Quantum Entanglement in Natural Language: The Case of VP-ellipsis</summary>

- *Gijs Wijnholds, Mehrnoosh Sadrzadeh*

- `1811.03276v1` - [abs](http://arxiv.org/abs/1811.03276v1) - [pdf](http://arxiv.org/pdf/1811.03276v1)

> This paper compares classical copying and quantum entanglement in natural language by considering the case of verb phrase (VP) ellipsis. VP ellipsis is a non-linear linguistic phenomenon that requires the reuse of resources, making it the ideal test case for a comparative study of different copying behaviours in compositional models of natural language. Following the line of research in compositional distributional semantics set out by (Coecke et al., 2010) we develop an extension of the Lambek calculus which admits a controlled form of contraction to deal with the copying of linguistic resources. We then develop two different compositional models of distributional meaning for this calculus. In the first model, we follow the categorical approach of (Coecke et al., 2013) in which a functorial passage sends the proofs of the grammar to linear maps on vector spaces and we use Frobenius algebras to allow for copying. In the second case, we follow the more traditional approach that one finds in categorial grammars, whereby an intermediate step interprets proofs as non-linear lambda terms, using multiple variable occurrences that model classical copying. As a case study, we apply the models to derive different readings of ambiguous elliptical phrases and compare the analyses that each model provides.

</details>

<details>

<summary>2018-11-08 05:14:19 - Towards Compositional Distributional Discourse Analysis</summary>

- *Bob Coecke, Giovanni de Felice, Dan Marsden, Alexis Toumi*

- `1811.03277v1` - [abs](http://arxiv.org/abs/1811.03277v1) - [pdf](http://arxiv.org/pdf/1811.03277v1)

> Categorical compositional distributional semantics provide a method to derive the meaning of a sentence from the meaning of its individual words: the grammatical reduction of a sentence automatically induces a linear map for composing the word vectors obtained from distributional semantics. In this paper, we extend this passage from word-to-sentence to sentence-to-discourse composition. To achieve this we introduce a notion of basic anaphoric discourses as a mid-level representation between natural language discourse formalised in terms of basic discourse representation structures (DRS); and knowledge base queries over the Semantic Web as described by basic graph patterns in the Resource Description Framework (RDF). This provides a high-level specification for compositional algorithms for question answering and anaphora resolution, and allows us to give a picture of natural language understanding as a process involving both statistical and logical resources.

</details>

<details>

<summary>2018-11-08 05:58:53 - Learning Depthwise Separable Graph Convolution from Data Manifold</summary>

- *Guokun Lai, Hanxiao Liu, Yiming Yang*

- `1710.11577v3` - [abs](http://arxiv.org/abs/1710.11577v3) - [pdf](http://arxiv.org/pdf/1710.11577v3)

> Convolution Neural Network (CNN) has gained tremendous success in computer vision tasks with its outstanding ability to capture the local latent features. Recently, there has been an increasing interest in extending convolution operations to the non-Euclidean geometry. Although various types of convolution operations have been proposed for graphs or manifolds, their connections with traditional convolution over grid-structured data are not well-understood. In this paper, we show that depthwise separable convolution can be successfully generalized for the unification of both graph-based and grid-based convolution methods. Based on this insight we propose a novel Depthwise Separable Graph Convolution (DSGC) approach which is compatible with the tradition convolution network and subsumes existing convolution methods as special cases. It is equipped with the combined strengths in model expressiveness, compatibility (relatively small number of parameters), modularity and computational efficiency in training. Extensive experiments show the outstanding performance of DSGC in comparison with strong baselines on multi-domain benchmark datasets.

</details>

<details>

<summary>2018-11-08 09:33:39 - Context-Aware Hierarchical Online Learning for Performance Maximization in Mobile Crowdsourcing</summary>

- *Sabrina Klos, Cem Tekin, Mihaela van der Schaar, Anja Klein*

- `1705.03822v2` - [abs](http://arxiv.org/abs/1705.03822v2) - [pdf](http://arxiv.org/pdf/1705.03822v2)

> In mobile crowdsourcing (MCS), mobile users accomplish outsourced human intelligence tasks. MCS requires an appropriate task assignment strategy, since different workers may have different performance in terms of acceptance rate and quality. Task assignment is challenging, since a worker's performance (i) may fluctuate, depending on both the worker's current personal context and the task context, (ii) is not known a priori, but has to be learned over time. Moreover, learning context-specific worker performance requires access to context information, which may not be available at a central entity due to communication overhead or privacy concerns. Additionally, evaluating worker performance might require costly quality assessments. In this paper, we propose a context-aware hierarchical online learning algorithm addressing the problem of performance maximization in MCS. In our algorithm, a local controller (LC) in the mobile device of a worker regularly observes the worker's context, her/his decisions to accept or decline tasks and the quality in completing tasks. Based on these observations, the LC regularly estimates the worker's context-specific performance. The mobile crowdsourcing platform (MCSP) then selects workers based on performance estimates received from the LCs. This hierarchical approach enables the LCs to learn context-specific worker performance and it enables the MCSP to select suitable workers. In addition, our algorithm preserves worker context locally, and it keeps the number of required quality assessments low. We prove that our algorithm converges to the optimal task assignment strategy. Moreover, the algorithm outperforms simpler task assignment strategies in experiments based on synthetic and real data.

</details>

<details>

<summary>2018-11-08 11:08:01 - On the Graded Acceptability of Arguments in Abstract and Instantiated Argumentation</summary>

- *Davide Grossi, Sanjay Modgil*

- `1811.03355v1` - [abs](http://arxiv.org/abs/1811.03355v1) - [pdf](http://arxiv.org/pdf/1811.03355v1)

> The paper develops a formal theory of the degree of justification of arguments, which relies solely on the structure of an argumentation framework, and which can be successfully interfaced with approaches to instantiated argumentation. The theory is developed in three steps. First, the paper introduces a graded generalization of the two key notions underpinning Dung's semantics: self-defense and conflict-freeness. This leads to a natural generalization of Dung's semantics, whereby standard extensions are weakened or strengthened depending on the level of self-defense and conflict-freeness they meet. The paper investigates the fixpoint theory of these semantics, establishing existence results for them. Second, the paper shows how graded semantics readily provide an approach to argument rankings, offering a novel contribution to the recently growing research programme on ranking-based semantics. Third, this novel approach to argument ranking is applied and studied in the context of instantiated argumentation frameworks, and in so doing is shown to account for a simple form of accrual of arguments within the Dung paradigm. Finally, the theory is compared in detail with existing approaches.

</details>

<details>

<summary>2018-11-08 13:33:18 - Amanuensis: The Programmer's Apprentice</summary>

- *Thomas Dean, Maurice Chiang, Marcus Gomez, Nate Gruver, Yousef Hindy, Michelle Lam, Peter Lu, Sophia Sanchez, Rohun Saxena, Michael Smith, Lucy Wang, Catherine Wong*

- `1807.00082v2` - [abs](http://arxiv.org/abs/1807.00082v2) - [pdf](http://arxiv.org/pdf/1807.00082v2)

> This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.

</details>

<details>

<summary>2018-11-08 14:33:41 - The RLLChatbot: a solution to the ConvAI challenge</summary>

- *Nicolas Gontier, Koustuv Sinha, Peter Henderson, Iulian Serban, Michael Noseworthy, Prasanna Parthasarathi, Joelle Pineau*

- `1811.02714v2` - [abs](http://arxiv.org/abs/1811.02714v2) - [pdf](http://arxiv.org/pdf/1811.02714v2)

> Current conversational systems can follow simple commands and answer basic questions, but they have difficulty maintaining coherent and open-ended conversations about specific topics. Competitions like the Conversational Intelligence (ConvAI) challenge are being organized to push the research development towards that goal. This article presents in detail the RLLChatbot that participated in the 2017 ConvAI challenge. The goal of this research is to better understand how current deep learning and reinforcement learning tools can be used to build a robust yet flexible open domain conversational agent. We provide a thorough description of how a dialog system can be built and trained from mostly public-domain datasets using an ensemble model. The first contribution of this work is a detailed description and analysis of different text generation models in addition to novel message ranking and selection methods. Moreover, a new open-source conversational dataset is presented. Training on this data significantly improves the Recall@k score of the ranking and selection mechanisms compared to our baseline model responsible for selecting the message returned at each interaction.

</details>

<details>

<summary>2018-11-08 14:43:37 - Unsupervised Attention-guided Image to Image Translation</summary>

- *Youssef A. Mejjati, Christian Richardt, James Tompkin, Darren Cosker, Kwang In Kim*

- `1806.02311v3` - [abs](http://arxiv.org/abs/1806.02311v3) - [pdf](http://arxiv.org/pdf/1806.02311v3)

> Current unsupervised image-to-image translation techniques struggle to focus their attention on individual objects without altering the background or the way multiple objects interact within a scene. Motivated by the important role of attention in human perception, we tackle this limitation by introducing unsupervised attention mechanisms that are jointly adversarialy trained with the generators and discriminators. We demonstrate qualitatively and quantitatively that our approach is able to attend to relevant regions in the image without requiring supervision, and that by doing so it achieves more realistic mappings compared to recent approaches.

</details>

<details>

<summary>2018-11-08 16:25:27 - Scalable Robust Kidney Exchange</summary>

- *Duncan C McElfresh, Hoda Bidkhori, John P Dickerson*

- `1811.03532v1` - [abs](http://arxiv.org/abs/1811.03532v1) - [pdf](http://arxiv.org/pdf/1811.03532v1)

> In barter exchanges, participants directly trade their endowed goods in a constrained economic setting without money. Transactions in barter exchanges are often facilitated via a central clearinghouse that must match participants even in the face of uncertainty---over participants, existence and quality of potential trades, and so on. Leveraging robust combinatorial optimization techniques, we address uncertainty in kidney exchange, a real-world barter market where patients swap (in)compatible paired donors. We provide two scalable robust methods to handle two distinct types of uncertainty in kidney exchange---over the quality and the existence of a potential match. The latter case directly addresses a weakness in all stochastic-optimization-based methods to the kidney exchange clearing problem, which all necessarily require explicit estimates of the probability of a transaction existing---a still-unsolved problem in this nascent market. We also propose a novel, scalable kidney exchange formulation that eliminates the need for an exponential-time constraint generation process in competing formulations, maintains provable optimality, and serves as a subsolver for our robust approach. For each type of uncertainty we demonstrate the benefits of robustness on real data from a large, fielded kidney exchange in the United States. We conclude by drawing parallels between robustness and notions of fairness in the kidney exchange setting.

</details>

<details>

<summary>2018-11-08 17:13:50 - Modular Architecture for StarCraft II with Deep Reinforcement Learning</summary>

- *Dennis Lee, Haoran Tang, Jeffrey O Zhang, Huazhe Xu, Trevor Darrell, Pieter Abbeel*

- `1811.03555v1` - [abs](http://arxiv.org/abs/1811.03555v1) - [pdf](http://arxiv.org/pdf/1811.03555v1)

> We present a novel modular architecture for StarCraft II AI. The architecture splits responsibilities between multiple modules that each control one aspect of the game, such as build-order selection or tactics. A centralized scheduler reviews macros suggested by all modules and decides their order of execution. An updater keeps track of environment changes and instantiates macros into series of executable actions. Modules in this framework can be optimized independently or jointly via human design, planning, or reinforcement learning. We apply deep reinforcement learning techniques to training two out of six modules of a modular agent with self-play, achieving 94% or 87% win rates against the "Harder" (level 5) built-in Blizzard bot in Zerg vs. Zerg matches, with or without fog-of-war.

</details>

<details>

<summary>2018-11-08 18:41:48 - Deep Generative Classifiers for Thoracic Disease Diagnosis with Chest X-ray Images</summary>

- *Chengsheng Mao, Yiheng Pan, Zexian Zeng, Liang Yao, Yuan Luo*

- `1809.07436v2` - [abs](http://arxiv.org/abs/1809.07436v2) - [pdf](http://arxiv.org/pdf/1809.07436v2)

> Thoracic diseases are very serious health problems that plague a large number of people. Chest X-ray is currently one of the most popular methods to diagnose thoracic diseases, playing an important role in the healthcare workflow. However, reading the chest X-ray images and giving an accurate diagnosis remain challenging tasks for expert radiologists. With the success of deep learning in computer vision, a growing number of deep neural network architectures were applied to chest X-ray image classification. However, most of the previous deep neural network classifiers were based on deterministic architectures which are usually very noise-sensitive and are likely to aggravate the overfitting issue. In this paper, to make a deep architecture more robust to noise and to reduce overfitting, we propose using deep generative classifiers to automatically diagnose thorax diseases from the chest X-ray images. Unlike the traditional deterministic classifier, a deep generative classifier has a distribution middle layer in the deep neural network. A sampling layer then draws a random sample from the distribution layer and input it to the following layer for classification. The classifier is generative because the class label is generated from samples of a related distribution. Through training the model with a certain amount of randomness, the deep generative classifiers are expected to be robust to noise and can reduce overfitting and then achieve good performances. We implemented our deep generative classifiers based on a number of well-known deterministic neural network architectures, and tested our models on the chest X-ray14 dataset. The results demonstrated the superiority of deep generative classifiers compared with the corresponding deep deterministic classifiers.

</details>

<details>

<summary>2018-11-08 19:19:53 - Stovepiping and Malicious Software: A Critical Review of AGI Containment</summary>

- *Jason M. Pittman, Jesus P. Espinoza, Courtney Soboleski Crosby*

- `1811.03653v1` - [abs](http://arxiv.org/abs/1811.03653v1) - [pdf](http://arxiv.org/pdf/1811.03653v1)

> Awareness of the possible impacts associated with artificial intelligence has risen in proportion to progress in the field. While there are tremendous benefits to society, many argue that there are just as many, if not more, concerns related to advanced forms of artificial intelligence. Accordingly, research into methods to develop artificial intelligence safely is increasingly important. In this paper, we provide an overview of one such safety paradigm: containment with a critical lens aimed toward generative adversarial networks and potentially malicious artificial intelligence. Additionally, we illuminate the potential for a developmental blindspot in the stovepiping of containment mechanisms.

</details>

<details>

<summary>2018-11-08 21:30:57 - New CleverHans Feature: Better Adversarial Robustness Evaluations with Attack Bundling</summary>

- *Ian Goodfellow*

- `1811.03685v1` - [abs](http://arxiv.org/abs/1811.03685v1) - [pdf](http://arxiv.org/pdf/1811.03685v1)

> This technical report describes a new feature of the CleverHans library called "attack bundling". Many papers about adversarial examples present lists of error rates corresponding to different attack algorithms. A common approach is to take the maximum across this list and compare defenses against that error rate. We argue that a better approach is to use attack bundling: the max should be taken across many examples at the level of individual examples, then the error rate should be calculated by averaging after this maximization operation. Reporting the bundled attacker error rate provides a lower bound on the true worst-case error rate. The traditional approach of reporting the maximum error rate across attacks can underestimate the true worst-case error rate by an amount approaching 100\% as the number of attacks approaches infinity. Attack bundling can be used with different prioritization schemes to optimize quantities such as error rate on adversarial examples, perturbation size needed to cause misclassification, or failure rate when using a specific confidence threshold.

</details>

<details>

<summary>2018-11-09 00:57:11 - EPDA: Enhancing Privacy-Preserving Data Authentication for Mobile Crowd Sensing</summary>

- *Jingwei Liu, Fanghui Cai, Longfei Wu, Rong Sun, Liehuang Zhu, Xiaojiang Du*

- `1811.03725v1` - [abs](http://arxiv.org/abs/1811.03725v1) - [pdf](http://arxiv.org/pdf/1811.03725v1)

> As a popular application, mobile crowd sensing systems aim at providing more convenient service via the swarm intelligence. With the popularity of sensor-embedded smart phones and intelligent wearable devices, mobile crowd sensing is becoming an efficient way to obtain various types of sensing data from individuals, which will make people's life more convenient. However, mobile crowd sensing systems today are facing a critical challenge, namely the privacy leakage of the sensitive information and valuable data, which can raise grave concerns among the participants. To address this issue, we propose an enhanced secure certificateless privacy-preserving verifiable data authentication scheme for mobile crowd sensing, named EPDA. The proposed scheme provides unconditional anonymous data authentication service for mobile crowd sensing, by deploying an improved certificateless ring signature as the cryptogram essential, in which the big sensing data should be signed by one of legitimate members in a specific group and could be verified without exposing the actual identity of the participant. The formal security proof demonstrates that EPDA is secure against existential forgery under adaptive chosen message and identity attacks in random oracle model. Finally, extensive simulations are conducted. The results show that the proposed EPDA efficiently decreases computational cost and time consumption in the sensing data authentication process.

</details>

<details>

<summary>2018-11-09 01:06:58 - VDAS: Verifiable Data Aggregation Scheme for Internet of Things</summary>

- *Jingwei Liu, Jinping Han, Longfei Wu, Rong Sun, Xiaojiang Du*

- `1811.03727v1` - [abs](http://arxiv.org/abs/1811.03727v1) - [pdf](http://arxiv.org/pdf/1811.03727v1)

> Along with the miniaturization of various types of sensors, a mass of intelligent terminals are gaining stronger sensing capability, which raises a deeper perception and better prospect of Internet of Things (IoT). With big sensing data, IoT provides lots of convenient services for the monitoring and management of smart cities and people's daily lives. However, there are still many security challenges influencing the further development of IoT, one of which is how to quickly verify the big data obtained from IoT terminals. Aggregate signature is an efficient approach to perform big data authentication. It can effectively reduce the computation and communication overheads. In this paper, utilizing these features, we construct a verifiable data aggregation scheme for Internet of Things, named VDAS, based on an improved certificateless aggregate signature algorithm. In VDAS, the length of the aggregated authentication message is independent of the number of IoT terminals. Then, we prove that VDAS is existentially unforgeable under adaptive chosen message attacks assuming that the computational Diffie-Hellman problem is hard. Additionally, the proposed VDAS achieves a better trade-off on the computation overheads between the resource-constrained IoT terminals and the data center.

</details>

<details>

<summary>2018-11-09 03:02:35 - Imagining an Engineer: On GAN-Based Data Augmentation Perpetuating Biases</summary>

- *Niharika Jain, Lydia Manikonda, Alberto Olmo Hernandez, Sailik Sengupta, Subbarao Kambhampati*

- `1811.03751v1` - [abs](http://arxiv.org/abs/1811.03751v1) - [pdf](http://arxiv.org/pdf/1811.03751v1)

> The use of synthetic data generated by Generative Adversarial Networks (GANs) has become quite a popular method to do data augmentation for many applications. While practitioners celebrate this as an economical way to get more synthetic data that can be used to train downstream classifiers, it is not clear that they recognize the inherent pitfalls of this technique. In this paper, we aim to exhort practitioners against deriving any false sense of security against data biases based on data augmentation. To drive this point home, we show that starting with a dataset consisting of head-shots of engineering researchers, GAN-based augmentation "imagines" synthetic engineers, most of whom have masculine features and white skin color (inferred from a human subject study conducted on Amazon Mechanical Turk). This demonstrates how biases inherent in the training data are reinforced, and sometimes even amplified, by GAN-based data augmentation; it should serve as a cautionary tale for the lay practitioners.

</details>

<details>

<summary>2018-11-09 07:06:46 - Encoding Implicit Relation Requirements for Relation Extraction: A Joint Inference Approach</summary>

- *Liwei Chen, Yansong Feng, Songfang Huang, Bingfeng Luo, Dongyan Zhao*

- `1811.03796v1` - [abs](http://arxiv.org/abs/1811.03796v1) - [pdf](http://arxiv.org/pdf/1811.03796v1)

> Relation extraction is the task of identifying predefined relationship between entities, and plays an essential role in information extraction, knowledge base construction, question answering and so on. Most existing relation extractors make predictions for each entity pair locally and individually, while ignoring implicit global clues available across different entity pairs and in the knowledge base, which often leads to conflicts among local predictions from different entity pairs. This paper proposes a joint inference framework that employs such global clues to resolve disagreements among local predictions. We exploit two kinds of clues to generate constraints which can capture the implicit type and cardinality requirements of a relation. Those constraints can be examined in either hard style or soft style, both of which can be effectively explored in an integer linear program formulation. Experimental results on both English and Chinese datasets show that our proposed framework can effectively utilize those two categories of global clues and resolve the disagreements among local predictions, thus improve various relation extractors when such clues are applicable to the datasets. Our experiments also indicate that the clues learnt automatically from existing knowledge bases perform comparably to or better than those refined by human.

</details>

<details>

<summary>2018-11-09 08:58:16 - The Price of Governance: A Middle Ground Solution to Coordination in Organizational Control</summary>

- *Chao Yu*

- `1811.03819v1` - [abs](http://arxiv.org/abs/1811.03819v1) - [pdf](http://arxiv.org/pdf/1811.03819v1)

> Achieving coordination is crucial in organizational control. This paper investigates a middle ground solution between decentralized interactions and centralized administrations for coordinating agents beyond inefficient behavior. We first propose the price of governance (PoG) to evaluate how such a middle ground solution performs in terms of effectiveness and cost. We then propose a hierarchical supervision framework to explicitly model the PoG, and define step by step how to realize the core principle of the framework and compute the optimal PoG for a control problem. Two illustrative case studies are carried out to exemplify the applications of the proposed framework and its methodology. Results show that by properly formulating and implementing each step, the hierarchical supervision framework is capable of promoting coordination among agents while bounding administrative cost to a minimum in different kinds of organizational control problems.

</details>

<details>

<summary>2018-11-09 09:07:52 - A Very Brief and Critical Discussion on AutoML</summary>

- *Bin Liu*

- `1811.03822v1` - [abs](http://arxiv.org/abs/1811.03822v1) - [pdf](http://arxiv.org/pdf/1811.03822v1)

> This contribution presents a very brief and critical discussion on automated machine learning (AutoML), which is categorized here into two classes, referred to as narrow AutoML and generalized AutoML, respectively. The conclusions yielded from this discussion can be summarized as follows: (1) most existent research on AutoML belongs to the class of narrow AutoML; (2) advances in narrow AutoML are mainly motivated by commercial needs, while any possible benefit obtained is definitely at a cost of increase in computing burdens; (3)the concept of generalized AutoML has a strong tie in spirit with artificial general intelligence (AGI), also called "strong AI", for which obstacles abound for obtaining pivotal progresses.

</details>

<details>

<summary>2018-11-09 10:34:53 - Sample-Efficient Policy Learning based on Completely Behavior Cloning</summary>

- *Qiming Zou, Ling Wang, Ke Lu, Yu Li*

- `1811.03853v1` - [abs](http://arxiv.org/abs/1811.03853v1) - [pdf](http://arxiv.org/pdf/1811.03853v1)

> Direct policy search is one of the most important algorithm of reinforcement learning. However, learning from scratch needs a large amount of experience data and can be easily prone to poor local optima. In addition to that, a partially trained policy tends to perform dangerous action to agent and environment. In order to overcome these challenges, this paper proposed a policy initialization algorithm called Policy Learning based on Completely Behavior Cloning (PLCBC). PLCBC first transforms the Model Predictive Control (MPC) controller into a piecewise affine (PWA) function using multi-parametric programming, and uses a neural network to express this function. By this way, PLCBC can completely clone the MPC controller without any performance loss, and is totally training-free. The experiments show that this initialization strategy can help agent learn at the high reward state region, and converge faster and better.

</details>

<details>

<summary>2018-11-09 11:41:10 - Reasoning From Data in the Mathematical Theory of Evidence</summary>

- *Mieczysław Kłopotek*

- `1811.04790v1` - [abs](http://arxiv.org/abs/1811.04790v1) - [pdf](http://arxiv.org/pdf/1811.04790v1)

> Mathematical Theory of Evidence (MTE) is known as a foundation for reasoning when knowledge is expressed at various levels of detail. Though much research effort has been committed to this theory since its foundation, many questions remain open. One of the most important open questions seems to be the relationship between frequencies and the Mathematical Theory of Evidence. The theory is blamed to leave frequencies outside (or aside of) its framework. The seriousness of this accusation is obvious: no experiment may be run to compare the performance of MTE-based models of real world processes against real world data.   In this paper we develop a frequentist model of the MTE bringing to fall the above argument against MTE. We describe, how to interpret data in terms of MTE belief functions, how to reason from data about conditional belief functions, how to generate a random sample out of a MTE model, how to derive MTE model from data and how to compare results of reasoning in MTE model and reasoning from data.   It is claimed in this paper that MTE is suitable to model some types of destructive processes

</details>

<details>

<summary>2018-11-09 11:44:05 - Learning Semantic Representations for Novel Words: Leveraging Both Form and Context</summary>

- *Timo Schick, Hinrich Schütze*

- `1811.03866v1` - [abs](http://arxiv.org/abs/1811.03866v1) - [pdf](http://arxiv.org/pdf/1811.03866v1)

> Word embeddings are a key component of high-performing natural language processing (NLP) systems, but it remains a challenge to learn good representations for novel words on the fly, i.e., for words that did not occur in the training data. The general problem setting is that word embeddings are induced on an unlabeled training corpus and then a model is trained that embeds novel words into this induced embedding space. Currently, two approaches for learning embeddings of novel words exist: (i) learning an embedding from the novel word's surface-form (e.g., subword n-grams) and (ii) learning an embedding from the context in which it occurs. In this paper, we propose an architecture that leverages both sources of information - surface-form and context - and show that it results in large increases in embedding quality. Our architecture obtains state-of-the-art results on the Definitional Nonce and Contextual Rare Words datasets. As input, we only require an embedding set and an unlabeled corpus for training our architecture to produce embeddings appropriate for the induced embedding space. Thus, our model can easily be integrated into any existing NLP system and enhance its capability to handle novel words.

</details>

<details>

<summary>2018-11-09 11:48:44 - Suggesting Cooking Recipes Through Simulation and Bayesian Optimization</summary>

- *Eduardo C. Garrido-Merchán, Alejandro Albarca-Molina*

- `1811.03868v1` - [abs](http://arxiv.org/abs/1811.03868v1) - [pdf](http://arxiv.org/pdf/1811.03868v1)

> Cooking typically involves a plethora of decisions about ingredients and tools that need to be chosen in order to write a good cooking recipe. Cooking can be modelled in an optimization framework, as it involves a search space of ingredients, kitchen tools, cooking times or temperatures. If we model as an objective function the quality of the recipe, several problems arise. No analytical expression can model all the recipes, so no gradients are available. The objective function is subjective, in other words, it contains noise. Moreover, evaluations are expensive both in time and human resources. Bayesian Optimization (BO) emerges as an ideal methodology to tackle problems with these characteristics. In this paper, we propose a methodology to suggest recipe recommendations based on a Machine Learning (ML) model that fits real and simulated data and BO. We provide empirical evidence with two experiments that support the adequacy of the methodology.

</details>

<details>

<summary>2018-11-09 12:01:26 - Mathematical Theory of Evidence Versus Evidence</summary>

- *Mieczysław Kłopotek*

- `1811.04787v1` - [abs](http://arxiv.org/abs/1811.04787v1) - [pdf](http://arxiv.org/pdf/1811.04787v1)

> This paper is concerned with the apparent greatest weakness of the Mathematical Theory of Evidence (MTE) of Shafer \cite{Shafer:76}, which has been strongly criticized by Wasserman \cite{Wasserman:92ijar}.   Weaknesses of Shafer's proposal \cite{Shafer:90b} of probabilistic interpretation of MTE belief functions is demonstrated. Thereafter a new probabilistic interpretation of MTE conforming both to definition of belief function and to Dempster's rule of combination of independent evidence. It is shown that shaferian conditioning of belief functions on observations \cite{Shafer:90b} may be treated as selection combined with modification of data, that is data is not viewed as it is but it is casted into one's beliefs in what it should be like.

</details>

<details>

<summary>2018-11-09 12:06:16 - Patient-Centric Cellular Networks Optimization using Big Data Analytics</summary>

- *Mohammed S. Hadi, Ahmed Q. Lawey, Taisir E. H. El-Gorashi, J. M. H Elmirghani*

- `1812.04712v1` - [abs](http://arxiv.org/abs/1812.04712v1) - [pdf](http://arxiv.org/pdf/1812.04712v1)

> Big data analytics is one of the state-of-the-art tools to optimize networks and transform them from merely being a blind tube that conveys data, into a cognitive, conscious, and self-optimizing entity that can intelligently adapt according to the needs of its users. This, in fact, can be regarded as one of the highest forthcoming priorities of future networks. In this paper, we propose a system for Out-Patient (OP) centric Long Term Evolution-Advanced (LTE-A) network optimization. Big data harvested from the OPs' medical records, along with current readings from their body sensors are processed and analyzed to predict the likelihood of a life-threatening medical condition, for instance, an imminent stroke. This prediction is used to ensure that the OP is assigned an optimal LTE-A Physical Resource Blocks (PRBs) to transmit their critical data to their healthcare provider with minimal delay. To the best of our knowledge, this is the first time big data analytics are utilized to optimize a cellular network in an OP-conscious manner. The PRBs assignment is optimized using Mixed Integer Linear Programming (MILP) and a real-time heuristic. Two approaches are proposed, the Weighted Sum Rate Maximization (WSRMax) approach and the Proportional Fairness (PF) approach. The approaches increased the OPs' average SINR by 26.6% and 40.5%, respectively. The WSRMax approach increased the system's total SINR to a level higher than that of the PF approach, however, the PF approach reported higher SINRs for the OPs, better fairness and a lower margin of error.

</details>

<details>

<summary>2018-11-09 12:28:53 - Enhancing Operation of a Sewage Pumping Station for Inter Catchment Wastewater Transfer by Using Deep Learning and Hydraulic Model</summary>

- *Duo Zhang, Erlend Skullestad Holland, Geir Lindholm, Harsha Ratnaweera*

- `1811.06367v1` - [abs](http://arxiv.org/abs/1811.06367v1) - [pdf](http://arxiv.org/pdf/1811.06367v1)

> This paper presents a novel Inter Catchment Wastewater Transfer (ICWT) method for mitigating sewer overflow. The ICWT aims at balancing the spatial mismatch of sewer flow and treatment capacity of Wastewater Treatment Plant (WWTP), through collaborative operation of sewer system facilities. Using a hydraulic model, the effectiveness of ICWT is investigated in a sewer system in Drammen, Norway. Concerning the whole system performance, we found that the S{\o}ren Lemmich pump station plays a vital role in the ICWT framework. To enhance the operation of this pump station, it is imperative to construct a multi-step ahead water level prediction model. Hence, one of the most promising artificial intelligence techniques, Long Short Term Memory (LSTM), is employed to undertake this task. Experiments demonstrated that LSTM is superior to Gated Recurrent Unit (GRU), Recurrent Neural Network (RNN), Feed-forward Neural Network (FFNN) and Support Vector Regression (SVR).

</details>

<details>

<summary>2018-11-09 14:26:16 - Expeditious Generation of Knowledge Graph Embeddings</summary>

- *Tommaso Soru, Stefano Ruberto, Diego Moussallem, André Valdestilhas, Alexander Bigerl, Edgard Marx, Diego Esteves*

- `1803.07828v2` - [abs](http://arxiv.org/abs/1803.07828v2) - [pdf](http://arxiv.org/pdf/1803.07828v2)

> Knowledge Graph Embedding methods aim at representing entities and relations in a knowledge base as points or vectors in a continuous vector space. Several approaches using embeddings have shown promising results on tasks such as link prediction, entity recommendation, question answering, and triplet classification. However, only a few methods can compute low-dimensional embeddings of very large knowledge bases without needing state-of-the-art computational resources. In this paper, we propose KG2Vec, a simple and fast approach to Knowledge Graph Embedding based on the skip-gram model. Instead of using a predefined scoring function, we learn it relying on Long Short-Term Memories. We show that our embeddings achieve results comparable with the most scalable approaches on knowledge graph completion as well as on a new metric. Yet, KG2Vec can embed large graphs in lesser time by processing more than 250 million triples in less than 7 hours on common hardware.

</details>

<details>

<summary>2018-11-09 18:03:14 - A Microprocessor implemented in 65nm CMOS with Configurable and Bit-scalable Accelerator for Programmable In-memory Computing</summary>

- *Hongyang Jia, Yinqi Tang, Hossein Valavi, Jintao Zhang, Naveen Verma*

- `1811.04047v1` - [abs](http://arxiv.org/abs/1811.04047v1) - [pdf](http://arxiv.org/pdf/1811.04047v1)

> This paper presents a programmable in-memory-computing processor, demonstrated in a 65nm CMOS technology. For data-centric workloads, such as deep neural networks, data movement often dominates when implemented with today's computing architectures. This has motivated spatial architectures, where the arrangement of data-storage and compute hardware is distributed and explicitly aligned to the computation dataflow, most notably for matrix-vector multiplication. In-memory computing is a spatial architecture where processing elements correspond to dense bit cells, providing local storage and compute, typically employing analog operation. Though this raises the potential for high energy efficiency and throughput, analog operation has significantly limited robustness, scale, and programmability. This paper describes a 590kb in-memory-computing accelerator integrated in a programmable processor architecture, by exploiting recent approaches to charge-domain in-memory computing. The architecture takes the approach of tight coupling with an embedded CPU, through accelerator interfaces enabling integration in the standard processor memory space. Additionally, a near-memory-computing datapath both enables diverse computations locally, to address operations required across applications, and enables bit-precision scalability for matrix/input-vector elements, through a bit-parallel/bit-serial (BP/BS) scheme. Chip measurements show an energy efficiency of 152/297 1b-TOPS/W and throughput of 4.7/1.9 1b-TOPS (scaling linearly with the matrix/input-vector element precisions) at VDD of 1.2/0.85V. Neural network demonstrations with 1-b/4-b weights and activations for CIFAR-10 classification consume 5.3/105.2 $\mu$J/image at 176/23 fps, with accuracy at the level of digital/software implementation (89.3/92.4 $\%$ accuracy).

</details>

<details>

<summary>2018-11-09 19:41:56 - ADNet: A Deep Network for Detecting Adverts</summary>

- *Murhaf Hossari, Soumyabrata Dev, Matthew Nicholson, Killian McCabe, Atul Nautiyal, Clare Conran, Jian Tang, Wei Xu, François Pitié*

- `1811.04115v1` - [abs](http://arxiv.org/abs/1811.04115v1) - [pdf](http://arxiv.org/pdf/1811.04115v1)

> Online video advertising gives content providers the ability to deliver compelling content, reach a growing audience, and generate additional revenue from online media. Recently, advertising strategies are designed to look for original advert(s) in a video frame, and replacing them with new adverts. These strategies, popularly known as product placement or embedded marketing, greatly help the marketing agencies to reach out to a wider audience. However, in the existing literature, such detection of candidate frames in a video sequence for the purpose of advert integration, is done manually. In this paper, we propose a deep-learning architecture called ADNet, that automatically detects the presence of advertisements in video frames. Our approach is the first of its kind that automatically detects the presence of adverts in a video frame, and achieves state-of-the-art results on a public dataset.

</details>

<details>

<summary>2018-11-09 20:08:58 - Reinforcement Learning for Automatic Test Case Prioritization and Selection in Continuous Integration</summary>

- *Helge Spieker, Arnaud Gotlieb, Dusica Marijan, Morten Mossige*

- `1811.04122v1` - [abs](http://arxiv.org/abs/1811.04122v1) - [pdf](http://arxiv.org/pdf/1811.04122v1)

> Testing in Continuous Integration (CI) involves test case prioritization, selection, and execution at each cycle. Selecting the most promising test cases to detect bugs is hard if there are uncertainties on the impact of committed code changes or, if traceability links between code and tests are not available. This paper introduces Retecs, a new method for automatically learning test case selection and prioritization in CI with the goal to minimize the round-trip time between code commits and developer feedback on failed test cases. The Retecs method uses reinforcement learning to select and prioritize test cases according to their duration, previous last execution and failure history. In a constantly changing environment, where new test cases are created and obsolete test cases are deleted, the Retecs method learns to prioritize error-prone test cases higher under guidance of a reward function and by observing previous CI cycles. By applying Retecs on data extracted from three industrial case studies, we show for the first time that reinforcement learning enables fruitful automatic adaptive test case selection and prioritization in CI and regression testing.

</details>

<details>

<summary>2018-11-09 21:00:46 - Reasoning over RDF Knowledge Bases using Deep Learning</summary>

- *Monireh Ebrahimi, Md Kamruzzaman Sarker, Federico Bianchi, Ning Xie, Derek Doran, Pascal Hitzler*

- `1811.04132v1` - [abs](http://arxiv.org/abs/1811.04132v1) - [pdf](http://arxiv.org/pdf/1811.04132v1)

> Semantic Web knowledge representation standards, and in particular RDF and OWL, often come endowed with a formal semantics which is considered to be of fundamental importance for the field. Reasoning, i.e., the drawing of logical inferences from knowledge expressed in such standards, is traditionally based on logical deductive methods and algorithms which can be proven to be sound and complete and terminating, i.e. correct in a very strong sense. For various reasons, though, in particular, the scalability issues arising from the ever-increasing amounts of Semantic Web data available and the inability of deductive algorithms to deal with noise in the data, it has been argued that alternative means of reasoning should be investigated which bear high promise for high scalability and better robustness. From this perspective, deductive algorithms can be considered the gold standard regarding correctness against which alternative methods need to be tested. In this paper, we show that it is possible to train a Deep Learning system on RDF knowledge graphs, such that it is able to perform reasoning over new RDF knowledge graphs, with high precision and recall compared to the deductive gold standard.

</details>

<details>

<summary>2018-11-10 01:46:28 - New Movement and Transformation Principle of Fuzzy Reasoning and Its Application to Fuzzy Neural Network</summary>

- *Chung-Jin Kwak, Son-Il Kwak, Dae-Song Kang, Song-Il Choe, Jin-Ung Kim, Hyok-Gi Chea*

- `1811.04173v1` - [abs](http://arxiv.org/abs/1811.04173v1) - [pdf](http://arxiv.org/pdf/1811.04173v1)

> In this paper, we propose a new fuzzy reasoning principle, so called Movement and Transformation Principle(MTP). This Principle is to obtain a new fuzzy reasoning result by Movement and Transformation the consequent fuzzy set in response to the Movement, Transformation, and Movement-Transformation operations between the antecedent fuzzy set and fuzzificated observation information. And then we presented fuzzy modus ponens and fuzzy modus tollens based on MTP. We compare proposed method with Mamdani fuzzy system, Sugeno fuzzy system, Wang distance type fuzzy reasoning method and Hellendoorn functional type method. And then we applied to the learning experiments of the fuzzy neural network based on MTP and compared it with the Sugeno method. Through prediction experiments of fuzzy neural network on the precipitation data and security situation data, learning accuracy and time performance are clearly improved. Consequently we show that our method based on MTP is computationally simple and does not involve nonlinear operations, so it is easy to handle mathematically.

</details>

<details>

<summary>2018-11-10 02:31:56 - Deep Dynamical Modeling and Control of Unsteady Fluid Flows</summary>

- *Jeremy Morton, Freddie D. Witherden, Antony Jameson, Mykel J. Kochenderfer*

- `1805.07472v2` - [abs](http://arxiv.org/abs/1805.07472v2) - [pdf](http://arxiv.org/pdf/1805.07472v2)

> The design of flow control systems remains a challenge due to the nonlinear nature of the equations that govern fluid flow. However, recent advances in computational fluid dynamics (CFD) have enabled the simulation of complex fluid flows with high accuracy, opening the possibility of using learning-based approaches to facilitate controller design. We present a method for learning the forced and unforced dynamics of airflow over a cylinder directly from CFD data. The proposed approach, grounded in Koopman theory, is shown to produce stable dynamical models that can predict the time evolution of the cylinder system over extended time horizons. Finally, by performing model predictive control with the learned dynamical models, we are able to find a straightforward, interpretable control law for suppressing vortex shedding in the wake of the cylinder.

</details>

<details>

<summary>2018-11-10 03:43:05 - CAPTAIN: Comprehensive Composition Assistance for Photo Taking</summary>

- *Farshid Farhat, Mohammad Mahdi Kamani, James Z. Wang*

- `1811.04184v1` - [abs](http://arxiv.org/abs/1811.04184v1) - [pdf](http://arxiv.org/pdf/1811.04184v1)

> Many people are interested in taking astonishing photos and sharing with others. Emerging hightech hardware and software facilitate ubiquitousness and functionality of digital photography. Because composition matters in photography, researchers have leveraged some common composition techniques to assess the aesthetic quality of photos computationally. However, composition techniques developed by professionals are far more diverse than well-documented techniques can cover. We leverage the vast underexplored innovations in photography for computational composition assistance. We propose a comprehensive framework, named CAPTAIN (Composition Assistance for Photo Taking), containing integrated deep-learned semantic detectors, sub-genre categorization, artistic pose clustering, personalized aesthetics-based image retrieval, and style set matching. The framework is backed by a large dataset crawled from a photo-sharing Website with mostly photography enthusiasts and professionals. The work proposes a sequence of steps that have not been explored in the past by researchers. The work addresses personal preferences for composition through presenting a ranked-list of photographs to the user based on user-specified weights in the similarity measure. The matching algorithm recognizes the best shot among a sequence of shots with respect to the user's preferred style set. We have conducted a number of experiments on the newly proposed components and reported findings. A user study demonstrates that the work is useful to those taking photos.

</details>

<details>

<summary>2018-11-10 09:43:26 - Number Sequence Prediction Problems for Evaluating Computational Powers of Neural Networks</summary>

- *Hyoungwook Nam, Segwang Kim, Kyomin Jung*

- `1805.07494v2` - [abs](http://arxiv.org/abs/1805.07494v2) - [pdf](http://arxiv.org/pdf/1805.07494v2)

> Inspired by number series tests to measure human intelligence, we suggest number sequence prediction tasks to assess neural network models' computational powers for solving algorithmic problems. We define the complexity and difficulty of a number sequence prediction task with the structure of the smallest automaton that can generate the sequence. We suggest two types of number sequence prediction problems: the number-level and the digit-level problems. The number-level problems format sequences as 2-dimensional grids of digits and the digit-level problems provide a single digit input per a time step. The complexity of a number-level sequence prediction can be defined with the depth of an equivalent combinatorial logic, and the complexity of a digit-level sequence prediction can be defined with an equivalent state automaton for the generation rule. Experiments with number-level sequences suggest that CNN models are capable of learning the compound operations of sequence generation rules, but the depths of the compound operations are limited. For the digit-level problems, simple GRU and LSTM models can solve some problems with the complexity of finite state automata. Memory augmented models such as Stack-RNN, Attention, and Neural Turing Machines can solve the reverse-order task which has the complexity of simple pushdown automaton. However, all of above cannot solve general Fibonacci, Arithmetic or Geometric sequence generation problems that represent the complexity of queue automata or Turing machines. The results show that our number sequence prediction problems effectively evaluate machine learning models' computational capabilities.

</details>

<details>

<summary>2018-11-10 10:57:11 - The unreasonable effectiveness of small neural ensembles in high-dimensional brain</summary>

- *A. N. Gorban, V. A. Makarov, I. Y. Tyukin*

- `1809.07656v2` - [abs](http://arxiv.org/abs/1809.07656v2) - [pdf](http://arxiv.org/pdf/1809.07656v2)

> Despite the widely-spread consensus on the brain complexity, sprouts of the single neuron revolution emerged in neuroscience in the 1970s. They brought many unexpected discoveries, including grandmother or concept cells and sparse coding of information in the brain.   In machine learning for a long time, the famous curse of dimensionality seemed to be an unsolvable problem. Nevertheless, the idea of the blessing of dimensionality becomes gradually more and more popular. Ensembles of non-interacting or weakly interacting simple units prove to be an effective tool for solving essentially multidimensional problems. This approach is especially useful for one-shot (non-iterative) correction of errors in large legacy artificial intelligence systems.   These simplicity revolutions in the era of complexity have deep fundamental reasons grounded in geometry of multidimensional data spaces. To explore and understand these reasons we revisit the background ideas of statistical physics. In the course of the 20th century they were developed into the concentration of measure theory. New stochastic separation theorems reveal the fine structure of the data clouds.   We review and analyse biological, physical, and mathematical problems at the core of the fundamental question: how can high-dimensional brain organise reliable and fast learning in high-dimensional world of data by simple tools?   Two critical applications are reviewed to exemplify the approach: one-shot correction of errors in intellectual systems and emergence of static and associative memories in ensembles of single neurons.

</details>

<details>

<summary>2018-11-10 11:20:18 - Towards Formula Translation using Recursive Neural Networks</summary>

- *Felix Petersen, Moritz Schubotz, Bela Gipp*

- `1811.04234v1` - [abs](http://arxiv.org/abs/1811.04234v1) - [pdf](http://arxiv.org/pdf/1811.04234v1)

> While it has become common to perform automated translations on natural language, performing translations between different representations of mathematical formulae has thus far not been possible. We implemented the first translator for mathematical formulae based on recursive neural networks. We chose recursive neural networks because mathematical formulae inherently include a structural encoding. In our implementation, we developed new techniques and topologies for recursive tree-to-tree neural networks based on multi-variate multi-valued Long Short-Term Memory cells. We propose a novel approach for mini-batch training that utilizes clustering and tree traversal. We evaluate our translator and analyze the behavior of our proposed topologies and techniques based on a translation from generic LaTeX to the semantic LaTeX notation. We use the semantic LaTeX notation from the Digital Library for Mathematical Formulae and the Digital Repository for Mathematical Formulae at the National Institute for Standards and Technology. We find that a simple heuristics-based clustering algorithm outperforms the conventional clustering algorithms on the task of clustering binary trees of mathematical formulae with respect to their topology. Furthermore, we find a mask for the loss function, which can prevent the neural network from finding a local minimum of the loss function. Given our preliminary results, a complete translation from formula to formula is not yet possible. However, we achieved a prediction accuracy of 47.05% for predicting symbols at the correct position and an accuracy of 92.3% when ignoring the predicted position. Concluding, our work advances the field of recursive neural networks by improving the training speed and quality of training. In the future, we will work towards a complete translation allowing a machine-interpretation of LaTeX formulae.

</details>

<details>

<summary>2018-11-10 13:05:02 - Ineffectiveness of Dictionary Coding to Infer Predictability Limits of Human Mobility</summary>

- *Yunheng Han, Weiwei Sun, Baihua Zheng*

- `1810.06405v2` - [abs](http://arxiv.org/abs/1810.06405v2) - [pdf](http://arxiv.org/pdf/1810.06405v2)

> Recently, a series of models have been proposed to predict future movements of people. Meanwhile, dictionary coding algorithms are used to estimate the predictability limit of human mobility. Although dictionary coding is optimal, it takes long time to converge. Consequently, it is ineffective to infer predictability through dictionary coding algorithms. In this report, we illustrate this ineffectiveness on the basis of human movements in urban space.

</details>

<details>

<summary>2018-11-10 15:26:31 - Learning Shaping Strategies in Human-in-the-loop Interactive Reinforcement Learning</summary>

- *Chao Yu, Tianpei Yang, Wenxuan Zhu, Dongxu wang, Guangliang Li*

- `1811.04272v1` - [abs](http://arxiv.org/abs/1811.04272v1) - [pdf](http://arxiv.org/pdf/1811.04272v1)

> Providing reinforcement learning agents with informationally rich human knowledge can dramatically improve various aspects of learning. Prior work has developed different kinds of shaping methods that enable agents to learn efficiently in complex environments. All these methods, however, tailor human guidance to agents in specialized shaping procedures, thus embodying various characteristics and advantages in different domains. In this paper, we investigate the interplay between different shaping methods for more robust learning performance. We propose an adaptive shaping algorithm which is capable of learning the most suitable shaping method in an on-line manner. Results in two classic domains verify its effectiveness from both simulated and real human studies, shedding some light on the role and impact of human factors in human-robot collaborative learning.

</details>

<details>

<summary>2018-11-10 20:14:26 - PolyNeuron: Automatic Neuron Discovery via Learned Polyharmonic Spline Activations</summary>

- *Andrew Hryniowski, Alexander Wong*

- `1811.04303v1` - [abs](http://arxiv.org/abs/1811.04303v1) - [pdf](http://arxiv.org/pdf/1811.04303v1)

> Automated deep neural network architecture design has received a significant amount of recent attention. However, this attention has not been equally shared by one of the fundamental building blocks of a deep neural network, the neurons. In this study, we propose PolyNeuron, a novel automatic neuron discovery approach based on learned polyharmonic spline activations. More specifically, PolyNeuron revolves around learning polyharmonic splines, characterized by a set of control points, that represent the activation functions of the neurons in a deep neural network. A relaxed variant of PolyNeuron, which we term PolyNeuron-R, loosens the constraints imposed by PolyNeuron to reduce the computational complexity for discovering the neuron activation functions in an automated manner. Experiments show both PolyNeuron and PolyNeuron-R lead to networks that have improved or comparable performance on multiple network architectures (LeNet-5 and ResNet-20) using different datasets (MNIST and CIFAR10). As such, automatic neuron discovery approaches such as PolyNeuron is a worthy direction to explore.

</details>

<details>

<summary>2018-11-10 20:55:20 - Robust Kronecker Component Analysis</summary>

- *Mehdi Bahri, Yannis Panagakis, Stefanos Zafeiriou*

- `1801.06432v2` - [abs](http://arxiv.org/abs/1801.06432v2) - [pdf](http://arxiv.org/pdf/1801.06432v2)

> Dictionary learning and component analysis models are fundamental for learning compact representations that are relevant to a given task (feature extraction, dimensionality reduction, denoising, etc.). The model complexity is encoded by means of specific structure, such as sparsity, low-rankness, or nonnegativity. Unfortunately, approaches like K-SVD - that learn dictionaries for sparse coding via Singular Value Decomposition (SVD) - are hard to scale to high-volume and high-dimensional visual data, and fragile in the presence of outliers. Conversely, robust component analysis methods such as the Robust Principal Component Analysis (RPCA) are able to recover low-complexity (e.g., low-rank) representations from data corrupted with noise of unknown magnitude and support, but do not provide a dictionary that respects the structure of the data (e.g., images), and also involve expensive computations. In this paper, we propose a novel Kronecker-decomposable component analysis model, coined as Robust Kronecker Component Analysis (RKCA), that combines ideas from sparse dictionary learning and robust component analysis. RKCA has several appealing properties, including robustness to gross corruption; it can be used for low-rank modeling, and leverages separability to solve significantly smaller problems. We design an efficient learning algorithm by drawing links with a restricted form of tensor factorization, and analyze its optimality and low-rankness properties. The effectiveness of the proposed approach is demonstrated on real-world applications, namely background subtraction and image denoising and completion, by performing a thorough comparison with the current state of the art.

</details>

<details>

<summary>2018-11-11 03:53:54 - Langevin-gradient parallel tempering for Bayesian neural learning</summary>

- *Rohitash Chandra, Konark Jain, Ratneel V. Deo, Sally Cripps*

- `1811.04343v1` - [abs](http://arxiv.org/abs/1811.04343v1) - [pdf](http://arxiv.org/pdf/1811.04343v1)

> Bayesian neural learning feature a rigorous approach to estimation and uncertainty quantification via the posterior distribution of weights that represent knowledge of the neural network. This not only provides point estimates of optimal set of weights but also the ability to quantify uncertainty in decision making using the posterior distribution. Markov chain Monte Carlo (MCMC) techniques are typically used to obtain sample-based estimates of the posterior distribution. However, these techniques face challenges in convergence and scalability, particularly in settings with large datasets and network architectures. This paper address these challenges in two ways. First, parallel tempering is used used to explore multiple modes of the posterior distribution and implemented in multi-core computing architecture. Second, we make within-chain sampling schemes more efficient by using Langevin gradient information in forming Metropolis-Hastings proposal distributions. We demonstrate the techniques using time series prediction and pattern classification applications. The results show that the method not only improves the computational time, but provides better prediction or decision making capabilities when compared to related methods.

</details>

<details>

<summary>2018-11-11 04:13:31 - Optimizing Taxi Carpool Policies via Reinforcement Learning and Spatio-Temporal Mining</summary>

- *Ishan Jindal, Zhiwei Qin, Xuewen Chen, Matthew Nokleby, Jieping Ye*

- `1811.04345v1` - [abs](http://arxiv.org/abs/1811.04345v1) - [pdf](http://arxiv.org/pdf/1811.04345v1)

> In this paper, we develop a reinforcement learning (RL) based system to learn an effective policy for carpooling that maximizes transportation efficiency so that fewer cars are required to fulfill the given amount of trip demand. For this purpose, first, we develop a deep neural network model, called ST-NN (Spatio-Temporal Neural Network), to predict taxi trip time from the raw GPS trip data. Secondly, we develop a carpooling simulation environment for RL training, with the output of ST-NN and using the NYC taxi trip dataset. In order to maximize transportation efficiency and minimize traffic congestion, we choose the effective distance covered by the driver on a carpool trip as the reward. Therefore, the more effective distance a driver achieves over a trip (i.e. to satisfy more trip demand) the higher the efficiency and the less will be the traffic congestion. We compared the performance of RL learned policy to a fixed policy (which always accepts carpool) as a baseline and obtained promising results that are interpretable and demonstrate the advantage of our RL approach. We also compare the performance of ST-NN to that of state-of-the-art travel time estimation methods and observe that ST-NN significantly improves the prediction performance and is more robust to outliers.

</details>

<details>

<summary>2018-11-11 04:48:15 - Towards Governing Agent's Efficacy: Action-Conditional $β$-VAE for Deep Transparent Reinforcement Learning</summary>

- *John Yang, Gyujeong Lee, Minsung Hyun, Simyung Chang, Nojun Kwak*

- `1811.04350v1` - [abs](http://arxiv.org/abs/1811.04350v1) - [pdf](http://arxiv.org/pdf/1811.04350v1)

> We tackle the blackbox issue of deep neural networks in the settings of reinforcement learning (RL) where neural agents learn towards maximizing reward gains in an uncontrollable way. Such learning approach is risky when the interacting environment includes an expanse of state space because it is then almost impossible to foresee all unwanted outcomes and penalize them with negative rewards beforehand. Unlike reverse analysis of learned neural features from previous works, our proposed method \nj{tackles the blackbox issue by encouraging} an RL policy network to learn interpretable latent features through an implementation of a disentangled representation learning method. Toward this end, our method allows an RL agent to understand self-efficacy by distinguishing its influences from uncontrollable environmental factors, which closely resembles the way humans understand their scenes. Our experimental results show that the learned latent factors not only are interpretable, but also enable modeling the distribution of entire visited state space with a specific action condition. We have experimented that this characteristic of the proposed structure can lead to ex post facto governance for desired behaviors of RL agents.

</details>

<details>

<summary>2018-11-11 05:37:37 - Semi-supervised Text Regression with Conditional Generative Adversarial Networks</summary>

- *Tao Li, Xudong Liu, Shihan Su*

- `1810.01165v2` - [abs](http://arxiv.org/abs/1810.01165v2) - [pdf](http://arxiv.org/pdf/1810.01165v2)

> Enormous online textual information provides intriguing opportunities for understandings of social and economic semantics. In this paper, we propose a novel text regression model based on a conditional generative adversarial network (GAN), with an attempt to associate textual data and social outcomes in a semi-supervised manner. Besides promising potential of predicting capabilities, our superiorities are twofold: (i) the model works with unbalanced datasets of limited labelled data, which align with real-world scenarios; and (ii) predictions are obtained by an end-to-end framework, without explicitly selecting high-level representations. Finally we point out related datasets for experiments and future research directions.

</details>

<details>

<summary>2018-11-11 08:21:55 - User Modeling for Task Oriented Dialogues</summary>

- *Izzeddin Gur, Dilek Hakkani-Tur, Gokhan Tur, Pararth Shah*

- `1811.04369v1` - [abs](http://arxiv.org/abs/1811.04369v1) - [pdf](http://arxiv.org/pdf/1811.04369v1)

> We introduce end-to-end neural network based models for simulating users of task-oriented dialogue systems. User simulation in dialogue systems is crucial from two different perspectives: (i) automatic evaluation of different dialogue models, and (ii) training task-oriented dialogue systems. We design a hierarchical sequence-to-sequence model that first encodes the initial user goal and system turns into fixed length representations using Recurrent Neural Networks (RNN). It then encodes the dialogue history using another RNN layer. At each turn, user responses are decoded from the hidden representations of the dialogue level RNN. This hierarchical user simulator (HUS) approach allows the model to capture undiscovered parts of the user goal without the need of an explicit dialogue state tracking. We further develop several variants by utilizing a latent variable model to inject random variations into user responses to promote diversity in simulated user responses and a novel goal regularization mechanism to penalize divergence of user responses from the initial user goal. We evaluate the proposed models on movie ticket booking domain by systematically interacting each user simulator with various dialogue system policies trained with different objectives and users.

</details>

<details>

<summary>2018-11-11 09:26:55 - Explaining Deep Learning Models using Causal Inference</summary>

- *Tanmayee Narendra, Anush Sankaran, Deepak Vijaykeerthy, Senthil Mani*

- `1811.04376v1` - [abs](http://arxiv.org/abs/1811.04376v1) - [pdf](http://arxiv.org/pdf/1811.04376v1)

> Although deep learning models have been successfully applied to a variety of tasks, due to the millions of parameters, they are becoming increasingly opaque and complex. In order to establish trust for their widespread commercial use, it is important to formalize a principled framework to reason over these models. In this work, we use ideas from causal inference to describe a general framework to reason over CNN models. Specifically, we build a Structural Causal Model (SCM) as an abstraction over a specific aspect of the CNN. We also formulate a method to quantitatively rank the filters of a convolution layer according to their counterfactual importance. We illustrate our approach with popular CNN architectures such as LeNet5, VGG19, and ResNet32.

</details>

<details>

<summary>2018-11-11 09:45:41 - ReSet: Learning Recurrent Dynamic Routing in ResNet-like Neural Networks</summary>

- *Iurii Kemaev, Daniil Polykovskiy, Dmitry Vetrov*

- `1811.04380v1` - [abs](http://arxiv.org/abs/1811.04380v1) - [pdf](http://arxiv.org/pdf/1811.04380v1)

> Neural Network is a powerful Machine Learning tool that shows outstanding performance in Computer Vision, Natural Language Processing, and Artificial Intelligence. In particular, recently proposed ResNet architecture and its modifications produce state-of-the-art results in image classification problems. ResNet and most of the previously proposed architectures have a fixed structure and apply the same transformation to all input images. In this work, we develop a ResNet-based model that dynamically selects Computational Units (CU) for each input object from a learned set of transformations. Dynamic selection allows the network to learn a sequence of useful transformations and apply only required units to predict the image label. We compare our model to ResNet-38 architecture and achieve better results than the original ResNet on CIFAR-10.1 test set. While examining the produced paths, we discovered that the network learned different routes for images from different classes and similar routes for similar images.

</details>

<details>

<summary>2018-11-11 13:04:29 - Causal Inference and Mechanism Clustering of A Mixture of Additive Noise Models</summary>

- *Shoubo Hu, Zhitang Chen, Vahid Partovi Nia, Laiwan Chan, Yanhui Geng*

- `1809.08568v3` - [abs](http://arxiv.org/abs/1809.08568v3) - [pdf](http://arxiv.org/pdf/1809.08568v3)

> The inference of the causal relationship between a pair of observed variables is a fundamental problem in science, and most existing approaches are based on one single causal model. In practice, however, observations are often collected from multiple sources with heterogeneous causal models due to certain uncontrollable factors, which renders causal analysis results obtained by a single model skeptical. In this paper, we generalize the Additive Noise Model (ANM) to a mixture model, which consists of a finite number of ANMs, and provide the condition of its causal identifiability. To conduct model estimation, we propose Gaussian Process Partially Observable Model (GPPOM), and incorporate independence enforcement into it to learn latent parameter associated with each observation. Causal inference and clustering according to the underlying generating mechanisms of the mixture model are addressed in this work. Experiments on synthetic and real data demonstrate the effectiveness of our proposed approach.

</details>

<details>

<summary>2018-11-11 13:11:13 - Correction of AI systems by linear discriminants: Probabilistic foundations</summary>

- *A. N. Gorban, A. Golubkov, B. Grechuk, E. M. Mirkes, I. Y. Tyukin*

- `1811.05321v1` - [abs](http://arxiv.org/abs/1811.05321v1) - [pdf](http://arxiv.org/pdf/1811.05321v1)

> Artificial Intelligence (AI) systems sometimes make errors and will make errors in the future, from time to time. These errors are usually unexpected, and can lead to dramatic consequences. Intensive development of AI and its practical applications makes the problem of errors more important. Total re-engineering of the systems can create new errors and is not always possible due to the resources involved. The important challenge is to develop fast methods to correct errors without damaging existing skills. We formulated the technical requirements to the 'ideal' correctors. Such correctors include binary classifiers, which separate the situations with high risk of errors from the situations where the AI systems work properly. Surprisingly, for essentially high-dimensional data such methods are possible: simple linear Fisher discriminant can separate the situations with errors from correctly solved tasks even for exponentially large samples. The paper presents the probabilistic basis for fast non-destructive correction of AI systems. A series of new stochastic separation theorems is proven. These theorems provide new instruments for fast non-iterative correction of errors of legacy AI systems. The new approaches become efficient in high-dimensions, for correction of high-dimensional systems in high-dimensional world (i.e. for processing of essentially high-dimensional data by large systems).

</details>

<details>

<summary>2018-11-11 15:57:21 - FAST$^2$: an Intelligent Assistant for Finding Relevant Papers</summary>

- *Zhe Yu, Tim Menzies*

- `1705.05420v6` - [abs](http://arxiv.org/abs/1705.05420v6) - [pdf](http://arxiv.org/pdf/1705.05420v6)

> Literature reviews are essential for any researcher trying to keep up to date with the burgeoning software engineering literature. FAST$^2$ is a novel tool for reducing the effort required for conducting literature reviews by assisting the researchers to find the next promising paper to read (among a set of unread papers). This paper describes FAST$^2$ and tests it on four large software engineering literature reviews conducted by Wahono (2015), Hall (2012), Radjenovi\'c (2013) and Kitchenham (2017). We find that FAST$^2$ is a faster and robust tool to assist researcher finding relevant SE papers which can compensate for the errors made by humans during the review process. The effectiveness of FAST$^2$ can be attributed to three key innovations: (1) a novel way of applying external domain knowledge (a simple two or three keyword search) to guide the initial selection of papers---which helps to find relevant research papers faster with less variances; (2) an estimator of the number of remaining relevant papers yet to be found---which in practical settings can be used to decide if the reviewing process needs to be terminated; (3) a novel self-correcting classification algorithm---automatically corrects itself, in cases where the researcher wrongly classifies a paper.

</details>

<details>

<summary>2018-11-11 18:40:52 - Modeling car-following behavior on urban expressways in Shanghai: A naturalistic driving study</summary>

- *Meixin Zhu, Xuesong Wang, Andrew P. Tarko, Shou'en Fang*

- `1811.06395v1` - [abs](http://arxiv.org/abs/1811.06395v1) - [pdf](http://arxiv.org/pdf/1811.06395v1)

> Five car-following models were calibrated, validated and cross-compared. The intelligent driver model performed best among the evaluated models. Considerable behavioral differences between different drivers were found. Calibrated model parameters may not be numerically equivalent with observed ones.

</details>

<details>

<summary>2018-11-11 19:02:50 - ReDecode Framework for Iterative Improvement in Paraphrase Generation</summary>

- *Milan Aggarwal, Nupur Kumari, Ayush Bansal, Balaji Krishnamurthy*

- `1811.04454v1` - [abs](http://arxiv.org/abs/1811.04454v1) - [pdf](http://arxiv.org/pdf/1811.04454v1)

> Generating paraphrases, that is, different variations of a sentence conveying the same meaning, is an important yet challenging task in NLP. Automatically generating paraphrases has its utility in many NLP tasks like question answering, information retrieval, conversational systems to name a few. In this paper, we introduce iterative refinement of generated paraphrases within VAE based generation framework. Current sequence generation models lack the capability to (1) make improvements once the sentence is generated; (2) rectify errors made while decoding. We propose a technique to iteratively refine the output using multiple decoders, each one attending on the output sentence generated by the previous decoder. We improve current state of the art results significantly - with over 9% and 28% absolute increase in METEOR scores on Quora question pairs and MSCOCO datasets respectively. We also show qualitatively through examples that our re-decoding approach generates better paraphrases compared to a single decoder by rectifying errors and making improvements in paraphrase structure, inducing variations and introducing new but semantically coherent information.

</details>

<details>

<summary>2018-11-11 19:13:20 - Time-interval balancing in multi-processor scheduling of composite modular jobs (preliminary description)</summary>

- *Mark Sh. Levin*

- `1811.04458v1` - [abs](http://arxiv.org/abs/1811.04458v1) - [pdf](http://arxiv.org/pdf/1811.04458v1)

> The article describes a special time-interval balancing in multi-processor scheduling of composite modular jobs. This scheduling problem is close to just-in-time planning approach. First, brief literature surveys are presented on just-in-time scheduling and due-data/due-window scheduling problems. Further, the problem and its formulation are proposed for the time-interval balanced scheduling of composite modular jobs. The illustrative real world planning example for modular home-building is described. Here, the main objective function consists in a balance between production of the typical building modules (details) and the assembly processes of the building(s) (by several teams). The assembly plan has to be modified to satisfy the balance requirements. The solving framework is based on the following: (i) clustering of initial set of modular detail types to obtain about ten basic detail types that correspond to main manufacturing conveyors; (ii) designing a preliminary plan of assembly for buildings; (iii) detection of unbalanced time periods, (iv) modification of the planning solution to improve the schedule balance. The framework implements a metaheuristic based on local optimization approach. Two other applications (supply chain management, information transmission systems) are briefly described.

</details>

<details>

<summary>2018-11-12 01:28:11 - What If We Simply Swap the Two Text Fragments? A Straightforward yet Effective Way to Test the Robustness of Methods to Confounding Signals in Nature Language Inference Tasks</summary>

- *Haohan Wang, Da Sun, Eric P. Xing*

- `1809.02719v2` - [abs](http://arxiv.org/abs/1809.02719v2) - [pdf](http://arxiv.org/pdf/1809.02719v2)

> Nature language inference (NLI) task is a predictive task of determining the inference relationship of a pair of natural language sentences. With the increasing popularity of NLI, many state-of-the-art predictive models have been proposed with impressive performances. However, several works have noticed the statistical irregularities in the collected NLI data set that may result in an over-estimated performance of these models and proposed remedies. In this paper, we further investigate the statistical irregularities, what we refer as confounding factors, of the NLI data sets. With the belief that some NLI labels should preserve under swapping operations, we propose a simple yet effective way (swapping the two text fragments) of evaluating the NLI predictive models that naturally mitigate the observed problems. Further, we continue to train the predictive models with our swapping manner and propose to use the deviation of the model's evaluation performances under different percentages of training text fragments to be swapped to describe the robustness of a predictive model. Our evaluation metrics leads to some interesting understandings of recent published NLI methods. Finally, we also apply the swapping operation on NLI models to see the effectiveness of this straightforward method in mitigating the confounding factor problems in training generic sentence embeddings for other NLP transfer tasks.

</details>

<details>

<summary>2018-11-12 02:35:48 - A Smart System for Selection of Optimal Product Images in E-Commerce</summary>

- *Abon Chaudhuri, Paolo Messina, Samrat Kokkula, Aditya Subramanian, Abhinandan Krishnan, Shreyansh Gandhi, Alessandro Magnani, Venkatesh Kandaswamy*

- `1811.07996v1` - [abs](http://arxiv.org/abs/1811.07996v1) - [pdf](http://arxiv.org/pdf/1811.07996v1)

> In e-commerce, content quality of the product catalog plays a key role in delivering a satisfactory experience to the customers. In particular, visual content such as product images influences customers' engagement and purchase decisions. With the rapid growth of e-commerce and the advent of artificial intelligence, traditional content management systems are giving way to automated scalable systems. In this paper, we present a machine learning driven visual content management system for extremely large e-commerce catalogs. For a given product, the system aggregates images from various suppliers, understands and analyzes them to produce a superior image set with optimal image count and quality, and arranges them in an order tailored to the demands of the customers. The system makes use of an array of technologies, ranging from deep learning to traditional computer vision, at different stages of analysis. In this paper, we outline how the system works and discuss the unique challenges related to applying machine learning techniques to real-world data from e-commerce domain. We emphasize how we tune state-of-the-art image classification techniques to develop solutions custom made for a massive, diverse, and constantly evolving product catalog. We also provide the details of how we measure the system's impact on various customer engagement metrics.

</details>

<details>

<summary>2018-11-12 03:33:45 - Adversarial Learning-Based On-Line Anomaly Monitoring for Assured Autonomy</summary>

- *Naman Patel, Apoorva Nandini Saridena, Anna Choromanska, Prashanth Krishnamurthy, Farshad Khorrami*

- `1811.04539v1` - [abs](http://arxiv.org/abs/1811.04539v1) - [pdf](http://arxiv.org/pdf/1811.04539v1)

> The paper proposes an on-line monitoring framework for continuous real-time safety/security in learning-based control systems (specifically application to a unmanned ground vehicle). We monitor validity of mappings from sensor inputs to actuator commands, controller-focused anomaly detection (CFAM), and from actuator commands to sensor inputs, system-focused anomaly detection (SFAM). CFAM is an image conditioned energy based generative adversarial network (EBGAN) in which the energy based discriminator distinguishes between proper and anomalous actuator commands. SFAM is based on an action condition video prediction framework to detect anomalies between predicted and observed temporal evolution of sensor data. We demonstrate the effectiveness of the approach on our autonomous ground vehicle for indoor environments and on Udacity dataset for outdoor environments.

</details>

<details>

<summary>2018-11-12 06:47:38 - Navigating Assistance System for Quadcopter with Deep Reinforcement Learning</summary>

- *Tung-Cheng Wu, Shau-Yin Tseng, Chin-Feng Lai, Chia-Yu Ho, Ying-Hsun Lai*

- `1811.04584v1` - [abs](http://arxiv.org/abs/1811.04584v1) - [pdf](http://arxiv.org/pdf/1811.04584v1)

> In this paper, we present a deep reinforcement learning method for quadcopter bypassing the obstacle on the flying path. In the past study, the algorithm only controls the forward direction about quadcopter. In this letter, we use two functions to control quadcopter. One is quadcopter navigating function. It is based on calculating coordination point and find the straight path to the goal. The other function is collision avoidance function. It is implemented by deep Q-network model. Both two function will output rotating degree, the agent will combine both output and turn direct. Besides, deep Q-network can also make quadcopter fly up and down to bypass the obstacle and arrive at the goal. Our experimental result shows that the collision rate is 14% after 500 flights. Based on this work, we will train more complex sense and transfer model to the real quadcopter.

</details>

<details>

<summary>2018-11-12 07:09:36 - Differentiating Concepts and Instances for Knowledge Graph Embedding</summary>

- *Xin Lv, Lei Hou, Juanzi Li, Zhiyuan Liu*

- `1811.04588v1` - [abs](http://arxiv.org/abs/1811.04588v1) - [pdf](http://arxiv.org/pdf/1811.04588v1)

> Concepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Specifically, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e., instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classification tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation. Our codes and datasets can be obtained from https:// github.com/davidlvxin/TransC.

</details>

<details>

<summary>2018-11-12 07:46:33 - Image-Level Attentional Context Modeling Using Nested-Graph Neural Networks</summary>

- *Guillaume Jaume, Behzad Bozorgtabar, Hazim Kemal Ekenel, Jean-Philippe Thiran, Maria Gabrani*

- `1811.03830v2` - [abs](http://arxiv.org/abs/1811.03830v2) - [pdf](http://arxiv.org/pdf/1811.03830v2)

> We introduce a new scene graph generation method called image-level attentional context modeling (ILAC). Our model includes an attentional graph network that effectively propagates contextual information across the graph using image-level features. Whereas previous works use an object-centric context, we build an image-level context agent to encode the scene properties. The proposed method comprises a single-stream network that iteratively refines the scene graph with a nested graph neural network. We demonstrate that our approach achieves competitive performance with the state-of-the-art for scene graph generation on the Visual Genome dataset, while requiring fewer parameters than other methods. We also show that ILAC can improve regular object detectors by incorporating relational image-level information.

</details>

<details>

<summary>2018-11-12 10:29:42 - The Goldilocks zone: Towards better understanding of neural network loss landscapes</summary>

- *Stanislav Fort, Adam Scherlis*

- `1807.02581v2` - [abs](http://arxiv.org/abs/1807.02581v2) - [pdf](http://arxiv.org/pdf/1807.02581v2)

> We explore the loss landscape of fully-connected and convolutional neural networks using random, low-dimensional hyperplanes and hyperspheres. Evaluating the Hessian, $H$, of the loss function on these hypersurfaces, we observe 1) an unusual excess of the number of positive eigenvalues of $H$, and 2) a large value of $\mathrm{Tr}(H) / ||H||$ at a well defined range of configuration space radii, corresponding to a thick, hollow, spherical shell we refer to as the \textit{Goldilocks zone}. We observe this effect for fully-connected neural networks over a range of network widths and depths on MNIST and CIFAR-10 datasets with the $\mathrm{ReLU}$ and $\tanh$ non-linearities, and a similar effect for convolutional networks. Using our observations, we demonstrate a close connection between the Goldilocks zone, measures of local convexity/prevalence of positive curvature, and the suitability of a network initialization. We show that the high and stable accuracy reached when optimizing on random, low-dimensional hypersurfaces is directly related to the overlap between the hypersurface and the Goldilocks zone, and as a corollary demonstrate that the notion of intrinsic dimension is initialization-dependent. We note that common initialization techniques initialize neural networks in this particular region of unusually high convexity/prevalence of positive curvature, and offer a geometric intuition for their success. Furthermore, we demonstrate that initializing a neural network at a number of points and selecting for high measures of local convexity such as $\mathrm{Tr}(H) / ||H||$, number of positive eigenvalues of $H$, or low initial loss, leads to statistically significantly faster training on MNIST. Based on our observations, we hypothesize that the Goldilocks zone contains an unusually high density of suitable initialization configurations.

</details>

<details>

<summary>2018-11-12 10:48:43 - Combining Learned Lyrical Structures and Vocabulary for Improved Lyric Generation</summary>

- *Pablo Samuel Castro, Maria Attarian*

- `1811.04651v1` - [abs](http://arxiv.org/abs/1811.04651v1) - [pdf](http://arxiv.org/pdf/1811.04651v1)

> The use of language models for generating lyrics and poetry has received an increased interest in the last few years. They pose a unique challenge relative to standard natural language problems, as their ultimate purpose is reative, notions of accuracy and reproducibility are secondary to notions of lyricism, structure, and diversity. In this creative setting, traditional quantitative measures for natural language problems, such as BLEU scores, prove inadequate: a high-scoring model may either fail to produce output respecting the desired structure (e.g. song verses), be a terribly boring creative companion, or both. In this work we propose a mechanism for combining two separately trained language models into a framework that is able to produce output respecting the desired song structure, while providing a richness and diversity of vocabulary that renders it more creatively appealing.

</details>

<details>

<summary>2018-11-12 11:40:09 - A Deep Ensemble Framework for Fake News Detection and Classification</summary>

- *Arjun Roy, Kingshuk Basak, Asif Ekbal, Pushpak Bhattacharyya*

- `1811.04670v1` - [abs](http://arxiv.org/abs/1811.04670v1) - [pdf](http://arxiv.org/pdf/1811.04670v1)

> Fake news, rumor, incorrect information, and misinformation detection are nowadays crucial issues as these might have serious consequences for our social fabrics. The rate of such information is increasing rapidly due to the availability of enormous web information sources including social media feeds, news blogs, online newspapers etc.   In this paper, we develop various deep learning models for detecting fake news and classifying them into the pre-defined fine-grained categories.   At first, we develop models based on Convolutional Neural Network (CNN) and Bi-directional Long Short Term Memory (Bi-LSTM) networks. The representations obtained from these two models are fed into a Multi-layer Perceptron Model (MLP) for the final classification. Our experiments on a benchmark dataset show promising results with an overall accuracy of 44.87\%, which outperforms the current state of the art.

</details>

<details>

<summary>2018-11-12 13:55:15 - Universal Marginalizer for Amortised Inference and Embedding of Generative Models</summary>

- *Robert Walecki, Albert Buchard, Kostis Gourgoulias, Chris Hart, Maria Lomeli, A. K. W. Navarro, Max Zwiessele, Yura Perov, Saurabh Johri*

- `1811.04727v1` - [abs](http://arxiv.org/abs/1811.04727v1) - [pdf](http://arxiv.org/pdf/1811.04727v1)

> Probabilistic graphical models are powerful tools which allow us to formalise our knowledge about the world and reason about its inherent uncertainty. There exist a considerable number of methods for performing inference in probabilistic graphical models; however, they can be computationally costly due to significant time burden and/or storage requirements; or they lack theoretical guarantees of convergence and accuracy when applied to large scale graphical models. To this end, we propose the Universal Marginaliser Importance Sampler (UM-IS) -- a hybrid inference scheme that combines the flexibility of a deep neural network trained on samples from the model and inherits the asymptotic guarantees of importance sampling. We show how combining samples drawn from the graphical model with an appropriate masking function allows us to train a single neural network to approximate any of the corresponding conditional marginal distributions, and thus amortise the cost of inference. We also show that the graph embeddings can be applied for tasks such as: clustering, classification and interpretation of relationships between the nodes. Finally, we benchmark the method on a large graph (>1000 nodes), showing that UM-IS outperforms sampling-based methods by a large margin while being computationally efficient.

</details>

<details>

<summary>2018-11-12 16:59:39 - On the practice of classification learning for clinical diagnosis and therapy advice in oncology</summary>

- *Flavio S Correa da Silva, Frederico P Costa, Antonio F Iemma*

- `1811.04854v1` - [abs](http://arxiv.org/abs/1811.04854v1) - [pdf](http://arxiv.org/pdf/1811.04854v1)

> Artificial intelligence and medicine have a longstanding and proficuous relationship. In the present work we develop a brief assessment of this relationship with specific focus on machine learning, in which we highlight some critical points which may hinder the use of machine learning techniques for clinical diagnosis and therapy advice in practice. We then suggest a conceptual framework to build successful systems to aid clinical diagnosis and therapy advice, grounded on a novel concept we have coined drifting domains. We focus on oncology to build our arguments, as this area of medicine furnishes strong evidence for the critical points we take into account here.

</details>

<details>

<summary>2018-11-12 17:06:53 - Bio-YODIE: A Named Entity Linking System for Biomedical Text</summary>

- *Genevieve Gorrell, Xingyi Song, Angus Roberts*

- `1811.04860v1` - [abs](http://arxiv.org/abs/1811.04860v1) - [pdf](http://arxiv.org/pdf/1811.04860v1)

> Ever-expanding volumes of biomedical text require automated semantic annotation techniques to curate and put to best use. An established field of research seeks to link mentions in text to knowledge bases such as those included in the UMLS (Unified Medical Language System), in order to enable a more sophisticated understanding. This work has yielded good results for tasks such as curating literature, but increasingly, annotation systems are more broadly applied. Medical vocabularies are expanding in size, and with them the extent of term ambiguity. Document collections are increasing in size and complexity, creating a greater need for speed and robustness. Furthermore, as the technologies are turned to new tasks, requirements change; for example greater coverage of expressions may be required in order to annotate patient records, and greater accuracy may be needed for applications that affect patients. This places new demands on the approaches currently in use. In this work, we present a new system, Bio-YODIE, and compare it to two other popular systems in order to give guidance about suitable approaches in different scenarios and how systems might be designed to accommodate future needs.

</details>

<details>

<summary>2018-11-12 17:09:14 - Classification with Costly Features using Deep Reinforcement Learning</summary>

- *Jaromír Janisch, Tomáš Pevný, Viliam Lisý*

- `1711.07364v2` - [abs](http://arxiv.org/abs/1711.07364v2) - [pdf](http://arxiv.org/pdf/1711.07364v2)

> We study a classification problem where each feature can be acquired for a cost and the goal is to optimize a trade-off between the expected classification error and the feature cost. We revisit a former approach that has framed the problem as a sequential decision-making problem and solved it by Q-learning with a linear approximation, where individual actions are either requests for feature values or terminate the episode by providing a classification decision. On a set of eight problems, we demonstrate that by replacing the linear approximation with neural networks the approach becomes comparable to the state-of-the-art algorithms developed specifically for this problem. The approach is flexible, as it can be improved with any new reinforcement learning enhancement, it allows inclusion of pre-trained high-performance classifier, and unlike prior art, its performance is robust across all evaluated datasets.

</details>

<details>

<summary>2018-11-12 18:13:01 - Identifying Sources and Sinks in the Presence of Multiple Agents with Gaussian Process Vector Calculus</summary>

- *Adam D. Cobb, Richard Everett, Andrew Markham, Stephen J. Roberts*

- `1802.10446v2` - [abs](http://arxiv.org/abs/1802.10446v2) - [pdf](http://arxiv.org/pdf/1802.10446v2)

> In systems of multiple agents, identifying the cause of observed agent dynamics is challenging. Often, these agents operate in diverse, non-stationary environments, where models rely on hand-crafted environment-specific features to infer influential regions in the system's surroundings. To overcome the limitations of these inflexible models, we present GP-LAPLACE, a technique for locating sources and sinks from trajectories in time-varying fields. Using Gaussian processes, we jointly infer a spatio-temporal vector field, as well as canonical vector calculus operations on that field. Notably, we do this from only agent trajectories without requiring knowledge of the environment, and also obtain a metric for denoting the significance of inferred causal features in the environment by exploiting our probabilistic method. To evaluate our approach, we apply it to both synthetic and real-world GPS data, demonstrating the applicability of our technique in the presence of multiple agents, as well as its superiority over existing methods.

</details>

<details>

<summary>2018-11-12 19:23:15 - Baselines for Reinforcement Learning in Text Games</summary>

- *Mikuláš Zelinka*

- `1811.02872v2` - [abs](http://arxiv.org/abs/1811.02872v2) - [pdf](http://arxiv.org/pdf/1811.02872v2)

> The ability to learn optimal control policies in systems where action space is defined by sentences in natural language would allow many interesting real-world applications such as automatic optimisation of dialogue systems. Text-based games with multiple endings and rewards are a promising platform for this task, since their feedback allows us to employ reinforcement learning techniques to jointly learn text representations and control policies. We argue that the key property of AI agents, especially in the text-games context, is their ability to generalise to previously unseen games. We present a minimalistic text-game playing agent, testing its generalisation and transfer learning performance and showing its ability to play multiple games at once. We also present pyfiction, an open-source library for universal access to different text games that could, together with our agent that implements its interface, serve as a baseline for future research.

</details>

<details>

<summary>2018-11-12 20:02:00 - Unseen Word Representation by Aligning Heterogeneous Lexical Semantic Spaces</summary>

- *Victor Prokhorov, Mohammad Taher Pilehvar, Dimitri Kartsaklis, Pietro Lio, Nigel Collier*

- `1811.04983v1` - [abs](http://arxiv.org/abs/1811.04983v1) - [pdf](http://arxiv.org/pdf/1811.04983v1)

> Word embedding techniques heavily rely on the abundance of training data for individual words. Given the Zipfian distribution of words in natural language texts, a large number of words do not usually appear frequently or at all in the training data. In this paper we put forward a technique that exploits the knowledge encoded in lexical resources, such as WordNet, to induce embeddings for unseen words. Our approach adapts graph embedding and cross-lingual vector space transformation techniques in order to merge lexical knowledge encoded in ontologies with that derived from corpus statistics. We show that the approach can provide consistent performance improvements across multiple evaluation benchmarks: in-vitro, on multiple rare word similarity datasets, and in-vivo, in two downstream text classification tasks.

</details>

<details>

<summary>2018-11-12 21:45:41 - Blindfold Baselines for Embodied QA</summary>

- *Ankesh Anand, Eugene Belilovsky, Kyle Kastner, Hugo Larochelle, Aaron Courville*

- `1811.05013v1` - [abs](http://arxiv.org/abs/1811.05013v1) - [pdf](http://arxiv.org/pdf/1811.05013v1)

> We explore blindfold (question-only) baselines for Embodied Question Answering. The EmbodiedQA task requires an agent to answer a question by intelligently navigating in a simulated environment, gathering necessary visual information only through first-person vision before finally answering. Consequently, a blindfold baseline which ignores the environment and visual information is a degenerate solution, yet we show through our experiments on the EQAv1 dataset that a simple question-only baseline achieves state-of-the-art results on the EmbodiedQA task in all cases except when the agent is spawned extremely close to the object.

</details>

<details>

<summary>2018-11-12 23:19:51 - Finding All Bayesian Network Structures within a Factor of Optimal</summary>

- *Zhenyu A. Liao, Charupriya Sharma, James Cussens, Peter van Beek*

- `1811.05039v1` - [abs](http://arxiv.org/abs/1811.05039v1) - [pdf](http://arxiv.org/pdf/1811.05039v1)

> A Bayesian network is a widely used probabilistic graphical model with applications in knowledge discovery and prediction. Learning a Bayesian network (BN) from data can be cast as an optimization problem using the well-known score-and-search approach. However, selecting a single model (i.e., the best scoring BN) can be misleading or may not achieve the best possible accuracy. An alternative to committing to a single model is to perform some form of Bayesian or frequentist model averaging, where the space of possible BNs is sampled or enumerated in some fashion. Unfortunately, existing approaches for model averaging either severely restrict the structure of the Bayesian network or have only been shown to scale to networks with fewer than 30 random variables. In this paper, we propose a novel approach to model averaging inspired by performance guarantees in approximation algorithms. Our approach has two primary advantages. First, our approach only considers credible models in that they are optimal or near-optimal in score. Second, our approach is more efficient and scales to significantly larger Bayesian networks than existing approaches.

</details>

<details>

<summary>2018-11-13 02:21:57 - Private Model Compression via Knowledge Distillation</summary>

- *Ji Wang, Weidong Bao, Lichao Sun, Xiaomin Zhu, Bokai Cao, Philip S. Yu*

- `1811.05072v1` - [abs](http://arxiv.org/abs/1811.05072v1) - [pdf](http://arxiv.org/pdf/1811.05072v1)

> The soaring demand for intelligent mobile applications calls for deploying powerful deep neural networks (DNNs) on mobile devices. However, the outstanding performance of DNNs notoriously relies on increasingly complex models, which in turn is associated with an increase in computational expense far surpassing mobile devices' capacity. What is worse, app service providers need to collect and utilize a large volume of users' data, which contain sensitive information, to build the sophisticated DNN models. Directly deploying these models on public mobile devices presents prohibitive privacy risk. To benefit from the on-device deep learning without the capacity and privacy concerns, we design a private model compression framework RONA. Following the knowledge distillation paradigm, we jointly use hint learning, distillation learning, and self learning to train a compact and fast neural network. The knowledge distilled from the cumbersome model is adaptively bounded and carefully perturbed to enforce differential privacy. We further propose an elegant query sample selection method to reduce the number of queries and control the privacy loss. A series of empirical evaluations as well as the implementation on an Android mobile device show that RONA can not only compress cumbersome models efficiently but also provide a strong privacy guarantee. For example, on SVHN, when a meaningful $(9.83,10^{-6})$-differential privacy is guaranteed, the compact model trained by RONA can obtain 20$\times$ compression ratio and 19$\times$ speed-up with merely 0.97% accuracy loss.

</details>

<details>

<summary>2018-11-13 04:10:24 - Differentiable Fine-grained Quantization for Deep Neural Network Compression</summary>

- *Hsin-Pai Cheng, Yuanjun Huang, Xuyang Guo, Yifei Huang, Feng Yan, Hai Li, Yiran Chen*

- `1810.10351v3` - [abs](http://arxiv.org/abs/1810.10351v3) - [pdf](http://arxiv.org/pdf/1810.10351v3)

> Neural networks have shown great performance in cognitive tasks. When deploying network models on mobile devices with limited resources, weight quantization has been widely adopted. Binary quantization obtains the highest compression but usually results in big accuracy drop. In practice, 8-bit or 16-bit quantization is often used aiming at maintaining the same accuracy as the original 32-bit precision. We observe different layers have different accuracy sensitivity of quantization. Thus judiciously selecting different precision for different layers/structures can potentially produce more efficient models compared to traditional quantization methods by striking a better balance between accuracy and compression rate. In this work, we propose a fine-grained quantization approach for deep neural network compression by relaxing the search space of quantization bitwidth from discrete to a continuous domain. The proposed approach applies gradient descend based optimization to generate a mixed-precision quantization scheme that outperforms the accuracy of traditional quantization methods under the same compression rate.

</details>

<details>

<summary>2018-11-13 04:57:48 - Interpreting Models by Allowing to Ask</summary>

- *Sungmin Kang, David Keetae Park, Jaehyuk Chang, Jaegul Choo*

- `1811.05106v1` - [abs](http://arxiv.org/abs/1811.05106v1) - [pdf](http://arxiv.org/pdf/1811.05106v1)

> Questions convey information about the questioner, namely what one does not know. In this paper, we propose a novel approach to allow a learning agent to ask what it considers as tricky to predict, in the course of producing a final output. By analyzing when and what it asks, we can make our model more transparent and interpretable. We first develop this idea to propose a general framework of deep neural networks that can ask questions, which we call asking networks. A specific architecture and training process for an asking network is proposed for the task of colorization, which is an exemplar one-to-many task and thus a task where asking questions is helpful in performing the task accurately. Our results show that the model learns to generate meaningful questions, asks difficult questions first, and utilizes the provided hint more efficiently than baseline models. We conclude that the proposed asking framework makes the learning agent reveal its weaknesses, which poses a promising new direction in developing interpretable and interactive models.

</details>

<details>

<summary>2018-11-13 05:23:40 - Graph Convolutional Networks for Text Classification</summary>

- *Liang Yao, Chengsheng Mao, Yuan Luo*

- `1809.05679v3` - [abs](http://arxiv.org/abs/1809.05679v3) - [pdf](http://arxiv.org/pdf/1809.05679v3)

> Text classification is an important and classical problem in natural language processing. There have been a number of studies that applied convolutional neural networks (convolution on regular grid, e.g., sequence) to classification. However, only a limited number of studies have explored the more flexible graph convolutional neural networks (convolution on non-grid, e.g., arbitrary graph) for the task. In this work, we propose to use graph convolutional networks for text classification. We build a single text graph for a corpus based on word co-occurrence and document word relations, then learn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents. Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or knowledge outperforms state-of-the-art methods for text classification. On the other hand, Text GCN also learns predictive word and document embeddings. In addition, experimental results show that the improvement of Text GCN over state-of-the-art comparison methods become more prominent as we lower the percentage of training data, suggesting the robustness of Text GCN to less training data in text classification.

</details>

<details>

<summary>2018-11-13 06:02:57 - Influence-Directed Explanations for Deep Convolutional Networks</summary>

- *Klas Leino, Shayak Sen, Anupam Datta, Matt Fredrikson, Linyi Li*

- `1802.03788v2` - [abs](http://arxiv.org/abs/1802.03788v2) - [pdf](http://arxiv.org/pdf/1802.03788v2)

> We study the problem of explaining a rich class of behavioral properties of deep neural networks. Distinctively, our influence-directed explanations approach this problem by peering inside the network to identify neurons with high influence on a quantity and distribution of interest, using an axiomatically-justified influence measure, and then providing an interpretation for the concepts these neurons represent. We evaluate our approach by demonstrating a number of its unique capabilities on convolutional neural networks trained on ImageNet. Our evaluation demonstrates that influence-directed explanations (1) identify influential concepts that generalize across instances, (2) can be used to extract the "essence" of what the network learned about a class, and (3) isolate individual features the network uses to make decisions and distinguish related classes.

</details>

<details>

<summary>2018-11-13 09:27:24 - Jointly identifying opinion mining elements and fuzzy measurement of opinion intensity to analyze product features</summary>

- *Haiqing Zhang, Aicha Sekhari, Yacine Ouzrout, Abdelaziz Bouras*

- `1811.05827v1` - [abs](http://arxiv.org/abs/1811.05827v1) - [pdf](http://arxiv.org/pdf/1811.05827v1)

> Opinion mining mainly involves three elements: feature and feature-of relations, opinion expressions and the related opinion attributes (e.g. Polarity), and feature-opinion relations. Although many works have emerged to achieve its aim of gaining information, the previous researches typically handled each of the three elements in isolation, which cannot give sufficient information extraction results; hence, the complexity and the running time of information extraction is increased. In this paper, we propose an opinion mining extraction algorithm to jointly discover the main opinion mining elements. Specifically, the algorithm automatically builds kernels to combine closely related words into new terms from word level to phrase level based on dependency relations; and we ensure the accuracy of opinion expressions and polarity based on: fuzzy measurements, opinion degree intensifiers, and opinion patterns. The 3458 analyzed reviews show that the proposed algorithm can effectively identify the main elements simultaneously and outperform the baseline methods. The proposed algorithm is used to analyze the features among heterogeneous products in the same category. The feature-by-feature comparison can help to select the weaker features and recommend the correct specifications from the beginning life of a product. From this comparison, some interesting observations are revealed. For example, the negative polarity of video dimension is higher than the product usability dimension for a product. Yet, enhancing the dimension of product usability can more effectively improve the product (C) 2015 Elsevier Ltd. All rights reserved.

</details>

<details>

<summary>2018-11-13 09:39:53 - Learning to Compensate Photovoltaic Power Fluctuations from Images of the Sky by Imitating an Optimal Policy</summary>

- *Robin Spiess, Felix Berkenkamp, Jan Poland, Andreas Krause*

- `1811.05788v1` - [abs](http://arxiv.org/abs/1811.05788v1) - [pdf](http://arxiv.org/pdf/1811.05788v1)

> The energy output of photovoltaic (PV) power plants depends on the environment and thus fluctuates over time. As a result, PV power can cause instability in the power grid, in particular when increasingly used. Limiting the rate of change of the power output is a common way to mitigate these fluctuations, often with the help of large batteries. A reactive controller that uses these batteries to compensate ramps works in practice, but causes stress on the battery due to a high energy throughput. In this paper, we present a deep learning approach that uses images of the sky to compensate power fluctuations predictively and reduces battery stress. In particular, we show that the optimal control policy can be computed using information that is only available in hindsight. Based on this, we use imitation learning to train a neural network that approximates this hindsight-optimal policy, but uses only currently available sky images and sensor data. We evaluate our method on a large dataset of measurements and images from a real power plant and show that the trained policy reduces stress on the battery.

</details>

<details>

<summary>2018-11-13 09:51:57 - An Orchestrated Empirical Study on Deep Learning Frameworks and Platforms</summary>

- *Qianyu Guo, Xiaofei Xie, Lei Ma, Qiang Hu, Ruitao Feng, Li Li, Yang Liu, Jianjun Zhao, Xiaohong Li*

- `1811.05187v1` - [abs](http://arxiv.org/abs/1811.05187v1) - [pdf](http://arxiv.org/pdf/1811.05187v1)

> Deep learning (DL) has recently achieved tremendous success in a variety of cutting-edge applications, e.g., image recognition, speech and natural language processing, and autonomous driving. Besides the available big data and hardware evolution, DL frameworks and platforms play a key role to catalyze the research, development, and deployment of DL intelligent solutions. However, the difference in computation paradigm, architecture design and implementation of existing DL frameworks and platforms brings challenges for DL software development, deployment, maintenance, and migration. Up to the present, it still lacks a comprehensive study on how current diverse DL frameworks and platforms influence the DL software development process.   In this paper, we initiate the first step towards the investigation on how existing state-of-the-art DL frameworks (i.e., TensorFlow, Theano, and Torch) and platforms (i.e., server/desktop, web, and mobile) support the DL software development activities. We perform an in-depth and comparative evaluation on metrics such as learning accuracy, DL model size, robustness, and performance, on state-of-the-art DL frameworks across platforms using two popular datasets MNIST and CIFAR-10. Our study reveals that existing DL frameworks still suffer from compatibility issues, which becomes even more severe when it comes to different platforms. We pinpoint the current challenges and opportunities towards developing high quality and compatible DL systems. To ignite further investigation along this direction to address urgent industrial demands of intelligent solutions, we make all of our assembled feasible toolchain and dataset publicly available.

</details>

<details>

<summary>2018-11-13 10:26:58 - Diversity-Driven Extensible Hierarchical Reinforcement Learning</summary>

- *Yuhang Song, Jianyi Wang, Thomas Lukasiewicz, Zhenghua Xu, Mai Xu*

- `1811.04324v2` - [abs](http://arxiv.org/abs/1811.04324v2) - [pdf](http://arxiv.org/pdf/1811.04324v2)

> Hierarchical reinforcement learning (HRL) has recently shown promising advances on speeding up learning, improving the exploration, and discovering intertask transferable skills. Most recent works focus on HRL with two levels, i.e., a master policy manipulates subpolicies, which in turn manipulate primitive actions. However, HRL with multiple levels is usually needed in many real-world scenarios, whose ultimate goals are highly abstract, while their actions are very primitive. Therefore, in this paper, we propose a diversity-driven extensible HRL (DEHRL), where an extensible and scalable framework is built and learned levelwise to realize HRL with multiple levels. DEHRL follows a popular assumption: diverse subpolicies are useful, i.e., subpolicies are believed to be more useful if they are more diverse. However, existing implementations of this diversity assumption usually have their own drawbacks, which makes them inapplicable to HRL with multiple levels. Consequently, we further propose a novel diversity-driven solution to achieve this assumption in DEHRL. Experimental studies evaluate DEHRL with five baselines from four perspectives in two domains; the results show that DEHRL outperforms the state-of-the-art baselines in all four aspects.

</details>

<details>

<summary>2018-11-13 11:30:29 - Modelling the Dynamic Joint Policy of Teammates with Attention Multi-agent DDPG</summary>

- *Hangyu Mao, Zhengchao Zhang, Zhen Xiao, Zhibo Gong*

- `1811.07029v1` - [abs](http://arxiv.org/abs/1811.07029v1) - [pdf](http://arxiv.org/pdf/1811.07029v1)

> Modelling and exploiting teammates' policies in cooperative multi-agent systems have long been an interest and also a big challenge for the reinforcement learning (RL) community. The interest lies in the fact that if the agent knows the teammates' policies, it can adjust its own policy accordingly to arrive at proper cooperations; while the challenge is that the agents' policies are changing continuously due to they are learning concurrently, which imposes difficulty to model the dynamic policies of teammates accurately. In this paper, we present \emph{ATTention Multi-Agent Deep Deterministic Policy Gradient} (ATT-MADDPG) to address this challenge. ATT-MADDPG extends DDPG, a single-agent actor-critic RL method, with two special designs. First, in order to model the teammates' policies, the agent should get access to the observations and actions of teammates. ATT-MADDPG adopts a centralized critic to collect such information. Second, to model the teammates' policies using the collected information in an effective way, ATT-MADDPG enhances the centralized critic with an attention mechanism. This attention mechanism introduces a special structure to explicitly model the dynamic joint policy of teammates, making sure that the collected information can be processed efficiently. We evaluate ATT-MADDPG on both benchmark tasks and the real-world packet routing tasks. Experimental results show that it not only outperforms the state-of-the-art RL-based methods and rule-based methods by a large margin, but also achieves better performance in terms of scalability and robustness.

</details>

<details>

<summary>2018-11-13 12:24:23 - Modular Networks: Learning to Decompose Neural Computation</summary>

- *Louis Kirsch, Julius Kunze, David Barber*

- `1811.05249v1` - [abs](http://arxiv.org/abs/1811.05249v1) - [pdf](http://arxiv.org/pdf/1811.05249v1)

> Scaling model capacity has been vital in the success of deep learning. For a typical network, necessary compute resources and training time grow dramatically with model size. Conditional computation is a promising way to increase the number of parameters with a relatively small increase in resources. We propose a training algorithm that flexibly chooses neural modules based on the data to be processed. Both the decomposition and modules are learned end-to-end. In contrast to existing approaches, training does not rely on regularization to enforce diversity in module use. We apply modular networks both to image recognition and language modeling tasks, where we achieve superior performance compared to several baselines. Introspection reveals that modules specialize in interpretable contexts.

</details>

<details>

<summary>2018-11-13 13:08:47 - Anomaly Detection using Autoencoders in High Performance Computing Systems</summary>

- *Andrea Borghesi, Andrea Bartolini, Michele Lombardi, Michela Milano, Luca Benini*

- `1811.05269v1` - [abs](http://arxiv.org/abs/1811.05269v1) - [pdf](http://arxiv.org/pdf/1811.05269v1)

> Anomaly detection in supercomputers is a very difficult problem due to the big scale of the systems and the high number of components. The current state of the art for automated anomaly detection employs Machine Learning methods or statistical regression models in a supervised fashion, meaning that the detection tool is trained to distinguish among a fixed set of behaviour classes (healthy and unhealthy states).   We propose a novel approach for anomaly detection in High Performance Computing systems based on a Machine (Deep) Learning technique, namely a type of neural network called autoencoder. The key idea is to train a set of autoencoders to learn the normal (healthy) behaviour of the supercomputer nodes and, after training, use them to identify abnormal conditions. This is different from previous approaches which where based on learning the abnormal condition, for which there are much smaller datasets (since it is very hard to identify them to begin with).   We test our approach on a real supercomputer equipped with a fine-grained, scalable monitoring infrastructure that can provide large amount of data to characterize the system behaviour. The results are extremely promising: after the training phase to learn the normal system behaviour, our method is capable of detecting anomalies that have never been seen before with a very good accuracy (values ranging between 88% and 96%).

</details>

<details>

<summary>2018-11-13 13:56:56 - Intelligent Drone Swarm for Search and Rescue Operations at Sea</summary>

- *Vincenzo Lomonaco, Angelo Trotta, Marta Ziosi, Juan de Dios Yáñez Ávila, Natalia Díaz-Rodríguez*

- `1811.05291v1` - [abs](http://arxiv.org/abs/1811.05291v1) - [pdf](http://arxiv.org/pdf/1811.05291v1)

> In recent years, a rising numbers of people arrived in the European Union, traveling across the Mediterranean Sea or overland through Southeast Europe in what has been later named as the European migrant crisis. In the last 5 years, more than 16 thousands people have lost their lives in the Mediterranean sea during the crossing. The United Nations Secretary General Strategy on New Technologies is supporting the use of Artificial Intelligence (AI) and Robotics to accelerate the achievement of the 2030 Sustainable Development Agenda, which includes safe and regular migration processes among the others. In the same spirit, the central idea of this project aims at using AI technology for Search And Rescue (SAR) operations at sea. In particular, we propose an autonomous fleet of self-organizing intelligent drones that would enable the coverage of a broader area, speeding-up the search processes and finally increasing the efficiency and effectiveness of migrants rescue operations.

</details>

<details>

<summary>2018-11-13 14:02:29 - Genetic algorithm for optimal distribution in cities</summary>

- *Esteban Quintero, Mateo Sanchez, Nicolas Roldan, Mauricio Toro*

- `1811.05297v1` - [abs](http://arxiv.org/abs/1811.05297v1) - [pdf](http://arxiv.org/pdf/1811.05297v1)

> The problem to deal with in this project is the problem of routing electric vehicles, which consists of finding the best routes for this type of vehicle, so that they reach their destination, without running out of power and optimizing to the maximum transportation costs. The importance of this problem is mainly in the sector of shipments in the recent future, when obsolete energy sources are replaced with renewable sources, where each vehicle contains a number of packages that must be delivered at specific points in the city , but, being electric, they do not have an optimal battery life, so having the ideal routes traced is a vital aspect for the proper functioning of these. Now days you can see applications of this problem in the cleaning sector, specifically with the trucks responsible for collecting garbage, which aims to travel the entire city in the most efficient way, without letting excessive garbage accumulate.

</details>

<details>

<summary>2018-11-13 14:06:58 - Translating Natural Language to SQL using Pointer-Generator Networks and How Decoding Order Matters</summary>

- *Denis Lukovnikov, Nilesh Chakraborty, Jens Lehmann, Asja Fischer*

- `1811.05303v1` - [abs](http://arxiv.org/abs/1811.05303v1) - [pdf](http://arxiv.org/pdf/1811.05303v1)

> Translating natural language to SQL queries for table-based question answering is a challenging problem and has received significant attention from the research community. In this work, we extend a pointer-generator and investigate the order-matters problem in semantic parsing for SQL. Even though our model is a straightforward extension of a general-purpose pointer-generator, it outperforms early works for WikiSQL and remains competitive to concurrently introduced, more complex models. Moreover, we provide a deeper investigation of the potential order-matters problem that could arise due to having multiple correct decoding paths, and investigate the use of REINFORCE as well as a dynamic oracle in this context.

</details>

<details>

<summary>2018-11-13 14:50:36 - Regular Boardgames</summary>

- *Jakub Kowalski, Maksymilian Mika, Jakub Sutowicz, Marek Szykuła*

- `1706.02462v2` - [abs](http://arxiv.org/abs/1706.02462v2) - [pdf](http://arxiv.org/pdf/1706.02462v2)

> We propose a new General Game Playing (GGP) language called Regular Boardgames (RBG), which is based on the theory of regular languages. The objective of RBG is to join key properties as expressiveness, efficiency, and naturalness of the description in one GGP formalism, compensating certain drawbacks of the existing languages. This often makes RBG more suitable for various research and practical developments in GGP. While dedicated mostly for describing board games, RBG is universal for the class of all finite deterministic turn-based games with perfect information. We establish foundations of RBG, and analyze it theoretically and experimentally, focusing on the efficiency of reasoning. Regular Boardgames is the first GGP language that allows efficient encoding and playing games with complex rules and with large branching factor (e.g.\ amazons, arimaa, large chess variants, go, international checkers, paper soccer).

</details>

<details>

<summary>2018-11-13 15:44:31 - Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents</summary>

- *Aditya Siddhant, Anuj Goyal, Angeliki Metallinou*

- `1811.05370v1` - [abs](http://arxiv.org/abs/1811.05370v1) - [pdf](http://arxiv.org/pdf/1811.05370v1)

> User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding (SLU) tasks. We use Embeddings from Language Model (ELMo) to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose ELMo-Light (ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data.

</details>

<details>

<summary>2018-11-13 15:49:54 - Benchmarking datasets for Anomaly-based Network Intrusion Detection: KDD CUP 99 alternatives</summary>

- *Abhishek Divekar, Meet Parekh, Vaibhav Savla, Rudra Mishra, Mahesh Shirole*

- `1811.05372v1` - [abs](http://arxiv.org/abs/1811.05372v1) - [pdf](http://arxiv.org/pdf/1811.05372v1)

> Machine Learning has been steadily gaining traction for its use in Anomaly-based Network Intrusion Detection Systems (A-NIDS). Research into this domain is frequently performed using the KDD~CUP~99 dataset as a benchmark. Several studies question its usability while constructing a contemporary NIDS, due to the skewed response distribution, non-stationarity, and failure to incorporate modern attacks. In this paper, we compare the performance for KDD-99 alternatives when trained using classification models commonly found in literature: Neural Network, Support Vector Machine, Decision Tree, Random Forest, Naive Bayes and K-Means. Applying the SMOTE oversampling technique and random undersampling, we create a balanced version of NSL-KDD and prove that skewed target classes in KDD-99 and NSL-KDD hamper the efficacy of classifiers on minority classes (U2R and R2L), leading to possible security risks. We explore UNSW-NB15, a modern substitute to KDD-99 with greater uniformity of pattern distribution. We benchmark this dataset before and after SMOTE oversampling to observe the effect on minority performance. Our results indicate that classifiers trained on UNSW-NB15 match or better the Weighted F1-Score of those trained on NSL-KDD and KDD-99 in the binary case, thus advocating UNSW-NB15 as a modern substitute to these datasets.

</details>

<details>

<summary>2018-11-13 15:56:52 - Universal Decision-Based Black-Box Perturbations: Breaking Security-Through-Obscurity Defenses</summary>

- *Thomas A. Hogan, Bhavya Kailkhura*

- `1811.03733v2` - [abs](http://arxiv.org/abs/1811.03733v2) - [pdf](http://arxiv.org/pdf/1811.03733v2)

> We study the problem of finding a universal (image-agnostic) perturbation to fool machine learning (ML) classifiers (e.g., neural nets, decision tress) in the hard-label black-box setting. Recent work in adversarial ML in the white-box setting (model parameters are known) has shown that many state-of-the-art image classifiers are vulnerable to universal adversarial perturbations: a fixed human-imperceptible perturbation that, when added to any image, causes it to be misclassified with high probability Kurakin et al. [2016], Szegedy et al. [2013], Chen et al. [2017a], Carlini and Wagner [2017]. This paper considers a more practical and challenging problem of finding such universal perturbations in an obscure (or black-box) setting. More specifically, we use zeroth order optimization algorithms to find such a universal adversarial perturbation when no model information is revealed-except that the attacker can make queries to probe the classifier. We further relax the assumption that the output of a query is continuous valued confidence scores for all the classes and consider the case where the output is a hard-label decision. Surprisingly, we found that even in these extremely obscure regimes, state-of-the-art ML classifiers can be fooled with a very high probability just by adding a single human-imperceptible image perturbation to any natural image. The surprising existence of universal perturbations in a hard-label black-box setting raises serious security concerns with the existence of a universal noise vector that adversaries can possibly exploit to break a classifier on most natural images.

</details>

<details>

<summary>2018-11-13 15:58:01 - Fully Convolutional Network with Multi-Step Reinforcement Learning for Image Processing</summary>

- *Ryosuke Furuta, Naoto Inoue, Toshihiko Yamasaki*

- `1811.04323v2` - [abs](http://arxiv.org/abs/1811.04323v2) - [pdf](http://arxiv.org/pdf/1811.04323v2)

> This paper tackles a new problem setting: reinforcement learning with pixel-wise rewards (pixelRL) for image processing. After the introduction of the deep Q-network, deep RL has been achieving great success. However, the applications of deep RL for image processing are still limited. Therefore, we extend deep RL to pixelRL for various image processing applications. In pixelRL, each pixel has an agent, and the agent changes the pixel value by taking an action. We also propose an effective learning method for pixelRL that significantly improves the performance by considering not only the future states of the own pixel but also those of the neighbor pixels. The proposed method can be applied to some image processing tasks that require pixel-wise manipulations, where deep RL has never been applied. We apply the proposed method to three image processing tasks: image denoising, image restoration, and local color enhancement. Our experimental results demonstrate that the proposed method achieves comparable or better performance, compared with the state-of-the-art methods based on supervised learning.

</details>

<details>

<summary>2018-11-13 17:18:48 - ABox Abduction via Forgetting in ALC (Long Version)</summary>

- *Warren Del-Pinto, Renate A. Schmidt*

- `1811.05420v1` - [abs](http://arxiv.org/abs/1811.05420v1) - [pdf](http://arxiv.org/pdf/1811.05420v1)

> Abductive reasoning generates explanatory hypotheses for new observations using prior knowledge. This paper investigates the use of forgetting, also known as uniform interpolation, to perform ABox abduction in description logic (ALC) ontologies. Non-abducibles are specified by a forgetting signature which can contain concept, but not role, symbols. The resulting hypotheses are semantically minimal and each consist of a set of disjuncts. These disjuncts are each independent explanations, and are not redundant with respect to the background ontology or the other disjuncts, representing a form of hypothesis space. The observations and hypotheses handled by the method can contain both atomic or complex ALC concepts, excluding role assertions, and are not restricted to Horn clauses. Two approaches to redundancy elimination are explored for practical use: full and approximate. Using a prototype implementation, experiments were performed over a corpus of real world ontologies to investigate the practicality of both approaches across several settings.

</details>

<details>

<summary>2018-11-13 18:45:10 - Efficient Decentralized Deep Learning by Dynamic Model Averaging</summary>

- *Michael Kamp, Linara Adilova, Joachim Sicking, Fabian Hüger, Peter Schlicht, Tim Wirtz, Stefan Wrobel*

- `1807.03210v2` - [abs](http://arxiv.org/abs/1807.03210v2) - [pdf](http://arxiv.org/pdf/1807.03210v2)

> We propose an efficient protocol for decentralized training of deep neural networks from distributed data sources. The proposed protocol allows to handle different phases of model training equally well and to quickly adapt to concept drifts. This leads to a reduction of communication by an order of magnitude compared to periodically communicating state-of-the-art approaches. Moreover, we derive a communication bound that scales well with the hardness of the serialized learning problem. The reduction in communication comes at almost no cost, as the predictive performance remains virtually unchanged. Indeed, the proposed protocol retains loss bounds of periodically averaging schemes. An extensive empirical evaluation validates major improvement of the trade-off between model performance and communication which could be beneficial for numerous decentralized learning applications, such as autonomous driving, or voice recognition and image classification on mobile phones.

</details>

<details>

<summary>2018-11-13 19:14:50 - FermiNets: Learning generative machines to generate efficient neural networks via generative synthesis</summary>

- *Alexander Wong, Mohammad Javad Shafiee, Brendan Chwyl, Francis Li*

- `1809.05989v2` - [abs](http://arxiv.org/abs/1809.05989v2) - [pdf](http://arxiv.org/pdf/1809.05989v2)

> The tremendous potential exhibited by deep learning is often offset by architectural and computational complexity, making widespread deployment a challenge for edge scenarios such as mobile and other consumer devices. To tackle this challenge, we explore the following idea: Can we learn generative machines to automatically generate deep neural networks with efficient network architectures? In this study, we introduce the idea of generative synthesis, which is premised on the intricate interplay between a generator-inquisitor pair that work in tandem to garner insights and learn to generate highly efficient deep neural networks that best satisfies operational requirements. What is most interesting is that, once a generator has been learned through generative synthesis, it can be used to generate not just one but a large variety of different, unique highly efficient deep neural networks that satisfy operational requirements. Experimental results for image classification, semantic segmentation, and object detection tasks illustrate the efficacy of generative synthesis in producing generators that automatically generate highly efficient deep neural networks (which we nickname FermiNets) with higher model efficiency and lower computational costs (reaching >10x more efficient and fewer multiply-accumulate operations than several tested state-of-the-art networks), as well as higher energy efficiency (reaching >4x improvements in image inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As such, generative synthesis can be a powerful, generalized approach for accelerating and improving the building of deep neural networks for on-device edge scenarios.

</details>

<details>

<summary>2018-11-13 20:10:03 - Natural Gradient Deep Q-learning</summary>

- *Ethan Knight, Osher Lerner*

- `1803.07482v2` - [abs](http://arxiv.org/abs/1803.07482v2) - [pdf](http://arxiv.org/pdf/1803.07482v2)

> We present a novel algorithm to train a deep Q-learning agent using natural-gradient techniques. We compare the original deep Q-network (DQN) algorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a collection of classic control domains. Without employing target networks, NGDQN significantly outperforms DQN without target networks, and performs no worse than DQN with target networks, suggesting that NGDQN stabilizes training and can help reduce the need for additional hyperparameter tuning. We also find that NGDQN is less sensitive to hyperparameter optimization relative to DQN. Together these results suggest that natural-gradient techniques can improve value-function optimization in deep reinforcement learning.

</details>

<details>

<summary>2018-11-13 20:23:37 - Deep Q learning for fooling neural networks</summary>

- *Mandar Kulkarni*

- `1811.05521v1` - [abs](http://arxiv.org/abs/1811.05521v1) - [pdf](http://arxiv.org/pdf/1811.05521v1)

> Deep learning models are vulnerable to external attacks. In this paper, we propose a Reinforcement Learning (RL) based approach to generate adversarial examples for the pre-trained (target) models. We assume a semi black-box setting where the only access an adversary has to the target model is the class probabilities obtained for the input queries. We train a Deep Q Network (DQN) agent which, with experience, learns to attack only a small portion of image pixels to generate non-targeted adversarial images. Initially, an agent explores an environment by sequentially modifying random sets of image pixels and observes its effect on the class probabilities. At the end of an episode, it receives a positive (negative) reward if it succeeds (fails) to alter the label of the image. Experimental results with MNIST, CIFAR-10 and Imagenet datasets demonstrate that our RL framework is able to learn an effective attack policy.

</details>

<details>

<summary>2018-11-13 20:56:14 - Semi-dual Regularized Optimal Transport</summary>

- *Marco Cuturi, Gabriel Peyré*

- `1811.05527v1` - [abs](http://arxiv.org/abs/1811.05527v1) - [pdf](http://arxiv.org/pdf/1811.05527v1)

> Variational problems that involve Wasserstein distances and more generally optimal transport (OT) theory are playing an increasingly important role in data sciences. Such problems can be used to form an examplar measure out of various probability measures, as in the Wasserstein barycenter problem, or to carry out parametric inference and density fitting, where the loss is measured in terms of an optimal transport cost to the measure of observations. Despite being conceptually simple, such problems are computationally challenging because they involve minimizing over quantities (Wasserstein distances) that are themselves hard to compute. Entropic regularization has recently emerged as an efficient tool to approximate the solution of such variational Wasserstein problems. In this paper, we give a thorough duality tour of these regularization techniques. In particular, we show how important concepts from classical OT such as c-transforms and semi-discrete approaches translate into similar ideas in a regularized setting. These dual formulations lead to smooth variational problems, which can be solved using smooth, differentiable and convex optimization problems that are simpler to implement and numerically more stable that their un-regularized counterparts. We illustrate the versatility of this approach by applying it to the computation of Wasserstein barycenters and gradient flows of spatial regularization functionals.

</details>

<details>

<summary>2018-11-13 21:12:08 - SAFE: A Neural Survival Analysis Model for Fraud Early Detection</summary>

- *Panpan Zheng, Shuhan Yuan, Xintao Wu*

- `1809.04683v2` - [abs](http://arxiv.org/abs/1809.04683v2) - [pdf](http://arxiv.org/pdf/1809.04683v2)

> Many online platforms have deployed anti-fraud systems to detect and prevent fraudulent activities. However, there is usually a gap between the time that a user commits a fraudulent action and the time that the user is suspended by the platform. How to detect fraudsters in time is a challenging problem. Most of the existing approaches adopt classifiers to predict fraudsters given their activity sequences along time. The main drawback of classification models is that the prediction results between consecutive timestamps are often inconsistent. In this paper, we propose a survival analysis based fraud early detection model, SAFE, which maps dynamic user activities to survival probabilities that are guaranteed to be monotonically decreasing along time. SAFE adopts recurrent neural network (RNN) to handle user activity sequences and directly outputs hazard values at each timestamp, and then, survival probability derived from hazard values is deployed to achieve consistent predictions. Because we only observe the user suspended time instead of the fraudulent activity time in the training data, we revise the loss function of the regular survival model to achieve fraud early detection. Experimental results on two real world datasets demonstrate that SAFE outperforms both the survival analysis model and recurrent neural network model alone as well as state-of-the-art fraud early detection approaches.

</details>

<details>

<summary>2018-11-13 21:42:51 - Scaling simulation-to-real transfer by learning composable robot skills</summary>

- *Ryan Julian, Eric Heiden, Zhanpeng He, Hejia Zhang, Stefan Schaal, Joseph J. Lim, Gaurav Sukhatme, Karol Hausman*

- `1809.10253v3` - [abs](http://arxiv.org/abs/1809.10253v3) - [pdf](http://arxiv.org/pdf/1809.10253v3)

> We present a novel solution to the problem of simulation-to-real transfer, which builds on recent advances in robot skill decomposition. Rather than focusing on minimizing the simulation-reality gap, we learn a set of diverse policies that are parameterized in a way that makes them easily reusable. This diversity and parameterization of low-level skills allows us to find a transferable policy that is able to use combinations and variations of different skills to solve more complex, high-level tasks. In particular, we first use simulation to jointly learn a policy for a set of low-level skills, and a "skill embedding" parameterization which can be used to compose them. Later, we learn high-level policies which actuate the low-level policies via this skill embedding parameterization. The high-level policies encode how and when to reuse the low-level skills together to achieve specific high-level tasks. Importantly, our method learns to control a real robot in joint-space to achieve these high-level tasks with little or no on-robot time, despite the fact that the low-level policies may not be perfectly transferable from simulation to real, and that the low-level skills were not trained on any examples of high-level tasks. We illustrate the principles of our method using informative simulation experiments. We then verify its usefulness for real robotics problems by learning, transferring, and composing free-space and contact motion skills on a Sawyer robot using only joint-space control. We experiment with several techniques for composing pre-learned skills, and find that our method allows us to use both learning-based approaches and efficient search-based planning to achieve high-level tasks using only pre-learned skills.

</details>

<details>

<summary>2018-11-13 23:11:26 - Text Assisted Insight Ranking Using Context-Aware Memory Network</summary>

- *Qi Zeng, Liangchen Luo, Wenhao Huang, Yang Tang*

- `1811.05563v1` - [abs](http://arxiv.org/abs/1811.05563v1) - [pdf](http://arxiv.org/pdf/1811.05563v1)

> Extracting valuable facts or informative summaries from multi-dimensional tables, i.e. insight mining, is an important task in data analysis and business intelligence. However, ranking the importance of insights remains a challenging and unexplored task. The main challenge is that explicitly scoring an insight or giving it a rank requires a thorough understanding of the tables and costs a lot of manual efforts, which leads to the lack of available training data for the insight ranking problem. In this paper, we propose an insight ranking model that consists of two parts: A neural ranking model explores the data characteristics, such as the header semantics and the data statistical features, and a memory network model introduces table structure and context information into the ranking process. We also build a dataset with text assistance. Experimental results show that our approach largely improves the ranking precision as reported in multi evaluation metrics.

</details>

<details>

<summary>2018-11-13 23:57:54 - Modular Materialisation of Datalog Programs</summary>

- *Pan Hu, Boris Motik, Ian Horrocks*

- `1811.02304v2` - [abs](http://arxiv.org/abs/1811.02304v2) - [pdf](http://arxiv.org/pdf/1811.02304v2)

> The semina\"ive algorithm can materialise all consequences of arbitrary datalog rules, and it also forms the basis for incremental algorithms that update a materialisation as the input facts change. Certain (combinations of) rules, however, can be handled much more efficiently using custom algorithms. To integrate such algorithms into a general reasoning approach that can handle arbitrary rules, we propose a modular framework for materialisation computation and its maintenance. We split a datalog program into modules that can be handled using specialised algorithms, and handle the remaining rules using the semina\"ive algorithm. We also present two algorithms for computing the transitive and the symmetric-transitive closure of a relation that can be used within our framework. Finally, we show empirically that our framework can handle arbitrary datalog programs while outperforming existing approaches, often by orders of magnitude.

</details>

<details>

<summary>2018-11-14 01:30:00 - Emergence of Addictive Behaviors in Reinforcement Learning Agents</summary>

- *Vahid Behzadan, Roman V. Yampolskiy, Arslan Munir*

- `1811.05590v1` - [abs](http://arxiv.org/abs/1811.05590v1) - [pdf](http://arxiv.org/pdf/1811.05590v1)

> This paper presents a novel approach to the technical analysis of wireheading in intelligent agents. Inspired by the natural analogues of wireheading and their prevalent manifestations, we propose the modeling of such phenomenon in Reinforcement Learning (RL) agents as psychological disorders. In a preliminary step towards evaluating this proposal, we study the feasibility and dynamics of emergent addictive policies in Q-learning agents in the tractable environment of the game of Snake. We consider a slightly modified settings for this game, in which the environment provides a "drug" seed alongside the original "healthy" seed for the consumption of the snake. We adopt and extend an RL-based model of natural addiction to Q-learning agents in this settings, and derive sufficient parametric conditions for the emergence of addictive behaviors in such agents. Furthermore, we evaluate our theoretical analysis with three sets of simulation-based experiments. The results demonstrate the feasibility of addictive wireheading in RL agents, and provide promising venues of further research on the psychopathological modeling of complex AI safety problems.

</details>

<details>

<summary>2018-11-14 01:50:20 - TrolleyMod v1.0: An Open-Source Simulation and Data-Collection Platform for Ethical Decision Making in Autonomous Vehicles</summary>

- *Vahid Behzadan, James Minton, Arslan Munir*

- `1811.05594v1` - [abs](http://arxiv.org/abs/1811.05594v1) - [pdf](http://arxiv.org/pdf/1811.05594v1)

> This paper presents TrolleyMod v1.0, an open-source platform based on the CARLA simulator for the collection of ethical decision-making data for autonomous vehicles. This platform is designed to facilitate experiments aiming to observe and record human decisions and actions in high-fidelity simulations of ethical dilemmas that occur in the context of driving. Targeting experiments in the class of trolley problems, TrolleyMod provides a seamless approach to creating new experimental settings and environments with the realistic physics-engine and the high-quality graphical capabilities of CARLA and the Unreal Engine. Also, TrolleyMod provides a straightforward interface between the CARLA environment and Python to enable the implementation of custom controllers, such as deep reinforcement learning agents. The results of such experiments can be used for sociological analyses, as well as the training and tuning of value-aligned autonomous vehicles based on social values that are inferred from observations.

</details>

<details>

<summary>2018-11-14 02:47:05 - Bayesian Reinforcement Learning in Factored POMDPs</summary>

- *Sammie Katt, Frans Oliehoek, Christopher Amato*

- `1811.05612v1` - [abs](http://arxiv.org/abs/1811.05612v1) - [pdf](http://arxiv.org/pdf/1811.05612v1)

> Bayesian approaches provide a principled solution to the exploration-exploitation trade-off in Reinforcement Learning. Typical approaches, however, either assume a fully observable environment or scale poorly. This work introduces the Factored Bayes-Adaptive POMDP model, a framework that is able to exploit the underlying structure while learning the dynamics in partially observable systems. We also present a belief tracking method to approximate the joint posterior over state and model variables, and an adaptation of the Monte-Carlo Tree Search solution method, which together are capable of solving the underlying problem near-optimally. Our method is able to learn efficiently given a known factorization or also learn the factorization and the model parameters at the same time. We demonstrate that this approach is able to outperform current methods and tackle problems that were previously infeasible.

</details>

<details>

<summary>2018-11-14 03:02:12 - Improving Distantly Supervised Relation Extraction with Neural Noise Converter and Conditional Optimal Selector</summary>

- *Shanchan Wu, Kai Fan, Qiong Zhang*

- `1811.05616v1` - [abs](http://arxiv.org/abs/1811.05616v1) - [pdf](http://arxiv.org/pdf/1811.05616v1)

> Distant supervised relation extraction has been successfully applied to large corpus with thousands of relations. However, the inevitable wrong labeling problem by distant supervision will hurt the performance of relation extraction. In this paper, we propose a method with neural noise converter to alleviate the impact of noisy data, and a conditional optimal selector to make proper prediction. Our noise converter learns the structured transition matrix on logit level and captures the property of distant supervised relation extraction dataset. The conditional optimal selector on the other hand helps to make proper prediction decision of an entity pair even if the group of sentences is overwhelmed by no-relation sentences. We conduct experiments on a widely used dataset and the results show significant improvement over competitive baseline methods.

</details>

<details>

<summary>2018-11-14 05:35:37 - Bias Reduction via End-to-End Shift Learning: Application to Citizen Science</summary>

- *Di Chen, Carla P. Gomes*

- `1811.00458v4` - [abs](http://arxiv.org/abs/1811.00458v4) - [pdf](http://arxiv.org/pdf/1811.00458v4)

> Citizen science projects are successful at gathering rich datasets for various applications. However, the data collected by citizen scientists are often biased --- in particular, aligned more with the citizens' preferences than with scientific objectives. We propose the Shift Compensation Network (SCN), an end-to-end learning scheme which learns the shift from the scientific objectives to the biased data while compensating for the shift by re-weighting the training data. Applied to bird observational data from the citizen science project eBird, we demonstrate how SCN quantifies the data distribution shift and outperforms supervised learning models that do not address the data bias. Compared with competing models in the context of covariate shift, we further demonstrate the advantage of SCN in both its effectiveness and its capability of handling massive high-dimensional data.

</details>

<details>

<summary>2018-11-14 08:37:01 - Layout Design for Intelligent Warehouse by Evolution with Fitness Approximation</summary>

- *Haifeng Zhang, Zilong Guo, Han Cai, Chris Wang, Weinan Zhang, Yong Yu, Wenxin Li, Jun Wang*

- `1811.05685v1` - [abs](http://arxiv.org/abs/1811.05685v1) - [pdf](http://arxiv.org/pdf/1811.05685v1)

> With the rapid growth of the express industry, intelligent warehouses that employ autonomous robots for carrying parcels have been widely used to handle the vast express volume. For such warehouses, the warehouse layout design plays a key role in improving the transportation efficiency. However, this work is still done by human experts, which is expensive and leads to suboptimal results. In this paper, we aim to automate the warehouse layout designing process. We propose a two-layer evolutionary algorithm to efficiently explore the warehouse layout space, where an auxiliary objective fitness approximation model is introduced to predict the outcome of the designed warehouse layout and a two-layer population structure is proposed to incorporate the approximation model into the ordinary evolution framework. Empirical experiments show that our method can efficiently design effective warehouse layouts that outperform both heuristic-designed and vanilla evolution-designed warehouse layouts.

</details>

<details>

<summary>2018-11-14 11:02:55 - An Introduction to Fuzzy & Annotated Semantic Web Languages</summary>

- *Umberto Straccia*

- `1811.05724v1` - [abs](http://arxiv.org/abs/1811.05724v1) - [pdf](http://arxiv.org/pdf/1811.05724v1)

> We present the state of the art in representing and reasoning with fuzzy knowledge in Semantic Web Languages such as triple languages RDF/RDFS, conceptual languages of the OWL 2 family and rule languages. We further show how one may generalise them to so-called annotation domains, that cover also e.g. temporal and provenance extensions.

</details>

<details>

<summary>2018-11-14 12:49:17 - Towards Dialogue-based Navigation with Multivariate Adaptation driven by Intention and Politeness for Social Robots</summary>

- *Chandrakant Bothe, Fernando Garcia, Arturo Cruz Maya, Amit Kumar Pandey, Stefan Wermter*

- `1809.07269v2` - [abs](http://arxiv.org/abs/1809.07269v2) - [pdf](http://arxiv.org/pdf/1809.07269v2)

> Service robots need to show appropriate social behaviour in order to be deployed in social environments such as healthcare, education, retail, etc. Some of the main capabilities that robots should have are navigation and conversational skills. If the person is impatient, the person might want a robot to navigate faster and vice versa. Linguistic features that indicate politeness can provide social cues about a person's patient and impatient behaviour. The novelty presented in this paper is to dynamically incorporate politeness in robotic dialogue systems for navigation. Understanding the politeness in users' speech can be used to modulate the robot behaviour and responses. Therefore, we developed a dialogue system to navigate in an indoor environment, which produces different robot behaviours and responses based on users' intention and degree of politeness. We deploy and test our system with the Pepper robot that adapts to the changes in user's politeness.

</details>

<details>

<summary>2018-11-14 15:24:51 - A task in a suit and a tie: paraphrase generation with semantic augmentation</summary>

- *Su Wang, Rahul Gupta, Nancy Chang, Jason Baldridge*

- `1811.00119v2` - [abs](http://arxiv.org/abs/1811.00119v2) - [pdf](http://arxiv.org/pdf/1811.00119v2)

> Paraphrasing is rooted in semantics. We show the effectiveness of transformers (Vaswani et al. 2017) for paraphrase generation and further improvements by incorporating PropBank labels via a multi-encoder. Evaluating on MSCOCO and WikiAnswers, we find that transformers are fast and effective, and that semantic augmentation for both transformers and LSTMs leads to sizable 2-3 point gains in BLEU, METEOR and TER. More importantly, we find surprisingly large gains on human evaluations compared to previous models. Nevertheless, manual inspection of generated paraphrases reveals ample room for improvement: even our best model produces human-acceptable paraphrases for only 28% of captions from the CHIA dataset (Sharma et al. 2018), and it fails spectacularly on sentences from Wikipedia. Overall, these results point to the potential for incorporating semantics in the task while highlighting the need for stronger evaluation.

</details>

<details>

<summary>2018-11-14 15:30:31 - ColNet: Embedding the Semantics of Web Tables for Column Type Prediction</summary>

- *Jiaoyan Chen, Ernesto Jimenez-Ruiz, Ian Horrocks, Charles Sutton*

- `1811.01304v2` - [abs](http://arxiv.org/abs/1811.01304v2) - [pdf](http://arxiv.org/pdf/1811.01304v2)

> Automatically annotating column types with knowledge base (KB) concepts is a critical task to gain a basic understanding of web tables. Current methods rely on either table metadata like column name or entity correspondences of cells in the KB, and may fail to deal with growing web tables with incomplete meta information. In this paper we propose a neural network based column type annotation framework named ColNet which is able to integrate KB reasoning and lookup with machine learning and can automatically train Convolutional Neural Networks for prediction. The prediction model not only considers the contextual semantics within a cell using word representation, but also embeds the semantics of a column by learning locality features from multiple cells. The method is evaluated with DBPedia and two different web table datasets, T2Dv2 from the general Web and Limaye from Wikipedia pages, and achieves higher performance than the state-of-the-art approaches.

</details>

<details>

<summary>2018-11-14 15:46:57 - CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling</summary>

- *Ning Miao, Hao Zhou, Lili Mou, Rui Yan, Lei Li*

- `1811.10996v1` - [abs](http://arxiv.org/abs/1811.10996v1) - [pdf](http://arxiv.org/pdf/1811.10996v1)

> In real-world applications of natural language generation, there are often constraints on the target sentences in addition to fluency and naturalness requirements. Existing language generation techniques are usually based on recurrent neural networks (RNNs). However, it is non-trivial to impose constraints on RNNs while maintaining generation quality, since RNNs generate sentences sequentially (or with beam search) from the first word to the last. In this paper, we propose CGMH, a novel approach using Metropolis-Hastings sampling for constrained sentence generation. CGMH allows complicated constraints such as the occurrence of multiple keywords in the target sentences, which cannot be handled in traditional RNN-based approaches. Moreover, CGMH works in the inference stage, and does not require parallel corpora for training. We evaluate our method on a variety of tasks, including keywords-to-sentence generation, unsupervised sentence paraphrasing, and unsupervised sentence error correction. CGMH achieves high performance compared with previous supervised methods for sentence generation. Our code is released at https://github.com/NingMiao/CGMH

</details>

<details>

<summary>2018-11-14 15:53:25 - Large-scale Interactive Recommendation with Tree-structured Policy Gradient</summary>

- *Haokun Chen, Xinyi Dai, Han Cai, Weinan Zhang, Xuejian Wang, Ruiming Tang, Yuzhou Zhang, Yong Yu*

- `1811.05869v1` - [abs](http://arxiv.org/abs/1811.05869v1) - [pdf](http://arxiv.org/pdf/1811.05869v1)

> Reinforcement learning (RL) has recently been introduced to interactive recommender systems (IRS) because of its nature of learning from dynamic interactions and planning for long-run performance. As IRS is always with thousands of items to recommend (i.e., thousands of actions), most existing RL-based methods, however, fail to handle such a large discrete action space problem and thus become inefficient. The existing work that tries to deal with the large discrete action space problem by utilizing the deep deterministic policy gradient framework suffers from the inconsistency between the continuous action representation (the output of the actor network) and the real discrete action. To avoid such inconsistency and achieve high efficiency and recommendation effectiveness, in this paper, we propose a Tree-structured Policy Gradient Recommendation (TPGR) framework, where a balanced hierarchical clustering tree is built over the items and picking an item is formulated as seeking a path from the root to a certain leaf of the tree. Extensive experiments on carefully-designed environments based on two real-world datasets demonstrate that our model provides superior recommendation performance and significant efficiency improvement over state-of-the-art methods.

</details>

<details>

<summary>2018-11-14 16:38:42 - QUENN: QUantization Engine for low-power Neural Networks</summary>

- *Miguel de Prado, Maurizio Denna, Luca Benini, Nuria Pazos*

- `1811.05896v1` - [abs](http://arxiv.org/abs/1811.05896v1) - [pdf](http://arxiv.org/pdf/1811.05896v1)

> Deep Learning is moving to edge devices, ushering in a new age of distributed Artificial Intelligence (AI). The high demand of computational resources required by deep neural networks may be alleviated by approximate computing techniques, and most notably reduced-precision arithmetic with coarsely quantized numerical representations. In this context, Bonseyes comes in as an initiative to enable stakeholders to bring AI to low-power and autonomous environments such as: Automotive, Medical Healthcare and Consumer Electronics. To achieve this, we introduce LPDNN, a framework for optimized deployment of Deep Neural Networks on heterogeneous embedded devices. In this work, we detail the quantization engine that is integrated in LPDNN. The engine depends on a fine-grained workflow which enables a Neural Network Design Exploration and a sensitivity analysis of each layer for quantization. We demonstrate the engine with a case study on Alexnet and VGG16 for three different techniques for direct quantization: standard fixed-point, dynamic fixed-point and k-means clustering, and demonstrate the potential of the latter. We argue that using a Gaussian quantizer with k-means clustering can achieve better performance than linear quantizers. Without retraining, we achieve over 55.64\% saving for weights' storage and 69.17\% for run-time memory accesses with less than 1\% drop in top5 accuracy in Imagenet.

</details>

<details>

<summary>2018-11-14 18:08:39 - Interactive Semantic Parsing for If-Then Recipes via Hierarchical Reinforcement Learning</summary>

- *Ziyu Yao, Xiujun Li, Jianfeng Gao, Brian Sadler, Huan Sun*

- `1808.06740v2` - [abs](http://arxiv.org/abs/1808.06740v2) - [pdf](http://arxiv.org/pdf/1808.06740v2)

> Given a text description, most existing semantic parsers synthesize a program in one shot. However, it is quite challenging to produce a correct program solely based on the description, which in reality is often ambiguous or incomplete. In this paper, we investigate interactive semantic parsing, where the agent can ask the user clarification questions to resolve ambiguities via a multi-turn dialogue, on an important type of programs called "If-Then recipes." We develop a hierarchical reinforcement learning (HRL) based agent that significantly improves the parsing performance with minimal questions to the user. Results under both simulation and human evaluation show that our agent substantially outperforms non-interactive semantic parsers and rule-based agents.

</details>

<details>

<summary>2018-11-14 19:14:20 - Domain Agnostic Real-Valued Specificity Prediction</summary>

- *Wei-Jen Ko, Greg Durrett, Junyi Jessy Li*

- `1811.05085v2` - [abs](http://arxiv.org/abs/1811.05085v2) - [pdf](http://arxiv.org/pdf/1811.05085v2)

> Sentence specificity quantifies the level of detail in a sentence, characterizing the organization of information in discourse. While this information is useful for many downstream applications, specificity prediction systems predict very coarse labels (binary or ternary) and are trained on and tailored toward specific domains (e.g., news). The goal of this work is to generalize specificity prediction to domains where no labeled data is available and output more nuanced real-valued specificity ratings.   We present an unsupervised domain adaptation system for sentence specificity prediction, specifically designed to output real-valued estimates from binary training labels. To calibrate the values of these predictions appropriately, we regularize the posterior distribution of the labels towards a reference distribution. We show that our framework generalizes well to three different domains with 50%~68% mean absolute error reduction than the current state-of-the-art system trained for news sentence specificity. We also demonstrate the potential of our work in improving the quality and informativeness of dialogue generation systems.

</details>

<details>

<summary>2018-11-14 19:50:54 - Natural Environment Benchmarks for Reinforcement Learning</summary>

- *Amy Zhang, Yuxin Wu, Joelle Pineau*

- `1811.06032v1` - [abs](http://arxiv.org/abs/1811.06032v1) - [pdf](http://arxiv.org/pdf/1811.06032v1)

> While current benchmark reinforcement learning (RL) tasks have been useful to drive progress in the field, they are in many ways poor substitutes for learning with real-world data. By testing increasingly complex RL algorithms on low-complexity simulation environments, we often end up with brittle RL policies that generalize poorly beyond the very specific domain. To combat this, we propose three new families of benchmark RL domains that contain some of the complexity of the natural world, while still supporting fast and extensive data acquisition. The proposed domains also permit a characterization of generalization through fair train/test separation, and easy comparison and replication of results. Through this work, we challenge the RL research community to develop more robust algorithms that meet high standards of evaluation.

</details>

<details>

<summary>2018-11-14 20:21:25 - A Model for General Intelligence</summary>

- *Paul Yaworsky*

- `1811.02546v2` - [abs](http://arxiv.org/abs/1811.02546v2) - [pdf](http://arxiv.org/pdf/1811.02546v2)

> The overarching problem in artificial intelligence (AI) is that we do not understand the intelligence process well enough to enable the development of adequate computational models. Much work has been done in AI over the years at lower levels, but a big part of what has been missing involves the high level, abstract, general nature of intelligence. We address this gap by developing a model for general intelligence. To accomplish this, we focus on three basic aspects of intelligence. First, we must realize the general order and nature of intelligence at a high level. Second, we must come to know what these realizations mean with respect to the overall intelligence process. Third, we must describe these realizations as clearly as possible. We propose a hierarchical model to help capture and exploit the order within intelligence. The underlying order involves patterns of signals that become organized, stored and activated in space and time. These patterns can be described using a simple, general hierarchy, with physical signals at the lowest level, information in the middle, and abstract signal representations at the top. This high level perspective provides a big picture that literally helps us see the intelligence process, thereby enabling fundamental realizations, a better understanding and clear descriptions of the intelligence process. The resulting model can be used to support all kinds of information processing across multiple levels of abstraction. As computer technology improves, and as cooperation increases between humans and computers, people will become more efficient and more productive in performing their information processing tasks.

</details>

<details>

<summary>2018-11-14 20:44:50 - Human-like machine learning: limitations and suggestions</summary>

- *Georgios Mastorakis*

- `1811.06052v1` - [abs](http://arxiv.org/abs/1811.06052v1) - [pdf](http://arxiv.org/pdf/1811.06052v1)

> This paper attempts to address the issues of machine learning in its current implementation. It is known that machine learning algorithms require a significant amount of data for training purposes, whereas recent developments in deep learning have increased this requirement dramatically. The performance of an algorithm depends on the quality of data and hence, algorithms are as good as the data they are trained on. Supervised learning is developed based on human learning processes by analysing named (i.e. annotated) objects, scenes and actions. Whether training on large quantities of data (i.e. big data) is the right or the wrong approach, is debatable. The fact is, that training algorithms the same way we learn ourselves, comes with limitations. This paper discusses the issues around applying a human-like approach to train algorithms and the implications of this approach when using limited data. Several current studies involving non-data-driven algorithms and natural examples are also discussed and certain alternative approaches are suggested.

</details>

<details>

<summary>2018-11-14 21:54:58 - Constraint-based Sequential Pattern Mining with Decision Diagrams</summary>

- *Amin Hosseininasab, Willem-Jan van Hoeve, Andre A. Cire*

- `1811.06086v1` - [abs](http://arxiv.org/abs/1811.06086v1) - [pdf](http://arxiv.org/pdf/1811.06086v1)

> Constrained sequential pattern mining aims at identifying frequent patterns on a sequential database of items while observing constraints defined over the item attributes. We introduce novel techniques for constraint-based sequential pattern mining that rely on a multi-valued decision diagram representation of the database. Specifically, our representation can accommodate multiple item attributes and various constraint types, including a number of non-monotone constraints. To evaluate the applicability of our approach, we develop an MDD-based prefix-projection algorithm and compare its performance against a typical generate-and-check variant, as well as a state-of-the-art constraint-based sequential pattern mining algorithm. Results show that our approach is competitive with or superior to these other methods in terms of scalability and efficiency.

</details>

<details>

<summary>2018-11-14 22:26:16 - Deep Bayesian Trust : A Dominant and Fair Incentive Mechanism for Crowd</summary>

- *Naman Goel, Boi Faltings*

- `1804.05560v2` - [abs](http://arxiv.org/abs/1804.05560v2) - [pdf](http://arxiv.org/pdf/1804.05560v2)

> An important class of game-theoretic incentive mechanisms for eliciting effort from a crowd are the peer based mechanisms, in which workers are paid by matching their answers with one another. The other classic mechanism is to have the workers solve some gold standard tasks and pay them according to their accuracy on gold tasks. This mechanism ensures stronger incentive compatibility than the peer based mechanisms but assigning gold tasks to all workers becomes inefficient at large scale. We propose a novel mechanism that assigns gold tasks to only a few workers and exploits transitivity to derive accuracy of the rest of the workers from their peers' accuracy. We show that the resulting mechanism ensures a dominant notion of incentive compatibility and fairness.

</details>

<details>

<summary>2018-11-14 23:08:14 - Predictive Modeling with Delayed Information: a Case Study in E-commerce Transaction Fraud Control</summary>

- *Junxuan Li, Yung-wen Liu, Yuting Jia, Yifei Ren, Jay Nanduri*

- `1811.06109v1` - [abs](http://arxiv.org/abs/1811.06109v1) - [pdf](http://arxiv.org/pdf/1811.06109v1)

> In Business Intelligence, accurate predictive modeling is the key for providing adaptive decisions. We studied predictive modeling problems in this research which was motivated by real-world cases that Microsoft data scientists encountered while dealing with e-commerce transaction fraud control decisions using transaction streaming data in an uncertain probabilistic decision environment. The values of most online transactions related features can return instantly, while the true fraud labels only return after a stochastic delay. Using partially mature data directly for predictive modeling in an uncertain probabilistic decision environment would lead to significant inaccuracy on risk decision-making. To improve accurate estimation of the probabilistic prediction environment, which leads to more accurate predictive modeling, two frameworks, Current Environment Inference (CEI) and Future Environment Inference (FEI), are proposed. These frameworks generated decision environment related features using long-term fully mature and short-term partially mature data, and the values of those features were estimated using varies of learning methods, including linear regression, random forest, gradient boosted tree, artificial neural network, and recurrent neural network. Performance tests were conducted using some e-commerce transaction data from Microsoft. Testing results suggested that proposed frameworks significantly improved the accuracy of decision environment estimation.

</details>

<details>

<summary>2018-11-14 23:53:32 - PhoneMD: Learning to Diagnose Parkinson's Disease from Smartphone Data</summary>

- *Patrick Schwab, Walter Karlen*

- `1810.01485v2` - [abs](http://arxiv.org/abs/1810.01485v2) - [pdf](http://arxiv.org/pdf/1810.01485v2)

> Parkinson's disease is a neurodegenerative disease that can affect a person's movement, speech, dexterity, and cognition. Clinicians primarily diagnose Parkinson's disease by performing a clinical assessment of symptoms. However, misdiagnoses are common. One factor that contributes to misdiagnoses is that the symptoms of Parkinson's disease may not be prominent at the time the clinical assessment is performed. Here, we present a machine-learning approach towards distinguishing between people with and without Parkinson's disease using long-term data from smartphone-based walking, voice, tapping and memory tests. We demonstrate that our attentive deep-learning models achieve significant improvements in predictive performance over strong baselines (area under the receiver operating characteristic curve = 0.85) in data from a cohort of 1853 participants. We also show that our models identify meaningful features in the input data. Our results confirm that smartphone data collected over extended periods of time could in the future potentially be used as a digital biomarker for the diagnosis of Parkinson's disease.

</details>

<details>

<summary>2018-11-14 23:57:14 - Granger-causal Attentive Mixtures of Experts: Learning Important Features with Neural Networks</summary>

- *Patrick Schwab, Djordje Miladinovic, Walter Karlen*

- `1802.02195v6` - [abs](http://arxiv.org/abs/1802.02195v6) - [pdf](http://arxiv.org/pdf/1802.02195v6)

> Knowledge of the importance of input features towards decisions made by machine-learning models is essential to increase our understanding of both the models and the underlying data. Here, we present a new approach to estimating feature importance with neural networks based on the idea of distributing the features of interest among experts in an attentive mixture of experts (AME). AMEs use attentive gating networks trained with a Granger-causal objective to learn to jointly produce accurate predictions as well as estimates of feature importance in a single model. Our experiments show (i) that the feature importance estimates provided by AMEs compare favourably to those provided by state-of-the-art methods, (ii) that AMEs are significantly faster at estimating feature importance than existing methods, and (iii) that the associations discovered by AMEs are consistent with those reported by domain experts.

</details>

<details>

<summary>2018-11-15 01:14:53 - End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion</summary>

- *Chao Shang, Yun Tang, Jing Huang, Jinbo Bi, Xiaodong He, Bowen Zhou*

- `1811.04441v2` - [abs](http://arxiv.org/abs/1811.04441v2) - [pdf](http://arxiv.org/pdf/1811.04441v2)

> Knowledge graph embedding has been an active research topic for knowledge base completion, with progressive improvement from the initial TransE, TransH, DistMult et al to the current state-of-the-art ConvE. ConvE uses 2D convolution over embeddings and multiple layers of nonlinear features to model knowledge graphs. The model can be efficiently trained and scalable to large knowledge graphs. However, there is no structure enforcement in the embedding space of ConvE. The recent graph convolutional network (GCN) provides another way of learning graph node embedding by successfully utilizing graph connectivity structure. In this work, we propose a novel end-to-end Structure-Aware Convolutional Network (SACN) that takes the benefit of GCN and ConvE together. SACN consists of an encoder of a weighted graph convolutional network (WGCN), and a decoder of a convolutional network called Conv-TransE. WGCN utilizes knowledge graph node structure, node attributes and edge relation types. It has learnable weights that adapt the amount of information from neighbors used in local aggregation, leading to more accurate embeddings of graph nodes. Node attributes in the graph are represented as additional nodes in the WGCN. The decoder Conv-TransE enables the state-of-the-art ConvE to be translational between entities and relations while keeps the same link prediction performance as ConvE. We demonstrate the effectiveness of the proposed SACN on standard FB15k-237 and WN18RR datasets, and it gives about 10% relative improvement over the state-of-the-art ConvE in terms of HITS@1, HITS@3 and HITS@10.

</details>

<details>

<summary>2018-11-15 02:38:57 - Concept Learning through Deep Reinforcement Learning with Memory-Augmented Neural Networks</summary>

- *Jing Shi, Jiaming Xu, Yiqun Yao, Bo Xu*

- `1811.06145v1` - [abs](http://arxiv.org/abs/1811.06145v1) - [pdf](http://arxiv.org/pdf/1811.06145v1)

> Deep neural networks have shown superior performance in many regimes to remember familiar patterns with large amounts of data. However, the standard supervised deep learning paradigm is still limited when facing the need to learn new concepts efficiently from scarce data. In this paper, we present a memory-augmented neural network which is motivated by the process of human concept learning. The training procedure, imitating the concept formation course of human, learns how to distinguish samples from different classes and aggregate samples of the same kind. In order to better utilize the advantages originated from the human behavior, we propose a sequential process, during which the network should decide how to remember each sample at every step. In this sequential process, a stable and interactive memory serves as an important module. We validate our model in some typical one-shot learning tasks and also an exploratory outlier detection problem. In all the experiments, our model gets highly competitive to reach or outperform those strong baselines.

</details>

<details>

<summary>2018-11-15 02:52:43 - Orthogonal Policy Gradient and Autonomous Driving Application</summary>

- *Mincong Luo, Yin Tong, Jiachi Liu*

- `1811.06151v1` - [abs](http://arxiv.org/abs/1811.06151v1) - [pdf](http://arxiv.org/pdf/1811.06151v1)

> One less addressed issue of deep reinforcement learning is the lack of generalization capability based on new state and new target, for complex tasks, it is necessary to give the correct strategy and evaluate all possible actions for current state. Fortunately, deep reinforcement learning has enabled enormous progress in both subproblems: giving the correct strategy and evaluating all actions based on the state.   In this paper we present an approach called orthogonal policy gradient descent(OPGD) that can make agent learn the policy gradient based on the current state and the actions set, by which the agent can learn a policy network with generalization capability. we evaluate the proposed method on the 3D autonomous driving enviroment TORCS compared with the baseline model, detailed analyses of experimental results and proofs are also given.

</details>

<details>

<summary>2018-11-15 03:18:06 - Learning to Embed Sentences Using Attentive Recursive Trees</summary>

- *Jiaxin Shi, Lei Hou, Juanzi Li, Zhiyuan Liu, Hanwang Zhang*

- `1811.02338v2` - [abs](http://arxiv.org/abs/1811.02338v2) - [pdf](http://arxiv.org/pdf/1811.02338v2)

> Sentence embedding is an effective feature representation for most deep learning-based NLP tasks. One prevailing line of methods is using recursive latent tree-structured networks to embed sentences with task-specific structures. However, existing models have no explicit mechanism to emphasize task-informative words in the tree structure. To this end, we propose an Attentive Recursive Tree model (AR-Tree), where the words are dynamically located according to their importance in the task. Specifically, we construct the latent tree for a sentence in a proposed important-first strategy, and place more attentive words nearer to the root; thus, AR-Tree can inherently emphasize important words during the bottom-up composition of the sentence embedding. We propose an end-to-end reinforced training strategy for AR-Tree, which is demonstrated to consistently outperform, or be at least comparable to, the state-of-the-art sentence embedding methods on three sentence understanding tasks.

</details>

<details>

<summary>2018-11-15 03:38:20 - Exploiting Sentence Embedding for Medical Question Answering</summary>

- *Yu Hao, Xien Liu, Ji Wu, Ping Lv*

- `1811.06156v1` - [abs](http://arxiv.org/abs/1811.06156v1) - [pdf](http://arxiv.org/pdf/1811.06156v1)

> Despite the great success of word embedding, sentence embedding remains a not-well-solved problem. In this paper, we present a supervised learning framework to exploit sentence embedding for the medical question answering task. The learning framework consists of two main parts: 1) a sentence embedding producing module, and 2) a scoring module. The former is developed with contextual self-attention and multi-scale techniques to encode a sentence into an embedding tensor. This module is shortly called Contextual self-Attention Multi-scale Sentence Embedding (CAMSE). The latter employs two scoring strategies: Semantic Matching Scoring (SMS) and Semantic Association Scoring (SAS). SMS measures similarity while SAS captures association between sentence pairs: a medical question concatenated with a candidate choice, and a piece of corresponding supportive evidence. The proposed framework is examined by two Medical Question Answering(MedicalQA) datasets which are collected from real-world applications: medical exam and clinical diagnosis based on electronic medical records (EMR). The comparison results show that our proposed framework achieved significant improvements compared to competitive baseline approaches. Additionally, a series of controlled experiments are also conducted to illustrate that the multi-scale strategy and the contextual self-attention layer play important roles for producing effective sentence embedding, and the two kinds of scoring strategies are highly complementary to each other for question answering problems.

</details>

<details>

<summary>2018-11-15 04:58:21 - Implementing a Portable Clinical NLP System with a Common Data Model - a Lisp Perspective</summary>

- *Yuan Luo, Peter Szolovits*

- `1811.06179v1` - [abs](http://arxiv.org/abs/1811.06179v1) - [pdf](http://arxiv.org/pdf/1811.06179v1)

> This paper presents a Lisp architecture for a portable NLP system, termed LAPNLP, for processing clinical notes. LAPNLP integrates multiple standard, customized and in-house developed NLP tools. Our system facilitates portability across different institutions and data systems by incorporating an enriched Common Data Model (CDM) to standardize necessary data elements. It utilizes UMLS to perform domain adaptation when integrating generic domain NLP tools. It also features stand-off annotations that are specified by positional reference to the original document. We built an interval tree based search engine to efficiently query and retrieve the stand-off annotations by specifying positional requirements. We also developed a utility to convert an inline annotation format to stand-off annotations to enable the reuse of clinical text datasets with inline annotations. We experimented with our system on several NLP facilitated tasks including computational phenotyping for lymphoma patients and semantic relation extraction for clinical notes. These experiments showcased the broader applicability and utility of LAPNLP.

</details>

<details>

<summary>2018-11-15 05:12:33 - Characterizing Design Patterns of EHR-Driven Phenotype Extraction Algorithms</summary>

- *Yizhen Zhong, Luke Rasmussen, Yu Deng, Jennifer Pacheco, Maureen Smith, Justin Starren, Wei-Qi Wei, Peter Speltz, Joshua Denny, Nephi Walton, George Hripcsak, Christopher G Chute, Yuan Luo*

- `1811.06183v1` - [abs](http://arxiv.org/abs/1811.06183v1) - [pdf](http://arxiv.org/pdf/1811.06183v1)

> The automatic development of phenotype algorithms from Electronic Health Record data with machine learning (ML) techniques is of great interest given the current practice is very time-consuming and resource intensive. The extraction of design patterns from phenotype algorithms is essential to understand their rationale and standard, with great potential to automate the development process. In this pilot study, we perform network visualization on the design patterns and their associations with phenotypes and sites. We classify design patterns using the fragments from previously annotated phenotype algorithms as the ground truth. The classification performance is used as a proxy for coherence at the attribution level. The bag-of-words representation with knowledge-based features generated a good performance in the classification task (0.79 macro-f1 scores). Good classification accuracy with simple features demonstrated the attribution coherence and the feasibility of automatic identification of design patterns. Our results point to both the feasibility and challenges of automatic identification of phenotyping design patterns, which would power the automatic development of phenotype algorithms.

</details>

<details>

<summary>2018-11-15 05:26:38 - Intervention Aided Reinforcement Learning for Safe and Practical Policy Optimization in Navigation</summary>

- *Fan Wang, Bo Zhou, Ke Chen, Tingxiang Fan, Xi Zhang, Jiangyong Li, Hao Tian, Jia Pan*

- `1811.06187v1` - [abs](http://arxiv.org/abs/1811.06187v1) - [pdf](http://arxiv.org/pdf/1811.06187v1)

> Combining deep neural networks with reinforcement learning has shown great potential in the next-generation intelligent control. However, there are challenges in terms of safety and cost in practical applications. In this paper, we propose the Intervention Aided Reinforcement Learning (IARL) framework, which utilizes human intervened robot-environment interaction to improve the policy. We used the Unmanned Aerial Vehicle (UAV) as the test platform. We built neural networks as our policy to map sensor readings to control signals on the UAV. Our experiment scenarios cover both simulation and reality. We show that our approach substantially reduces the human intervention and improves the performance in autonomous navigation, at the same time it ensures safety and keeps training cost acceptable.

</details>

<details>

<summary>2018-11-15 05:41:18 - Knowledge Tracing Machines: Factorization Machines for Knowledge Tracing</summary>

- *Jill-Jênn Vie, Hisashi Kashima*

- `1811.03388v2` - [abs](http://arxiv.org/abs/1811.03388v2) - [pdf](http://arxiv.org/pdf/1811.03388v2)

> Knowledge tracing is a sequence prediction problem where the goal is to predict the outcomes of students over questions as they are interacting with a learning platform. By tracking the evolution of the knowledge of some student, one can optimize instruction. Existing methods are either based on temporal latent variable models, or factor analysis with temporal features. We here show that factorization machines (FMs), a model for regression or classification, encompasses several existing models in the educational literature as special cases, notably additive factor model, performance factor model, and multidimensional item response theory. We show, using several real datasets of tens of thousands of users and items, that FMs can estimate student knowledge accurately and fast even when student data is sparsely observed, and handle side information such as multiple knowledge components and number of attempts at item or skill level. Our approach allows to fit student models of higher dimension than existing models, and provides a testbed to try new combinations of features in order to improve existing models.

</details>

<details>

<summary>2018-11-15 06:40:39 - Combining Axiom Injection and Knowledge Base Completion for Efficient Natural Language Inference</summary>

- *Masashi Yoshikawa, Koji Mineshima, Hiroshi Noji, Daisuke Bekki*

- `1811.06203v1` - [abs](http://arxiv.org/abs/1811.06203v1) - [pdf](http://arxiv.org/pdf/1811.06203v1)

> In logic-based approaches to reasoning tasks such as Recognizing Textual Entailment (RTE), it is important for a system to have a large amount of knowledge data. However, there is a tradeoff between adding more knowledge data for improved RTE performance and maintaining an efficient RTE system, as such a big database is problematic in terms of the memory usage and computational complexity. In this work, we show the processing time of a state-of-the-art logic-based RTE system can be significantly reduced by replacing its search-based axiom injection (abduction) mechanism by that based on Knowledge Base Completion (KBC). We integrate this mechanism in a Coq plugin that provides a proof automation tactic for natural language inference. Additionally, we show empirically that adding new knowledge data contributes to better RTE performance while not harming the processing speed in this framework.

</details>

<details>

<summary>2018-11-15 08:15:04 - A Way to Facilitate Decision Making in a Mixed Group of Manned and Unmanned Aerial Vehicles</summary>

- *Dmitry Maximov, Yury Legovich, Vladimir Goncharenko*

- `1809.10441v2` - [abs](http://arxiv.org/abs/1809.10441v2) - [pdf](http://arxiv.org/pdf/1809.10441v2)

> A mixed group of manned and unmanned aerial vehicles is considered as a distributed system. A lattice of tasks which may be fulfilled by the system matches to it. An external multiplication operation is defined at the lattice, which defines correspondingly linear logic operations. Linear implication and tensor product are used to choose a system reconfiguration variant, i.e., to determine a new task executor choice. The task lattice structure (i.e., the system purpose) and the operation definitions largely define the choice. Thus, the choice is mainly the system purpose consequence. Such a method of the behavior variant choice facilitates the decision making by the pilot controlling the group. The suggested approach is illustrated using an example of a mixed group control at forest fire compression.

</details>

<details>

<summary>2018-11-15 08:39:04 - On Training Targets and Objective Functions for Deep-Learning-Based Audio-Visual Speech Enhancement</summary>

- *Daniel Michelsanti, Zheng-Hua Tan, Sigurdur Sigurdsson, Jesper Jensen*

- `1811.06234v1` - [abs](http://arxiv.org/abs/1811.06234v1) - [pdf](http://arxiv.org/pdf/1811.06234v1)

> Audio-visual speech enhancement (AV-SE) is the task of improving speech quality and intelligibility in a noisy environment using audio and visual information from a talker. Recently, deep learning techniques have been adopted to solve the AV-SE task in a supervised manner. In this context, the choice of the target, i.e. the quantity to be estimated, and the objective function, which quantifies the quality of this estimate, to be used for training is critical for the performance. This work is the first that presents an experimental study of a range of different targets and objective functions used to train a deep-learning-based AV-SE system. The results show that the approaches that directly estimate a mask perform the best overall in terms of estimated speech quality and intelligibility, although the model that directly estimates the log magnitude spectrum performs as good in terms of estimated speech quality.

</details>

<details>

<summary>2018-11-15 08:50:34 - SGR: Self-Supervised Spectral Graph Representation Learning</summary>

- *Anton Tsitsulin, Davide Mottin, Panagiotis Karras, Alex Bronstein, Emmanuel Müller*

- `1811.06237v1` - [abs](http://arxiv.org/abs/1811.06237v1) - [pdf](http://arxiv.org/pdf/1811.06237v1)

> Representing a graph as a vector is a challenging task; ideally, the representation should be easily computable and conducive to efficient comparisons among graphs, tailored to the particular data and analytical task at hand. Unfortunately, a "one-size-fits-all" solution is unattainable, as different analytical tasks may require different attention to global or local graph features. We develop SGR, the first, to our knowledge, method for learning graph representations in a self-supervised manner. Grounded on spectral graph analysis, SGR seamlessly combines all aforementioned desirable properties. In extensive experiments, we show how our approach works on large graph collections, facilitates self-supervised representation learning across a variety of application domains, and performs competitively to state-of-the-art methods without re-training.

</details>

<details>

<summary>2018-11-15 09:35:51 - Axiomatic Characterization of Data-Driven Influence Measures for Classification</summary>

- *Jakub Sliwinski, Martin Strobel, Yair Zick*

- `1708.02153v2` - [abs](http://arxiv.org/abs/1708.02153v2) - [pdf](http://arxiv.org/pdf/1708.02153v2)

> We study the following problem: given a labeled dataset and a specific datapoint x, how did the i-th feature influence the classification for x? We identify a family of numerical influence measures - functions that, given a datapoint x, assign a numeric value phi_i(x) to every feature i, corresponding to how altering i's value would influence the outcome for x. This family, which we term monotone influence measures (MIM), is uniquely derived from a set of desirable properties, or axioms. The MIM family constitutes a provably sound methodology for measuring feature influence in classification domains; the values generated by MIM are based on the dataset alone, and do not make any queries to the classifier. While this requirement naturally limits the scope of our framework, we demonstrate its effectiveness on data.

</details>

<details>

<summary>2018-11-15 10:34:33 - Guiding the One-to-one Mapping in CycleGAN via Optimal Transport</summary>

- *Guansong Lu, Zhiming Zhou, Yuxuan Song, Kan Ren, Yong Yu*

- `1811.06284v1` - [abs](http://arxiv.org/abs/1811.06284v1) - [pdf](http://arxiv.org/pdf/1811.06284v1)

> CycleGAN is capable of learning a one-to-one mapping between two data distributions without paired examples, achieving the task of unsupervised data translation. However, there is no theoretical guarantee on the property of the learned one-to-one mapping in CycleGAN. In this paper, we experimentally find that, under some circumstances, the one-to-one mapping learned by CycleGAN is just a random one within the large feasible solution space. Based on this observation, we explore to add extra constraints such that the one-to-one mapping is controllable and satisfies more properties related to specific tasks. We propose to solve an optimal transport mapping restrained by a task-specific cost function that reflects the desired properties, and use the barycenters of optimal transport mapping to serve as references for CycleGAN. Our experiments indicate that the proposed algorithm is capable of learning a one-to-one mapping with the desired properties.

</details>

<details>

<summary>2018-11-15 10:43:18 - Probabilistic Logic Programming with Beta-Distributed Random Variables</summary>

- *Federico Cerutti, Lance Kaplan, Angelika Kimmig, Murat Sensoy*

- `1809.07888v3` - [abs](http://arxiv.org/abs/1809.07888v3) - [pdf](http://arxiv.org/pdf/1809.07888v3)

> We enable aProbLog---a probabilistic logical programming approach---to reason in presence of uncertain probabilities represented as Beta-distributed random variables. We achieve the same performance of state-of-the-art algorithms for highly specified and engineered domains, while simultaneously we maintain the flexibility offered by aProbLog in handling complex relational domains. Our motivation is that faithfully capturing the distribution of probabilities is necessary to compute an expected utility for effective decision making under uncertainty: unfortunately, these probability distributions can be highly uncertain due to sparse data. To understand and accurately manipulate such probability distributions we need a well-defined theoretical framework that is provided by the Beta distribution, which specifies a distribution of probabilities representing all the possible values of a probability when the exact value is unknown.

</details>

<details>

<summary>2018-11-15 10:47:38 - R2-D2: ColoR-inspired Convolutional NeuRal Network (CNN)-based AndroiD Malware Detections</summary>

- *TonTon Hsien-De Huang, Hung-Yu Kao*

- `1705.04448v5` - [abs](http://arxiv.org/abs/1705.04448v5) - [pdf](http://arxiv.org/pdf/1705.04448v5)

> The influence of Deep Learning on image identification and natural language processing has attracted enormous attention globally. The convolution neural network that can learn without prior extraction of features fits well in response to the rapid iteration of Android malware. The traditional solution for detecting Android malware requires continuous learning through pre-extracted features to maintain high performance of identifying the malware. In order to reduce the manpower of feature engineering prior to the condition of not to extract pre-selected features, we have developed a coloR-inspired convolutional neuRal networks (CNN)-based AndroiD malware Detection (R2-D2) system. The system can convert the bytecode of classes.dex from Android archive file to rgb color code and store it as a color image with fixed size. The color image is input to the convolutional neural network for automatic feature extraction and training. The data was collected from Jan. 2017 to Aug 2017. During the period of time, we have collected approximately 2 million of benign and malicious Android apps for our experiments with the help from our research partner Leopard Mobile Inc. Our experiment results demonstrate that the proposed system has accurate security analysis on contracts. Furthermore, we keep our research results and experiment materials on http://R2D2.TWMAN.ORG.

</details>

<details>

<summary>2018-11-15 11:06:52 - Stream Reasoning in Temporal Datalog</summary>

- *Alessandro Ronca, Mark Kaminski, Bernardo Cuenca Grau, Boris Motik, Ian Horrocks*

- `1711.04013v2` - [abs](http://arxiv.org/abs/1711.04013v2) - [pdf](http://arxiv.org/pdf/1711.04013v2)

> In recent years, there has been an increasing interest in extending traditional stream processing engines with logical, rule-based, reasoning capabilities. This poses significant theoretical and practical challenges since rules can derive new information and propagate it both towards past and future time points; as a result, streamed query answers can depend on data that has not yet been received, as well as on data that arrived far in the past. Stream reasoning algorithms, however, must be able to stream out query answers as soon as possible, and can only keep a limited number of previous input facts in memory. In this paper, we propose novel reasoning problems to deal with these challenges, and study their computational properties on Datalog extended with a temporal sort and the successor function (a core rule-based language for stream reasoning applications).

</details>

<details>

<summary>2018-11-15 11:09:58 - Individualized Time-Series Segmentation for Mining Mobile Phone User Behavior</summary>

- *Iqbal H. Sarker, Alan Colman, MA Kabir, Jun Han*

- `1811.09577v1` - [abs](http://arxiv.org/abs/1811.09577v1) - [pdf](http://arxiv.org/pdf/1811.09577v1)

> Mobile phones can record individual's daily behavioral data as a time-series. In this paper, we present an effective time-series segmentation technique that extracts optimal time segments of individual's similar behavioral characteristics utilizing their mobile phone data. One of the determinants of an individual's behavior is the various activities undertaken at various times-of-the-day and days-of-the-week. In many cases, such behavior will follow temporal patterns. Currently, researchers use either equal or unequal interval-based segmentation of time for mining mobile phone users' behavior. Most of them take into account static temporal coverage of 24-h-a-day and few of them take into account the number of incidences in time-series data. However, such segmentations do not necessarily map to the patterns of individual user activity and subsequent behavior because of not taking into account the diverse behaviors of individuals over time-of-the-week. Therefore, we propose a behavior-oriented time segmentation (BOTS) technique that takes into account not only the temporal coverage of the week but also the number of incidences of diverse behaviors dynamically for producing similar behavioral time segments over the week utilizing time-series data. Experiments on the real mobile phone datasets show that our proposed segmentation technique better captures the user's dominant behavior at various times-of-the-day and days-of-the-week enabling the generation of high confidence temporal rules in order to mine individual mobile phone users' behavior.

</details>

<details>

<summary>2018-11-15 14:13:16 - iSTRICT: An Interdependent Strategic Trust Mechanism for the Cloud-Enabled Internet of Controlled Things</summary>

- *Jeffrey Pawlick, Juntao Chen, Quanyan Zhu*

- `1805.00403v2` - [abs](http://arxiv.org/abs/1805.00403v2) - [pdf](http://arxiv.org/pdf/1805.00403v2)

> The cloud-enabled Internet of controlled things (IoCT) envisions a network of sensors, controllers, and actuators connected through a local cloud in order to intelligently control physical devices. Because cloud services are vulnerable to advanced persistent threats (APTs), each device in the IoCT must strategically decide whether to trust cloud services that may be compromised. In this paper, we present iSTRICT, an interdependent strategic trust mechanism for the cloud-enabled IoCT. iSTRICT is composed of three interdependent layers. In the cloud layer, iSTRICT uses FlipIt games to conceptualize APTs. In the communication layer, it captures the interaction between devices and the cloud using signaling games. In the physical layer, iSTRICT uses optimal control to quantify the utilities in the higher level games. Best response dynamics link the three layers in an overall "game-of-games," for which the outcome is captured by a concept called Gestalt Nash equilibrium (GNE). We prove the existence of a GNE under a set of natural assumptions and develop an adaptive algorithm to iteratively compute the equilibrium. Finally, we apply iSTRICT to trust management for autonomous vehicles that rely on measurements from remote sources. We show that strategic trust in the communication layer achieves a worst-case probability of compromise for any attack and defense costs in the cyber layer.

</details>

<details>

<summary>2018-11-15 16:08:05 - Adversarial Resilience Learning - Towards Systemic Vulnerability Analysis for Large and Complex Systems</summary>

- *Lars Fischer, Jan-Menno Memmen, Eric MSP Veith, Martin Tröschel*

- `1811.06447v1` - [abs](http://arxiv.org/abs/1811.06447v1) - [pdf](http://arxiv.org/pdf/1811.06447v1)

> This paper introduces Adversarial Resilience Learning (ARL), a concept to model, train, and analyze artificial neural networks as representations of competitive agents in highly complex systems. In our examples, the agents normally take the roles of attackers or defenders that aim at worsening or improving-or keeping, respectively-defined performance indicators of the system. Our concept provides adaptive, repeatable, actor-based testing with a chance of detecting previously unknown attack vectors. We provide the constitutive nomenclature of ARL and, based on it, the description of experimental setups and results of a preliminary implementation of ARL in simulated power systems.

</details>

<details>

<summary>2018-11-15 17:53:44 - The Window Validity Problem in Rule-Based Stream Reasoning</summary>

- *Alessandro Ronca, Mark Kaminski, Bernardo Cuenca Grau, Ian Horrocks*

- `1808.02291v3` - [abs](http://arxiv.org/abs/1808.02291v3) - [pdf](http://arxiv.org/pdf/1808.02291v3)

> Rule-based temporal query languages provide the expressive power and flexibility required to capture in a natural way complex analysis tasks over streaming data. Stream processing applications, however, typically require near real-time response using limited resources. In particular, it becomes essential that the underpinning query language has favourable computational properties and that stream processing algorithms are able to keep only a small number of previously received facts in memory at any point in time without sacrificing correctness. In this paper, we propose a recursive fragment of temporal Datalog with tractable data complexity and study the properties of a generic stream reasoning algorithm for this fragment. We focus on the window validity problem as a way to minimise the number of time points for which the stream reasoning algorithm needs to keep data in memory at any point in time.

</details>

<details>

<summary>2018-11-15 17:53:47 - Randomized Prior Functions for Deep Reinforcement Learning</summary>

- *Ian Osband, John Aslanides, Albin Cassirer*

- `1806.03335v2` - [abs](http://arxiv.org/abs/1806.03335v2) - [pdf](http://arxiv.org/pdf/1806.03335v2)

> Dealing with uncertainty is essential for efficient reinforcement learning. There is a growing literature on uncertainty estimation for deep learning from fixed datasets, but many of the most popular approaches are poorly-suited to sequential decision problems. Other methods, such as bootstrap sampling, have no mechanism for uncertainty that does not come from the observed data. We highlight why this can be a crucial shortcoming and propose a simple remedy through addition of a randomized untrainable `prior' network to each ensemble member. We prove that this approach is efficient with linear representations, provide simple illustrations of its efficacy with nonlinear representations and show that this approach scales to large-scale problems far better than previous attempts.

</details>

<details>

<summary>2018-11-15 18:33:43 - Reward learning from human preferences and demonstrations in Atari</summary>

- *Borja Ibarz, Jan Leike, Tobias Pohlen, Geoffrey Irving, Shane Legg, Dario Amodei*

- `1811.06521v1` - [abs](http://arxiv.org/abs/1811.06521v1) - [pdf](http://arxiv.org/pdf/1811.06521v1)

> To solve complex real-world problems with reinforcement learning, we cannot rely on manually specified reward functions. Instead, we can have humans communicate an objective to the agent directly. In this work, we combine two approaches to learning from human feedback: expert demonstrations and trajectory preferences. We train a deep neural network to model the reward function and use its predicted reward to train an DQN-based deep reinforcement learning agent on 9 Atari games. Our approach beats the imitation learning baseline in 7 games and achieves strictly superhuman performance on 2 games without using game rewards. Additionally, we investigate the goodness of fit of the reward model, present some reward hacking problems, and study the effects of noise in the human labels.

</details>

<details>

<summary>2018-11-15 19:16:18 - Seq2Seq Mimic Games: A Signaling Perspective</summary>

- *Juan Leni, John Levine, John Quigley*

- `1811.06564v1` - [abs](http://arxiv.org/abs/1811.06564v1) - [pdf](http://arxiv.org/pdf/1811.06564v1)

> We study the emergence of communication in multiagent adversarial settings inspired by the classic Imitation game. A class of three player games is used to explore how agents based on sequence to sequence (Seq2Seq) models can learn to communicate information in adversarial settings. We propose a modeling approach, an initial set of experiments and use signaling theory to support our analysis. In addition, we describe how we operationalize the learning process of actor-critic Seq2Seq based agents in these communicational games.

</details>

<details>

<summary>2018-11-15 21:22:58 - Streaming Kernel PCA with $\tilde{O}(\sqrt{n})$ Random Features</summary>

- *Enayat Ullah, Poorya Mianjy, Teodor V. Marinov, Raman Arora*

- `1808.00934v2` - [abs](http://arxiv.org/abs/1808.00934v2) - [pdf](http://arxiv.org/pdf/1808.00934v2)

> We study the statistical and computational aspects of kernel principal component analysis using random Fourier features and show that under mild assumptions, $O(\sqrt{n} \log n)$ features suffices to achieve $O(1/\epsilon^2)$ sample complexity. Furthermore, we give a memory efficient streaming algorithm based on classical Oja's algorithm that achieves this rate.

</details>

<details>

<summary>2018-11-15 21:29:26 - On Generality and Knowledge Transferability in Cross-Domain Duplicate Question Detection for Heterogeneous Community Question Answering</summary>

- *Mohomed Shazan Mohomed Jabbar, Luke Kumar, Hamman Samuel, Mi-Young Kim, Sankalp Prabhakar, Randy Goebel, Osmar Zaïane*

- `1811.06596v1` - [abs](http://arxiv.org/abs/1811.06596v1) - [pdf](http://arxiv.org/pdf/1811.06596v1)

> Duplicate question detection is an ongoing challenge in community question answering because semantically equivalent questions can have significantly different words and structures. In addition, the identification of duplicate questions can reduce the resources required for retrieval, when the same questions are not repeated. This study compares the performance of deep neural networks and gradient tree boosting, and explores the possibility of domain adaptation with transfer learning to improve the under-performing target domains for the text-pair duplicates classification task, using three heterogeneous datasets: general-purpose Quora, technical Ask Ubuntu, and academic English Stack Exchange. Ultimately, our study exposes the alternative hypothesis that the meaning of a "duplicate" is not inherently general-purpose, but rather is dependent on the domain of learning, hence reducing the chance of transfer learning through adapting to the domain.

</details>

<details>

<summary>2018-11-15 22:42:16 - A Polynomial-Time Deterministic Approach to the Traveling Salesperson Problem</summary>

- *Ali Jazayeri, Hiroki Sayama*

- `1608.01716v4` - [abs](http://arxiv.org/abs/1608.01716v4) - [pdf](http://arxiv.org/pdf/1608.01716v4)

> We propose a new polynomial-time deterministic algorithm that produces an approximated solution for the traveling salesperson problem. The proposed algorithm ranks cities based on their priorities calculated using a power function of means and standard deviations of their distances from other cities and then connects the cities to their neighbors in the order of their priorities. When connecting a city, a neighbor is selected based on their neighbors' priorities calculated as another power function that additionally includes their distance from the focal city to be connected. This repeats until all the cities are connected into a single loop. The time complexity of the proposed algorithm is $O(n^2)$, where $n$ is the number of cities. Numerical evaluation shows that, despite its simplicity, the proposed algorithm produces shorter tours with less time complexity than other conventional tour construction heuristics. The proposed algorithm can be used by itself or as an initial tour generator for other more complex heuristic optimization algorithms.

</details>

<details>

<summary>2018-11-15 22:59:25 - Generating Responses Expressing Emotion in an Open-domain Dialogue System</summary>

- *Chenyang Huang, Osmar R. Zaïane*

- `1811.10990v1` - [abs](http://arxiv.org/abs/1811.10990v1) - [pdf](http://arxiv.org/pdf/1811.10990v1)

> Neural network-based Open-ended conversational agents automatically generate responses based on predictive models learned from a large number of pairs of utterances. The generated responses are typically acceptable as a sentence but are often dull, generic, and certainly devoid of any emotion. In this paper, we present neural models that learn to express a given emotion in the generated response. We propose four models and evaluate them against 3 baselines. An encoder-decoder framework-based model with multiple attention layers provides the best overall performance in terms of expressing the required emotion. While it does not outperform other models on all emotions, it presents promising results in most cases.

</details>

<details>

<summary>2018-11-15 23:13:26 - Concept-Oriented Deep Learning: Generative Concept Representations</summary>

- *Daniel T. Chang*

- `1811.06622v1` - [abs](http://arxiv.org/abs/1811.06622v1) - [pdf](http://arxiv.org/pdf/1811.06622v1)

> Generative concept representations have three major advantages over discriminative ones: they can represent uncertainty, they support integration of learning and reasoning, and they are good for unsupervised and semi-supervised learning. We discuss probabilistic and generative deep learning, which generative concept representations are based on, and the use of variational autoencoders and generative adversarial networks for learning generative concept representations, particularly for concepts whose data are sequences, structured data or graphs.

</details>

<details>

<summary>2018-11-15 23:23:36 - The Utility of Sparse Representations for Control in Reinforcement Learning</summary>

- *Vincent Liu, Raksha Kumaraswamy, Lei Le, Martha White*

- `1811.06626v1` - [abs](http://arxiv.org/abs/1811.06626v1) - [pdf](http://arxiv.org/pdf/1811.06626v1)

> We investigate sparse representations for control in reinforcement learning. While these representations are widely used in computer vision, their prevalence in reinforcement learning is limited to sparse coding where extracting representations for new data can be computationally intensive. Here, we begin by demonstrating that learning a control policy incrementally with a representation from a standard neural network fails in classic control domains, whereas learning with a representation obtained from a neural network that has sparsity properties enforced is effective. We provide evidence that the reason for this is that the sparse representation provides locality, and so avoids catastrophic interference, and particularly keeps consistent, stable values for bootstrapping. We then discuss how to learn such sparse representations. We explore the idea of Distributional Regularizers, where the activation of hidden nodes is encouraged to match a particular distribution that results in sparse activation across time. We identify a simple but effective way to obtain sparse representations, not afforded by previously proposed strategies, making it more practical for further investigation into sparse representations for reinforcement learning.

</details>

<details>

<summary>2018-11-15 23:47:39 - Nudging Neural Conversational Model with Domain Knowledge</summary>

- *Sungjin Lee*

- `1811.06630v1` - [abs](http://arxiv.org/abs/1811.06630v1) - [pdf](http://arxiv.org/pdf/1811.06630v1)

> Neural conversation models are attractive because one can train a model directly on dialog examples with minimal labeling. With a small amount of data, however, they often fail to generalize over test data since they tend to capture spurious features instead of semantically meaningful domain knowledge. To address this issue, we propose a novel approach that allows any human teachers to transfer their domain knowledge to the conversation model in the form of natural language rules. We tested our method with three different dialog datasets. The improved performance across all domains demonstrates the efficacy of our proposed method.

</details>

<details>

<summary>2018-11-16 01:35:09 - A Voice Controlled E-Commerce Web Application</summary>

- *Mandeep Singh Kandhari, Farhana Zulkernine, Haruna Isah*

- `1811.09688v1` - [abs](http://arxiv.org/abs/1811.09688v1) - [pdf](http://arxiv.org/pdf/1811.09688v1)

> Automatic voice-controlled systems have changed the way humans interact with a computer. Voice or speech recognition systems allow a user to make a hands-free request to the computer, which in turn processes the request and serves the user with appropriate responses. After years of research and developments in machine learning and artificial intelligence, today voice-controlled technologies have become more efficient and are widely applied in many domains to enable and improve human-to-human and human-to-computer interactions. The state-of-the-art e-commerce applications with the help of web technologies offer interactive and user-friendly interfaces. However, there are some instances where people, especially with visual disabilities, are not able to fully experience the serviceability of such applications. A voice-controlled system embedded in a web application can enhance user experience and can provide voice as a means to control the functionality of e-commerce websites. In this paper, we propose a taxonomy of speech recognition systems (SRS) and present a voice-controlled commodity purchase e-commerce application using IBM Watson speech-to-text to demonstrate its usability. The prototype can be extended to other application scenarios such as government service kiosks and enable analytics of the converted text data for scenarios such as medical diagnosis at the clinics.

</details>

<details>

<summary>2018-11-16 02:40:00 - Generative Model for Material Experiments Based on Prior Knowledge and Attention Mechanism</summary>

- *Mincong Luo, Xinfu He, Li Liu*

- `1811.07982v1` - [abs](http://arxiv.org/abs/1811.07982v1) - [pdf](http://arxiv.org/pdf/1811.07982v1)

> Material irradiation experiment is dangerous and complex, thus it requires those with a vast advanced expertise to process the images and data manually. In this paper, we propose a generative adversarial model based on prior knowledge and attention mechanism to achieve the generation of irradiated material images (data-to-image model), and a prediction model for corresponding industrial performance (image-to-data model). With the proposed models, researchers can skip the dangerous and complex irradiation experiments and obtain the irradiation images and industrial performance parameters directly by inputing some experimental parameters only. We also introduce a new dataset ISMD which contains 22000 irradiated images with 22,143 sets of corresponding parameters. Our model achieved high quality results by compared with several baseline models. The evaluation and detailed analysis are also performed.

</details>

<details>

<summary>2018-11-16 03:59:22 - Detecting Irregular Patterns in IoT Streaming Data for Fall Detection</summary>

- *Sazia Mahfuz, Haruna Isah, Farhana Zulkernine, Peter Nicholls*

- `1811.06672v1` - [abs](http://arxiv.org/abs/1811.06672v1) - [pdf](http://arxiv.org/pdf/1811.06672v1)

> Detecting patterns in real time streaming data has been an interesting and challenging data analytics problem. With the proliferation of a variety of sensor devices, real-time analytics of data from the Internet of Things (IoT) to learn regular and irregular patterns has become an important machine learning problem to enable predictive analytics for automated notification and decision support. In this work, we address the problem of learning an irregular human activity pattern, fall, from streaming IoT data from wearable sensors. We present a deep neural network model for detecting fall based on accelerometer data giving 98.75 percent accuracy using an online physical activity monitoring dataset called "MobiAct", which was published by Vavoulas et al. The initial model was developed using IBM Watson studio and then later transferred and deployed on IBM Cloud with the streaming analytics service supported by IBM Streams for monitoring real-time IoT data. We also present the systems architecture of the real-time fall detection framework that we intend to use with mbientlabs wearable health monitoring sensors for real time patient monitoring at retirement homes or rehabilitation clinics.

</details>

<details>

<summary>2018-11-16 05:36:16 - DeepHunter: Hunting Deep Neural Network Defects via Coverage-Guided Fuzzing</summary>

- *Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Hongxu Chen, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, Jianxiong Yin, Simon See*

- `1809.01266v3` - [abs](http://arxiv.org/abs/1809.01266v3) - [pdf](http://arxiv.org/pdf/1809.01266v3)

> In company with the data explosion over the past decade, deep neural network (DNN) based software has experienced unprecedented leap and is becoming the key driving force of many novel industrial applications, including many safety-critical scenarios such as autonomous driving. Despite great success achieved in various human intelligence tasks, similar to traditional software, DNNs could also exhibit incorrect behaviors caused by hidden defects causing severe accidents and losses. In this paper, we propose DeepHunter, an automated fuzz testing framework for hunting potential defects of general-purpose DNNs. DeepHunter performs metamorphic mutation to generate new semantically preserved tests, and leverages multiple plugable coverage criteria as feedback to guide the test generation from different perspectives. To be scalable towards practical-sized DNNs, DeepHunter maintains multiple tests in a batch, and prioritizes the tests selection based on active feedback. The effectiveness of DeepHunter is extensively investigated on 3 popular datasets (MNIST, CIFAR-10, ImageNet) and 7 DNNs with diverse complexities, under a large set of 6 coverage criteria as feedback. The large-scale experiments demonstrate that DeepHunter can (1) significantly boost the coverage with guidance; (2) generate useful tests to detect erroneous behaviors and facilitate the DNN model quality evaluation; (3) accurately capture potential defects during DNN quantization for platform migration.

</details>

<details>

<summary>2018-11-16 07:18:19 - Activation Maximization Generative Adversarial Nets</summary>

- *Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang, Yong Yu, Jun Wang*

- `1703.02000v9` - [abs](http://arxiv.org/abs/1703.02000v9) - [pdf](http://arxiv.org/pdf/1703.02000v9)

> Class labels have been empirically shown useful in improving the sample quality of generative adversarial nets (GANs). In this paper, we mathematically study the properties of the current variants of GANs that make use of class label information. With class aware gradient and cross-entropy decomposition, we reveal how class labels and associated losses influence GAN's training. Based on that, we propose Activation Maximization Generative Adversarial Networks (AM-GAN) as an advanced solution. Comprehensive experiments have been conducted to validate our analysis and evaluate the effectiveness of our solution, where AM-GAN outperforms other strong baselines and achieves state-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we demonstrate that, with the Inception ImageNet classifier, Inception Score mainly tracks the diversity of the generator, and there is, however, no reliable evidence that it can reflect the true sample quality. We thus propose a new metric, called AM Score, to provide a more accurate estimation of the sample quality. Our proposed model also outperforms the baseline methods in the new metric.

</details>

<details>

<summary>2018-11-16 09:06:54 - An Algorithmic Perspective on Imitation Learning</summary>

- *Takayuki Osa, Joni Pajarinen, Gerhard Neumann, J. Andrew Bagnell, Pieter Abbeel, Jan Peters*

- `1811.06711v1` - [abs](http://arxiv.org/abs/1811.06711v1) - [pdf](http://arxiv.org/pdf/1811.06711v1)

> As robots and other intelligent agents move from simple environments and problems to more complex, unstructured settings, manually programming their behavior has become increasingly challenging and expensive. Often, it is easier for a teacher to demonstrate a desired behavior rather than attempt to manually engineer it. This process of learning from demonstrations, and the study of algorithms to do so, is called imitation learning. This work provides an introduction to imitation learning. It covers the underlying assumptions, approaches, and how they relate; the rich set of algorithms developed to tackle the problem; and advice on effective tools and implementation.   We intend this paper to serve two audiences. First, we want to familiarize machine learning experts with the challenges of imitation learning, particularly those arising in robotics, and the interesting theoretical and practical distinctions between it and more familiar frameworks like statistical supervised learning theory and reinforcement learning. Second, we want to give roboticists and experts in applied artificial intelligence a broader appreciation for the frameworks and tools available for imitation learning.

</details>

<details>

<summary>2018-11-16 10:04:21 - Interpretable Credit Application Predictions With Counterfactual Explanations</summary>

- *Rory Mc Grath, Luca Costabello, Chan Le Van, Paul Sweeney, Farbod Kamiab, Zhao Shen, Freddy Lecue*

- `1811.05245v2` - [abs](http://arxiv.org/abs/1811.05245v2) - [pdf](http://arxiv.org/pdf/1811.05245v2)

> We predict credit applications with off-the-shelf, interchangeable black-box classifiers and we explain single predictions with counterfactual explanations. Counterfactual explanations expose the minimal changes required on the input data to obtain a different result e.g., approved vs rejected application. Despite their effectiveness, counterfactuals are mainly designed for changing an undesired outcome of a prediction i.e. loan rejected. Counterfactuals, however, can be difficult to interpret, especially when a high number of features are involved in the explanation. Our contribution is two-fold: i) we propose positive counterfactuals, i.e. we adapt counterfactual explanations to also explain accepted loan applications, and ii) we propose two weighting strategies to generate more interpretable counterfactuals. Experiments on the HELOC loan applications dataset show that our contribution outperforms the baseline counterfactual generation strategy, by leading to smaller and hence more interpretable counterfactuals.

</details>

<details>

<summary>2018-11-16 12:10:20 - Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP</summary>

- *Marcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Luis Lamb, Moshe Vardi*

- `1809.02721v3` - [abs](http://arxiv.org/abs/1809.02721v3) - [pdf](http://arxiv.org/pdf/1809.02721v3)

> Graph Neural Networks (GNN) are a promising technique for bridging differential programming and combinatorial domains. GNNs employ trainable modules which can be assembled in different configurations that reflect the relational structure of each problem instance. In this paper, we show that GNNs can learn to solve, with very little supervision, the decision variant of the Traveling Salesperson Problem (TSP), a highly relevant $\mathcal{NP}$-Complete problem. Our model is trained to function as an effective message-passing algorithm in which edges (embedded with their weights) communicate with vertices for a number of iterations after which the model is asked to decide whether a route with cost $<C$ exists. We show that such a network can be trained with sets of dual examples: given the optimal tour cost $C^{*}$, we produce one decision instance with target cost $x\%$ smaller and one with target cost $x\%$ larger than $C^{*}$. We were able to obtain $80\%$ accuracy training with $-2\%,+2\%$ deviations, and the same trained model can generalize for more relaxed deviations with increasing performance. We also show that the model is capable of generalizing for larger problem sizes. Finally, we provide a method for predicting the optimal route cost within $2\%$ deviation from the ground truth. In summary, our work shows that Graph Neural Networks are powerful enough to solve $\mathcal{NP}$-Complete problems which combine symbolic and numeric data.

</details>

<details>

<summary>2018-11-16 13:58:42 - Using recurrences in time and frequency within U-net architecture for speech enhancement</summary>

- *Tomasz Grzywalski, Szymon Drgas*

- `1811.06805v1` - [abs](http://arxiv.org/abs/1811.06805v1) - [pdf](http://arxiv.org/pdf/1811.06805v1)

> When designing fully-convolutional neural network, there is a trade-off between receptive field size, number of parameters and spatial resolution of features in deeper layers of the network. In this work we present a novel network design based on combination of many convolutional and recurrent layers that solves these dilemmas. We compare our solution with U-nets based models known from the literature and other baseline models on speech enhancement task. We test our solution on TIMIT speech utterances combined with noise segments extracted from NOISEX-92 database and show clear advantage of proposed solution in terms of SDR (signal-to-distortion ratio), SIR (signal-to-interference ratio) and STOI (spectro-temporal objective intelligibility) metrics compared to the current state-of-the-art.

</details>

<details>

<summary>2018-11-16 15:18:09 - Saliency Supervision: An Intuitive and Effective Approach for Pain Intensity Regression</summary>

- *Conghui Li, Zhaocheng Zhu, Yuming Zhao*

- `1811.07987v1` - [abs](http://arxiv.org/abs/1811.07987v1) - [pdf](http://arxiv.org/pdf/1811.07987v1)

> Getting pain intensity from face images is an important problem in autonomous nursing systems. However, due to the limitation in data sources and the subjectiveness in pain intensity values, it is hard to adopt modern deep neural networks for this problem without domain-specific auxiliary design. Inspired by human vision priori, we propose a novel approach called saliency supervision, where we directly regularize deep networks to focus on facial area that is discriminative for pain regression. Through alternative training between saliency supervision and global loss, our method can learn sparse and robust features, which is proved helpful for pain intensity regression. We verified saliency supervision with face-verification network backbone on the widely-used dataset, and achieved state-of-art performance without bells and whistles. Our saliency supervision is intuitive in spirit, yet effective in performance. We believe such saliency supervision is essential in dealing with ill-posed datasets, and has potential in a wide range of vision tasks.

</details>

<details>

<summary>2018-11-16 16:03:32 - Ontology based Approach for Precision Agriculture</summary>

- *Quoc Hung Ngo, Nhien-An Le-Khac, Tahar Kechadi*

- `1811.06884v1` - [abs](http://arxiv.org/abs/1811.06884v1) - [pdf](http://arxiv.org/pdf/1811.06884v1)

> In this paper, we propose a framework of knowledge for an agriculture ontology which can be used for the purpose of smart agriculture systems. This ontology not only includes basic concepts in the agricultural domain but also contains geographical, IoT, business subdomains, and other knowledge extracted from various datasets. With this ontology, any users can easily understand agricultural data links between them collected from many different data resources. In our experiment, we also import country, sub-country and disease entities into this ontology as basic entities for building agricultural linked datasets later.

</details>

<details>

<summary>2018-11-16 16:17:27 - On the Complexity of Exploration in Goal-Driven Navigation</summary>

- *Maruan Al-Shedivat, Lisa Lee, Ruslan Salakhutdinov, Eric Xing*

- `1811.06889v1` - [abs](http://arxiv.org/abs/1811.06889v1) - [pdf](http://arxiv.org/pdf/1811.06889v1)

> Building agents that can explore their environments intelligently is a challenging open problem. In this paper, we make a step towards understanding how a hierarchical design of the agent's policy can affect its exploration capabilities. First, we design EscapeRoom environments, where the agent must figure out how to navigate to the exit by accomplishing a number of intermediate tasks (\emph{subgoals}), such as finding keys or opening doors. Our environments are procedurally generated and vary in complexity, which can be controlled by the number of subgoals and relationships between them. Next, we propose to measure the complexity of each environment by constructing dependency graphs between the goals and analytically computing \emph{hitting times} of a random walk in the graph. We empirically evaluate Proximal Policy Optimization (PPO) with sparse and shaped rewards, a variation of policy sketches, and a hierarchical version of PPO (called HiPPO) akin to h-DQN. We show that analytically estimated \emph{hitting time} in goal dependency graphs is an informative metric of the environment complexity. We conjecture that the result should hold for environments other than navigation. Finally, we show that solving environments beyond certain level of complexity requires hierarchical approaches.

</details>

<details>

<summary>2018-11-16 16:38:03 - A Bayesian Clearing Mechanism for Combinatorial Auctions</summary>

- *Gianluca Brero, Sébastien Lahaie*

- `1712.05291v2` - [abs](http://arxiv.org/abs/1712.05291v2) - [pdf](http://arxiv.org/pdf/1712.05291v2)

> We cast the problem of combinatorial auction design in a Bayesian framework in order to incorporate prior information into the auction process and minimize the number of rounds to convergence. We first develop a generative model of agent valuations and market prices such that clearing prices become maximum a posteriori estimates given observed agent valuations. This generative model then forms the basis of an auction process which alternates between refining estimates of agent valuations and computing candidate clearing prices. We provide an implementation of the auction using assumed density filtering to estimate valuations and expectation maximization to compute prices. An empirical evaluation over a range of valuation domains demonstrates that our Bayesian auction mechanism is highly competitive against the combinatorial clock auction in terms of rounds to convergence, even under the most favorable choices of price increment for this baseline.

</details>

<details>

<summary>2018-11-16 17:52:25 - Automatic Paper Summary Generation from Visual and Textual Information</summary>

- *Shintaro Yamamoto, Yoshihiro Fukuhara, Ryota Suzuki, Shigeo Morishima, Hirokatsu Kataoka*

- `1811.06943v1` - [abs](http://arxiv.org/abs/1811.06943v1) - [pdf](http://arxiv.org/pdf/1811.06943v1)

> Due to the recent boom in artificial intelligence (AI) research, including computer vision (CV), it has become impossible for researchers in these fields to keep up with the exponentially increasing number of manuscripts. In response to this situation, this paper proposes the paper summary generation (PSG) task using a simple but effective method to automatically generate an academic paper summary from raw PDF data. We realized PSG by combination of vision-based supervised components detector and language-based unsupervised important sentence extractor, which is applicable for a trained format of manuscripts. We show the quantitative evaluation of ability of simple vision-based components extraction, and the qualitative evaluation that our system can extract both visual item and sentence that are helpful for understanding. After processing via our PSG, the 979 manuscripts accepted by the Conference on Computer Vision and Pattern Recognition (CVPR) 2018 are available. It is believed that the proposed method will provide a better way for researchers to stay caught with important academic papers.

</details>

<details>

<summary>2018-11-16 18:37:25 - Exploring Gameplay With AI Agents</summary>

- *Fernando de Mesentier Silva, Igor Borovikov, John Kolen, Navid Aghdaie, Kazi Zaman*

- `1811.06962v1` - [abs](http://arxiv.org/abs/1811.06962v1) - [pdf](http://arxiv.org/pdf/1811.06962v1)

> The process of playtesting a game is subjective, expensive and incomplete. In this paper, we present a playtesting approach that explores the game space with automated agents and collects data to answer questions posed by the designers. Rather than have agents interacting with an actual game client, this approach recreates the bare bone mechanics of the game as a separate system. Our agent is able to play in minutes what would take testers days of organic gameplay. The analysis of thousands of game simulations exposed imbalances in game actions, identified inconsequential rewards and evaluated the effectiveness of optional strategic choices. Our test case game, The Sims Mobile, was recently released and the findings shown here influenced design changes that resulted in improved player experience.

</details>

<details>

<summary>2018-11-16 19:41:42 - The Barbados 2018 List of Open Issues in Continual Learning</summary>

- *Tom Schaul, Hado van Hasselt, Joseph Modayil, Martha White, Adam White, Pierre-Luc Bacon, Jean Harb, Shibl Mourad, Marc Bellemare, Doina Precup*

- `1811.07004v1` - [abs](http://arxiv.org/abs/1811.07004v1) - [pdf](http://arxiv.org/pdf/1811.07004v1)

> We want to make progress toward artificial general intelligence, namely general-purpose agents that autonomously learn how to competently act in complex environments. The purpose of this report is to sketch a research outline, share some of the most important open issues we are facing, and stimulate further discussion in the community. The content is based on some of our discussions during a week-long workshop held in Barbados in February 2018.

</details>

<details>

<summary>2018-11-16 20:45:25 - On the Persistence of Clustering Solutions and True Number of Clusters in a Dataset</summary>

- *Amber Srivastava, Mayank Baranwal, Srinivasa Salapaka*

- `1811.00102v2` - [abs](http://arxiv.org/abs/1811.00102v2) - [pdf](http://arxiv.org/pdf/1811.00102v2)

> Typically clustering algorithms provide clustering solutions with prespecified number of clusters. The lack of a priori knowledge on the true number of underlying clusters in the dataset makes it important to have a metric to compare the clustering solutions with different number of clusters. This article quantifies a notion of persistence of clustering solutions that enables comparing solutions with different number of clusters. The persistence relates to the range of data-resolution scales over which a clustering solution persists; it is quantified in terms of the maximum over two-norms of all the associated cluster-covariance matrices. Thus we associate a persistence value for each element in a set of clustering solutions with different number of clusters. We show that the datasets where natural clusters are a priori known, the clustering solutions that identify the natural clusters are most persistent - in this way, this notion can be used to identify solutions with true number of clusters. Detailed experiments on a variety of standard and synthetic datasets demonstrate that the proposed persistence-based indicator outperforms the existing approaches, such as, gap-statistic method, $X$-means, $G$-means, $PG$-means, dip-means algorithms and information-theoretic method, in accurately identifying the clustering solutions with true number of clusters. Interestingly, our method can be explained in terms of the phase-transition phenomenon in the deterministic annealing algorithm, where the number of distinct cluster centers changes (bifurcates) with respect to an annealing parameter.

</details>

<details>

<summary>2018-11-16 21:12:24 - Analyzing Compositionality-Sensitivity of NLI Models</summary>

- *Yixin Nie, Yicheng Wang, Mohit Bansal*

- `1811.07033v1` - [abs](http://arxiv.org/abs/1811.07033v1) - [pdf](http://arxiv.org/pdf/1811.07033v1)

> Success in natural language inference (NLI) should require a model to understand both lexical and compositional semantics. However, through adversarial evaluation, we find that several state-of-the-art models with diverse architectures are over-relying on the former and fail to use the latter. Further, this compositionality unawareness is not reflected via standard evaluation on current datasets. We show that removing RNNs in existing models or shuffling input words during training does not induce large performance loss despite the explicit removal of compositional information. Therefore, we propose a compositionality-sensitivity testing setup that analyzes models on natural examples from existing datasets that cannot be solved via lexical features alone (i.e., on which a bag-of-words model gives a high probability to one wrong label), hence revealing the models' actual compositionality awareness. We show that this setup not only highlights the limited compositional ability of current NLI models, but also differentiates model performance based on design, e.g., separating shallow bag-of-words models from deeper, linguistically-grounded tree-based models. Our evaluation setup is an important analysis tool: complementing currently existing adversarial and linguistically driven diagnostic evaluations, and exposing opportunities for future work on evaluating models' compositional understanding.

</details>

<details>

<summary>2018-11-16 21:37:59 - Combining Fact Extraction and Verification with Neural Semantic Matching Networks</summary>

- *Yixin Nie, Haonan Chen, Mohit Bansal*

- `1811.07039v1` - [abs](http://arxiv.org/abs/1811.07039v1) - [pdf](http://arxiv.org/pdf/1811.07039v1)

> The increasing concern with misinformation has stimulated research efforts on automatic fact checking. The recently-released FEVER dataset introduced a benchmark fact-verification task in which a system is asked to verify a claim using evidential sentences from Wikipedia documents. In this paper, we present a connected system consisting of three homogeneous neural semantic matching models that conduct document retrieval, sentence selection, and claim verification jointly for fact extraction and verification. For evidence retrieval (document retrieval and sentence selection), unlike traditional vector space IR models in which queries and sources are matched in some pre-designed term vector space, we develop neural models to perform deep semantic matching from raw textual input, assuming no intermediate term representation and no access to structured external knowledge bases. We also show that Pageview frequency can also help improve the performance of evidence retrieval results, that later can be matched by using our neural semantic matching network. For claim verification, unlike previous approaches that simply feed upstream retrieved evidence and the claim to a natural language inference (NLI) model, we further enhance the NLI model by providing it with internal semantic relatedness scores (hence integrating it with the evidence retrieval modules) and ontological WordNet features. Experiments on the FEVER dataset indicate that (1) our neural semantic matching method outperforms popular TF-IDF and encoder models, by significant margins on all evidence retrieval metrics, (2) the additional relatedness score and WordNet features improve the NLI model via better semantic awareness, and (3) by formalizing all three subtasks as a similar semantic matching problem and improving on all three stages, the complete model is able to achieve the state-of-the-art results on the FEVER test set.

</details>

<details>

<summary>2018-11-17 02:09:35 - Autonomous Extraction of a Hierarchical Structure of Tasks in Reinforcement Learning, A Sequential Associate Rule Mining Approach</summary>

- *Behzad Ghazanfari, Fatemeh Afghah, Matthew E. Taylor*

- `1811.08275v1` - [abs](http://arxiv.org/abs/1811.08275v1) - [pdf](http://arxiv.org/pdf/1811.08275v1)

> Reinforcement learning (RL) techniques, while often powerful, can suffer from slow learning speeds, particularly in high dimensional spaces. Decomposition of tasks into a hierarchical structure holds the potential to significantly speed up learning, generalization, and transfer learning. However, the current task decomposition techniques often rely on high-level knowledge provided by an expert (e.g. using dynamic Bayesian networks) to extract a hierarchical task structure; which is not necessarily available in autonomous systems. In this paper, we propose a novel method based on Sequential Association Rule Mining that can extract Hierarchical Structure of Tasks in Reinforcement Learning (SARM-HSTRL) in an autonomous manner for both Markov decision processes (MDPs) and factored MDPs. The proposed method leverages association rule mining to discover the causal and temporal relationships among states in different trajectories, and extracts a task hierarchy that captures these relationships among sub-goals as termination conditions of different sub-tasks. We prove that the extracted hierarchical policy offers a hierarchically optimal policy in MDPs and factored MDPs. It should be noted that SARM-HSTRL extracts this hierarchical optimal policy without having dynamic Bayesian networks in scenarios with a single task trajectory and also with multiple tasks' trajectories. Furthermore, it has been theoretically and empirically shown that the extracted hierarchical task structure is consistent with trajectories and provides the most efficient, reliable, and compact structure under appropriate assumptions. The numerical results compare the performance of the proposed SARM-HSTRL method with conventional HRL algorithms in terms of the accuracy in detecting the sub-goals, the validity of the extracted hierarchies, and the speed of learning in several testbeds.

</details>

<details>

<summary>2018-11-17 02:29:18 - An Affect-Rich Neural Conversational Model with Biased Attention and Weighted Cross-Entropy Loss</summary>

- *Peixiang Zhong, Di Wang, Chunyan Miao*

- `1811.07078v1` - [abs](http://arxiv.org/abs/1811.07078v1) - [pdf](http://arxiv.org/pdf/1811.07078v1)

> Affect conveys important implicit information in human communication. Having the capability to correctly express affect during human-machine conversations is one of the major milestones in artificial intelligence. In recent years, extensive research on open-domain neural conversational models has been conducted. However, embedding affect into such models is still under explored. In this paper, we propose an end-to-end affect-rich open-domain neural conversational model that produces responses not only appropriate in syntax and semantics, but also with rich affect. Our model extends the Seq2Seq model and adopts VAD (Valence, Arousal and Dominance) affective notations to embed each word with affects. In addition, our model considers the effect of negators and intensifiers via a novel affective attention mechanism, which biases attention towards affect-rich words in input sentences. Lastly, we train our model with an affect-incorporated objective function to encourage the generation of affect-rich words in the output responses. Evaluations based on both perplexity and human evaluations show that our model outperforms the state-of-the-art baseline model of comparable size in producing natural and affect-rich responses.

</details>

<details>

<summary>2018-11-17 04:20:50 - Learning to Address Health Inequality in the United States with a Bayesian Decision Network</summary>

- *Tavpritesh Sethi, Anant Mittal, Shubham Maheshwari, Samarth Chugh*

- `1809.09215v2` - [abs](http://arxiv.org/abs/1809.09215v2) - [pdf](http://arxiv.org/pdf/1809.09215v2)

> Life-expectancy is a complex outcome driven by genetic, socio-demographic, environmental and geographic factors. Increasing socio-economic and health disparities in the United States are propagating the longevity-gap, making it a cause for concern. Earlier studies have probed individual factors but an integrated picture to reveal quantifiable actions has been missing. There is a growing concern about a further widening of healthcare inequality caused by Artificial Intelligence (AI) due to differential access to AI-driven services. Hence, it is imperative to explore and exploit the potential of AI for illuminating biases and enabling transparent policy decisions for positive social and health impact. In this work, we reveal actionable interventions for decreasing the longevity-gap in the United States by analyzing a County-level data resource containing healthcare, socio-economic, behavioral, education and demographic features. We learn an ensemble-averaged structure, draw inferences using the joint probability distribution and extend it to a Bayesian Decision Network for identifying policy actions. We draw quantitative estimates for the impact of diversity, preventive-care quality and stable-families within the unified framework of our decision network. Finally, we make this analysis and dashboard available as an interactive web-application for enabling users and policy-makers to validate our reported findings and to explore the impact of ones beyond reported in this work.

</details>

<details>

<summary>2018-11-17 06:20:12 - Learning the Joint Representation of Heterogeneous Temporal Events for Clinical Endpoint Prediction</summary>

- *Luchen Liu, Jianhao Shen, Ming Zhang, Zichang Wang, Jian Tang*

- `1803.04837v4` - [abs](http://arxiv.org/abs/1803.04837v4) - [pdf](http://arxiv.org/pdf/1803.04837v4)

> The availability of a large amount of electronic health records (EHR) provides huge opportunities to improve health care service by mining these data. One important application is clinical endpoint prediction, which aims to predict whether a disease, a symptom or an abnormal lab test will happen in the future according to patients' history records. This paper develops deep learning techniques for clinical endpoint prediction, which are effective in many practical applications. However, the problem is very challenging since patients' history records contain multiple heterogeneous temporal events such as lab tests, diagnosis, and drug administrations. The visiting patterns of different types of events vary significantly, and there exist complex nonlinear relationships between different events. In this paper, we propose a novel model for learning the joint representation of heterogeneous temporal events. The model adds a new gate to control the visiting rates of different events which effectively models the irregular patterns of different events and their nonlinear correlations. Experiment results with real-world clinical data on the tasks of predicting death and abnormal lab tests prove the effectiveness of our proposed approach over competitive baselines.

</details>

<details>

<summary>2018-11-17 09:29:17 - Advanced Memory Buoyancy for Forgetful Information Systems</summary>

- *Christian Jilek, Jessica Chwalek, Sven Schwarz, Markus Schröder, Heiko Maus, Andreas Dengel*

- `1811.12177v1` - [abs](http://arxiv.org/abs/1811.12177v1) - [pdf](http://arxiv.org/pdf/1811.12177v1)

> Knowledge workers face an ever increasing flood of information in their daily lives. To counter this and provide better support for information management and knowledge work in general, we have been investigating solutions inspired by human forgetting since 2013. These solutions are based on Semantic Desktop (SD) and Managed Forgetting (MF) technology. A key concept of the latter is the so-called Memory Buoyancy (MB), which is intended to represent an information item's current value for the user and allows to employ forgetting mechanisms. The SD thus continuously performs information value assessment updating MB and triggering respective MF measures. We extended an SD-based organizational memory system, which we have been using in daily work for over seven years now, with MF mechanisms directly embedding them in daily activities, too, and enabling us to test and optimize them in real-world scenarios. In this paper, we first present our initial version of MB and discuss success and failure stories we have been experiencing with it during three years of practical usage. We learned from cognitive psychology that our previous research on context can be beneficial for MF. Thus, we created an advanced MB version especially taking user context, and in particular context switches, into account. These enhancements as well as a first prototypical implementation are presented, too.

</details>

<details>

<summary>2018-11-17 09:33:35 - Managed Forgetting to Support Information Management and Knowledge Work</summary>

- *Christian Jilek, Yannick Runge, Claudia Niederée, Heiko Maus, Tobias Tempel, Andreas Dengel, Christian Frings*

- `1811.12155v1` - [abs](http://arxiv.org/abs/1811.12155v1) - [pdf](http://arxiv.org/pdf/1811.12155v1)

> Trends like digital transformation even intensify the already overwhelming mass of information knowledge workers face in their daily life. To counter this, we have been investigating knowledge work and information management support measures inspired by human forgetting. In this paper, we give an overview of solutions we have found during the last five years as well as challenges that still need to be tackled. Additionally, we share experiences gained with the prototype of a first forgetful information system used 24/7 in our daily work for the last three years. We also address the untapped potential of more explicated user context as well as features inspired by Memory Inhibition, which is our current focus of research.

</details>

<details>

<summary>2018-11-17 10:55:10 - A Comparison of Lattice-free Discriminative Training Criteria for Purely Sequence-Trained Neural Network Acoustic Models</summary>

- *Chao Weng, Dong Yu*

- `1811.03700v2` - [abs](http://arxiv.org/abs/1811.03700v2) - [pdf](http://arxiv.org/pdf/1811.03700v2)

> In this work, three lattice-free (LF) discriminative training criteria for purely sequence-trained neural network acoustic models are compared on LVCSR tasks, namely maximum mutual information (MMI), boosted maximum mutual information (bMMI) and state-level minimum Bayes risk (sMBR). We demonstrate that, analogous to LF-MMI, a neural network acoustic model can also be trained from scratch using LF-bMMI or LF-sMBR criteria respectively without the need of cross-entropy pre-training. Furthermore, experimental results on Switchboard-300hrs and Switchboard+Fisher-2100hrs datasets show that models trained with LF-bMMI consistently outperform those trained with plain LF-MMI and achieve a relative word error rate (WER) reduction of 5% over competitive temporal convolution projected LSTM (TDNN-LSTMP) LF-MMI baselines.

</details>

<details>

<summary>2018-11-17 11:23:58 - The Impatient May Use Limited Optimism to Minimize Regret</summary>

- *Michaël Cadilhac, Guillermo A. Pérez, Marie van den Bogaard*

- `1811.07146v1` - [abs](http://arxiv.org/abs/1811.07146v1) - [pdf](http://arxiv.org/pdf/1811.07146v1)

> Discounted-sum games provide a formal model for the study of reinforcement learning, where the agent is enticed to get rewards early since later rewards are discounted. When the agent interacts with the environment, she may regret her actions, realizing that a previous choice was suboptimal given the behavior of the environment. The main contribution of this paper is a PSPACE algorithm for computing the minimum possible regret of a given game. To this end, several results of independent interest are shown. (1) We identify a class of regret-minimizing and admissible strategies that first assume that the environment is collaborating, then assume it is adversarial---the precise timing of the switch is key here. (2) Disregarding the computational cost of numerical analysis, we provide an NP algorithm that checks that the regret entailed by a given time-switching strategy exceeds a given value. (3) We show that determining whether a strategy minimizes regret is decidable in PSPACE.

</details>

<details>

<summary>2018-11-17 12:36:38 - Monotonic classification: an overview on algorithms, performance measures and data sets</summary>

- *José-Ramón Cano, Pedro Antonio Gutiérrez, Bartosz Krawczyk, Michał Woźniak, Salvador García*

- `1811.07155v1` - [abs](http://arxiv.org/abs/1811.07155v1) - [pdf](http://arxiv.org/pdf/1811.07155v1)

> Currently, knowledge discovery in databases is an essential step to identify valid, novel and useful patterns for decision making. There are many real-world scenarios, such as bankruptcy prediction, option pricing or medical diagnosis, where the classification models to be learned need to fulfil restrictions of monotonicity (i.e. the target class label should not decrease when input attributes values increase). For instance, it is rational to assume that a higher debt ratio of a company should never result in a lower level of bankruptcy risk. Consequently, there is a growing interest from the data mining research community concerning monotonic predictive models. This paper aims to present an overview about the literature in the field, analyzing existing techniques and proposing a taxonomy of the algorithms based on the type of model generated. For each method, we review the quality metrics considered in the evaluation and the different data sets and monotonic problems used in the analysis. In this way, this paper serves as an overview of the research about monotonic classification in specialized literature and can be used as a functional guide of the field.

</details>

<details>

<summary>2018-11-17 13:46:04 - Multi-Source Neural Variational Inference</summary>

- *Richard Kurle, Stephan Günnemann, Patrick van der Smagt*

- `1811.04451v2` - [abs](http://arxiv.org/abs/1811.04451v2) - [pdf](http://arxiv.org/pdf/1811.04451v2)

> Learning from multiple sources of information is an important problem in machine-learning research. The key challenges are learning representations and formulating inference methods that take into account the complementarity and redundancy of various information sources. In this paper we formulate a variational autoencoder based multi-source learning framework in which each encoder is conditioned on a different information source. This allows us to relate the sources via the shared latent variables by computing divergence measures between individual source's posterior approximations. We explore a variety of options to learn these encoders and to integrate the beliefs they compute into a consistent posterior approximation. We visualise learned beliefs on a toy dataset and evaluate our methods for learning shared representations and structured output prediction, showing trade-offs of learning separate encoders for each information source. Furthermore, we demonstrate how conflict detection and redundancy can increase robustness of inference in a multi-source setting.

</details>

<details>

<summary>2018-11-17 17:38:34 - ASVRG: Accelerated Proximal SVRG</summary>

- *Fanhua Shang, Licheng Jiao, Kaiwen Zhou, James Cheng, Yan Ren, Yufei Jin*

- `1810.03105v2` - [abs](http://arxiv.org/abs/1810.03105v2) - [pdf](http://arxiv.org/pdf/1810.03105v2)

> This paper proposes an accelerated proximal stochastic variance reduced gradient (ASVRG) method, in which we design a simple and effective momentum acceleration trick. Unlike most existing accelerated stochastic variance reduction methods such as Katyusha, ASVRG has only one additional variable and one momentum parameter. Thus, ASVRG is much simpler than those methods, and has much lower per-iteration complexity. We prove that ASVRG achieves the best known oracle complexities for both strongly convex and non-strongly convex objectives. In addition, we extend ASVRG to mini-batch and non-smooth settings. We also empirically verify our theoretical results and show that the performance of ASVRG is comparable with, and sometimes even better than that of the state-of-the-art stochastic methods.

</details>

<details>

<summary>2018-11-17 18:28:44 - On Human Robot Interaction using Multiple Modes</summary>

- *Neha Baranwal*

- `1811.07206v1` - [abs](http://arxiv.org/abs/1811.07206v1) - [pdf](http://arxiv.org/pdf/1811.07206v1)

> Humanoid robots have apparently similar body structure like human beings. Due to their technical design, they are sharing the same workspace with humans. They are placed to clean things, to assist old age people, to entertain us and most importantly to serve us. To be acceptable in the household, they must have higher level of intelligence than industrial robots and they must be social and capable of interacting people around it, who are not supposed to be robot specialist. All these come under the field of human robot interaction (HRI). There are various modes like speech, gesture, behavior etc. through which human can interact with robots. To solve all these challenges, a multimodel technique has been introduced where gesture as well as speech is used as a mode of interaction.

</details>

<details>

<summary>2018-11-17 19:51:34 - Parameter Sharing Reinforcement Learning Architecture for Multi Agent Driving Behaviors</summary>

- *Meha Kaushik, Phaniteja S, K. Madhava Krishna*

- `1811.07214v1` - [abs](http://arxiv.org/abs/1811.07214v1) - [pdf](http://arxiv.org/pdf/1811.07214v1)

> Multi-agent learning provides a potential framework for learning and simulating traffic behaviors. This paper proposes a novel architecture to learn multiple driving behaviors in a traffic scenario. The proposed architecture can learn multiple behaviors independently as well as simultaneously. We take advantage of the homogeneity of agents and learn in a parameter sharing paradigm. To further speed up the training process asynchronous updates are employed into the architecture. While learning different behaviors simultaneously, the given framework was also able to learn cooperation between the agents, without any explicit communication. We applied this framework to learn two important behaviors in driving: 1) Lane-Keeping and 2) Over-Taking. Results indicate faster convergence and learning of a more generic behavior, that is scalable to any number of agents. When compared the results with existing approaches, our results indicate equal and even better performance in some cases.

</details>

<details>

<summary>2018-11-17 22:05:04 - Learning Features and Abstract Actions for Computing Generalized Plans</summary>

- *Blai Bonet, Guillem Francès, Hector Geffner*

- `1811.07231v1` - [abs](http://arxiv.org/abs/1811.07231v1) - [pdf](http://arxiv.org/pdf/1811.07231v1)

> Generalized planning is concerned with the computation of plans that solve not one but multiple instances of a planning domain. Recently, it has been shown that generalized plans can be expressed as mappings of feature values into actions, and that they can often be computed with fully observable non-deterministic (FOND) planners. The actions in such plans, however, are not the actions in the instances themselves, which are not necessarily common to other instances, but abstract actions that are defined on a set of common features. The formulation assumes that the features and the abstract actions are given. In this work, we address this limitation by showing how to learn them automatically. The resulting account of generalized planning combines learning and planning in a novel way: a learner, based on a Max SAT formulation, yields the features and abstract actions from sampled state transitions, and a FOND planner uses this information, suitably transformed, to produce the general plans. Correctness guarantees are given and experimental results on several domains are reported.

</details>

<details>

<summary>2018-11-17 22:34:20 - Robust cross-domain disfluency detection with pattern match networks</summary>

- *Vicky Zayats, Mari Ostendorf*

- `1811.07236v1` - [abs](http://arxiv.org/abs/1811.07236v1) - [pdf](http://arxiv.org/pdf/1811.07236v1)

> In this paper we introduce a novel pattern match neural network architecture that uses neighbor similarity scores as features, eliminating the need for feature engineering in a disfluency detection task. We evaluate the approach in disfluency detection for four different speech genres, showing that the approach is as effective as hand-engineered pattern match features when used on in-domain data and achieves superior performance in cross-domain scenarios.

</details>

<details>

<summary>2018-11-18 01:36:05 - Quantifying Uncertainties in Natural Language Processing Tasks</summary>

- *Yijun Xiao, William Yang Wang*

- `1811.07253v1` - [abs](http://arxiv.org/abs/1811.07253v1) - [pdf](http://arxiv.org/pdf/1811.07253v1)

> Reliable uncertainty quantification is a first step towards building explainable, transparent, and accountable artificial intelligent systems. Recent progress in Bayesian deep learning has made such quantification realizable. In this paper, we propose novel methods to study the benefits of characterizing model and data uncertainties for natural language processing (NLP) tasks. With empirical experiments on sentiment analysis, named entity recognition, and language modeling using convolutional and recurrent neural network models, we show that explicitly modeling uncertainties is not only necessary to measure output confidence levels, but also useful at enhancing model performances in various NLP tasks.

</details>

<details>

<summary>2018-11-18 02:39:45 - GLStyleNet: Higher Quality Style Transfer Combining Global and Local Pyramid Features</summary>

- *Zhizhong Wang, Lei Zhao, Wei Xing, Dongming Lu*

- `1811.07260v1` - [abs](http://arxiv.org/abs/1811.07260v1) - [pdf](http://arxiv.org/pdf/1811.07260v1)

> Recent studies using deep neural networks have shown remarkable success in style transfer especially for artistic and photo-realistic images. However, the approaches using global feature correlations fail to capture small, intricate textures and maintain correct texture scales of the artworks, and the approaches based on local patches are defective on global effect. In this paper, we present a novel feature pyramid fusion neural network, dubbed GLStyleNet, which sufficiently takes into consideration multi-scale and multi-level pyramid features by best aggregating layers across a VGG network, and performs style transfer hierarchically with multiple losses of different scales. Our proposed method retains high-frequency pixel information and low frequency construct information of images from two aspects: loss function constraint and feature fusion. Our approach is not only flexible to adjust the trade-off between content and style, but also controllable between global and local. Compared to state-of-the-art methods, our method can transfer not just large-scale, obvious style cues but also subtle, exquisite ones, and dramatically improves the quality of style transfer. We demonstrate the effectiveness of our approach on portrait style transfer, artistic style transfer, photo-realistic style transfer and Chinese ancient painting style transfer tasks. Experimental results indicate that our unified approach improves image style transfer quality over previous state-of-the-art methods, while also accelerating the whole process in a certain extent. Our code is available at https://github.com/EndyWon/GLStyleNet.

</details>

<details>

<summary>2018-11-18 04:00:32 - Probabilistic Graphs for Sensor Data-driven Modelling of Power Systems at Scale</summary>

- *Francesco Fusco*

- `1811.07267v1` - [abs](http://arxiv.org/abs/1811.07267v1) - [pdf](http://arxiv.org/pdf/1811.07267v1)

> The growing complexity of the power grid, driven by increasing share of distributed energy resources and by massive deployment of intelligent internet-connected devices, requires new modelling tools for planning and operation. Physics-based state estimation models currently used for data filtering, prediction and anomaly detection are hard to maintain and adapt to the ever-changing complex dynamics of the power system. A data-driven approach based on probabilistic graphs is proposed, where custom non-linear, localised models of the joint density of subset of system variables can be combined to model arbitrarily large and complex systems. The graphical model allows to naturally embed domain knowledge in the form of variables dependency structure or local quantitative relationships. A specific instance where neural-network models are used to represent the local joint densities is proposed, although the methodology generalises to other model classes. Accuracy and scalability are evaluated on a large-scale data set representative of the European transmission grid.

</details>

<details>

<summary>2018-11-18 04:03:39 - Research on Artificial Intelligence Ethics Based on the Evolution of Population Knowledge Base</summary>

- *Feng Liu, Yong Shi*

- `1806.10095v3` - [abs](http://arxiv.org/abs/1806.10095v3) - [pdf](http://arxiv.org/pdf/1806.10095v3)

> The unclear development direction of human society is a deep reason for that it is difficult to form a uniform ethical standard for human society and artificial intelligence. Since the 21st century, the latest advances in the Internet, brain science and artificial intelligence have brought new inspiration to the research on the development direction of human society. Through the study of the Internet brain model, AI IQ evaluation, and the evolution of the brain, this paper proposes that the evolution of population knowledge base is the key for judging the development direction of human society, thereby discussing the standards and norms for the construction of artificial intelligence ethics.

</details>

<details>

<summary>2018-11-18 07:27:21 - Self-Organizing Maps for Storage and Transfer of Knowledge in Reinforcement Learning</summary>

- *Thommen George Karimpanal, Roland Bouffanais*

- `1811.08318v1` - [abs](http://arxiv.org/abs/1811.08318v1) - [pdf](http://arxiv.org/pdf/1811.08318v1)

> The idea of reusing or transferring information from previously learned tasks (source tasks) for the learning of new tasks (target tasks) has the potential to significantly improve the sample efficiency of a reinforcement learning agent. In this work, we describe a novel approach for reusing previously acquired knowledge by using it to guide the exploration of an agent while it learns new tasks. In order to do so, we employ a variant of the growing self-organizing map algorithm, which is trained using a measure of similarity that is defined directly in the space of the vectorized representations of the value functions. In addition to enabling transfer across tasks, the resulting map is simultaneously used to enable the efficient storage of previously acquired task knowledge in an adaptive and scalable manner. We empirically validate our approach in a simulated navigation environment, and also demonstrate its utility through simple experiments using a mobile micro-robotics platform. In addition, we demonstrate the scalability of this approach, and analytically examine its relation to the proposed network growth mechanism. Further, we briefly discuss some of the possible improvements and extensions to this approach, as well as its relevance to real world scenarios in the context of continual learning.

</details>

<details>

<summary>2018-11-18 15:45:31 - Transform-Based Multilinear Dynamical System for Tensor Time Series Analysis</summary>

- *Weijun Lu, Xiao-Yang Liu, Qingwei Wu, Yue Sun, Anwar Walid*

- `1811.07342v1` - [abs](http://arxiv.org/abs/1811.07342v1) - [pdf](http://arxiv.org/pdf/1811.07342v1)

> We propose a novel multilinear dynamical system (MLDS) in a transform domain, named $\mathcal{L}$-MLDS, to model tensor time series. With transformations applied to a tensor data, the latent multidimensional correlations among the frontal slices are built, and thus resulting in the computational independence in the transform domain. This allows the exact separability of the multi-dimensional problem into multiple smaller LDS problems. To estimate the system parameters, we utilize the expectation-maximization (EM) algorithm to determine the parameters of each LDS. Further, $\mathcal{L}$-MLDSs significantly reduce the model parameters and allows parallel processing. Our general $\mathcal{L}$-MLDS model is implemented based on different transforms: discrete Fourier transform, discrete cosine transform and discrete wavelet transform. Due to the nonlinearity of these transformations, $\mathcal{L}$-MLDS is able to capture the nonlinear correlations within the data unlike the MLDS \cite{rogers2013multilinear} which assumes multi-way linear correlations. Using four real datasets, the proposed $\mathcal{L}$-MLDS is shown to achieve much higher prediction accuracy than the state-of-the-art MLDS and LDS with an equal number of parameters under different noise models. In particular, the relative errors are reduced by $50\% \sim 99\%$. Simultaneously, $\mathcal{L}$-MLDS achieves an exponential improvement in the model's training time than MLDS.

</details>

<details>

<summary>2018-11-18 17:57:06 - WISE: Lightweight Intelligent Swarm Attestation Scheme for IoT (The Verifier's Perspective)</summary>

- *Mahmoud Ammar, Mahdi Washha, Bruno Crispo*

- `1811.07366v1` - [abs](http://arxiv.org/abs/1811.07366v1) - [pdf](http://arxiv.org/pdf/1811.07366v1)

> The growing pervasiveness of Internet of Things (IoT) expands the attack surface by connecting more and more attractive attack targets, i.e. embedded devices, to the Internet. One key component in securing these devices is software integrity checking, which typically attained with Remote Attestation (RA). RA is realized as an interactive protocol, whereby a trusted party, verifier, verifies the software integrity of a potentially compromised remote device, prover. In the vast majority of IoT applications, smart devices operate in swarms, thus triggering the need for efficient swarm attestation schemes. In this paper, we present WISE, the first intelligent swarm attestation protocol that aims to minimize the communication overhead while preserving an adequate level of security. WISE depends on a resource-efficient smart broadcast authentication scheme where devices are organized in fine-grained multi-clusters, and whenever needed, the most likely compromised devices are attested. The candidate devices are selected intelligently taking into account the attestation history and the diverse characteristics (and constraints) of each device in the swarm. We show that WISE is very suitable for resource-constrained embedded devices, highly efficient and scalable in heterogenous IoT networks, and offers an adjustable level of security.

</details>

<details>

<summary>2018-11-18 21:31:22 - Multimodal Densenet</summary>

- *Faisal Mahmood, Ziyun Yang, Thomas Ashley, Nicholas J. Durr*

- `1811.07407v1` - [abs](http://arxiv.org/abs/1811.07407v1) - [pdf](http://arxiv.org/pdf/1811.07407v1)

> Humans make accurate decisions by interpreting complex data from multiple sources. Medical diagnostics, in particular, often hinge on human interpretation of multi-modal information. In order for artificial intelligence to make progress in automated, objective, and accurate diagnosis and prognosis, methods to fuse information from multiple medical imaging modalities are required. However, combining information from multiple data sources has several challenges, as current deep learning architectures lack the ability to extract useful representations from multimodal information, and often simple concatenation is used to fuse such information. In this work, we propose Multimodal DenseNet, a novel architecture for fusing multimodal data. Instead of focusing on concatenation or early and late fusion, our proposed architectures fuses information over several layers and gives the model flexibility in how it combines information from multiple sources. We apply this architecture to the challenge of polyp characterization and landmark identification in endoscopy. Features from white light images are fused with features from narrow band imaging or depth maps. This study demonstrates that Multimodal DenseNet outperforms monomodal classification as well as other multimodal fusion techniques by a significant margin on two different datasets.

</details>

<details>

<summary>2018-11-18 22:37:16 - Realtime Scheduling and Power Allocation Using Deep Neural Networks</summary>

- *Shenghe Xu, Pei Liu, Ran Wang, Shivendra S. Panwar*

- `1811.07416v1` - [abs](http://arxiv.org/abs/1811.07416v1) - [pdf](http://arxiv.org/pdf/1811.07416v1)

> With the increasing number of base stations (BSs) and network densification in 5G, interference management using link scheduling and power control are vital for better utilization of radio resources. However, the complexity of solving link scheduling and the power control problem grows exponentially with the number of BS. Due to high computation time, previous methods are useful for research purposes but impractical for real time usage. In this paper we propose to use deep neural networks (DNNs) to approximate optimal link scheduling and power control for the case with multiple small cells. A deep Q-network (DQN) estimates a suitable schedule, then a DNN allocates power for the corresponding schedule. Simulation results show that the proposed method achieves over five orders of magnitude speed-up with less than nine percent performance loss, making real time usage practical.

</details>

<details>

<summary>2018-11-18 23:47:15 - Combined Reinforcement Learning via Abstract Representations</summary>

- *Vincent François-Lavet, Yoshua Bengio, Doina Precup, Joelle Pineau*

- `1809.04506v2` - [abs](http://arxiv.org/abs/1809.04506v2) - [pdf](http://arxiv.org/pdf/1809.04506v2)

> In the quest for efficient and robust reinforcement learning methods, both model-free and model-based approaches offer advantages. In this paper we propose a new way of explicitly bridging both approaches via a shared low-dimensional learned encoding of the environment, meant to capture summarizing abstractions. We show that the modularity brought by this approach leads to good generalization while being computationally efficient, with planning happening in a smaller latent state space. In addition, this approach recovers a sufficient low-dimensional representation of the environment, which opens up new strategies for interpretable AI, exploration and transfer learning.

</details>

<details>

<summary>2018-11-19 01:43:12 - Improving Neural Question Generation using Answer Separation</summary>

- *Yanghoon Kim, Hwanhee Lee, Joongbo Shin, Kyomin Jung*

- `1809.02393v2` - [abs](http://arxiv.org/abs/1809.02393v2) - [pdf](http://arxiv.org/pdf/1809.02393v2)

> Neural question generation (NQG) is the task of generating a question from a given passage with deep neural networks. Previous NQG models suffer from a problem that a significant proportion of the generated questions include words in the question target, resulting in the generation of unintended questions. In this paper, we propose answer-separated seq2seq, which better utilizes the information from both the passage and the target answer. By replacing the target answer in the original passage with a special token, our model learns to identify which interrogative word should be used. We also propose a new module termed keyword-net, which helps the model better capture the key information in the target answer and generate an appropriate question. Experimental results demonstrate that our answer separation method significantly reduces the number of improper questions which include answers. Consequently, our model significantly outperforms previous state-of-the-art NQG models.

</details>

<details>

<summary>2018-11-19 01:48:49 - Economics of Human-AI Ecosystem: Value Bias and Lost Utility in Multi-Dimensional Gaps</summary>

- *Daniel Muller*

- `1811.06606v2` - [abs](http://arxiv.org/abs/1811.06606v2) - [pdf](http://arxiv.org/pdf/1811.06606v2)

> In recent years, artificial intelligence (AI) decision-making and autonomous systems became an integrated part of the economy, industry, and society. The evolving economy of the human-AI ecosystem raising concerns regarding the risks and values inherited in AI systems. This paper investigates the dynamics of creation and exchange of values and points out gaps in perception of cost-value, knowledge, space and time dimensions. It shows aspects of value bias in human perception of achievements and costs that encoded in AI systems. It also proposes rethinking hard goals definitions and cost-optimal problem-solving principles in the lens of effectiveness and efficiency in the development of trusted machines. The paper suggests a value-driven with cost awareness strategy and principles for problem-solving and planning of effective research progress to address real-world problems that involve diverse forms of achievements, investments, and survival scenarios.

</details>

<details>

<summary>2018-11-19 02:18:44 - Neural network state estimation for full quantum state tomography</summary>

- *Qian Xu, Shuqi Xu*

- `1811.06654v2` - [abs](http://arxiv.org/abs/1811.06654v2) - [pdf](http://arxiv.org/pdf/1811.06654v2)

> An efficient state estimation model, neural network estimation (NNE), empowered by machine learning techniques, is presented for full quantum state tomography (FQST). A parameterized function based on neural network is applied to map the measurement outcomes to the estimated quantum states. Parameters are updated with supervised learning procedures. From the computational complexity perspective our algorithm is the most efficient one among existing state estimation algorithms for full quantum state tomography. We perform numerical tests to prove both the accuracy and scalability of our model.

</details>

<details>

<summary>2018-11-19 04:03:03 - Quantifying Human Behavior on the Block Design Test Through Automated Multi-Level Analysis of Overhead Video</summary>

- *Seunghwan Cha, James Ainooson, Maithilee Kunda*

- `1811.07488v1` - [abs](http://arxiv.org/abs/1811.07488v1) - [pdf](http://arxiv.org/pdf/1811.07488v1)

> The block design test is a standardized, widely used neuropsychological assessment of visuospatial reasoning that involves a person recreating a series of given designs out of a set of colored blocks. In current testing procedures, an expert neuropsychologist observes a person's accuracy and completion time as well as overall impressions of the person's problem-solving procedures, errors, etc., thus obtaining a holistic though subjective and often qualitative view of the person's cognitive processes. We propose a new framework that combines room sensors and AI techniques to augment the information available to neuropsychologists from block design and similar tabletop assessments. In particular, a ceiling-mounted camera captures an overhead view of the table surface. From this video, we demonstrate how automated classification using machine learning can produce a frame-level description of the state of the block task and the person's actions over the course of each test problem. We also show how a sequence-comparison algorithm can classify one individual's problem-solving strategy relative to a database of simulated strategies, and how these quantitative results can be visualized for use by neuropsychologists.

</details>

<details>

<summary>2018-11-19 07:51:25 - Contributors profile modelization in crowdsourcing platforms</summary>

- *Constance Thierry, Jean-Christophe Dubois, Yolande Le Gall, Arnaud Martin*

- `1811.07536v1` - [abs](http://arxiv.org/abs/1811.07536v1) - [pdf](http://arxiv.org/pdf/1811.07536v1)

> The crowdsourcing consists in the externalisation of tasks to a crowd of people remunerated to execute this ones. The crowd, usually diversified, can include users without qualification and/or motivation for the tasks. In this paper we will introduce a new method of user expertise modelization in the crowdsourcing platforms based on the theory of belief functions in order to identify serious and qualificated users.

</details>

<details>

<summary>2018-11-19 08:19:56 - Path planning for Robotic Mobile Fulfillment Systems</summary>

- *Marius Merschformann, Lin Xie, Daniel Erdmann*

- `1706.09347v2` - [abs](http://arxiv.org/abs/1706.09347v2) - [pdf](http://arxiv.org/pdf/1706.09347v2)

> This paper presents a collection of path planning algorithms for real-time movement of multiple robots across a Robotic Mobile Fulfillment System (RMFS). Robots are assigned to move storage units to pickers at working stations instead of requiring pickers to go to the storage area. Path planning algorithms aim to find paths for the robots to fulfill the requests without collisions or deadlocks. The state-of-the-art path planning algorithms, including WHCA*, FAR, BCP, OD&ID and CBS, were adapted to suit path planning in RMFS and integrated within a simulation tool to guide the robots from their starting points to their destinations during the storage and retrieval processes. Ten different layouts with a variety of numbers of robots, floors, pods, stations and the sizes of storage areas were considered in the simulation study. Performance metrics of throughput, path length and search time were monitored. Simulation results demonstrate the best algorithm based on each performance metric.

</details>

<details>

<summary>2018-11-19 08:23:34 - Switch-based Active Deep Dyna-Q: Efficient Adaptive Planning for Task-Completion Dialogue Policy Learning</summary>

- *Yuexin Wu, Xiujun Li, Jingjing Liu, Jianfeng Gao, Yiming Yang*

- `1811.07550v1` - [abs](http://arxiv.org/abs/1811.07550v1) - [pdf](http://arxiv.org/pdf/1811.07550v1)

> Training task-completion dialogue agents with reinforcement learning usually requires a large number of real user experiences. The Dyna-Q algorithm extends Q-learning by integrating a world model, and thus can effectively boost training efficiency using simulated experiences generated by the world model. The effectiveness of Dyna-Q, however, depends on the quality of the world model - or implicitly, the pre-specified ratio of real vs. simulated experiences used for Q-learning. To this end, we extend the recently proposed Deep Dyna-Q (DDQ) framework by integrating a switcher that automatically determines whether to use a real or simulated experience for Q-learning. Furthermore, we explore the use of active learning for improving sample efficiency, by encouraging the world model to generate simulated experiences in the state-action space where the agent has not (fully) explored. Our results show that by combining switcher and active learning, the new framework named as Switch-based Active Deep Dyna-Q (Switch-DDQ), leads to significant improvement over DDQ and Q-learning baselines in both simulation and human evaluations.

</details>

<details>

<summary>2018-11-19 10:30:52 - Latent Multi-task Architecture Learning</summary>

- *Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, Anders Søgaard*

- `1705.08142v3` - [abs](http://arxiv.org/abs/1705.08142v3) - [pdf](http://arxiv.org/pdf/1705.08142v3)

> Multi-task learning (MTL) allows deep neural networks to learn from related tasks by sharing parameters with other networks. In practice, however, MTL involves searching an enormous space of possible parameter sharing architectures to find (a) the layers or subspaces that benefit from sharing, (b) the appropriate amount of sharing, and (c) the appropriate relative weights of the different task losses. Recent work has addressed each of the above problems in isolation. In this work we present an approach that learns a latent multi-task architecture that jointly addresses (a)--(c). We present experiments on synthetic data and data from OntoNotes 5.0, including four different tasks and seven different domains. Our extension consistently outperforms previous approaches to learning latent architectures for multi-task problems and achieves up to 15% average error reductions over common approaches to MTL.

</details>

<details>

<summary>2018-11-19 10:51:00 - Quantum Inspired High Dimensional Conceptual Space as KID Model for Elderly Assistance</summary>

- *Ishwarya M S, Aswani Kumar Ch*

- `1811.07603v1` - [abs](http://arxiv.org/abs/1811.07603v1) - [pdf](http://arxiv.org/pdf/1811.07603v1)

> In this paper, we propose a cognitive system that acquires knowledge on elderly daily activities to ensure their wellness in a smart home using a Knowledge-Information-Data (KID) model. The novel cognitive framework called high dimensional conceptual space is proposed and used as KID model. This KID model is built using geometrical framework of conceptual spaces and formal concept analysis (FCA) to overcome imprecise concept notation of conceptual space with the help of topology based FCA. By doing so, conceptual space can be represented using Hilbert space. This high dimensional conceptual space is quantum inspired in terms of its concept representation. The knowledge learnt by the KID model recognizes the daily activities of the elderly. Consequently, the model identifies the scenario on which the wellness of the elderly has to be ensured.

</details>

<details>

<summary>2018-11-19 10:59:34 - Outlier Aware Network Embedding for Attributed Networks</summary>

- *Sambaran Bandyopadhyay, Lokesh N, M. N. Murty*

- `1811.07609v1` - [abs](http://arxiv.org/abs/1811.07609v1) - [pdf](http://arxiv.org/pdf/1811.07609v1)

> Attributed network embedding has received much interest from the research community as most of the networks come with some content in each node, which is also known as node attributes. Existing attributed network approaches work well when the network is consistent in structure and attributes, and nodes behave as expected. But real world networks often have anomalous nodes. Typically these outliers, being relatively unexplainable, affect the embeddings of other nodes in the network. Thus all the downstream network mining tasks fail miserably in the presence of such outliers. Hence an integrated approach to detect anomalies and reduce their overall effect on the network embedding is required.   Towards this end, we propose an unsupervised outlier aware network embedding algorithm (ONE) for attributed networks, which minimizes the effect of the outlier nodes, and hence generates robust network embeddings. We align and jointly optimize the loss functions coming from structure and attributes of the network. To the best of our knowledge, this is the first generic network embedding approach which incorporates the effect of outliers for an attributed network without any supervision. We experimented on publicly available real networks and manually planted different types of outliers to check the performance of the proposed algorithm. Results demonstrate the superiority of our approach to detect the network outliers compared to the state-of-the-art approaches. We also consider different downstream machine learning applications on networks to show the efficiency of ONE as a generic network embedding technique. The source code is made available at https://github.com/sambaranban/ONE.

</details>

<details>

<summary>2018-11-19 11:11:36 - Towards Easier and Faster Sequence Labeling for Natural Language Processing: A Search-based Probabilistic Online Learning Framework (SAPO)</summary>

- *Xu Sun, Shuming Ma, Yi Zhang, Xuancheng Ren*

- `1503.08381v4` - [abs](http://arxiv.org/abs/1503.08381v4) - [pdf](http://arxiv.org/pdf/1503.08381v4)

> There are two major approaches for sequence labeling. One is the probabilistic gradient-based methods such as conditional random fields (CRF) and neural networks (e.g., RNN), which have high accuracy but drawbacks: slow training, and no support of search-based optimization (which is important in many cases). The other is the search-based learning methods such as structured perceptron and margin infused relaxed algorithm (MIRA), which have fast training but also drawbacks: low accuracy, no probabilistic information, and non-convergence in real-world tasks. We propose a novel and "easy" solution, a search-based probabilistic online learning method, to address most of those issues. The method is "easy", because the optimization algorithm at the training stage is as simple as the decoding algorithm at the test stage. This method searches the output candidates, derives probabilities, and conducts efficient online learning. We show that this method with fast training and theoretical guarantee of convergence, which is easy to implement, can support search-based optimization and obtain top accuracy. Experiments on well-known tasks show that our method has better accuracy than CRF and BiLSTM\footnote{The SAPO code is released at \url{https://github.com/lancopku/SAPO}.}.

</details>

<details>

<summary>2018-11-19 11:54:25 - Chat More If You Like: Dynamic Cue Words Planning to Flow Longer Conversations</summary>

- *Lili Yao, Ruijian Xu, Chao Li, Dongyan Zhao, Rui Yan*

- `1811.07631v1` - [abs](http://arxiv.org/abs/1811.07631v1) - [pdf](http://arxiv.org/pdf/1811.07631v1)

> To build an open-domain multi-turn conversation system is one of the most interesting and challenging tasks in Artificial Intelligence. Many research efforts have been dedicated to building such dialogue systems, yet few shed light on modeling the conversation flow in an ongoing dialogue. Besides, it is common for people to talk about highly relevant aspects during a conversation. And the topics are coherent and drift naturally, which demonstrates the necessity of dialogue flow modeling. To this end, we present the multi-turn cue-words driven conversation system with reinforcement learning method (RLCw), which strives to select an adaptive cue word with the greatest future credit, and therefore improve the quality of generated responses. We introduce a new reward to measure the quality of cue words in terms of effectiveness and relevance. To further optimize the model for long-term conversations, a reinforcement approach is adopted in this paper. Experiments on real-life dataset demonstrate that our model consistently outperforms a set of competitive baselines in terms of simulated turns, diversity and human evaluation.

</details>

<details>

<summary>2018-11-19 14:36:25 - Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?</summary>

- *Ping Luo, Zhanglin Peng, Jiamin Ren, Ruimao Zhang*

- `1811.07727v1` - [abs](http://arxiv.org/abs/1811.07727v1) - [pdf](http://arxiv.org/pdf/1811.07727v1)

> Yes, they do. This work investigates a perspective for deep learning: whether different normalization layers in a ConvNet require different normalizers. This is the first step towards understanding this phenomenon. We allow each convolutional layer to be stacked before a switchable normalization (SN) that learns to choose a normalizer from a pool of normalization methods. Through systematic experiments in ImageNet, COCO, Cityscapes, and ADE20K, we answer three questions: (a) Is it useful to allow each normalization layer to select its own normalizer? (b) What impacts the choices of normalizers? (c) Do different tasks and datasets prefer different normalizers? Our results suggest that (1) using distinct normalizers improves both learning and generalization of a ConvNet; (2) the choices of normalizers are more related to depth and batch size, but less relevant to parameter initialization, learning rate decay, and solver; (3) different tasks and datasets have different behaviors when learning to select normalizers.

</details>

<details>

<summary>2018-11-19 18:25:51 - Grasp2Vec: Learning Object Representations from Self-Supervised Grasping</summary>

- *Eric Jang, Coline Devin, Vincent Vanhoucke, Sergey Levine*

- `1811.06964v2` - [abs](http://arxiv.org/abs/1811.06964v2) - [pdf](http://arxiv.org/pdf/1811.06964v2)

> Well structured visual representations can make robot learning faster and can improve generalization. In this paper, we study how we can acquire effective object-centric representations for robotic manipulation tasks without human labeling by using autonomous robot interaction with the environment. Such representation learning methods can benefit from continuous refinement of the representation as the robot collects more experience, allowing them to scale effectively without human intervention. Our representation learning approach is based on object persistence: when a robot removes an object from a scene, the representation of that scene should change according to the features of the object that was removed. We formulate an arithmetic relationship between feature vectors from this observation, and use it to learn a representation of scenes and objects that can then be used to identify object instances, localize them in the scene, and perform goal-directed grasping tasks where the robot must retrieve commanded objects from a bin. The same grasping procedure can also be used to automatically collect training data for our method, by recording images of scenes, grasping and removing an object, and recording the outcome. Our experiments demonstrate that this self-supervised approach for tasked grasping substantially outperforms direct reinforcement learning from images and prior representation learning methods.

</details>

<details>

<summary>2018-11-19 18:32:41 - Numeral Understanding in Financial Tweets for Fine-grained Crowd-based Forecasting</summary>

- *Chung-Chi Chen, Hen-Hsen Huang, Yow-Ting Shiue, Hsin-Hsi Chen*

- `1809.05356v2` - [abs](http://arxiv.org/abs/1809.05356v2) - [pdf](http://arxiv.org/pdf/1809.05356v2)

> Numerals that contain much information in financial documents are crucial for financial decision making. They play different roles in financial analysis processes. This paper is aimed at understanding the meanings of numerals in financial tweets for fine-grained crowd-based forecasting. We propose a taxonomy that classifies the numerals in financial tweets into 7 categories, and further extend some of these categories into several subcategories. Neural network-based models with word and character-level encoders are proposed for 7-way classification and 17-way classification. We perform backtest to confirm the effectiveness of the numeric opinions made by the crowd. This work is the first attempt to understand numerals in financial social media data, and we provide the first comparison of fine-grained opinion of individual investors and analysts based on their forecast price. The numeral corpus used in our experiments, called FinNum 1.0 , is available for research purposes.

</details>

<details>

<summary>2018-11-19 18:48:04 - Scalable agent alignment via reward modeling: a research direction</summary>

- *Jan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, Shane Legg*

- `1811.07871v1` - [abs](http://arxiv.org/abs/1811.07871v1) - [pdf](http://arxiv.org/pdf/1811.07871v1)

> One obstacle to applying reinforcement learning algorithms to real-world problems is the lack of suitable reward functions. Designing such reward functions is difficult in part because the user only has an implicit understanding of the task objective. This gives rise to the agent alignment problem: how do we create agents that behave in accordance with the user's intentions? We outline a high-level research direction to solve the agent alignment problem centered around reward modeling: learning a reward function from interaction with the user and optimizing the learned reward function with reinforcement learning. We discuss the key challenges we expect to face when scaling reward modeling to complex and general domains, concrete approaches to mitigate these challenges, and ways to establish trust in the resulting agents.

</details>

<details>

<summary>2018-11-19 20:36:16 - Mitigating Architectural Mismatch During the Evolutionary Synthesis of Deep Neural Networks</summary>

- *Audrey Chung, Paul Fieguth, Alexander Wong*

- `1811.07966v1` - [abs](http://arxiv.org/abs/1811.07966v1) - [pdf](http://arxiv.org/pdf/1811.07966v1)

> Evolutionary deep intelligence has recently shown great promise for producing small, powerful deep neural network models via the organic synthesis of increasingly efficient architectures over successive generations. Existing evolutionary synthesis processes, however, have allowed the mating of parent networks independent of architectural alignment, resulting in a mismatch of network structures. We present a preliminary study into the effects of architectural alignment during evolutionary synthesis using a gene tagging system. Surprisingly, the network architectures synthesized using the gene tagging approach resulted in slower decreases in performance accuracy and storage size; however, the resultant networks were comparable in size and performance accuracy to the non-gene tagging networks. Furthermore, we speculate that there is a noticeable decrease in network variability for networks synthesized with gene tagging, indicating that enforcing a like-with-like mating policy potentially restricts the exploration of the search space of possible network architectures.

</details>

<details>

<summary>2018-11-20 02:30:02 - Mixture of Expert/Imitator Networks: Scalable Semi-supervised Learning Framework</summary>

- *Shun Kiyono, Jun Suzuki, Kentaro Inui*

- `1810.05788v2` - [abs](http://arxiv.org/abs/1810.05788v2) - [pdf](http://arxiv.org/pdf/1810.05788v2)

> The current success of deep neural networks (DNNs) in an increasingly broad range of tasks involving artificial intelligence strongly depends on the quality and quantity of labeled training data. In general, the scarcity of labeled data, which is often observed in many natural language processing tasks, is one of the most important issues to be addressed. Semi-supervised learning (SSL) is a promising approach to overcoming this issue by incorporating a large amount of unlabeled data. In this paper, we propose a novel scalable method of SSL for text classification tasks. The unique property of our method, Mixture of Expert/Imitator Networks, is that imitator networks learn to "imitate" the estimated label distribution of the expert network over the unlabeled data, which potentially contributes a set of features for the classification. Our experiments demonstrate that the proposed method consistently improves the performance of several types of baseline DNNs. We also demonstrate that our method has the more data, better performance property with promising scalability to the amount of unlabeled data.

</details>

<details>

<summary>2018-11-20 04:28:29 - Representation Learning of Pedestrian Trajectories Using Actor-Critic Sequence-to-Sequence Autoencoder</summary>

- *Ka-Ho Chow, Anish Hiranandani, Yifeng Zhang, S. -H. Gary Chan*

- `1811.08069v1` - [abs](http://arxiv.org/abs/1811.08069v1) - [pdf](http://arxiv.org/pdf/1811.08069v1)

> Representation learning of pedestrian trajectories transforms variable-length timestamp-coordinate tuples of a trajectory into a fixed-length vector representation that summarizes spatiotemporal characteristics. It is a crucial technique to connect feature-based data mining with trajectory data. Trajectory representation is a challenging problem, because both environmental constraints (e.g., wall partitions) and temporal user dynamics should be meticulously considered and accounted for. Furthermore, traditional sequence-to-sequence autoencoders using maximum log-likelihood often require dataset covering all the possible spatiotemporal characteristics to perform well. This is infeasible or impractical in reality. We propose TREP, a practical pedestrian trajectory representation learning algorithm which captures the environmental constraints and the pedestrian dynamics without the need of any training dataset. By formulating a sequence-to-sequence autoencoder with a spatial-aware objective function under the paradigm of actor-critic reinforcement learning, TREP intelligently encodes spatiotemporal characteristics of trajectories with the capability of handling diverse trajectory patterns. Extensive experiments on both synthetic and real datasets validate the high fidelity of TREP to represent trajectories.

</details>

<details>

<summary>2018-11-20 04:50:09 - Factorized Distillation: Training Holistic Person Re-identification Model by Distilling an Ensemble of Partial ReID Models</summary>

- *Pengyuan Ren, Jianmin Li*

- `1811.08073v1` - [abs](http://arxiv.org/abs/1811.08073v1) - [pdf](http://arxiv.org/pdf/1811.08073v1)

> Person re-identification (ReID) is aimed at identifying the same person across videos captured from different cameras. In the view that networks extracting global features using ordinary network architectures are difficult to extract local features due to their weak attention mechanisms, researchers have proposed a lot of elaborately designed ReID networks, while greatly improving the accuracy, the model size and the feature extraction latency are also soaring. We argue that a relatively compact ordinary network extracting globally pooled features has the capability to extract discriminative local features and can achieve state-of-the-art precision if only the model's parameters are properly learnt. In order to reduce the difficulty in learning hard identity labels, we propose a novel knowledge distillation method: Factorized Distillation, which factorizes both feature maps and retrieval features of holistic ReID network to mimic representations of multiple partial ReID models, thus transferring the knowledge from partial ReID models to the holistic network. Experiments show that the performance of model trained with the proposed method can outperform state-of-the-art with relatively few network parameters.

</details>

<details>

<summary>2018-11-20 06:11:26 - Model Learning for Look-ahead Exploration in Continuous Control</summary>

- *Arpit Agarwal, Katharina Muelling, Katerina Fragkiadaki*

- `1811.08086v1` - [abs](http://arxiv.org/abs/1811.08086v1) - [pdf](http://arxiv.org/pdf/1811.08086v1)

> We propose an exploration method that incorporates look-ahead search over basic learnt skills and their dynamics, and use it for reinforcement learning (RL) of manipulation policies . Our skills are multi-goal policies learned in isolation in simpler environments using existing multigoal RL formulations, analogous to options or macroactions. Coarse skill dynamics, i.e., the state transition caused by a (complete) skill execution, are learnt and are unrolled forward during lookahead search. Policy search benefits from temporal abstraction during exploration, though itself operates over low-level primitive actions, and thus the resulting policies does not suffer from suboptimality and inflexibility caused by coarse skill chaining. We show that the proposed exploration strategy results in effective learning of complex manipulation policies faster than current state-of-the-art RL methods, and converges to better policies than methods that use options or parametrized skills as building blocks of the policy itself, as opposed to guiding exploration. We show that the proposed exploration strategy results in effective learning of complex manipulation policies faster than current state-of-the-art RL methods, and converges to better policies than methods that use options or parameterized skills as building blocks of the policy itself, as opposed to guiding exploration.

</details>

<details>

<summary>2018-11-20 07:25:54 - Temporal anomaly detection: calibrating the surprise</summary>

- *Eyal Gutflaish, Aryeh Kontorovich, Sivan Sabato, Ofer Biller, Oded Sofer*

- `1705.10085v2` - [abs](http://arxiv.org/abs/1705.10085v2) - [pdf](http://arxiv.org/pdf/1705.10085v2)

> We propose a hybrid approach to temporal anomaly detection in access data of users to databases --- or more generally, any kind of subject-object co-occurrence data. We consider a high-dimensional setting that also requires fast computation at test time. Our methodology identifies anomalies based on a single stationary model, instead of requiring a full temporal one, which would be prohibitive in this setting. We learn a low-rank stationary model from the training data, and then fit a regression model for predicting the expected likelihood score of normal access patterns in the future. The disparity between the predicted likelihood score and the observed one is used to assess the `surprise' at test time. This approach enables calibration of the anomaly score, so that time-varying normal behavior patterns are not considered anomalous. We provide a detailed description of the algorithm, including a convergence analysis, and report encouraging empirical results. One of the data sets that we tested, TDA, is new for the public domain. It consists of two months' worth of database access records from a live system. Our code is publicly available at https://github.com/eyalgut/TLR_anomaly_detection.git. The TDA data set is available at https://www.kaggle.com/eyalgut/binary-traffic-matrices.

</details>

<details>

<summary>2018-11-20 08:31:24 - Explaining Latent Factor Models for Recommendation with Influence Functions</summary>

- *Weiyu Cheng, Yanyan Shen, Yanmin Zhu, Linpeng Huang*

- `1811.08120v1` - [abs](http://arxiv.org/abs/1811.08120v1) - [pdf](http://arxiv.org/pdf/1811.08120v1)

> Latent factor models (LFMs) such as matrix factorization achieve the state-of-the-art performance among various Collaborative Filtering (CF) approaches for recommendation. Despite the high recommendation accuracy of LFMs, a critical issue to be resolved is the lack of explainability. Extensive efforts have been made in the literature to incorporate explainability into LFMs. However, they either rely on auxiliary information which may not be available in practice, or fail to provide easy-to-understand explanations. In this paper, we propose a fast influence analysis method named FIA, which successfully enforces explicit neighbor-style explanations to LFMs with the technique of influence functions stemmed from robust statistics. We first describe how to employ influence functions to LFMs to deliver neighbor-style explanations. Then we develop a novel influence computation algorithm for matrix factorization with high efficiency. We further extend it to the more general neural collaborative filtering and introduce an approximation algorithm to accelerate influence analysis over neural network models. Experimental results on real datasets demonstrate the correctness, efficiency and usefulness of our proposed method.

</details>

<details>

<summary>2018-11-20 10:09:02 - Machine Learning Distinguishes Neurosurgical Skill Levels in a Virtual Reality Tumor Resection Task</summary>

- *Samaneh Siyar, Hamed Azarnoush, Saeid Rashidi, Alexandre Winkler-Schwartz, Vincent Bissonnette, Nirros Ponnudurai, Rolando F. Del Maestro*

- `1811.08159v1` - [abs](http://arxiv.org/abs/1811.08159v1) - [pdf](http://arxiv.org/pdf/1811.08159v1)

> Background: Virtual reality simulators and machine learning have the potential to augment understanding, assessment and training of psychomotor performance in neurosurgery residents. Objective: This study outlines the first application of machine learning to distinguish "skilled" and "novice" psychomotor performance during a virtual reality neurosurgical task. Methods: Twenty-three neurosurgeons and senior neurosurgery residents comprising the "skilled" group and 92 junior neurosurgery residents and medical students the "novice" group. The task involved removing a series of virtual brain tumors without causing injury to surrounding tissue. Over 100 features were extracted and 68 selected using t-test analysis. These features were provided to 4 classifiers: K-Nearest Neighbors, Parzen Window, Support Vector Machine, and Fuzzy K-Nearest Neighbors. Equal Error Rate was used to assess classifier performance. Results: Ratios of train set size to test set size from 10% to 90% and 5 to 30 features, chosen by the forward feature selection algorithm, were employed. A working point of 50% train to test set size ratio and 15 features resulted in an equal error rates as low as 8.3% using the Fuzzy K-Nearest Neighbors classifier. Conclusion: Machine learning may be one component helping realign the traditional apprenticeship educational paradigm to a more objective model based on proven performance standards.   Keywords: Artificial intelligence, Classifiers, Machine learning, Neurosurgery skill assessment, Surgical education, Tumor resection, Virtual reality simulation

</details>

<details>

<summary>2018-11-20 11:55:21 - An Information-Theoretic Optimality Principle for Deep Reinforcement Learning</summary>

- *Felix Leibfried, Jordi Grau-Moya, Haitham Bou-Ammar*

- `1708.01867v5` - [abs](http://arxiv.org/abs/1708.01867v5) - [pdf](http://arxiv.org/pdf/1708.01867v5)

> We methodologically address the problem of Q-value overestimation in deep reinforcement learning to handle high-dimensional state spaces efficiently. By adapting concepts from information theory, we introduce an intrinsic penalty signal encouraging reduced Q-value estimates. The resultant algorithm encompasses a wide range of learning outcomes containing deep Q-networks as a special case. Different learning outcomes can be demonstrated by tuning a Lagrange multiplier accordingly. We furthermore propose a novel scheduling scheme for this Lagrange multiplier to ensure efficient and robust learning. In experiments on Atari, our algorithm outperforms other algorithms (e.g. deep and double deep Q-networks) in terms of both game-play performance and sample complexity. These results remain valid under the recently proposed dueling architecture.

</details>

<details>

<summary>2018-11-20 12:37:55 - Computer-Assisted Fraud Detection, From Active Learning to Reward Maximization</summary>

- *Christelle Marfaing, Alexandre Garcia*

- `1811.08212v1` - [abs](http://arxiv.org/abs/1811.08212v1) - [pdf](http://arxiv.org/pdf/1811.08212v1)

> The automatic detection of frauds in banking transactions has been recently studied as a way to help the analysts finding fraudulent operations. Due to the availability of a human feedback, this task has been studied in the framework of active learning: the fraud predictor is allowed to sequentially call on an oracle. This human intervention is used to label new examples and improve the classification accuracy of the latter. Such a setting is not adapted in the case of fraud detection with financial data in European countries. Actually, as a human verification is mandatory to consider a fraud as really detected, it is not necessary to focus on improving the classifier. We introduce the setting of 'Computer-assisted fraud detection' where the goal is to minimize the number of non fraudulent operations submitted to an oracle. The existing methods are applied to this task and we show that a simple meta-algorithm provides competitive results in this scenario on benchmark datasets.

</details>

<details>

<summary>2018-11-20 13:00:51 - Self Organizing Classifiers: First Steps in Structured Evolutionary Machine Learning</summary>

- *Danilo Vasconcellos Vargas, Hirotaka Takano, Junichi Murata*

- `1811.08225v1` - [abs](http://arxiv.org/abs/1811.08225v1) - [pdf](http://arxiv.org/pdf/1811.08225v1)

> Learning classifier systems (LCSs) are evolutionary machine learning algorithms, flexible enough to be applied to reinforcement, supervised and unsupervised learning problems with good performance. Recently, self organizing classifiers were proposed which are similar to LCSs but have the advantage that in its structured population no balance between niching and fitness pressure is necessary. However, more tests and analysis are required to verify its benefits. Here, a variation of the first algorithm is proposed which uses a parameterless self organizing map (SOM). This algorithm is applied in challenging problems such as big, noisy as well as dynamically changing continuous input-action mazes (growing and compressing mazes are included) with good performance. Moreover, a genetic operator is proposed which utilizes the topological information of the SOM's population structure, improving the results. Thus, the first steps in structured evolutionary machine learning are shown, nonetheless, the problems faced are more difficult than the state-of-art continuous input-action multi-step ones.

</details>

<details>

<summary>2018-11-20 13:01:29 - Self Organizing Classifiers and Niched Fitness</summary>

- *Danilo Vasconcellos Vargas, Hirotaka Takano, Junichi Murata*

- `1811.08226v1` - [abs](http://arxiv.org/abs/1811.08226v1) - [pdf](http://arxiv.org/pdf/1811.08226v1)

> Learning classifier systems are adaptive learning systems which have been widely applied in a multitude of application domains. However, there are still some generalization problems unsolved. The hurdle is that fitness and niching pressures are difficult to balance. Here, a new algorithm called Self Organizing Classifiers is proposed which faces this problem from a different perspective. Instead of balancing the pressures, both pressures are separated and no balance is necessary. In fact, the proposed algorithm possesses a dynamical population structure that self-organizes itself to better project the input space into a map. The niched fitness concept is defined along with its dynamical population structure, both are indispensable for the understanding of the proposed method. Promising results are shown on two continuous multi-step problems. One of which is yet more challenging than previous problems of this class in the literature.

</details>

<details>

<summary>2018-11-20 13:33:02 - Geometry of Friston's active inference</summary>

- *Martin Biehl*

- `1811.08241v1` - [abs](http://arxiv.org/abs/1811.08241v1) - [pdf](http://arxiv.org/pdf/1811.08241v1)

> We reconstruct Karl Friston's active inference and give a geometrical interpretation of it.

</details>

<details>

<summary>2018-11-20 14:26:44 - Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures</summary>

- *Sergey Bartunov, Adam Santoro, Blake A. Richards, Luke Marris, Geoffrey E. Hinton, Timothy Lillicrap*

- `1807.04587v2` - [abs](http://arxiv.org/abs/1807.04587v2) - [pdf](http://arxiv.org/pdf/1807.04587v2)

> The backpropagation of error algorithm (BP) is impossible to implement in a real brain. The recent success of deep networks in machine learning and AI, however, has inspired proposals for understanding how the brain might learn across multiple layers, and hence how it might approximate BP. As of yet, none of these proposals have been rigorously evaluated on tasks where BP-guided deep learning has proved critical, or in architectures more structured than simple fully-connected networks. Here we present results on scaling up biologically motivated models of deep learning on datasets which need deep networks with appropriate architectures to achieve good performance. We present results on the MNIST, CIFAR-10, and ImageNet datasets and explore variants of target-propagation (TP) and feedback alignment (FA) algorithms, and explore performance in both fully- and locally-connected architectures. We also introduce weight-transport-free variants of difference target propagation (DTP) modified to remove backpropagation from the penultimate layer. Many of these algorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP and FA variants perform significantly worse than BP, especially for networks composed of locally connected units, opening questions about whether new architectures and algorithms are required to scale these approaches. Our results and implementation details help establish baselines for biologically motivated deep learning schemes going forward.

</details>

<details>

<summary>2018-11-20 15:50:33 - Improving Natural Language Inference Using External Knowledge in the Science Questions Domain</summary>

- *Xiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu, Kartik Talamadupula, Ibrahim Abdelaziz, Maria Chang, Achille Fokoue, Bassem Makni, Nicholas Mattei, Michael Witbrock*

- `1809.05724v2` - [abs](http://arxiv.org/abs/1809.05724v2) - [pdf](http://arxiv.org/pdf/1809.05724v2)

> Natural Language Inference (NLI) is fundamental to many Natural Language Processing (NLP) applications including semantic search and question answering. The NLI problem has gained significant attention thanks to the release of large scale, challenging datasets. Present approaches to the problem largely focus on learning-based methods that use only textual information in order to classify whether a given premise entails, contradicts, or is neutral with respect to a given hypothesis. Surprisingly, the use of methods based on structured knowledge -- a central topic in artificial intelligence -- has not received much attention vis-a-vis the NLI problem. While there are many open knowledge bases that contain various types of reasoning information, their use for NLI has not been well explored. To address this, we present a combination of techniques that harness knowledge graphs to improve performance on the NLI problem in the science questions domain. We present the results of applying our techniques on text, graph, and text-to-graph based models, and discuss implications for the use of external knowledge in solving the NLI problem. Our model achieves the new state-of-the-art performance on the NLI problem over the SciTail science questions dataset.

</details>

<details>

<summary>2018-11-20 17:11:47 - On a hypergraph probabilistic graphical model</summary>

- *Mohammad Ali Javidian, Linyuan Lu, Marco Valtorta, Zhiyu Wang*

- `1811.08372v1` - [abs](http://arxiv.org/abs/1811.08372v1) - [pdf](http://arxiv.org/pdf/1811.08372v1)

> We propose a directed acyclic hypergraph framework for a probabilistic graphical model that we call Bayesian hypergraphs. The space of directed acyclic hypergraphs is much larger than the space of chain graphs. Hence Bayesian hypergraphs can model much finer factorizations than Bayesian networks or LWF chain graphs and provide simpler and more computationally efficient procedures for factorizations and interventions. Bayesian hypergraphs also allow a modeler to represent causal patterns of interaction such as Noisy-OR graphically (without additional annotations). We introduce global, local and pairwise Markov properties of Bayesian hypergraphs and prove under which conditions they are equivalent. We define a projection operator, called shadow, that maps Bayesian hypergraphs to chain graphs, and show that the Markov properties of a Bayesian hypergraph are equivalent to those of its corresponding chain graph. We extend the causal interpretation of LWF chain graphs to Bayesian hypergraphs and provide corresponding formulas and a graphical criterion for intervention.

</details>

<details>

<summary>2018-11-20 20:59:38 - MimicGAN: Corruption-Mimicking for Blind Image Recovery & Adversarial Defense</summary>

- *Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Timo Bremer*

- `1811.08484v1` - [abs](http://arxiv.org/abs/1811.08484v1) - [pdf](http://arxiv.org/pdf/1811.08484v1)

> Solving inverse problems continues to be a central challenge in computer vision. Existing techniques either explicitly construct an inverse mapping using prior knowledge about the corruption, or learn the inverse directly using a large collection of examples. However, in practice, the nature of corruption may be unknown, and thus it is challenging to regularize the problem of inferring a plausible solution. On the other hand, collecting task-specific training data is tedious for known corruptions and impossible for unknown ones. We present MimicGAN, an unsupervised technique to solve general inverse problems based on image priors in the form of generative adversarial networks (GANs). Using a GAN prior, we show that one can reliably recover solutions to underdetermined inverse problems through a surrogate network that learns to mimic the corruption at test time. Our system successively estimates the corruption and the clean image without the need for supervisory training, while outperforming existing baselines in blind image recovery. We also demonstrate that MimicGAN improves upon recent GAN-based defenses against adversarial attacks and represents one of the strongest test-time defenses available today.

</details>

<details>

<summary>2018-11-20 23:30:46 - Understanding Learned Models by Identifying Important Features at the Right Resolution</summary>

- *Kyubin Lee, Akshay Sood, Mark Craven*

- `1811.07279v2` - [abs](http://arxiv.org/abs/1811.07279v2) - [pdf](http://arxiv.org/pdf/1811.07279v2)

> In many application domains, it is important to characterize how complex learned models make their decisions across the distribution of instances. One way to do this is to identify the features and interactions among them that contribute to a model's predictive accuracy. We present a model-agnostic approach to this task that makes the following specific contributions. Our approach (i) tests feature groups, in addition to base features, and tries to determine the level of resolution at which important features can be determined, (ii) uses hypothesis testing to rigorously assess the effect of each feature on the model's loss, (iii) employs a hierarchical approach to control the false discovery rate when testing feature groups and individual base features for importance, and (iv) uses hypothesis testing to identify important interactions among features and feature groups. We evaluate our approach by analyzing random forest and LSTM neural network models learned in two challenging biomedical applications.

</details>

<details>

<summary>2018-11-20 23:42:12 - Privacy Issues and Data Protection in Big Data: A Case Study Analysis under GDPR</summary>

- *Nils Gruschka, Vasileios Mavroeidis, Kamer Vishi, Meiko Jensen*

- `1811.08531v1` - [abs](http://arxiv.org/abs/1811.08531v1) - [pdf](http://arxiv.org/pdf/1811.08531v1)

> Big data has become a great asset for many organizations, promising improved operations and new business opportunities. However, big data has increased access to sensitive information that when processed can directly jeopardize the privacy of individuals and violate data protection laws. As a consequence, data controllers and data processors may be imposed tough penalties for non-compliance that can result even to bankruptcy. In this paper, we discuss the current state of the legal regulations and analyze different data protection and privacy-preserving techniques in the context of big data analysis. In addition, we present and analyze two real-life research projects as case studies dealing with sensitive data and actions for complying with the data regulation laws. We show which types of information might become a privacy risk, the employed privacy-preserving techniques in accordance with the legal requirements, and the influence of these techniques on the data processing phase and the research results.

</details>

<details>

<summary>2018-11-21 00:14:56 - Melding the Data-Decisions Pipeline: Decision-Focused Learning for Combinatorial Optimization</summary>

- *Bryan Wilder, Bistra Dilkina, Milind Tambe*

- `1809.05504v2` - [abs](http://arxiv.org/abs/1809.05504v2) - [pdf](http://arxiv.org/pdf/1809.05504v2)

> Creating impact in real-world settings requires artificial intelligence techniques to span the full pipeline from data, to predictive models, to decisions. These components are typically approached separately: a machine learning model is first trained via a measure of predictive accuracy, and then its predictions are used as input into an optimization algorithm which produces a decision. However, the loss function used to train the model may easily be misaligned with the end goal, which is to make the best decisions possible. Hand-tuning the loss function to align with optimization is a difficult and error-prone process (which is often skipped entirely).   We focus on combinatorial optimization problems and introduce a general framework for decision-focused learning, where the machine learning model is directly trained in conjunction with the optimization algorithm to produce high-quality decisions. Technically, our contribution is a means of integrating common classes of discrete optimization problems into deep learning or other predictive models, which are typically trained via gradient descent. The main idea is to use a continuous relaxation of the discrete problem to propagate gradients through the optimization procedure. We instantiate this framework for two broad classes of combinatorial problems: linear programs and submodular maximization. Experimental results across a variety of domains show that decision-focused learning often leads to improved optimization performance compared to traditional methods. We find that standard measures of accuracy are not a reliable proxy for a predictive model's utility in optimization, and our method's ability to specify the true goal as the model's training objective yields substantial dividends across a range of decision problems.

</details>

<details>

<summary>2018-11-21 01:35:54 - ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging Synthesis with Generative Adversarial Networks</summary>

- *Xiaodan Hu, Audrey G. Chung, Paul Fieguth, Farzad Khalvati, Masoom A. Haider, Alexander Wong*

- `1811.05817v2` - [abs](http://arxiv.org/abs/1811.05817v2) - [pdf](http://arxiv.org/pdf/1811.05817v2)

> Generative Adversarial Networks (GANs) have shown considerable promise for mitigating the challenge of data scarcity when building machine learning-driven analysis algorithms. Specifically, a number of studies have shown that GAN-based image synthesis for data augmentation can aid in improving classification accuracy in a number of medical image analysis tasks, such as brain and liver image analysis. However, the efficacy of leveraging GANs for tackling prostate cancer analysis has not been previously explored. Motivated by this, in this study we introduce ProstateGAN, a GAN-based model for synthesizing realistic prostate diffusion imaging data. More specifically, in order to generate new diffusion imaging data corresponding to a particular cancer grade (Gleason score), we propose a conditional deep convolutional GAN architecture that takes Gleason scores into consideration during the training process. Experimental results show that high-quality synthetic prostate diffusion imaging data can be generated using the proposed ProstateGAN for specified Gleason scores.

</details>

<details>

<summary>2018-11-21 01:48:22 - Neural Machine Translation with Adequacy-Oriented Learning</summary>

- *Xiang Kong, Zhaopeng Tu, Shuming Shi, Eduard Hovy, Tong Zhang*

- `1811.08541v1` - [abs](http://arxiv.org/abs/1811.08541v1) - [pdf](http://arxiv.org/pdf/1811.08541v1)

> Although Neural Machine Translation (NMT) models have advanced state-of-the-art performance in machine translation, they face problems like the inadequate translation. We attribute this to that the standard Maximum Likelihood Estimation (MLE) cannot judge the real translation quality due to its several limitations. In this work, we propose an adequacy-oriented learning mechanism for NMT by casting translation as a stochastic policy in Reinforcement Learning (RL), where the reward is estimated by explicitly measuring translation adequacy. Benefiting from the sequence-level training of RL strategy and a more accurate reward designed specifically for translation, our model outperforms multiple strong baselines, including (1) standard and coverage-augmented attention models with MLE-based training, and (2) advanced reinforcement and adversarial training strategies with rewards based on both word-level BLEU and character-level chrF3. Quantitative and qualitative analyses on different language pairs and NMT architectures demonstrate the effectiveness and universality of the proposed approach.

</details>

<details>

<summary>2018-11-21 02:34:15 - Deep Reinforcement Learning for Resource Management in Network Slicing</summary>

- *Rongpeng Li, Zhifeng Zhao, Qi Sun, Chi-Lin I, Chenyang Yang, Xianfu Chen, Minjian Zhao, Honggang Zhang*

- `1805.06591v3` - [abs](http://arxiv.org/abs/1805.06591v3) - [pdf](http://arxiv.org/pdf/1805.06591v3)

> Network slicing is born as an emerging business to operators, by allowing them to sell the customized slices to various tenants at different prices. In order to provide better-performing and cost-efficient services, network slicing involves challenging technical issues and urgently looks forward to intelligent innovations to make the resource management consistent with users' activities per slice. In that regard, deep reinforcement learning (DRL), which focuses on how to interact with the environment by trying alternative actions and reinforcing the tendency actions producing more rewarding consequences, is assumed to be a promising solution. In this paper, after briefly reviewing the fundamental concepts of DRL, we investigate the application of DRL in solving some typical resource management for network slicing scenarios, which include radio resource slicing and priority-based core network slicing, and demonstrate the advantage of DRL over several competing schemes through extensive simulations. Finally, we also discuss the possible challenges to apply DRL in network slicing from a general perspective.

</details>

<details>

<summary>2018-11-21 08:32:51 - CAAD 2018: Generating Transferable Adversarial Examples</summary>

- *Yash Sharma, Tien-Dung Le, Moustafa Alzantot*

- `1810.01268v2` - [abs](http://arxiv.org/abs/1810.01268v2) - [pdf](http://arxiv.org/pdf/1810.01268v2)

> Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations carefully crafted to fool the targeted DNN, in both the non-targeted and targeted case. In the non-targeted case, the attacker simply aims to induce misclassification. In the targeted case, the attacker aims to induce classification to a specified target class. In addition, it has been observed that strong adversarial examples can transfer to unknown models, yielding a serious security concern. The NIPS 2017 competition was organized to accelerate research in adversarial attacks and defenses, taking place in the realistic setting where submitted adversarial attacks attempt to transfer to submitted defenses. The CAAD 2018 competition took place with nearly identical rules to the NIPS 2017 one. Given the requirement that the NIPS 2017 submissions were to be open-sourced, participants in the CAAD 2018 competition were able to directly build upon previous solutions, and thus improve the state-of-the-art in this setting. Our team participated in the CAAD 2018 competition, and won 1st place in both attack subtracks, non-targeted and targeted adversarial attacks, and 3rd place in defense. We outline our solutions and development results in this article. We hope our results can inform researchers in both generating and defending against adversarial examples.

</details>

<details>

<summary>2018-11-21 10:05:23 - InfoSSM: Interpretable Unsupervised Learning of Nonparametric State-Space Model for Multi-modal Dynamics</summary>

- *Young-Jin Park, Han-Lim Choi*

- `1809.07109v2` - [abs](http://arxiv.org/abs/1809.07109v2) - [pdf](http://arxiv.org/pdf/1809.07109v2)

> The goal of system identification is to learn about underlying physics dynamics behind the time-series data. To model the probabilistic and nonparametric dynamics model, Gaussian process (GP) have been widely used; GP can estimate the uncertainty of prediction and avoid over-fitting. Traditional GPSSMs, however, are based on Gaussian transition model, thus often have difficulty in describing a more complex transition model, e.g. aircraft motions. To resolve the challenge, this paper proposes a framework using multiple GP transition models which is capable of describing multi-modal dynamics. Furthermore, we extend the model to the information-theoretic framework, the so-called InfoSSM, by introducing a mutual information regularizer helping the model to learn interpretable and distinguishable multiple dynamics models. Two illustrative numerical experiments in simple Dubins vehicle and high-fidelity flight simulator are presented to demonstrate the performance and interpretability of the proposed model. Finally, this paper introduces a framework using InfoSSM with Bayesian filtering for air traffic control tracking.

</details>

<details>

<summary>2018-11-21 11:43:29 - Automatic Language Identification in Texts: A Survey</summary>

- *Tommi Jauhiainen, Marco Lui, Marcos Zampieri, Timothy Baldwin, Krister Lindén*

- `1804.08186v2` - [abs](http://arxiv.org/abs/1804.08186v2) - [pdf](http://arxiv.org/pdf/1804.08186v2)

> Language identification (LI) is the problem of determining the natural language that a document or part thereof is written in. Automatic LI has been extensively researched for over fifty years. Today, LI is a key part of many text processing pipelines, as text processing techniques generally assume that the language of the input text is known. Research in this area has recently been especially active. This article provides a brief history of LI research, and an extensive survey of the features and methods used so far in the LI literature. For describing the features and methods we introduce a unified notation. We discuss evaluation methods, applications of LI, as well as off-the-shelf LI systems that do not require training by the end user. Finally, we identify open issues, survey the work to date on each issue, and propose future directions for research in LI.

</details>

<details>

<summary>2018-11-21 12:39:19 - Structure-Based Networks for Drug Validation</summary>

- *Cătălina Cangea, Arturas Grauslys, Pietro Liò, Francesco Falciani*

- `1811.09714v1` - [abs](http://arxiv.org/abs/1811.09714v1) - [pdf](http://arxiv.org/pdf/1811.09714v1)

> Classifying chemicals according to putative modes of action (MOAs) is of paramount importance in the context of risk assessment. However, current methods are only able to handle a very small proportion of the existing chemicals. We address this issue by proposing an integrative deep learning architecture that learns a joint representation from molecular structures of drugs and their effects on human cells. Our choice of architecture is motivated by the significant influence of a drug's chemical structure on its MOA. We improve on the strong ability of a unimodal architecture (F1 score of 0.803) to classify drugs by their toxic MOAs (Verhaar scheme) through adding another learning stream that processes transcriptional responses of human cells affected by drugs. Our integrative model achieves an even higher classification performance on the LINCS L1000 dataset - the error is reduced by 4.6%. We believe that our method can be used to extend the current Verhaar scheme and constitute a basis for fast drug validation and risk assessment.

</details>

<details>

<summary>2018-11-21 13:41:21 - Marginal Weighted Maximum Log-likelihood for Efficient Learning of Perturb-and-Map models</summary>

- *Tatiana Shpakova, Francis Bach, Anton Osokin*

- `1811.08725v1` - [abs](http://arxiv.org/abs/1811.08725v1) - [pdf](http://arxiv.org/pdf/1811.08725v1)

> We consider the structured-output prediction problem through probabilistic approaches and generalize the "perturb-and-MAP" framework to more challenging weighted Hamming losses, which are crucial in applications. While in principle our approach is a straightforward marginalization, it requires solving many related MAP inference problems. We show that for log-supermodular pairwise models these operations can be performed efficiently using the machinery of dynamic graph cuts. We also propose to use double stochastic gradient descent, both on the data and on the perturbations, for efficient learning. Our framework can naturally take weak supervision (e.g., partial labels) into account. We conduct a set of experiments on medium-scale character recognition and image segmentation, showing the benefits of our algorithms.

</details>

<details>

<summary>2018-11-21 14:46:36 - Using AI to Design Stone Jewelry</summary>

- *Khyatti Gupta, Sonam Damani, Kedhar Nath Narahari*

- `1811.08759v1` - [abs](http://arxiv.org/abs/1811.08759v1) - [pdf](http://arxiv.org/pdf/1811.08759v1)

> Jewelry has been an integral part of human culture since ages. One of the most popular styles of jewelry is created by putting together precious and semi-precious stones in diverse patterns. While technology is finding its way in the production process of such jewelry, designing it remains a time-consuming and involved task. In this paper, we propose a unique approach using optimization methods coupled with machine learning techniques to generate novel stone jewelry designs at scale. Our evaluation shows that designs generated by our approach are highly likeable and visually appealing.

</details>

<details>

<summary>2018-11-21 15:21:02 - Predicting Demographics, Moral Foundations, and Human Values from Digital Behaviors</summary>

- *Kyriaki Kalimeri, Mariano G. Beiro, Matteo Delfino, Robert Raleigh, Ciro Cattuto*

- `1712.01930v4` - [abs](http://arxiv.org/abs/1712.01930v4) - [pdf](http://arxiv.org/pdf/1712.01930v4)

> Personal electronic devices including smartphones give access to behavioural signals that can be used to learn about the characteristics and preferences of individuals. In this study, we explore the connection between demographic and psychological attributes and the digital behavioural records, for a cohort of 7,633 people, closely representative of the US population with respect to gender, age, geographical distribution, education, and income. Along with the demographic data, we collected self-reported assessments on validated psychometric questionnaires for moral traits and basic human values and combined this information with passively collected multi-modal digital data from web browsing behaviour and smartphone usage. A machine learning framework was then designed to infer both the demographic and psychological attributes from the behavioural data. In a cross-validated setting, our models predicted demographic attributes with good accuracy as measured by the weighted AUROC score (Area Under the Receiver Operating Characteristic), but were less performant for the moral traits and human values. These results call for further investigation since they are still far from unveiling individuals' psychological fabric. This connection, along with the most predictive features that we provide for each attribute, might prove useful for designing personalised services, communication strategies, and interventions, and can be used to sketch a portrait of people with a similar worldview.

</details>

<details>

<summary>2018-11-21 16:58:27 - Left Ventricle Segmentation and Volume Estimation on Cardiac MRI using Deep Learning</summary>

- *Ehab Abdelmaguid, Jolene Huang, Sanjay Kenchareddy, Disha Singla, Laura Wilke, Mai H. Nguyen, Ilkay Altintas*

- `1809.06247v2` - [abs](http://arxiv.org/abs/1809.06247v2) - [pdf](http://arxiv.org/pdf/1809.06247v2)

> In the United States, heart disease is the leading cause of death for both men and women, accounting for 610,000 deaths each year [1]. Physicians use Magnetic Resonance Imaging (MRI) scans to take images of the heart in order to non-invasively estimate its structural and functional parameters for cardiovascular diagnosis and disease management. The end-systolic volume (ESV) and end-diastolic volume (EDV) of the left ventricle (LV), and the ejection fraction (EF) are indicators of heart disease. These measures can be derived from the segmented contours of the LV; thus, consistent and accurate segmentation of the LV from MRI images are critical to the accuracy of the ESV, EDV, and EF, and to non-invasive cardiac disease detection.   In this work, various image preprocessing techniques, model configurations using the U-Net deep learning architecture, postprocessing methods, and approaches for volume estimation are investigated. An end-to-end analytics pipeline with multiple stages is provided for automated LV segmentation and volume estimation. First, image data are reformatted and processed from DICOM and NIfTI formats to raw images in array format. Secondly, raw images are processed with multiple image preprocessing methods and cropped to include only the Region of Interest (ROI). Thirdly, preprocessed images are segmented using U-Net models. Lastly, post processing of segmented images to remove extra contours along with intelligent slice and frame selection are applied, followed by calculation of the ESV, EDV, and EF. This analytics pipeline is implemented and runs on a distributed computing environment with a GPU cluster at the San Diego Supercomputer Center at UCSD.

</details>

<details>

<summary>2018-11-21 17:17:23 - Learning Safe Policies with Expert Guidance</summary>

- *Jessie Huang, Fa Wu, Doina Precup, Yang Cai*

- `1805.08313v2` - [abs](http://arxiv.org/abs/1805.08313v2) - [pdf](http://arxiv.org/pdf/1805.08313v2)

> We propose a framework for ensuring safe behavior of a reinforcement learning agent when the reward function may be difficult to specify. In order to do this, we rely on the existence of demonstrations from expert policies, and we provide a theoretical framework for the agent to optimize in the space of rewards consistent with its existing knowledge. We propose two methods to solve the resulting optimization: an exact ellipsoid-based method and a method in the spirit of the "follow-the-perturbed-leader" algorithm. Our experiments demonstrate the behavior of our algorithm in both discrete and continuous problems. The trained agent safely avoids states with potential negative effects while imitating the behavior of the expert in the other states.

</details>

<details>

<summary>2018-11-21 17:21:26 - A distinct approach to diagnose Dengue Fever with the help of Soft Set Theory</summary>

- *Maaz Amjad, fariha Bukhari, Iqra Ameer, Alexander Gelbukh*

- `1805.09169v3` - [abs](http://arxiv.org/abs/1805.09169v3) - [pdf](http://arxiv.org/pdf/1805.09169v3)

> Mathematics has played a substantial role to revolutionize the medical science. Intelligent systems based on mathematical theories have proved to be efficient in diagnosing various diseases. In this paper, we used an expert system based on soft set theory and fuzzy set theory named as a soft expert system to diagnose tropical disease dengue. The objective to use soft expert system is to predict the risk level of a patient having dengue fever by using input variables like age, TLC, SGOT, platelets count and blood pressure. The proposed method explicitly demonstrates the exact percentage of the risk level of dengue fever automatically circumventing for all possible (medical) imprecisions.

</details>

<details>

<summary>2018-11-21 17:59:56 - Resource Mention Extraction for MOOC Discussion Forums</summary>

- *Ya-Hui An, Liangming Pan, Min-Yen Kan, Qiang Dong, Yan Fu*

- `1811.08853v1` - [abs](http://arxiv.org/abs/1811.08853v1) - [pdf](http://arxiv.org/pdf/1811.08853v1)

> In discussions hosted on discussion forums for MOOCs, references to online learning resources are often of central importance. They contextualize the discussion, anchoring the discussion participants' presentation of the issues and their understanding. However they are usually mentioned in free text, without appropriate hyperlinking to their associated resource. Automated learning resource mention hyperlinking and categorization will facilitate discussion and searching within MOOC forums, and also benefit the contextualization of such resources across disparate views. We propose the novel problem of learning resource mention identification in MOOC forums. As this is a novel task with no publicly available data, we first contribute a large-scale labeled dataset, dubbed the Forum Resource Mention (FoRM) dataset, to facilitate our current research and future research on this task. We then formulate this task as a sequence tagging problem and investigate solution architectures to address the problem. Importantly, we identify two major challenges that hinder the application of sequence tagging models to the task: (1) the diversity of resource mention expression, and (2) long-range contextual dependencies. We address these challenges by incorporating character-level and thread context information into a LSTM-CRF model. First, we incorporate a character encoder to address the out-of-vocabulary problem caused by the diversity of mention expressions. Second, to address the context dependency challenge, we encode thread contexts using an RNN-based context encoder, and apply the attention mechanism to selectively leverage useful context information during sequence tagging. Experiments on FoRM show that the proposed method improves the baseline deep sequence tagging models notably, significantly bettering performance on instances that exemplify the two challenges.

</details>

<details>

<summary>2018-11-21 19:53:03 - Scaling provable adversarial defenses</summary>

- *Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, J. Zico Kolter*

- `1805.12514v2` - [abs](http://arxiv.org/abs/1805.12514v2) - [pdf](http://arxiv.org/pdf/1805.12514v2)

> Recent work has developed methods for learning deep network classifiers that are provably robust to norm-bounded adversarial perturbation; however, these methods are currently only possible for relatively small feedforward networks. In this paper, in an effort to scale these approaches to substantially larger models, we extend previous work in three main directions. First, we present a technique for extending these training procedures to much more general networks, with skip connections (such as ResNets) and general nonlinearities; the approach is fully modular, and can be implemented automatically (analogous to automatic differentiation). Second, in the specific case of $\ell_\infty$ adversarial perturbations and networks with ReLU nonlinearities, we adopt a nonlinear random projection for training, which scales linearly in the number of hidden units (previous approaches scaled quadratically). Third, we show how to further improve robust error through cascade models. On both MNIST and CIFAR data sets, we train classifiers that improve substantially on the state of the art in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST (with $\ell_\infty$ perturbations of $\epsilon=0.1$), and from 80% to 36.4% on CIFAR (with $\ell_\infty$ perturbations of $\epsilon=2/255$). Code for all experiments in the paper is available at https://github.com/locuslab/convex_adversarial/.

</details>

<details>

<summary>2018-11-21 21:05:16 - Fuzzy Least Squares Twin Support Vector Machines</summary>

- *Javad Salimi Sartakhti, Homayun Afrabandpey, Nasser Ghadiri*

- `1505.05451v3` - [abs](http://arxiv.org/abs/1505.05451v3) - [pdf](http://arxiv.org/pdf/1505.05451v3)

> Least Squares Twin Support Vector Machine (LST-SVM) has been shown to be an efficient and fast algorithm for binary classification. It combines the operating principles of Least Squares SVM (LS-SVM) and Twin SVM (T-SVM); it constructs two non-parallel hyperplanes (as in T-SVM) by solving two systems of linear equations (as in LS-SVM). Despite its efficiency, LST-SVM is still unable to cope with two features of real-world problems. First, in many real-world applications, labels of samples are not deterministic; they come naturally with their associated membership degrees. Second, samples in real-world applications may not be equally important and their importance degrees affect the classification. In this paper, we propose Fuzzy LST-SVM (FLST-SVM) to deal with these two characteristics of real-world data. Two models are introduced for FLST-SVM: the first model builds up crisp hyperplanes using training samples and their corresponding membership degrees. The second model, on the other hand, constructs fuzzy hyperplanes using training samples and their membership degrees. Numerical evaluation of the proposed method with synthetic and real datasets demonstrate significant improvement in the classification accuracy of FLST-SVM when compared to well-known existing versions of SVM.

</details>

<details>

<summary>2018-11-21 21:20:24 - Integrating Task-Motion Planning with Reinforcement Learning for Robust Decision Making in Mobile Robots</summary>

- *Yuqian Jiang, Fangkai Yang, Shiqi Zhang, Peter Stone*

- `1811.08955v1` - [abs](http://arxiv.org/abs/1811.08955v1) - [pdf](http://arxiv.org/pdf/1811.08955v1)

> Task-motion planning (TMP) addresses the problem of efficiently generating executable and low-cost task plans in a discrete space such that the (initially unknown) action costs are determined by motion plans in a corresponding continuous space. However, a task-motion plan can be sensitive to unexpected domain uncertainty and changes, leading to suboptimal behaviors or execution failures. In this paper, we propose a novel framework, TMP-RL, which is an integration of TMP and reinforcement learning (RL) from the execution experience, to solve the problem of robust task-motion planning in dynamic and uncertain domains. TMP-RL features two nested planning-learning loops. In the inner TMP loop, the robot generates a low-cost, feasible task-motion plan by iteratively planning in the discrete space and updating relevant action costs evaluated by the motion planner in continuous space. In the outer loop, the plan is executed, and the robot learns from the execution experience via model-free RL, to further improve its task-motion plans. RL in the outer loop is more accurate to the current domain but also more expensive, and using less costly task and motion planning leads to a jump-start for learning in the real world. Our approach is evaluated on a mobile service robot conducting navigation tasks in an office area. Results show that TMP-RL approach significantly improves adaptability and robustness (in comparison to TMP methods) and leads to rapid convergence (in comparison to task planning (TP)-RL methods). We also show that TMP-RL can reuse learned values to smoothly adapt to new scenarios during long-term deployments.

</details>

<details>

<summary>2018-11-21 23:34:57 - Improving Grey-Box Fuzzing by Modeling Program Behavior</summary>

- *Siddharth Karamcheti, Gideon Mann, David Rosenberg*

- `1811.08973v1` - [abs](http://arxiv.org/abs/1811.08973v1) - [pdf](http://arxiv.org/pdf/1811.08973v1)

> Grey-box fuzzers such as American Fuzzy Lop (AFL) are popular tools for finding bugs and potential vulnerabilities in programs. While these fuzzers have been able to find vulnerabilities in many widely used programs, they are not efficient; of the millions of inputs executed by AFL in a typical fuzzing run, only a handful discover unseen behavior or trigger a crash. The remaining inputs are redundant, exhibiting behavior that has already been observed. Here, we present an approach to increase the efficiency of fuzzers like AFL by applying machine learning to directly model how programs behave. We learn a forward prediction model that maps program inputs to execution traces, training on the thousands of inputs collected during standard fuzzing. This learned model guides exploration by focusing on fuzzing inputs on which our model is the most uncertain (measured via the entropy of the predicted execution trace distribution). By focusing on executing inputs our learned model is unsure about, and ignoring any input whose behavior our model is certain about, we show that we can significantly limit wasteful execution. Through testing our approach on a set of binaries released as part of the DARPA Cyber Grand Challenge, we show that our approach is able to find a set of inputs that result in more code coverage and discovered crashes than baseline fuzzers with significantly fewer executions.

</details>

<details>

<summary>2018-11-22 04:09:49 - Learning Attentional Communication for Multi-Agent Cooperation</summary>

- *Jiechuan Jiang, Zongqing Lu*

- `1805.07733v3` - [abs](http://arxiv.org/abs/1805.07733v3) - [pdf](http://arxiv.org/pdf/1805.07733v3)

> Communication could potentially be an effective way for multi-agent cooperation. However, information sharing among all agents or in predefined communication architectures that existing methods adopt can be problematic. When there is a large number of agents, agents cannot differentiate valuable information that helps cooperative decision making from globally shared information. Therefore, communication barely helps, and could even impair the learning of multi-agent cooperation. Predefined communication architectures, on the other hand, restrict communication among agents and thus restrain potential cooperation. To tackle these difficulties, in this paper, we propose an attentional communication model that learns when communication is needed and how to integrate shared information for cooperative decision making. Our model leads to efficient and effective communication for large-scale multi-agent cooperation. Empirically, we show the strength of our model in a variety of cooperative scenarios, where agents are able to develop more coordinated and sophisticated strategies than existing methods.

</details>

<details>

<summary>2018-11-22 05:14:00 - Trust-Aware Decision Making for Human-Robot Collaboration: Model Learning and Planning</summary>

- *Min Chen, Stefanos Nikolaidis, Harold Soh, David Hsu, Siddhartha Srinivasa*

- `1801.04099v3` - [abs](http://arxiv.org/abs/1801.04099v3) - [pdf](http://arxiv.org/pdf/1801.04099v3)

> Trust in autonomy is essential for effective human-robot collaboration and user adoption of autonomous systems such as robot assistants. This paper introduces a computational model which integrates trust into robot decision-making. Specifically, we learn from data a partially observable Markov decision process (POMDP) with human trust as a latent variable. The trust-POMDP model provides a principled approach for the robot to (i) infer the trust of a human teammate through interaction, (ii) reason about the effect of its own actions on human trust, and (iii) choose actions that maximize team performance over the long term. We validated the model through human subject experiments on a table-clearing task in simulation (201 participants) and with a real robot (20 participants). In our studies, the robot builds human trust by manipulating low-risk objects first. Interestingly, the robot sometimes fails intentionally in order to modulate human trust and achieve the best team performance. These results show that the trust-POMDP calibrates trust to improve human-robot team performance over the long term. Further, they highlight that maximizing trust alone does not always lead to the best performance.

</details>

<details>

<summary>2018-11-22 05:52:50 - BigDataBench: A Scalable and Unified Big Data and AI Benchmark Suite</summary>

- *Wanling Gao, Jianfeng Zhan, Lei Wang, Chunjie Luo, Daoyi Zheng, Xu Wen, Rui Ren, Chen Zheng, Xiwen He, Hainan Ye, Haoning Tang, Zheng Cao, Shujie Zhang, Jiahui Dai*

- `1802.08254v2` - [abs](http://arxiv.org/abs/1802.08254v2) - [pdf](http://arxiv.org/pdf/1802.08254v2)

> Several fundamental changes in technology indicate domain-specific hardware and software co-design is the only path left. In this context, architecture, system, data management, and machine learning communities pay greater attention to innovative big data and AI algorithms, architecture, and systems. Unfortunately, complexity, diversity, frequently-changed workloads, and rapid evolution of big data and AI systems raise great challenges. First, the traditional benchmarking methodology that creates a new benchmark or proxy for every possible workload is not scalable, or even impossible for Big Data and AI benchmarking. Second, it is prohibitively expensive to tailor the architecture to characteristics of one or more application or even a domain of applications. We consider each big data and AI workload as a pipeline of one or more classes of units of computation performed on different initial or intermediate data inputs, each class of which we call a data motif. On the basis of our previous work that identifies eight data motifs taking up most of the run time of a wide variety of big data and AI workloads, we propose a scalable benchmarking methodology that uses the combination of one or more data motifs---to represent diversity of big data and AI workloads. Following this methodology, we present a unified big data and AI benchmark suite---BigDataBench 4.0, publicly available from~\url{http://prof.ict.ac.cn/BigDataBench}. This unified benchmark suite sheds new light on domain-specific hardware and software co-design: tailoring the system and architecture to characteristics of the unified eight data motifs other than one or more application case by case. Also, for the first time, we comprehensively characterize the CPU pipeline efficiency using the benchmarks of seven workload types in BigDataBench 4.0.

</details>

<details>

<summary>2018-11-22 12:55:40 - Creating a contemporary corpus of similes in Serbian by using natural language processing</summary>

- *Nikola Milosevic, Goran Nenadic*

- `1811.10422v1` - [abs](http://arxiv.org/abs/1811.10422v1) - [pdf](http://arxiv.org/pdf/1811.10422v1)

> Simile is a figure of speech that compares two things through the use of connection words, but where comparison is not intended to be taken literally. They are often used in everyday communication, but they are also a part of linguistic cultural heritage. In this paper we present a methodology for semi-automated collection of similes from the World Wide Web using text mining and machine learning techniques. We expanded an existing corpus by collecting 442 similes from the internet and adding them to the existing corpus collected by Vuk Stefanovic Karadzic that contained 333 similes. We, also, introduce crowdsourcing to the collection of figures of speech, which helped us to build corpus containing 787 unique similes.

</details>

<details>

<summary>2018-11-22 13:51:34 - Goal-oriented Dialogue Policy Learning from Failures</summary>

- *Keting Lu, Shiqi Zhang, Xiaoping Chen*

- `1808.06497v2` - [abs](http://arxiv.org/abs/1808.06497v2) - [pdf](http://arxiv.org/pdf/1808.06497v2)

> Reinforcement learning methods have been used for learning dialogue policies. However, learning an effective dialogue policy frequently requires prohibitively many conversations. This is partly because of the sparse rewards in dialogues, and the very few successful dialogues in early learning phase. Hindsight experience replay (HER) enables learning from failures, but the vanilla HER is inapplicable to dialogue learning due to the implicit goals. In this work, we develop two complex HER methods providing different trade-offs between complexity and performance, and, for the first time, enabled HER-based dialogue policy learning. Experiments using a realistic user simulator show that our HER methods perform better than existing experience replay methods (as applied to deep Q-networks) in learning rate.

</details>

<details>

<summary>2018-11-22 13:56:47 - Robot Representation and Reasoning with Knowledge from Reinforcement Learning</summary>

- *Keting Lu, Shiqi Zhang, Peter Stone, Xiaoping Chen*

- `1809.11074v3` - [abs](http://arxiv.org/abs/1809.11074v3) - [pdf](http://arxiv.org/pdf/1809.11074v3)

> Reinforcement learning (RL) agents aim at learning by interacting with an environment, and are not designed for representing or reasoning with declarative knowledge. Knowledge representation and reasoning (KRR) paradigms are strong in declarative KRR tasks, but are ill-equipped to learn from such experiences. In this work, we integrate logical-probabilistic KRR with model-based RL, enabling agents to simultaneously reason with declarative knowledge and learn from interaction experiences. The knowledge from humans and RL is unified and used for dynamically computing task-specific planning models under potentially new environments. Experiments were conducted using a mobile robot working on dialog, navigation, and delivery tasks. Results show significant improvements, in comparison to existing model-based RL methods.

</details>

<details>

<summary>2018-11-22 17:31:18 - Automatic L3 slice detection in 3D CT images using fully-convolutional networks</summary>

- *Fahdi Kanavati, Shah Islam, Eric O. Aboagye, Andrea Rockall*

- `1811.09244v1` - [abs](http://arxiv.org/abs/1811.09244v1) - [pdf](http://arxiv.org/pdf/1811.09244v1)

> The analysis of single CT slices extracted at the third lumbar vertebra (L3) has garnered significant clinical interest in the past few years, in particular in regards to quantifying sarcopenia (muscle loss). In this paper, we propose an efficient method to automatically detect the L3 slice in 3D CT images. Our method works with images with a variety of fields of view, occlusions, and slice thicknesses. 3D CT images are first converted into 2D via Maximal Intensity Projection (MIP), reducing the dimensionality of the problem. The MIP images are then used as input to a 2D fully-convolutional network to predict the L3 slice locations in the form of 2D confidence maps. In addition we propose a variant architecture with less parameters allowing 1D confidence map prediction and slightly faster prediction time without loss of accuracy. Quantitative evaluation of our method on a dataset of 1006 3D CT images yields a median error of 1mm, similar to the inter-rater median error of 1mm obtained from two annotators, demonstrating the effectiveness of our method in efficiently and accurately detecting the L3 slice.

</details>

<details>

<summary>2018-11-22 17:31:41 - Oversight of Unsafe Systems via Dynamic Safety Envelopes</summary>

- *David Manheim*

- `1811.09246v1` - [abs](http://arxiv.org/abs/1811.09246v1) - [pdf](http://arxiv.org/pdf/1811.09246v1)

> This paper reviews the reasons that Human-in-the-Loop is both critical for preventing widely-understood failure modes for machine learning, and not a practical solution. Following this, we review two current heuristic methods for addressing this. The first is provable safety envelopes, which are possible only when the dynamics of the system are fully known, but can be useful safety guarantees when optimal behavior is based on machine learning with poorly-understood safety characteristics. The second is the simpler circuit breaker model, which can forestall or prevent catastrophic outcomes by stopping the system, without any specific model of the system. This paper proposes using heuristic, dynamic safety envelopes, which are a plausible halfway point between these approaches that allows human oversight without some of the more difficult problems faced by Human-in-the-Loop systems. Finally, the paper concludes with how this approach can be used for governance of systems where otherwise unsafe systems are deployed.

</details>

<details>

<summary>2018-11-22 19:37:01 - MixUp as Locally Linear Out-Of-Manifold Regularization</summary>

- *Hongyu Guo, Yongyi Mao, Richong Zhang*

- `1809.02499v3` - [abs](http://arxiv.org/abs/1809.02499v3) - [pdf](http://arxiv.org/pdf/1809.02499v3)

> MixUp is a recently proposed data-augmentation scheme, which linearly interpolates a random pair of training examples and correspondingly the one-hot representations of their labels. Training deep neural networks with such additional data is shown capable of significantly improving the predictive accuracy of the current art. The power of MixUp, however, is primarily established empirically and its working and effectiveness have not been explained in any depth. In this paper, we develop an understanding for MixUp as a form of "out-of-manifold regularization", which imposes certain "local linearity" constraints on the model's input space beyond the data manifold. This analysis enables us to identify a limitation of MixUp, which we call "manifold intrusion". In a nutshell, manifold intrusion in MixUp is a form of under-fitting resulting from conflicts between the synthetic labels of the mixed-up examples and the labels of original training data. Such a phenomenon usually happens when the parameters controlling the generation of mixing policies are not sufficiently fine-tuned on the training data. To address this issue, we propose a novel adaptive version of MixUp, where the mixing policies are automatically learned from the data using an additional network and objective function designed to avoid manifold intrusion. The proposed regularizer, AdaMixUp, is empirically evaluated on several benchmark datasets. Extensive experiments demonstrate that AdaMixUp improves upon MixUp when applied to the current art of deep classification models.

</details>

<details>

<summary>2018-11-22 19:56:43 - Dialectical Rough Sets, Parthood and Figures of Opposition-1</summary>

- *A. Mani*

- `1703.10251v2` - [abs](http://arxiv.org/abs/1703.10251v2) - [pdf](http://arxiv.org/pdf/1703.10251v2)

> In one perspective, the main theme of this research revolves around the inverse problem in the context of general rough sets that concerns the existence of rough basis for given approximations in a context. Granular operator spaces and variants were recently introduced by the present author as an optimal framework for anti-chain based algebraic semantics of general rough sets and the inverse problem. In the framework, various sub-types of crisp and non-crisp objects are identifiable that may be missed in more restrictive formalism. This is also because in the latter cases concepts of complementation and negation are taken for granted - while in reality they have a complicated dialectical basis. This motivates a general approach to dialectical rough sets building on previous work of the present author and figures of opposition. In this paper dialectical rough logics are invented from a semantic perspective, a concept of dialectical predicates is formalised, connection with dialetheias and glutty negation are established, parthood analyzed and studied from the viewpoint of classical and dialectical figures of opposition by the present author. Her methods become more geometrical and encompass parthood as a primary relation (as opposed to roughly equivalent objects) for algebraic semantics.

</details>

<details>

<summary>2018-11-23 03:08:30 - A Particle Filter based Multi-Objective Optimization Algorithm: PFOPS</summary>

- *Bin Liu, Yaochu Jin*

- `1808.09446v4` - [abs](http://arxiv.org/abs/1808.09446v4) - [pdf](http://arxiv.org/pdf/1808.09446v4)

> This paper is concerned with a recently developed paradigm for population-based optimization, termed particle filter optimization (PFO). This paradigm is attractive in terms of coherence in theory and easiness in mathematical analysis and interpretation. Current PFO algorithms only work for single-objective optimization cases, while many real-life problems involve multiple objectives to be optimized simultaneously. To this end, we make an effort to extend the scope of application of the PFO paradigm to multi-objective optimization (MOO) cases. An idea called path sampling is adopted within the PFO scheme to balance the different objectives to be optimized. The resulting algorithm is thus termed PFO with Path Sampling (PFOPS). The validity of the presented algorithm is assessed based on three benchmark MOO experiments, in which the shapes of the Pareto fronts are convex, concave and discontinuous, respectively.

</details>

<details>

<summary>2018-11-23 03:24:25 - Unsupervised Learning in Reservoir Computing for EEG-based Emotion Recognition</summary>

- *Rahma Fourati, Boudour Ammar, Javier Sanchez-Medina, Adel M. Alimi*

- `1811.07516v2` - [abs](http://arxiv.org/abs/1811.07516v2) - [pdf](http://arxiv.org/pdf/1811.07516v2)

> In real-world applications such as emotion recognition from recorded brain activity, data are captured from electrodes over time. These signals constitute a multidimensional time series. In this paper, Echo State Network (ESN), a recurrent neural network with a great success in time series prediction and classification, is optimized with different neural plasticity rules for classification of emotions based on electroencephalogram (EEG) time series. Actually, the neural plasticity rules are a kind of unsupervised learning adapted for the reservoir, i.e. the hidden layer of ESN. More specifically, an investigation of Oja's rule, BCM rule and gaussian intrinsic plasticity rule was carried out in the context of EEG-based emotion recognition. The study, also, includes a comparison of the offline and online training of the ESN. When testing on the well-known affective benchmark "DEAP dataset" which contains EEG signals from 32 subjects, we find that pretraining ESN with gaussian intrinsic plasticity enhanced the classification accuracy and outperformed the results achieved with an ESN pretrained with synaptic plasticity. Four classification problems were conducted in which the system complexity is increased and the discrimination is more challenging, i.e. inter-subject emotion discrimination. Our proposed method achieves higher performance over the state of the art methods.

</details>

<details>

<summary>2018-11-23 07:47:48 - Simulated Autonomous Driving in a Realistic Driving Environment using Deep Reinforcement Learning and a Deterministic Finite State Machine</summary>

- *Patrick Klose, Rudolf Mester*

- `1811.07868v2` - [abs](http://arxiv.org/abs/1811.07868v2) - [pdf](http://arxiv.org/pdf/1811.07868v2)

> In the field of Autonomous Driving, the system controlling the vehicle can be seen as an agent acting in a complex environment and thus naturally fits into the modern framework of Reinforcement Learning. However, learning to drive can be a challenging task and current results are often restricted to simplified driving environments. To advance the field, we present a method to adaptively restrict the action space of the agent according to its current driving situation and show that it can be used to swiftly learn to drive in a realistic environment based on the Deep Q-Network algorithm.

</details>

<details>

<summary>2018-11-23 12:10:30 - A Trustworthy, Responsible and Interpretable System to Handle Chit Chat in Conversational Bots</summary>

- *Parag Agrawal, Anshuman Suri, Tulasi Menon*

- `1811.07600v2` - [abs](http://arxiv.org/abs/1811.07600v2) - [pdf](http://arxiv.org/pdf/1811.07600v2)

> Most often, chat-bots are built to solve the purpose of a search engine or a human assistant: Their primary goal is to provide information to the user or help them complete a task. However, these chat-bots are incapable of responding to unscripted queries like "Hi, what's up", "What's your favourite food". Human evaluation judgments show that 4 humans come to a consensus on the intent of a given query which is from chat domain only 77% of the time, thus making it evident how non-trivial this task is. In our work, we show why it is difficult to break the chitchat space into clearly defined intents. We propose a system to handle this task in chat-bots, keeping in mind scalability, interpretability, appropriateness, trustworthiness, relevance and coverage. Our work introduces a pipeline for query understanding in chitchat using hierarchical intents as well as a way to use seq-seq auto-generation models in professional bots. We explore an interpretable model for chat domain detection and also show how various components such as adult/offensive classification, grammars/regex patterns, curated personality based responses, generic guided evasive responses and response generation models can be combined in a scalable way to solve this problem.

</details>

<details>

<summary>2018-11-23 13:45:30 - On Filter Size in Graph Convolutional Networks</summary>

- *Dinh Van Tran, Nicolò Navarin, Alessandro Sperduti*

- `1811.10435v1` - [abs](http://arxiv.org/abs/1811.10435v1) - [pdf](http://arxiv.org/pdf/1811.10435v1)

> Recently, many researchers have been focusing on the definition of neural networks for graphs. The basic component for many of these approaches remains the graph convolution idea proposed almost a decade ago. In this paper, we extend this basic component, following an intuition derived from the well-known convolutional filters over multi-dimensional tensors. In particular, we derive a simple, efficient and effective way to introduce a hyper-parameter on graph convolutions that influences the filter size, i.e. its receptive field over the considered graph. We show with experimental results on real-world graph datasets that the proposed graph convolutional filter improves the predictive performance of Deep Graph Convolutional Networks.

</details>

<details>

<summary>2018-11-23 16:00:51 - Competency Questions and SPARQL-OWL Queries Dataset and Analysis</summary>

- *Dawid Wisniewski, Jedrzej Potoniec, Agnieszka Lawrynowicz, C. Maria Keet*

- `1811.09529v1` - [abs](http://arxiv.org/abs/1811.09529v1) - [pdf](http://arxiv.org/pdf/1811.09529v1)

> Competency Questions (CQs) are natural language questions outlining and constraining the scope of knowledge represented by an ontology. Despite that CQs are a part of several ontology engineering methodologies, we have observed that the actual publication of CQs for the available ontologies is very limited and even scarcer is the publication of their respective formalisations in terms of, e.g., SPARQL queries. This paper aims to contribute to addressing the engineering shortcomings of using CQs in ontology development, to facilitate wider use of CQs. In order to understand the relation between CQs and the queries over the ontology to test the CQs on an ontology, we gather, analyse, and publicly release a set of 234 CQs and their translations to SPARQL-OWL for several ontologies in different domains developed by different groups. We analysed the CQs in two principal ways. The first stage focused on a linguistic analysis of the natural language text itself, i.e., a lexico-syntactic analysis without any presuppositions of ontology elements, and a subsequent step of semantic analysis in order to find patterns. This increased diversity of CQ sources resulted in a 5-fold increase of hitherto published patterns, to 106 distinct CQ patterns, which have a limited subset of few patterns shared across the CQ sets from the different ontologies. Next, we analysed the relation between the found CQ patterns and the 46 SPARQL-OWL query signatures, which revealed that one CQ pattern may be realised by more than one SPARQL-OWL query signature, and vice versa. We hope that our work will contribute to establishing common practices, templates, automation, and user tools that will support CQ formulation, formalisation, execution, and general management.

</details>

<details>

<summary>2018-11-23 16:49:02 - Learning Attractor Dynamics for Generative Memory</summary>

- *Yan Wu, Greg Wayne, Karol Gregor, Timothy Lillicrap*

- `1811.09556v1` - [abs](http://arxiv.org/abs/1811.09556v1) - [pdf](http://arxiv.org/pdf/1811.09556v1)

> A central challenge faced by memory systems is the robust retrieval of a stored pattern in the presence of interference due to other stored patterns and noise. A theoretically well-founded solution to robust retrieval is given by attractor dynamics, which iteratively clean up patterns during recall. However, incorporating attractor dynamics into modern deep learning systems poses difficulties: attractor basins are characterised by vanishing gradients, which are known to make training neural networks difficult. In this work, we avoid the vanishing gradient problem by training a generative distributed memory without simulating the attractor dynamics. Based on the idea of memory writing as inference, as proposed in the Kanerva Machine, we show that a likelihood-based Lyapunov function emerges from maximising the variational lower-bound of a generative memory. Experiments shows it converges to correct patterns upon iterative retrieval and achieves competitive performance as both a memory model and a generative model.

</details>

<details>

<summary>2018-11-23 16:54:45 - Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior</summary>

- *Zi Wang, Beomjoon Kim, Leslie Pack Kaelbling*

- `1811.09558v1` - [abs](http://arxiv.org/abs/1811.09558v1) - [pdf](http://arxiv.org/pdf/1811.09558v1)

> Bayesian optimization usually assumes that a Bayesian prior is given. However, the strong theoretical guarantees in Bayesian optimization are often regrettably compromised in practice because of unknown parameters in the prior. In this paper, we adopt a variant of empirical Bayes and show that, by estimating the Gaussian process prior from offline data sampled from the same prior and constructing unbiased estimators of the posterior, variants of both GP-UCB and probability of improvement achieve a near-zero regret bound, which decreases to a constant proportional to the observational noise as the number of offline data and the number of online evaluations increase. Empirically, we have verified our approach on challenging simulated robotic problems featuring task and motion planning.

</details>

<details>

<summary>2018-11-23 18:46:59 - Spectral Multigraph Networks for Discovering and Fusing Relationships in Molecules</summary>

- *Boris Knyazev, Xiao Lin, Mohamed R. Amer, Graham W. Taylor*

- `1811.09595v1` - [abs](http://arxiv.org/abs/1811.09595v1) - [pdf](http://arxiv.org/pdf/1811.09595v1)

> Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to a few problems where the graph is fixed, such as shape correspondence and node classification. In this work, we address this limitation by revisiting a particular family of spectral graph networks, Chebyshev GCNs, showing its efficacy in solving graph classification tasks with a variable graph structure and size. Chebyshev GCNs restrict graphs to have at most one edge between any pair of nodes. To this end, we propose a novel multigraph network that learns from multi-relational graphs. We model learned edges with abstract meaning and experiment with different ways to fuse the representations extracted from annotated and learned edges, achieving competitive results on a variety of chemical classification benchmarks.

</details>

<details>

<summary>2018-11-23 18:57:30 - Model-Based Reinforcement Learning for Sepsis Treatment</summary>

- *Aniruddh Raghu, Matthieu Komorowski, Sumeetpal Singh*

- `1811.09602v1` - [abs](http://arxiv.org/abs/1811.09602v1) - [pdf](http://arxiv.org/pdf/1811.09602v1)

> Sepsis is a dangerous condition that is a leading cause of patient mortality. Treating sepsis is highly challenging, because individual patients respond very differently to medical interventions and there is no universally agreed-upon treatment for sepsis. In this work, we explore the use of continuous state-space model-based reinforcement learning (RL) to discover high-quality treatment policies for sepsis patients. Our quantitative evaluation reveals that by blending the treatment strategy discovered with RL with what clinicians follow, we can obtain improved policies, potentially allowing for better medical treatment for sepsis.

</details>

<details>

<summary>2018-11-23 22:38:49 - Explicability? Legibility? Predictability? Transparency? Privacy? Security? The Emerging Landscape of Interpretable Agent Behavior</summary>

- *Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreedharan, David E. Smith, Subbarao Kambhampati*

- `1811.09722v1` - [abs](http://arxiv.org/abs/1811.09722v1) - [pdf](http://arxiv.org/pdf/1811.09722v1)

> There has been significant interest of late in generating behavior of agents that is interpretable to the human (observer) in the loop. However, the work in this area has typically lacked coherence on the topic, with proposed solutions for "explicable", "legible", "predictable" and "transparent" planning with overlapping, and sometimes conflicting, semantics all aimed at some notion of understanding what intentions the observer will ascribe to an agent by observing its behavior. This is also true for the recent works on "security" and "privacy" of plans which are also trying to answer the same question, but from the opposite point of view -- i.e. when the agent is trying to hide instead of revealing its intentions. This paper attempts to provide a workable taxonomy of relevant concepts in this exciting and emerging field of inquiry.

</details>

<details>

<summary>2018-11-24 00:29:31 - Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems</summary>

- *Christopher Stanton, Jeff Clune*

- `1806.00553v3` - [abs](http://arxiv.org/abs/1806.00553v3) - [pdf](http://arxiv.org/pdf/1806.00553v3)

> Traditional exploration methods in RL require agents to perform random actions to find rewards. But these approaches struggle on sparse-reward domains like Montezuma's Revenge where the probability that any random action sequence leads to reward is extremely low. Recent algorithms have performed well on such tasks by encouraging agents to visit new states or perform new actions in relation to all prior training episodes (which we call across-training novelty). But such algorithms do not consider whether an agent exhibits intra-life novelty: doing something new within the current episode, regardless of whether those behaviors have been performed in previous episodes. We hypothesize that across-training novelty might discourage agents from revisiting initially non-rewarding states that could become important stepping stones later in training. We introduce Deep Curiosity Search (DeepCS), which encourages intra-life exploration by rewarding agents for visiting as many different states as possible within each episode, and show that DeepCS matches the performance of current state-of-the-art methods on Montezuma's Revenge. We further show that DeepCS improves exploration on Amidar, Freeway, Gravitar, and Tutankham (many of which are hard exploration games). Surprisingly, DeepCS doubles A2C performance on Seaquest, a game we would not have expected to benefit from intra-life exploration because the arena is small and already easily navigated by naive exploration techniques. In one run, DeepCS achieves a maximum training score of 80,000 points on Seaquest, higher than any methods other than Ape-X. The strong performance of DeepCS on these sparse- and dense-reward tasks suggests that encouraging intra-life novelty is an interesting, new approach for improving performance in Deep RL and motivates further research into hybridizing across-training and intra-life exploration methods.

</details>

<details>

<summary>2018-11-24 05:23:39 - DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation</summary>

- *Rim Assouel, Mohamed Ahmed, Marwin H Segler, Amir Saffari, Yoshua Bengio*

- `1811.09766v1` - [abs](http://arxiv.org/abs/1811.09766v1) - [pdf](http://arxiv.org/pdf/1811.09766v1)

> Generating novel molecules with optimal properties is a crucial step in many industries such as drug discovery. Recently, deep generative models have shown a promising way of performing de-novo molecular design. Although graph generative models are currently available they either have a graph size dependency in their number of parameters, limiting their use to only very small graphs or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters, therefore preventing them to be used in scenarios such as conditional graph generation. In this work we propose a model for conditional graph generation that is computationally efficient and enables direct optimisation of the graph. We demonstrate favourable performance of our model on prototype-based molecular graph conditional generation tasks.

</details>

<details>

<summary>2018-11-24 05:29:03 - Epidemiological data challenges: planning for a more robust future through data standards</summary>

- *Geoffrey Fairchild, Byron Tasseff, Hari Khalsa, Nicholas Generous, Ashlynn R. Daughton, Nileena Velappan, Reid Priedhorsky, Alina Deshpande*

- `1805.00445v6` - [abs](http://arxiv.org/abs/1805.00445v6) - [pdf](http://arxiv.org/pdf/1805.00445v6)

> Accessible epidemiological data are of great value for emergency preparedness and response, understanding disease progression through a population, and building statistical and mechanistic disease models that enable forecasting. The status quo, however, renders acquiring and using such data difficult in practice. In many cases, a primary way of obtaining epidemiological data is through the internet, but the methods by which the data are presented to the public often differ drastically among institutions. As a result, there is a strong need for better data sharing practices. This paper identifies, in detail and with examples, the three key challenges one encounters when attempting to acquire and use epidemiological data: 1) interfaces, 2) data formatting, and 3) reporting. These challenges are used to provide suggestions and guidance for improvement as these systems evolve in the future. If these suggested data and interface recommendations were adhered to, epidemiological and public health analysis, modeling, and informatics work would be significantly streamlined, which can in turn yield better public health decision-making capabilities.

</details>

<details>

<summary>2018-11-24 07:47:01 - Alternating Loss Correction for Preterm-Birth Prediction from EHR Data with Noisy Labels</summary>

- *Sabri Boughorbel, Fethi Jarray, Neethu Venugopal, Haithum Elhadi*

- `1811.09782v1` - [abs](http://arxiv.org/abs/1811.09782v1) - [pdf](http://arxiv.org/pdf/1811.09782v1)

> In this paper we are interested in the prediction of preterm birth based on diagnosis codes from longitudinal EHR. We formulate the prediction problem as a supervised classification with noisy labels. Our base classifier is a Recurrent Neural Network with an attention mechanism. We assume the availability of a data subset with both noisy and clean labels. For the cohort definition, most of the diagnosis codes on mothers' records related to pregnancy are ambiguous for the definition of full-term and preterm classes. On the other hand, diagnosis codes on babies' records provide fine-grained information on prematurity. Due to data de-identification, the links between mothers and babies are not available. We developed a heuristic based on admission and discharge times to match babies to their mothers and hence enrich mothers' records with additional information on delivery status. The obtained additional dataset from the matching heuristic has noisy labels and was used to leverage the training of the deep learning model. We propose an Alternating Loss Correction (ALC) method to train deep models with both clean and noisy labels. First, the label corruption matrix is estimated using the data subset with both noisy and clean labels. Then it is used in the model as a dense output layer to correct for the label noise. The network is alternately trained on epochs with the clean dataset with a simple cross-entropy loss and on next epoch with the noisy dataset and a loss corrected with the estimated corruption matrix. The experiments for the prediction of preterm birth at 90 days before delivery showed an improvement in performance compared with baseline and state of-the-art methods.

</details>

<details>

<summary>2018-11-24 08:15:50 - Recurrently Controlled Recurrent Networks</summary>

- *Yi Tay, Luu Anh Tuan, Siu Cheung Hui*

- `1811.09786v1` - [abs](http://arxiv.org/abs/1811.09786v1) - [pdf](http://arxiv.org/pdf/1811.09786v1)

> Recurrent neural networks (RNNs) such as long short-term memory and gated recurrent units are pivotal building blocks across a broad spectrum of sequence modeling problems. This paper proposes a recurrently controlled recurrent network (RCRN) for expressive and powerful sequence encoding. More concretely, the key idea behind our approach is to learn the recurrent gating functions using recurrent networks. Our architecture is split into two components - a controller cell and a listener cell whereby the recurrent controller actively influences the compositionality of the listener cell. We conduct extensive experiments on a myriad of tasks in the NLP domain such as sentiment analysis (SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment classification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading comprehension (NarrativeQA). Across all 26 datasets, our results demonstrate that RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs, suggesting that our controller architecture might be a suitable replacement for the widely adopted stacked architecture.

</details>

<details>

<summary>2018-11-24 11:08:14 - Streamlining Variational Inference for Constraint Satisfaction Problems</summary>

- *Aditya Grover, Tudor Achim, Stefano Ermon*

- `1811.09813v1` - [abs](http://arxiv.org/abs/1811.09813v1) - [pdf](http://arxiv.org/pdf/1811.09813v1)

> Several algorithms for solving constraint satisfaction problems are based on survey propagation, a variational inference scheme used to obtain approximate marginal probability estimates for variable assignments. These marginals correspond to how frequently each variable is set to true among satisfying assignments, and are used to inform branching decisions during search; however, marginal estimates obtained via survey propagation are approximate and can be self-contradictory. We introduce a more general branching strategy based on streamlining constraints, which sidestep hard assignments to variables. We show that streamlined solvers consistently outperform decimation-based solvers on random k-SAT instances for several problem sizes, shrinking the gap between empirical performance and theoretical limits of satisfiability by 16.3% on average for k=3,4,5,6.

</details>

<details>

<summary>2018-11-24 14:41:48 - A Differentiable Physics Engine for Deep Learning in Robotics</summary>

- *Jonas Degrave, Michiel Hermans, Joni Dambre, Francis wyffels*

- `1611.01652v2` - [abs](http://arxiv.org/abs/1611.01652v2) - [pdf](http://arxiv.org/pdf/1611.01652v2)

> An important field in robotics is the optimization of controllers. Currently, robots are often treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. When gradient-based methods are used, models are kept small or rely on finite difference approximations for the Jacobian. This method quickly grows expensive with increasing numbers of parameters, such as found in deep learning. We propose the implementation of a modern physics engine, which can differentiate control parameters. This engine is implemented for both CPU and GPU. Firstly, this paper shows how such an engine speeds up the optimization process, even for small problems. Furthermore, it explains why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.

</details>

<details>

<summary>2018-11-24 15:00:48 - Optimizing positional scoring rules for rank aggregation</summary>

- *Ioannis Caragiannis, Xenophon Chatzigeorgiou, George A. Krimpas, Alexandros A. Voudouris*

- `1609.07460v2` - [abs](http://arxiv.org/abs/1609.07460v2) - [pdf](http://arxiv.org/pdf/1609.07460v2)

> Nowadays, several crowdsourcing projects exploit social choice methods for computing an aggregate ranking of alternatives given individual rankings provided by workers. Motivated by such systems, we consider a setting where each worker is asked to rank a fixed (small) number of alternatives and, then, a positional scoring rule is used to compute the aggregate ranking. Among the apparently infinite such rules, what is the best one to use? To answer this question, we assume that we have partial access to an underlying true ranking. Then, the important optimization problem to be solved is to compute the positional scoring rule whose outcome, when applied to the profile of individual rankings, is as close as possible to the part of the underlying true ranking we know. We study this fundamental problem from a theoretical viewpoint and present positive and negative complexity results and, furthermore, complement our theoretical findings with experiments on real-world and synthetic data.

</details>

<details>

<summary>2018-11-24 17:30:54 - Recognizing Plans by Learning Embeddings from Observed Action Distributions</summary>

- *Yantian Zha, Yikang Li, Sriram Gopalakrishnan, Baoxin Li, Subbarao Kambhampati*

- `1712.01949v2` - [abs](http://arxiv.org/abs/1712.01949v2) - [pdf](http://arxiv.org/pdf/1712.01949v2)

> Recent advances in visual activity recognition have raised the possibility of applications such as automated video surveillance. Effective approaches for such problems however require the ability to recognize the plans of agents from video information. Although traditional plan recognition algorithms depend on access to sophisticated planning domain models, one recent promising direction involves learning approximated (or shallow) domain models directly from the observed activity sequences DUP. One limitation is that such approaches expect observed action sequences as inputs. In many cases involving vision/sensing from raw data, there is considerable uncertainty about the specific action at any given time point. The most we can expect in such cases is probabilistic information about the action at that point. The input will then be sequences of such observed action distributions. In this work, we address the problem of constructing an effective data-interface that allows a plan recognition module to directly handle such observation distributions. Such an interface works like a bridge between the low-level perception module, and the high-level plan recognition module. We propose two approaches. The first involves resampling the distribution sequences to single action sequences, from which we could learn an action affinity model based on learned action (word) embeddings for plan recognition. The second is to directly learn action distribution embeddings by our proposed Distr2vec (distribution to vector) model, to construct an affinity model for plan recognition.

</details>

<details>

<summary>2018-11-24 21:27:53 - TGE-viz : Transition Graph Embedding for Visualization of Plan Traces and Domains</summary>

- *Sriram Gopalakrishnan, Subbarao Kambhampati*

- `1811.09900v1` - [abs](http://arxiv.org/abs/1811.09900v1) - [pdf](http://arxiv.org/pdf/1811.09900v1)

> Existing work for plan trace visualization in automated planning uses pipeline-style visualizations, similar to plans in Gantt charts. Such visualization do not capture the domain structure or dependencies between the various fluents and actions. Additionally, plan traces in such visualizations cannot be easily compared with one another without parsing the details of individual actions, which imposes a higher cognitive load. We introduce TGE-viz, a technique to visualize plan traces within an embedding of the entire transition graph of a domain in low dimensional space. TGE-viz allows users to visualize and criticize plans more intuitively for mixed-initiative planning. It also allows users to visually appraise the structure of domains and the dependencies in it.

</details>

<details>

<summary>2018-11-24 23:05:40 - The Morphospace of Consciousness</summary>

- *Xerxes D. Arsiwalla, Ricard Sole, Clement Moulin-Frier, Ivan Herreros, Marti Sanchez-Fibla, Paul Verschure*

- `1705.11190v3` - [abs](http://arxiv.org/abs/1705.11190v3) - [pdf](http://arxiv.org/pdf/1705.11190v3)

> We construct a complexity-based morphospace to study systems-level properties of conscious & intelligent systems. The axes of this space label 3 complexity types: autonomous, cognitive & social. Given recent proposals to synthesize consciousness, a generic complexity-based conceptualization provides a useful framework for identifying defining features of conscious & synthetic systems. Based on current clinical scales of consciousness that measure cognitive awareness and wakefulness, we take a perspective on how contemporary artificially intelligent machines & synthetically engineered life forms measure on these scales. It turns out that awareness & wakefulness can be associated to computational & autonomous complexity respectively. Subsequently, building on insights from cognitive robotics, we examine the function that consciousness serves, & argue the role of consciousness as an evolutionary game-theoretic strategy. This makes the case for a third type of complexity for describing consciousness: social complexity. Having identified these complexity types, allows for a representation of both, biological & synthetic systems in a common morphospace. A consequence of this classification is a taxonomy of possible conscious machines. We identify four types of consciousness, based on embodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii) group consciousness (resulting from group interactions), & (iv) simulated consciousness (embodied by virtual agents within a simulated reality). This taxonomy helps in the investigation of comparative signatures of consciousness across domains, in order to highlight design principles necessary to engineer conscious machines. This is particularly relevant in the light of recent developments at the crossroads of cognitive neuroscience, biomedical engineering, artificial intelligence & biomimetics.

</details>

<details>

<summary>2018-11-25 00:43:32 - RADMPC: A Fast Decentralized Approach for Chance-Constrained Multi-Vehicle Path-Planning</summary>

- *Aaron Huang, Benjamin J. Ayton, Brian C. Williams*

- `1811.09914v1` - [abs](http://arxiv.org/abs/1811.09914v1) - [pdf](http://arxiv.org/pdf/1811.09914v1)

> Robust multi-vehicle path-planning is important for ensuring the safety of multi-vehicle systems in applications like transportation, search and rescue, and robotic exploration. Chance-constrained methods like Iterative Risk Allocation (IRA)\cite{IRA} have been developed for situations where environmental disturbances are unbounded. However, chance-constrained methods for the multi-vehicle case generally use centralized strategies where the vehicle set is planned with couplings between all vehicle pairs. This approach is intractable as fleet size increases because computation time is exponential with respect to the number of vehicles being planned over due to a polynomial increase in coupling constraints between vehicle pairs. We present a faster approach for chance-constrained multi-vehicle path-planning that relies upon a decentralized path-planning method called Risk-Aware Decentralized Model Predictive Control (RADMPC) to rapidly approximate a centralized IRA approach. The RADMPC approximation is evaluated for vehicle interactions to determine the vehicle sets that should be planned in a coupled manner. Applying IRA to the smaller vehicle sets determined from the RADMPC approximation rapidly plans safe paths for the entire fleet. A Monte Carlo simulation analysis demonstrates the correctness of our approach and a significant improvement in computation time compared to a centralized IRA approach.

</details>

<details>

<summary>2018-11-25 01:31:38 - An Unified Intelligence-Communication Model for Multi-Agent System Part-I: Overview</summary>

- *Bo Zhang, Bin Chen, Jinyu Yang, Wenjing Yang, Jiankang Zhang*

- `1811.09920v1` - [abs](http://arxiv.org/abs/1811.09920v1) - [pdf](http://arxiv.org/pdf/1811.09920v1)

> Motivated by Shannon's model and recent rehabilitation of self-supervised artificial intelligence having a "World Model", this paper propose an unified intelligence-communication (UIC) model for describing a single agent and any multi-agent system.   Firstly, the environment is modelled as the generic communication channel between agents. Secondly, the UIC model adopts a learning-agent model for unifying several well-adopted agent architecture, e.g. rule-based agent model in complex adaptive systems, layered model for describing human-level intelligence, world-model based agent model. The model may also provide an unified approach to investigate a multi-agent system (MAS) having multiple action-perception modalities, e.g. explicitly information transfer and implicit information transfer.   This treatise would be divided into three parts, and this first part provides an overview of the UIC model without introducing cumbersome mathematical analysis and optimizations. In the second part of this treatise, case studies with quantitative analysis driven by the UIC model would be provided, exemplifying the adoption of the UIC model in multi-agent system. Specifically, two representative cases would be studied, namely the analysis of a natural multi-agent system, as well as the co-design of communication, perception and action in an artificial multi-agent system. In the third part of this treatise, the paper provides further insights and future research directions motivated by the UIC model, such as unification of single intelligence and collective intelligence, a possible explanation of intelligence emergence and a dual model for agent-environment intelligence hypothesis.   Notes: This paper is a Previewed Version, the extended full-version would be released after being accepted.

</details>

<details>

<summary>2018-11-25 06:31:13 - Intersectionality: Multiple Group Fairness in Expectation Constraints</summary>

- *Jack Fitzsimons, Michael Osborne, Stephen Roberts*

- `1811.09960v1` - [abs](http://arxiv.org/abs/1811.09960v1) - [pdf](http://arxiv.org/pdf/1811.09960v1)

> Group fairness is an important concern for machine learning researchers, developers, and regulators. However, the strictness to which models must be constrained to be considered fair is still under debate. The focus of this work is on constraining the expected outcome of subpopulations in kernel regression and, in particular, decision tree regression, with application to random forests, boosted trees and other ensemble models. While individual constraints were previously addressed, this work addresses concerns about incorporating multiple constraints simultaneously. The proposed solution does not affect the order of computational or memory complexity of the decision trees and is easily integrated into models post training.

</details>

<details>

<summary>2018-11-25 10:21:59 - Is Data Clustering in Adversarial Settings Secure?</summary>

- *Battista Biggio, Ignazio Pillai, Samuel Rota Bulò, Davide Ariu, Marcello Pelillo, Fabio Roli*

- `1811.09982v1` - [abs](http://arxiv.org/abs/1811.09982v1) - [pdf](http://arxiv.org/pdf/1811.09982v1)

> Clustering algorithms have been increasingly adopted in security applications to spot dangerous or illicit activities. However, they have not been originally devised to deal with deliberate attack attempts that may aim to subvert the clustering process itself. Whether clustering can be safely adopted in such settings remains thus questionable. In this work we propose a general framework that allows one to identify potential attacks against clustering algorithms, and to evaluate their impact, by making specific assumptions on the adversary's goal, knowledge of the attacked system, and capabilities of manipulating the input data. We show that an attacker may significantly poison the whole clustering process by adding a relatively small percentage of attack samples to the input data, and that some attack samples may be obfuscated to be hidden within some existing clusters. We present a case study on single-linkage hierarchical clustering, and report experiments on clustering of malware samples and handwritten digits.

</details>

<details>

<summary>2018-11-25 10:31:53 - Poisoning Behavioral Malware Clustering</summary>

- *Battista Biggio, Konrad Rieck, Davide Ariu, Christian Wressnegger, Igino Corona, Giorgio Giacinto, Fabio Roli*

- `1811.09985v1` - [abs](http://arxiv.org/abs/1811.09985v1) - [pdf](http://arxiv.org/pdf/1811.09985v1)

> Clustering algorithms have become a popular tool in computer security to analyze the behavior of malware variants, identify novel malware families, and generate signatures for antivirus systems. However, the suitability of clustering algorithms for security-sensitive settings has been recently questioned by showing that they can be significantly compromised if an attacker can exercise some control over the input data. In this paper, we revisit this problem by focusing on behavioral malware clustering approaches, and investigate whether and to what extent an attacker may be able to subvert these approaches through a careful injection of samples with poisoning behavior. To this end, we present a case study on Malheur, an open-source tool for behavioral malware clustering. Our experiments not only demonstrate that this tool is vulnerable to poisoning attacks, but also that it can be significantly compromised even if the attacker can only inject a very small percentage of attacks into the input data. As a remedy, we discuss possible countermeasures and highlight the need for more secure clustering algorithms.

</details>

<details>

<summary>2018-11-25 14:52:15 - Multimodal Classification of Stressful Environments in Visually Impaired Mobility Using EEG and Peripheral Biosignals</summary>

- *Charalampos Saitis, Kyriaki Kalimeri*

- `1811.10027v1` - [abs](http://arxiv.org/abs/1811.10027v1) - [pdf](http://arxiv.org/pdf/1811.10027v1)

> In this study, we aim to better understand the cognitive-emotional experience of visually impaired people when navigating in unfamiliar urban environments, both outdoor and indoor. We propose a multimodal framework based on random forest classifiers, which predict the actual environment among predefined generic classes of urban settings, inferring on real-time, non-invasive, ambulatory monitoring of brain and peripheral biosignals. Model performance reached 93% for the outdoor and 87% for the indoor environments (expressed in weighted AUROC), demonstrating the potential of the approach. Estimating the density distributions of the most predictive biomarkers, we present a series of geographic and temporal visualizations depicting the environmental contexts in which the most intense affective and cognitive reactions take place. A linear mixed model analysis revealed significant differences between categories of vision impairment, but not between normal and impaired vision. Despite the limited size of our cohort, these findings pave the way to emotionally intelligent mobility-enhancing systems, capable of implicit adaptation not only to changing environments but also to shifts in the affective state of the user in relation to different environmental and situational factors.

</details>

<details>

<summary>2018-11-25 21:10:10 - Planning in Dynamic Environments with Conditional Autoregressive Models</summary>

- *Johanna Hansen, Kyle Kastner, Aaron Courville, Gregory Dudek*

- `1811.10097v1` - [abs](http://arxiv.org/abs/1811.10097v1) - [pdf](http://arxiv.org/pdf/1811.10097v1)

> We demonstrate the use of conditional autoregressive generative models (van den Oord et al., 2016a) over a discrete latent space (van den Oord et al., 2017b) for forward planning with MCTS. In order to test this method, we introduce a new environment featuring varying difficulty levels, along with moving goals and obstacles. The combination of high-quality frame generation and classical planning approaches nearly matches true environment performance for our task, demonstrating the usefulness of this method for model-based planning in dynamic environments.

</details>

<details>

<summary>2018-11-26 01:58:39 - A Consolidated Approach to Convolutional Neural Networks and the Kolmogorov Complexity</summary>

- *D Yoan L. Mekontchou Yomba*

- `1812.00888v1` - [abs](http://arxiv.org/abs/1812.00888v1) - [pdf](http://arxiv.org/pdf/1812.00888v1)

> The ability to precisely quantify similarity between various entities has been a fundamental complication in various problem spaces specifically in the classification of cellular images. Contemporary similarity measures applied in the domain of image processing proposed by the scientific community are mainly pursued in supervised settings. In this work, we will explore the innovative algorithmic normalized compression distance metric based on the information theoretic concept of Kolmogorov Complexity. Additionally we will observe its possible implementation in Convolutional Neural Networks to facilitate and automate the classification of Retinal Pigment Epithelial cell cultures for use in Age Related Macular Degeneration Stem Cell therapy in an unsupervised setting.

</details>

<details>

<summary>2018-11-26 02:27:44 - Frequency Principle in Deep Learning with General Loss Functions and Its Potential Application</summary>

- *Zhi-Qin John Xu*

- `1811.10146v1` - [abs](http://arxiv.org/abs/1811.10146v1) - [pdf](http://arxiv.org/pdf/1811.10146v1)

> Previous studies have shown that deep neural networks (DNNs) with common settings often capture target functions from low to high frequency, which is called Frequency Principle (F-Principle). It has also been shown that F-Principle can provide an understanding to the often observed good generalization ability of DNNs. However, previous studies focused on the loss function of mean square error, while various loss functions are used in practice. In this work, we show that the F-Principle holds for a general loss function (e.g., mean square error, cross entropy, etc.). In addition, DNN's F-Principle may be applied to develop numerical schemes for solving various problems which would benefit from a fast converging of low frequency. As an example of the potential usage of F-Principle, we apply DNN in solving differential equations, in which conventional methods (e.g., Jacobi method) is usually slow in solving problems due to the convergence from high to low frequency.

</details>

<details>

<summary>2018-11-26 03:28:36 - Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors</summary>

- *Yansen Wang, Ying Shen, Zhun Liu, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency*

- `1811.09362v2` - [abs](http://arxiv.org/abs/1811.09362v2) - [pdf](http://arxiv.org/pdf/1811.09362v2)

> Humans convey their intentions through the usage of both verbal and nonverbal behaviors during face-to-face communication. Speaker intentions often vary dynamically depending on different nonverbal contexts, such as vocal patterns and facial expressions. As a result, when modeling human language, it is essential to not only consider the literal meaning of the words but also the nonverbal contexts in which these words appear. To better model human language, we first model expressive nonverbal representations by analyzing the fine-grained visual and acoustic patterns that occur during word segments. In addition, we seek to capture the dynamic nature of nonverbal intents by shifting word representations based on the accompanying nonverbal behaviors. To this end, we propose the Recurrent Attended Variation Embedding Network (RAVEN) that models the fine-grained structure of nonverbal subword sequences and dynamically shifts word representations based on nonverbal cues. Our proposed model achieves competitive performance on two publicly available datasets for multimodal sentiment analysis and emotion recognition. We also visualize the shifted word representations in different nonverbal contexts and summarize common patterns regarding multimodal variations of word representations.

</details>

<details>

<summary>2018-11-26 04:56:07 - Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning</summary>

- *Ramtin Keramati, Jay Whang, Patrick Cho, Emma Brunskill*

- `1806.00175v2` - [abs](http://arxiv.org/abs/1806.00175v2) - [pdf](http://arxiv.org/pdf/1806.00175v2)

> Humans learn to play video games significantly faster than the state-of-the-art reinforcement learning (RL) algorithms. People seem to build simple models that are easy to learn to support planning and strategic exploration. Inspired by this, we investigate two issues in leveraging model-based RL for sample efficiency. First we investigate how to perform strategic exploration when exact planning is not feasible and empirically show that optimistic Monte Carlo Tree Search outperforms posterior sampling methods. Second we show how to learn simple deterministic models to support fast learning using object representation. We illustrate the benefit of these ideas by introducing a novel algorithm, Strategic Object Oriented Reinforcement Learning (SOORL), that outperforms state-of-the-art algorithms in the game of Pitfall! in less than 50 episodes.

</details>

<details>

<summary>2018-11-26 04:56:31 - Deep Reinforcement Learning: An Overview</summary>

- *Yuxi Li*

- `1701.07274v6` - [abs](http://arxiv.org/abs/1701.07274v6) - [pdf](http://arxiv.org/pdf/1701.07274v6)

> We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions.   Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant update.

</details>

<details>

<summary>2018-11-26 06:10:01 - Ontology Matching Techniques: A Gold Standard Model</summary>

- *Alok Chauhan, Vijayakumar V, Layth Sliman*

- `1811.10191v1` - [abs](http://arxiv.org/abs/1811.10191v1) - [pdf](http://arxiv.org/pdf/1811.10191v1)

> Typically an ontology matching technique is a combination of much different type of matchers operating at various abstraction levels such as structure, semantic, syntax, instance etc. An ontology matching technique which employs matchers at all possible abstraction levels is expected to give, in general, best results in terms of precision, recall and F-measure due to improvement in matching opportunities and if we discount efficiency issues which may improve with better computing resources such as parallel processing. A gold standard ontology matching model is derived from a model classification of ontology matching techniques. A suitable metric is also defined based on gold standard ontology matching model. A review of various ontology matching techniques specified in recent research papers in the area was undertaken to categorize an ontology matching technique as per newly proposed gold standard model and a metric value for the whole group was computed. The results of the above study support proposed gold standard ontology matching model.

</details>

<details>

<summary>2018-11-26 07:11:59 - Representation based and Attention augmented Meta learning</summary>

- *Yunxiao Qin, Chenxu Zhao, Zezheng Wang, Junliang Xing, Jun Wan, Zhen Lei*

- `1811.07545v3` - [abs](http://arxiv.org/abs/1811.07545v3) - [pdf](http://arxiv.org/pdf/1811.07545v3)

> Deep learning based computer vision fails to work when labeled images are scarce. Recently, Meta learning algorithm has been confirmed as a promising way to improve the ability of learning from few images for computer vision. However, previous Meta learning approaches expose problems:   1) they ignored the importance of attention mechanism for the Meta learner;   2) they didn't give the Meta learner the ability of well using the past knowledge which can help to express images into high representations, resulting in that the Meta learner has to solve few shot learning task directly from the original high dimensional RGB images.   In this paper, we argue that the attention mechanism and the past knowledge are crucial for the Meta learner, and the Meta learner should be trained on high representations of the RGB images instead of directly on the original ones. Based on these arguments, we propose two methods: Attention augmented Meta Learning (AML) and Representation based and Attention augmented Meta Learning(RAML). The method AML aims to improve the Meta learner's attention ability by explicitly embedding an attention model into its network. The method RAML aims to give the Meta learner the ability of leveraging the past learned knowledge to reduce the dimension of the original input data by expressing it into high representations, and help the Meta learner to perform well. Extensive experiments demonstrate the effectiveness of the proposed models, with state-of-the-art few shot learning performances on several few shot learning benchmarks. The source code of our proposed methods will be released soon to facilitate further studies on those aforementioned problem.

</details>

<details>

<summary>2018-11-26 08:28:21 - Augmenting Robot Knowledge Consultants with Distributed Short Term Memory</summary>

- *Tom Williams, Ravenna Thielstrom, Evan Krause, Bradley Oosterveld, Matthias Scheutz*

- `1811.10229v1` - [abs](http://arxiv.org/abs/1811.10229v1) - [pdf](http://arxiv.org/pdf/1811.10229v1)

> Human-robot communication in situated environments involves a complex interplay between knowledge representations across a wide variety of modalities. Crucially, linguistic information must be associated with representations of objects, locations, people, and goals, which may be represented in very different ways. In previous work, we developed a Consultant Framework that facilitates modality-agnostic access to information distributed across a set of heterogeneously represented knowledge sources. In this work, we draw inspiration from cognitive science to augment these distributed knowledge sources with Short Term Memory Buffers to create an STM-augmented algorithm for referring expression generation. We then discuss the potential performance benefits of this approach and insights from cognitive science that may inform future refinements in the design of our approach.

</details>

<details>

<summary>2018-11-26 10:55:58 - Incremental learning abstract discrete planning domains and mappings to continuous perceptions</summary>

- *Luciano Serafini, Paolo Traverso*

- `1810.07096v2` - [abs](http://arxiv.org/abs/1810.07096v2) - [pdf](http://arxiv.org/pdf/1810.07096v2)

> Most of the works on planning and learning, e.g., planning by (model based) reinforcement learning, are based on two main assumptions: (i) the set of states of the planning domain is fixed; (ii) the mapping between the observations from the real word and the states is implicitly assumed or learned offline, and it is not part of the planning domain. Consequently, the focus is on learning the transitions between states. In this paper, we drop such assumptions. We provide a formal framework in which (i) the agent can learn dynamically new states of the planning domain; (ii) the mapping between abstract states and the perception from the real world, represented by continuous variables, is part of the planning domain; (iii) such mapping is learned and updated along the "life" of the agent. We define an algorithm that interleaves planning, acting, and learning, and allows the agent to update the planning domain depending on how much it trusts the model w.r.t. the new experiences learned by executing actions. We define a measure of coherence between the planning domain and the real world as perceived by the agent. We test our approach showing that the agent learns increasingly coherent models, and that the system can scale to deal with models with an order of $10^6$ states.

</details>

<details>

<summary>2018-11-26 12:14:14 - Machine Learning Classifications of Coronary Artery Disease</summary>

- *Ali Bou Nassif, Omar Mahdi, Qassim Nasir, Manar Abu Talib, Mohammad Azzeh*

- `1812.02828v1` - [abs](http://arxiv.org/abs/1812.02828v1) - [pdf](http://arxiv.org/pdf/1812.02828v1)

> Coronary Artery Disease (CAD) is one of the leading causes of death worldwide, and so it is very important to correctly diagnose patients with the disease. For medical diagnosis, machine learning is a useful tool, however features and algorithms must be carefully selected to get accurate classification. To this effect, three feature selection methods have been used on 13 input features from the Cleveland dataset with 297 entries, and 7 were selected. The selected features were used to train three different classifiers, which are SVM, Na\"ive Bayes and KNN using 10-fold cross-validation. The resulting models evaluated using Accuracy, Recall, Specificity and Precision. It is found that the Na\"ive Bayes classifier performs the best on this dataset and features, outperforming or matching SVM and KNN in all the four evaluation parameters used and achieving an accuracy of 84%.

</details>

<details>

<summary>2018-11-26 13:10:42 - Estimating Causal Effects With Partial Covariates For Clinical Interpretability</summary>

- *Sonali Parbhoo, Mario Wieser, Volker Roth*

- `1811.10347v1` - [abs](http://arxiv.org/abs/1811.10347v1) - [pdf](http://arxiv.org/pdf/1811.10347v1)

> Estimating the causal effects of an intervention in the presence of confounding is a frequently occurring problem in applications such as medicine. The task is challenging since there may be multiple confounding factors, some of which may be missing, and inferences must be made from high-dimensional, noisy measurements. In this paper, we propose a decision-theoretic approach to estimate the causal effects of interventions where a subset of the covariates is unavailable for some patients during testing. Our approach uses the information bottleneck principle to perform a discrete, low-dimensional sufficient reduction of the covariate data to estimate a distribution over confounders. In doing so, we can estimate the causal effect of an intervention where only partial covariate information is available. Our results on a causal inference benchmark and a real application for treating sepsis show that our method achieves state-of-the-art performance, without sacrificing interpretability.

</details>

<details>

<summary>2018-11-26 13:14:36 - Learning and Generalizing Motion Primitives from Driving Data for Path-Tracking Applications</summary>

- *Boyang Wang, Zirui Li, Jianwei Gong, Yidi Liu, Huiyan Chen, Chao Lu*

- `1806.00711v2` - [abs](http://arxiv.org/abs/1806.00711v2) - [pdf](http://arxiv.org/pdf/1806.00711v2)

> Considering the driving habits which are learned from the naturalistic driving data in the path-tracking system can significantly improve the acceptance of intelligent vehicles. Therefore, the goal of this paper is to generate the prediction results of lateral commands with confidence regions according to the reference based on the learned motion primitives. We present a two-level structure for learning and generalizing motion primitives through demonstrations. The lower-level motion primitives are generated under the path segmentation and clustering layer in the upper-level. The Gaussian Mixture Model(GMM) is utilized to represent the primitives and Gaussian Mixture Regression (GMR) is selected to generalize the motion primitives. We show how the upper-level can help to improve the prediction accuracy and evaluate the influence of different time scales and the number of Gaussian components. The model is trained and validated by using the driving data collected from the Beijing Institute of Technology (BIT) intelligent vehicle platform. Experiment results show that the proposed method can extract the motion primitives from the driving data and predict the future lateral control commands with high accuracy.

</details>

<details>

<summary>2018-11-26 13:22:17 - Unsupervised learning with sparse space-and-time autoencoders</summary>

- *Benjamin Graham*

- `1811.10355v1` - [abs](http://arxiv.org/abs/1811.10355v1) - [pdf](http://arxiv.org/pdf/1811.10355v1)

> We use spatially-sparse two, three and four dimensional convolutional autoencoder networks to model sparse structures in 2D space, 3D space, and 3+1=4 dimensional space-time. We evaluate the resulting latent spaces by testing their usefulness for downstream tasks. Applications are to handwriting recognition in 2D, segmentation for parts in 3D objects, segmentation for objects in 3D scenes, and body-part segmentation for 4D wire-frame models generated from motion capture data.

</details>

<details>

<summary>2018-11-26 13:41:03 - The Architecture of Mr. DLib's Scientific Recommender-System API</summary>

- *Joeran Beel, Andrew Collins, Akiko Aizawa*

- `1811.10364v1` - [abs](http://arxiv.org/abs/1811.10364v1) - [pdf](http://arxiv.org/pdf/1811.10364v1)

> Recommender systems in academia are not widely available. This may be in part due to the difficulty and cost of developing and maintaining recommender systems. Many operators of academic products such as digital libraries and reference managers avoid this effort, although a recommender system could provide significant benefits to their users. In this paper, we introduce Mr. DLib's "Recommendations as-a-Service" (RaaS) API that allows operators of academic products to easily integrate a scientific recommender system into their products. Mr. DLib generates recommendations for research articles but in the future, recommendations may include call for papers, grants, etc. Operators of academic products can request recommendations from Mr. DLib and display these recommendations to their users. Mr. DLib can be integrated in just a few hours or days; creating an equivalent recommender system from scratch would require several months for an academic operator. Mr. DLib has been used by GESIS Sowiport and by the reference manager JabRef. Mr. DLib is open source and its goal is to facilitate the application of, and research on, scientific recommender systems. In this paper, we present the motivation for Mr. DLib, the architecture and details about the effectiveness. Mr. DLib has delivered 94m recommendations over a span of two years with an average click-through rate of 0.12%.

</details>

<details>

<summary>2018-11-26 13:56:57 - ParsRec: A Novel Meta-Learning Approach to Recommending Bibliographic Reference Parsers</summary>

- *Dominika Tkaczyk, Rohit Gupta, Riccardo Cinti, Joeran Beel*

- `1811.10369v1` - [abs](http://arxiv.org/abs/1811.10369v1) - [pdf](http://arxiv.org/pdf/1811.10369v1)

> Bibliographic reference parsers extract machine-readable metadata such as author names, title, journal, and year from bibliographic reference strings. To extract the metadata, the parsers apply heuristics or machine learning. However, no reference parser, and no algorithm, consistently gives the best results in every scenario. For instance, one tool may be best in extracting titles in ACM citation style, but only third best when APA is used. Another tool may be best in extracting English author names, while another one is best for noisy data (i.e. inconsistent citation styles). In this paper, which is an extended version of our recent RecSys poster, we address the problem of reference parsing from a recommender-systems and meta-learning perspective. We propose ParsRec, a meta-learning based recommender-system that recommends the potentially most effective parser for a given reference string. ParsRec recommends one out of 10 open-source parsers: Anystyle-Parser, Biblio, CERMINE, Citation, Citation-Parser, GROBID, ParsCit, PDFSSA4MET, Reference Tagger, and Science Parse. We evaluate ParsRec on 105k references from chemistry. We propose two approaches to meta-learning recommendations. The first approach learns the best parser for an entire reference string. The second approach learns the best parser for each metadata type in a reference string. The second approach achieved a 2.6% increase in F1 (0.909 vs. 0.886) over the best single parser (GROBID), reducing the false positive rate by 20.2% (0.075 vs. 0.094), and the false negative rate by 18.9% (0.107 vs. 0.132).

</details>

<details>

<summary>2018-11-26 15:35:57 - A Framework for Implementing Machine Learning on Omics Data</summary>

- *Geoffroy Dubourg-Felonneau, Timothy Cannings, Fergal Cotter, Hannah Thompson, Nirmesh Patel, John W Cassidy, Harry W Clifford*

- `1811.10455v1` - [abs](http://arxiv.org/abs/1811.10455v1) - [pdf](http://arxiv.org/pdf/1811.10455v1)

> The potential benefits of applying machine learning methods to -omics data are becoming increasingly apparent, especially in clinical settings. However, the unique characteristics of these data are not always well suited to machine learning techniques. These data are often generated across different technologies in different labs, and frequently with high dimensionality. In this paper we present a framework for combining -omics data sets, and for handling high dimensional data, making -omics research more accessible to machine learning applications. We demonstrate the success of this framework through integration and analysis of multi-analyte data for a set of 3,533 breast cancers. We then use this data-set to predict breast cancer patient survival for individuals at risk of an impending event, with higher accuracy and lower variance than methods trained on individual data-sets. We hope that our pipelines for data-set generation and transformation will open up -omics data to machine learning researchers. We have made these freely available for noncommercial use at www.ccg.ai.

</details>

<details>

<summary>2018-11-26 16:07:36 - Sentence Encoding with Tree-constrained Relation Networks</summary>

- *Lei Yu, Cyprien de Masson d'Autume, Chris Dyer, Phil Blunsom, Lingpeng Kong, Wang Ling*

- `1811.10475v1` - [abs](http://arxiv.org/abs/1811.10475v1) - [pdf](http://arxiv.org/pdf/1811.10475v1)

> The meaning of a sentence is a function of the relations that hold between its words. We instantiate this relational view of semantics in a series of neural models based on variants of relation networks (RNs) which represent a set of objects (for us, words forming a sentence) in terms of representations of pairs of objects. We propose two extensions to the basic RN model for natural language. First, building on the intuition that not all word pairs are equally informative about the meaning of a sentence, we use constraints based on both supervised and unsupervised dependency syntax to control which relations influence the representation. Second, since higher-order relations are poorly captured by a sum of pairwise relations, we use a recurrent extension of RNs to propagate information so as to form representations of higher order relations. Experiments on sentence classification, sentence pair classification, and machine translation reveal that, while basic RNs are only modestly effective for sentence representation, recurrent RNs with latent syntax are a reliably powerful representational device.

</details>

<details>

<summary>2018-11-26 17:53:17 - Challenges in the Automatic Analysis of Students' Diagnostic Reasoning</summary>

- *Claudia Schulz, Christian M. Meyer, Michael Sailer, Jan Kiesewetter, Elisabeth Bauer, Frank Fischer, Martin R. Fischer, Iryna Gurevych*

- `1811.10550v1` - [abs](http://arxiv.org/abs/1811.10550v1) - [pdf](http://arxiv.org/pdf/1811.10550v1)

> Diagnostic reasoning is a key component of many professions. To improve students' diagnostic reasoning skills, educational psychologists analyse and give feedback on epistemic activities used by these students while diagnosing, in particular, hypothesis generation, evidence generation, evidence evaluation, and drawing conclusions. However, this manual analysis is highly time-consuming. We aim to enable the large-scale adoption of diagnostic reasoning analysis and feedback by automating the epistemic activity identification. We create the first corpus for this task, comprising diagnostic reasoning self-explanations of students from two domains annotated with epistemic activities. Based on insights from the corpus creation and the task's characteristics, we discuss three challenges for the automatic identification of epistemic activities using AI methods: the correct identification of epistemic activity spans, the reliable distinction of similar epistemic activities, and the detection of overlapping epistemic activities. We propose a separate performance metric for each challenge and thus provide an evaluation framework for future research. Indeed, our evaluation of various state-of-the-art recurrent neural network architectures reveals that current techniques fail to address some of these challenges.

</details>

<details>

<summary>2018-11-26 19:27:26 - Abduction-Based Explanations for Machine Learning Models</summary>

- *Alexey Ignatiev, Nina Narodytska, Joao Marques-Silva*

- `1811.10656v1` - [abs](http://arxiv.org/abs/1811.10656v1) - [pdf](http://arxiv.org/pdf/1811.10656v1)

> The growing range of applications of Machine Learning (ML) in a multitude of settings motivates the ability of computing small explanations for predictions made. Small explanations are generally accepted as easier for human decision makers to understand. Most earlier work on computing explanations is based on heuristic approaches, providing no guarantees of quality, in terms of how close such solutions are from cardinality- or subset-minimal explanations. This paper develops a constraint-agnostic solution for computing explanations for any ML model. The proposed solution exploits abductive reasoning, and imposes the requirement that the ML model can be represented as sets of constraints using some target constraint reasoning system for which the decision problem can be answered with some oracle. The experimental results, obtained on well-known datasets, validate the scalability of the proposed approach as well as the quality of the computed solutions.

</details>

<details>

<summary>2018-11-26 19:51:27 - Stepping Stones to Inductive Synthesis of Low-Level Looping Programs</summary>

- *Christopher D. Rosin*

- `1811.10665v1` - [abs](http://arxiv.org/abs/1811.10665v1) - [pdf](http://arxiv.org/pdf/1811.10665v1)

> Inductive program synthesis, from input/output examples, can provide an opportunity to automatically create programs from scratch without presupposing the algorithmic form of the solution. For induction of general programs with loops (as opposed to loop-free programs, or synthesis for domain-specific languages), the state of the art is at the level of introductory programming assignments. Most problems that require algorithmic subtlety, such as fast sorting, have remained out of reach without the benefit of significant problem-specific background knowledge. A key challenge is to identify cues that are available to guide search towards correct looping programs. We present MAKESPEARE, a simple delayed-acceptance hillclimbing method that synthesizes low-level looping programs from input/output examples. During search, delayed acceptance bypasses small gains to identify significantly-improved stepping stone programs that tend to generalize and enable further progress. The method performs well on a set of established benchmarks, and succeeds on the previously unsolved "Collatz Numbers" program synthesis problem. Additional benchmarks include the problem of rapidly sorting integer arrays, in which we observe the emergence of comb sort (a Shell sort variant that is empirically fast). MAKESPEARE has also synthesized a record-setting program on one of the puzzles from the TIS-100 assembly language programming game.

</details>

<details>

<summary>2018-11-26 20:11:30 - AI Fairness for People with Disabilities: Point of View</summary>

- *Shari Trewin*

- `1811.10670v1` - [abs](http://arxiv.org/abs/1811.10670v1) - [pdf](http://arxiv.org/pdf/1811.10670v1)

> We consider how fair treatment in society for people with disabilities might be impacted by the rise in the use of artificial intelligence, and especially machine learning methods. We argue that fairness for people with disabilities is different to fairness for other protected attributes such as age, gender or race. One major difference is the extreme diversity of ways disabilities manifest, and people adapt. Secondly, disability information is highly sensitive and not always shared, precisely because of the potential for discrimination. Given these differences, we explore definitions of fairness and how well they work in the disability space. Finally, we suggest ways of approaching fairness for people with disabilities in AI applications.

</details>

<details>

<summary>2018-11-26 21:09:20 - What Should I Learn First: Introducing LectureBank for NLP Education and Prerequisite Chain Learning</summary>

- *Irene Li, Alexander R. Fabbri, Robert R. Tung, Dragomir R. Radev*

- `1811.12181v1` - [abs](http://arxiv.org/abs/1811.12181v1) - [pdf](http://arxiv.org/pdf/1811.12181v1)

> Recent years have witnessed the rising popularity of Natural Language Processing (NLP) and related fields such as Artificial Intelligence (AI) and Machine Learning (ML). Many online courses and resources are available even for those without a strong background in the field. Often the student is curious about a specific topic but does not quite know where to begin studying. To answer the question of "what should one learn first," we apply an embedding-based method to learn prerequisite relations for course concepts in the domain of NLP. We introduce LectureBank, a dataset containing 1,352 English lecture files collected from university courses which are each classified according to an existing taxonomy as well as 208 manually-labeled prerequisite relation topics, which is publicly available. The dataset will be useful for educational purposes such as lecture preparation and organization as well as applications such as reading list generation. Additionally, we experiment with neural graph-based networks and non-neural classifiers to learn these prerequisite relations from our dataset.

</details>

<details>

<summary>2018-11-26 22:56:07 - Optimization of Information-Seeking Dialogue Strategy for Argumentation-Based Dialogue System</summary>

- *Hisao Katsumi, Takuya Hiraoka, Koichiro Yoshino, Kazeto Yamamoto, Shota Motoura, Kunihiko Sadamasa, Satoshi Nakamura*

- `1811.10728v1` - [abs](http://arxiv.org/abs/1811.10728v1) - [pdf](http://arxiv.org/pdf/1811.10728v1)

> Argumentation-based dialogue systems, which can handle and exchange arguments through dialogue, have been widely researched. It is required that these systems have sufficient supporting information to argue their claims rationally; however, the systems often do not have enough of such information in realistic situations. One way to fill in the gap is acquiring such missing information from dialogue partners (information-seeking dialogue). Existing information-seeking dialogue systems are based on handcrafted dialogue strategies that exhaustively examine missing information. However, the proposed strategies are not specialized in collecting information for constructing rational arguments. Moreover, the number of system's inquiry candidates grows in accordance with the size of the argument set that the system deal with. In this paper, we formalize the process of information-seeking dialogue as Markov decision processes (MDPs) and apply deep reinforcement learning (DRL) for automatically optimizing a dialogue strategy. By utilizing DRL, our dialogue strategy can successfully minimize objective functions, the number of turns it takes for our system to collect necessary information in a dialogue. We conducted dialogue experiments using two datasets from different domains of argumentative dialogue. Experimental results show that the proposed formalization based on MDP works well, and the policy optimized by DRL outperformed existing heuristic dialogue strategies.

</details>

<details>

<summary>2018-11-26 23:05:38 - DynamicGEM: A Library for Dynamic Graph Embedding Methods</summary>

- *Palash Goyal, Sujit Rokka Chhetri, Ninareh Mehrabi, Emilio Ferrara, Arquimedes Canedo*

- `1811.10734v1` - [abs](http://arxiv.org/abs/1811.10734v1) - [pdf](http://arxiv.org/pdf/1811.10734v1)

> DynamicGEM is an open-source Python library for learning node representations of dynamic graphs. It consists of state-of-the-art algorithms for defining embeddings of nodes whose connections evolve over time. The library also contains the evaluation framework for four downstream tasks on the network: graph reconstruction, static and temporal link prediction, node classification, and temporal visualization. We have implemented various metrics to evaluate the state-of-the-art methods, and examples of evolving networks from various domains. We have easy-to-use functions to call and evaluate the methods and have extensive usage documentation. Furthermore, DynamicGEM provides a template to add new algorithms with ease to facilitate further research on the topic.

</details>

<details>

<summary>2018-11-26 23:19:43 - GANtruth - an unpaired image-to-image translation method for driving scenarios</summary>

- *Sebastian Bujwid, Miquel Martí, Hossein Azizpour, Alessandro Pieropan*

- `1812.01710v1` - [abs](http://arxiv.org/abs/1812.01710v1) - [pdf](http://arxiv.org/pdf/1812.01710v1)

> Synthetic image translation has significant potentials in autonomous transportation systems. That is due to the expense of data collection and annotation as well as the unmanageable diversity of real-words situations. The main issue with unpaired image-to-image translation is the ill-posed nature of the problem. In this work, we propose a novel method for constraining the output space of unpaired image-to-image translation. We make the assumption that the environment of the source domain is known (e.g. synthetically generated), and we propose to explicitly enforce preservation of the ground-truth labels on the translated images.   We experiment on preserving ground-truth information such as semantic segmentation, disparity, and instance segmentation. We show significant evidence that our method achieves improved performance over the state-of-the-art model of UNIT for translating images from SYNTHIA to Cityscapes. The generated images are perceived as more realistic in human surveys and outperforms UNIT when used in a domain adaptation scenario for semantic segmentation.

</details>

<details>

<summary>2018-11-26 23:26:36 - Can Artificial Intelligence Do Everything That We Can?</summary>

- *Vincent Conitzer*

- `1812.02560v1` - [abs](http://arxiv.org/abs/1812.02560v1) - [pdf](http://arxiv.org/pdf/1812.02560v1)

> In this article, I discuss what AI can and cannot yet do, and the implications for humanity.

</details>

<details>

<summary>2018-11-27 00:45:31 - Towards Long-Term Memory for Social Robots: Proposing a New Challenge for the RoboCup@Home League</summary>

- *Matías Pavez, Javier Ruiz del Solar, Victoria Amo, Felix Meyer zu Driehausen*

- `1811.10758v1` - [abs](http://arxiv.org/abs/1811.10758v1) - [pdf](http://arxiv.org/pdf/1811.10758v1)

> Long-term memory is essential to feel like a continuous being, and to be able to interact/communicate coherently. Social robots need long-term memories in order to establish long-term relationships with humans and other robots, and do not act just for the moment. In this paper this challenge is highlighted, open questions are identified, the need of addressing this challenge in the RoboCup@Home League with new tests is motivated, and a new test is proposed.

</details>

<details>

<summary>2018-11-27 01:39:36 - Enter the Matrix: Safely Interruptible Autonomous Systems via Virtualization</summary>

- *Mark O. Riedl, Brent Harrison*

- `1703.10284v2` - [abs](http://arxiv.org/abs/1703.10284v2) - [pdf](http://arxiv.org/pdf/1703.10284v2)

> Autonomous systems that operate around humans will likely always rely on kill switches that stop their execution and allow them to be remote-controlled for the safety of humans or to prevent damage to the system. It is theoretically possible for an autonomous system with sufficient sensor and effector capability that learn online using reinforcement learning to discover that the kill switch deprives it of long-term reward and thus learn to disable the switch or otherwise prevent a human operator from using the switch. This is referred to as the big red button problem. We present a technique that prevents a reinforcement learning agent from learning to disable the kill switch. We introduce an interruption process in which the agent's sensors and effectors are redirected to a virtual simulation where it continues to believe it is receiving reward. We illustrate our technique in a simple grid world environment.

</details>

<details>

<summary>2018-11-27 06:58:59 - Robust Artificial Intelligence and Robust Human Organizations</summary>

- *Thomas G. Dietterich*

- `1811.10840v1` - [abs](http://arxiv.org/abs/1811.10840v1) - [pdf](http://arxiv.org/pdf/1811.10840v1)

> Every AI system is deployed by a human organization. In high risk applications, the combined human plus AI system must function as a high-reliability organization in order to avoid catastrophic errors. This short note reviews the properties of high-reliability organizations and draws implications for the development of AI technology and the safe application of that technology.

</details>

<details>

<summary>2018-11-27 08:27:49 - Sapiens Chain: A Blockchain-based Cybersecurity Framework</summary>

- *Yu Han, Zhongru Wang, Qiang Ruan, Binxing Fang*

- `1811.10868v1` - [abs](http://arxiv.org/abs/1811.10868v1) - [pdf](http://arxiv.org/pdf/1811.10868v1)

> Recently, cybersecurity becomes more and more important due to the rapid development of Internet. However, existing methods are in reality highly sensitive to attacks and are far more vulnerable than expected, as they are lack of trustable measures. In this paper, to address the aforementioned problems, we propose a blockchain-based cybersecurity framework, termed as Sapiens Chain, which can protect the privacy of the anonymous users and ensure that the transactions are immutable by providing decentralized and trustable services. Integrating semantic analysis, symbolic execution, and routing learning methods into intelligent auditing, this framework can achieve good accuracy for detecting hidden vulnerabilities. In addition, a revenue incentive mechanism, which aims to donate participants, is built. The practical results demonstrate the effectiveness of the proposed framework.

</details>

<details>

<summary>2018-11-27 09:21:17 - A Deeper Insight into the UnDEMoN: Unsupervised Deep Network for Depth and Ego-Motion Estimation</summary>

- *Madhu Babu V, Anima Majumder, Kaushik Das, Swagat Kumar*

- `1809.00969v3` - [abs](http://arxiv.org/abs/1809.00969v3) - [pdf](http://arxiv.org/pdf/1809.00969v3)

> This paper presents an unsupervised deep learning framework called UnDEMoN for estimating dense depth map and 6-DoF camera pose information directly from monocular images. The proposed network is trained using unlabeled monocular stereo image pairs and is shown to provide superior performance in depth and ego-motion estimation compared to the existing state-of-the-art. These improvements are achieved by introducing a new objective function that aims to minimize spatial as well as temporal reconstruction losses simultaneously. These losses are defined using bi-linear sampling kernel and penalized using the Charbonnier penalty function. The objective function, thus created, provides robustness to image gradient noises thereby improving the overall estimation accuracy without resorting to any coarse to fine strategies which are currently prevalent in the literature. Another novelty lies in the fact that we combine a disparity-based depth estimation network with a pose estimation network to obtain absolute scale-aware 6 DOF Camera pose and superior depth map. The effectiveness of the proposed approach is demonstrated through performance comparison with the existing supervised and unsupervised methods on the KITTI driving dataset.

</details>

<details>

<summary>2018-11-27 10:22:09 - Making Agents' Abilities Explicit</summary>

- *Yedi Zhang, Fu Song, Taolue Chen*

- `1811.10901v1` - [abs](http://arxiv.org/abs/1811.10901v1) - [pdf](http://arxiv.org/pdf/1811.10901v1)

> Alternating-time temporal logics (ATL/ATL*) represent a family of modal logics for reasoning about agents' strategic abilities in multiagent systems (MAS). The interpretations of ATL/ATL* over the semantic model Concurrent Game Structures (CGS) usually vary depending on the agents' abilities, for instance, perfect vs. imperfect information, perfect vs. imperfect recall, resulting in a variety of variants which have been studied extensively in literature. However, they are defined at the semantic level, which may limit modeling flexibilities and may give counter-intuitive interpretations. To mitigate these issues, in this work, we propose to extend CGS with agents' abilities and study the new semantics of ATL/ATL* under this model. We give PSACE/2EXPTIME model-checking algorithms for ATL/ATL* and implement them as a prototype tool. Experiment results show the practical feasibility of the approach.

</details>

<details>

<summary>2018-11-27 15:48:27 - Combining Deep Learning and Qualitative Spatial Reasoning to Learn Complex Structures from Sparse Examples with Noise</summary>

- *Nikhil Krishnaswamy, Scott Friedman, James Pustejovsky*

- `1811.11064v1` - [abs](http://arxiv.org/abs/1811.11064v1) - [pdf](http://arxiv.org/pdf/1811.11064v1)

> Many modern machine learning approaches require vast amounts of training data to learn new concepts; conversely, human learning often requires few examples--sometimes only one--from which the learner can abstract structural concepts. We present a novel approach to introducing new spatial structures to an AI agent, combining deep learning over qualitative spatial relations with various heuristic search algorithms. The agent extracts spatial relations from a sparse set of noisy examples of block-based structures, and trains convolutional and sequential models of those relation sets. To create novel examples of similar structures, the agent begins placing blocks on a virtual table, uses a CNN to predict the most similar complete example structure after each placement, an LSTM to predict the most likely set of remaining moves needed to complete it, and recommends one using heuristic search. We verify that the agent learned the concept by observing its virtual block-building activities, wherein it ranks each potential subsequent action toward building its learned concept. We empirically assess this approach with human participants' ratings of the block structures. Initial results and qualitative evaluations of structures generated by the trained agent show where it has generalized concepts from the training data, which heuristics perform best within the search space, and how we might improve learning and execution.

</details>

<details>

<summary>2018-11-27 16:46:19 - Efficient Anomaly Detection via Matrix Sketching</summary>

- *Vatsal Sharan, Parikshit Gopalan, Udi Wieder*

- `1804.03065v2` - [abs](http://arxiv.org/abs/1804.03065v2) - [pdf](http://arxiv.org/pdf/1804.03065v2)

> We consider the problem of finding anomalies in high-dimensional data using popular PCA based anomaly scores. The naive algorithms for computing these scores explicitly compute the PCA of the covariance matrix which uses space quadratic in the dimensionality of the data. We give the first streaming algorithms that use space that is linear or sublinear in the dimension. We prove general results showing that \emph{any} sketch of a matrix that satisfies a certain operator norm guarantee can be used to approximate these scores. We instantiate these results with powerful matrix sketching techniques such as Frequent Directions and random projections to derive efficient and practical algorithms for these problems, which we validate over real-world data sets. Our main technical contribution is to prove matrix perturbation inequalities for operators arising in the computation of these measures.

</details>

<details>

<summary>2018-11-27 19:00:07 - Semantically-aware population health risk analyses</summary>

- *Alexander New, Sabbir M. Rashid, John S. Erickson, Deborah L. McGuinness, Kristin P. Bennett*

- `1811.11190v1` - [abs](http://arxiv.org/abs/1811.11190v1) - [pdf](http://arxiv.org/pdf/1811.11190v1)

> One primary task of population health analysis is the identification of risk factors that, for some subpopulation, have a significant association with some health condition. Examples include finding lifestyle factors associated with chronic diseases and finding genetic mutations associated with diseases in precision health. We develop a combined semantic and machine learning system that uses a health risk ontology and knowledge graph (KG) to dynamically discover risk factors and their associated subpopulations. Semantics and the novel supervised cadre model make our system explainable. Future population health studies are easily performed and documented with provenance by specifying additional input and output KG cartridges.

</details>

<details>

<summary>2018-11-27 19:02:35 - A Survey of Mobile Computing for the Visually Impaired</summary>

- *Martin Weiss, Margaux Luck, Roger Girgis, Chris Pal, Joseph Paul Cohen*

- `1811.10120v2` - [abs](http://arxiv.org/abs/1811.10120v2) - [pdf](http://arxiv.org/pdf/1811.10120v2)

> The number of visually impaired or blind (VIB) people in the world is estimated at several hundred million. Based on a series of interviews with the VIB and developers of assistive technology, this paper provides a survey of machine-learning based mobile applications and identifies the most relevant applications. We discuss the functionality of these apps, how they align with the needs and requirements of the VIB users, and how they can be improved with techniques such as federated learning and model compression. As a result of this study we identify promising future directions of research in mobile perception, micro-navigation, and content-summarization.

</details>

<details>

<summary>2018-11-27 19:16:00 - Partitioned Variational Inference: A unified framework encompassing federated and continual learning</summary>

- *Thang D. Bui, Cuong V. Nguyen, Siddharth Swaroop, Richard E. Turner*

- `1811.11206v1` - [abs](http://arxiv.org/abs/1811.11206v1) - [pdf](http://arxiv.org/pdf/1811.11206v1)

> Variational inference (VI) has become the method of choice for fitting many modern probabilistic models. However, practitioners are faced with a fragmented literature that offers a bewildering array of algorithmic options. First, the variational family. Second, the granularity of the updates e.g. whether the updates are local to each data point and employ message passing or global. Third, the method of optimization (bespoke or blackbox, closed-form or stochastic updates, etc.). This paper presents a new framework, termed Partitioned Variational Inference (PVI), that explicitly acknowledges these algorithmic dimensions of VI, unifies disparate literature, and provides guidance on usage. Crucially, the proposed PVI framework allows us to identify new ways of performing VI that are ideally suited to challenging learning scenarios including federated learning (where distributed computing is leveraged to process non-centralized data) and continual learning (where new data and tasks arrive over time and must be accommodated quickly). We showcase these new capabilities by developing communication-efficient federated training of Bayesian neural networks and continual learning for Gaussian process models with private pseudo-points. The new methods significantly outperform the state-of-the-art, whilst being almost as straightforward to implement as standard VI.

</details>

<details>

<summary>2018-11-27 19:20:35 - AI Matrix - Synthetic Benchmarks for DNN</summary>

- *Wei Wei, Lingjie Xu, Lingling Jin, Wei Zhang, Tianjun Zhang*

- `1812.00886v1` - [abs](http://arxiv.org/abs/1812.00886v1) - [pdf](http://arxiv.org/pdf/1812.00886v1)

> Deep neural network (DNN) architectures, such as convolutional neural networks (CNN), involve heavy computation and require hardware, such as CPU, GPU, and AI accelerators, to provide the massive computing power. With the many varieties of AI hardware prevailing on the market, it is often hard to decide which one is the best to use. Thus, benchmarking AI hardware effectively becomes important and is of great help to select and optimize AI hardware. Unfortunately, there are few AI benchmarks available in both academia and industry. Examples are BenchNN[1], DeepBench[2], and Dawn Bench[3], which are usually a collection of typical real DNN applications. While these benchmarks provide performance comparison across different AI hardware, they suffer from a number of drawbacks. First, they cannot adapt to the emerging changes of DNN algorithms and are fixed once selected. Second, they contain tens to hundreds of applications and take very long time to finish running. Third, they are mainly selected from open sources, which are restricted by copyright and are not representable to proprietary applications. In this work, a synthetic benchmarks framework is firstly proposed to address the above drawbacks of AI benchmarks. Instead of pre-selecting a set of open-sourced benchmarks and running all of them, the synthetic approach generates only a one or few benchmarks that best represent a broad range of applications using profiled workload characteristics data of these applications. Thus, it can adapt to emerging changes of new DNN algorithms by re-profiling new applications and updating itself, greatly reduce benchmark count and running time, and strongly represent DNN applications of interests. The generated benchmarks are called AI Matrix, serving as a performance benchmarks matching the statistical workload characteristics of a combination of applications of interests.

</details>

<details>

<summary>2018-11-27 20:08:28 - Distributed traffic light control at uncoupled intersections with real-world topology by deep reinforcement learning</summary>

- *Mark Schutera, Niklas Goby, Stefan Smolarek, Markus Reischl*

- `1811.11233v1` - [abs](http://arxiv.org/abs/1811.11233v1) - [pdf](http://arxiv.org/pdf/1811.11233v1)

> This work examines the implications of uncoupled intersections with local real-world topology and sensor setup on traffic light control approaches. Control approaches are evaluated with respect to: Traffic flow, fuel consumption and noise emission at intersections.   The real-world road network of Friedrichshafen is depicted, preprocessed and the present traffic light controlled intersections are modeled with respect to state space and action space.   Different strategies, containing fixed-time, gap-based and time-based control approaches as well as our deep reinforcement learning based control approach, are implemented and assessed. Our novel DRL approach allows for modeling the TLC action space, with respect to phase selection as well as selection of transition timings. It was found that real-world topologies, and thus irregularly arranged intersections have an influence on the performance of traffic light control approaches. This is even to be observed within the same intersection types (n-arm, m-phases). Moreover we could show, that these influences can be efficiently dealt with by our deep reinforcement learning based control approach.

</details>

<details>

<summary>2018-11-27 20:30:36 - DeepPos: Deep Supervised Autoencoder Network for CSI Based Indoor Localization</summary>

- *Peyman Yazdanian, Vahid Pourahmadi*

- `1811.12182v1` - [abs](http://arxiv.org/abs/1811.12182v1) - [pdf](http://arxiv.org/pdf/1811.12182v1)

> The widespread mobile devices facilitated the emergence of many new applications and services. Among them are location-based services (LBS) that provide services based on user's location. Several techniques have been presented to enable LBS even in indoor environments where Global Positioning System (GPS) has low localization accuracy. These methods use some environment measurements (like Channel State Information (CSI) or Received Signal Strength (RSS)) for user localization. In this paper, we will use CSI and a novel deep learning algorithm to design a robust and efficient system for indoor localization. More precisely, we use supervised autoencoder (SAE) to model the environment using the data collected during the training phase. Then, during the testing phase, we use the trained model and estimate the coordinates of the unknown point by checking different possible labels. Unlike the previous fingerprinting approaches, in this work, we do not store the {CSI/RSS} of fingerprints and instead we model the environment only with a single SAE. The performance of the proposed scheme is then evaluated in two indoor environments and compared with that of similar approaches.

</details>

<details>

<summary>2018-11-27 21:04:24 - Improving Naive Bayes for Regression with Optimised Artificial Surrogate Data</summary>

- *Michael Mayo, Eibe Frank*

- `1707.04943v3` - [abs](http://arxiv.org/abs/1707.04943v3) - [pdf](http://arxiv.org/pdf/1707.04943v3)

> Can we evolve better training data for machine learning algorithms? To investigate this question we use population-based optimisation algorithms to generate artificial surrogate training data for naive Bayes for regression. We demonstrate that the generalisation performance of naive Bayes for regression models is enhanced by training them on the artificial data as opposed to the real data. These results are important for two reasons. Firstly, naive Bayes models are simple and interpretable but frequently underperform compared to more complex "black box" models, and therefore new methods of enhancing accuracy are called for. Secondly, the idea of using the real training data indirectly in the construction of the artificial training data, as opposed to directly for model training, is a novel twist on the usual machine learning paradigm.

</details>

<details>

<summary>2018-11-27 21:05:43 - Scaling Configuration of Energy Harvesting Sensors with Reinforcement Learning</summary>

- *Francesco Fraternali, Bharathan Balaji, Rajesh Gupta*

- `1811.11259v1` - [abs](http://arxiv.org/abs/1811.11259v1) - [pdf](http://arxiv.org/pdf/1811.11259v1)

> With the advent of the Internet of Things (IoT), an increasing number of energy harvesting methods are being used to supplement or supplant battery based sensors. Energy harvesting sensors need to be configured according to the application, hardware, and environmental conditions to maximize their usefulness. As of today, the configuration of sensors is either manual or heuristics based, requiring valuable domain expertise. Reinforcement learning (RL) is a promising approach to automate configuration and efficiently scale IoT deployments, but it is not yet adopted in practice. We propose solutions to bridge this gap: reduce the training phase of RL so that nodes are operational within a short time after deployment and reduce the computational requirements to scale to large deployments. We focus on configuration of the sampling rate of indoor solar panel based energy harvesting sensors. We created a simulator based on 3 months of data collected from 5 sensor nodes subject to different lighting conditions. Our simulation results show that RL can effectively learn energy availability patterns and configure the sampling rate of the sensor nodes to maximize the sensing data while ensuring that energy storage is not depleted. The nodes can be operational within the first day by using our methods. We show that it is possible to reduce the number of RL policies by using a single policy for nodes that share similar lighting conditions.

</details>

<details>

<summary>2018-11-27 21:53:09 - Is it Safe to Drive? An Overview of Factors, Challenges, and Datasets for Driveability Assessment in Autonomous Driving</summary>

- *Junyao Guo, Unmesh Kurup, Mohak Shah*

- `1811.11277v1` - [abs](http://arxiv.org/abs/1811.11277v1) - [pdf](http://arxiv.org/pdf/1811.11277v1)

> With recent advances in learning algorithms and hardware development, autonomous cars have shown promise when operating in structured environments under good driving conditions. However, for complex, cluttered and unseen environments with high uncertainty, autonomous driving systems still frequently demonstrate erroneous or unexpected behaviors, that could lead to catastrophic outcomes. Autonomous vehicles should ideally adapt to driving conditions; while this can be achieved through multiple routes, it would be beneficial as a first step to be able to characterize Driveability in some quantified form. To this end, this paper aims to create a framework for investigating different factors that can impact driveability. Also, one of the main mechanisms to adapt autonomous driving systems to any driving condition is to be able to learn and generalize from representative scenarios. The machine learning algorithms that currently do so learn predominantly in a supervised manner and consequently need sufficient data for robust and efficient learning. Therefore, we also perform a comparative overview of 45 public driving datasets that enable learning and publish this dataset index at https://sites.google.com/view/driveability-survey-datasets. Specifically, we categorize the datasets according to use cases, and highlight the datasets that capture complicated and hazardous driving conditions which can be better used for training robust driving models. Furthermore, by discussions of what driving scenarios are not covered by existing public datasets and what driveability factors need more investigation and data acquisition, this paper aims to encourage both targeted dataset collection and the proposal of novel driveability metrics that enhance the robustness of autonomous cars in adverse environments.

</details>

<details>

<summary>2018-11-27 23:37:19 - Target Driven Visual Navigation with Hybrid Asynchronous Universal Successor Representations</summary>

- *Shamane Siriwardhana, Rivindu Weerasekera, Suranga Nanayakkara*

- `1811.11312v1` - [abs](http://arxiv.org/abs/1811.11312v1) - [pdf](http://arxiv.org/pdf/1811.11312v1)

> Being able to navigate to a target with minimal supervision and prior knowledge is critical to creating human-like assistive agents. Prior work on map-based and map-less approaches have limited generalizability. In this paper, we present a novel approach, Hybrid Asynchronous Universal Successor Representations (HAUSR), which overcomes the problem of generalizability to new goals by adapting recent work on Universal Successor Representations with Asynchronous Actor-Critic Agents. We show that the agent was able to successfully reach novel goals and we were able to quickly fine-tune the network for adapting to new scenes. This opens up novel application scenarios where intelligent agents could learn from and adapt to a wide range of environments with minimal human input.

</details>

<details>

<summary>2018-11-28 00:27:12 - Automated Vulnerability Detection in Source Code Using Deep Representation Learning</summary>

- *Rebecca L. Russell, Louis Kim, Lei H. Hamilton, Tomo Lazovich, Jacob A. Harer, Onur Ozdemir, Paul M. Ellingwood, Marc W. McConley*

- `1807.04320v2` - [abs](http://arxiv.org/abs/1807.04320v2) - [pdf](http://arxiv.org/pdf/1807.04320v2)

> Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a large-scale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. The labeled dataset is available at: https://osf.io/d45bw/. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection.

</details>

<details>

<summary>2018-11-28 01:35:25 - Learning acoustic word embeddings with phonetically associated triplet network</summary>

- *Hyungjun Lim, Younggwan Kim, Youngmoon Jung, Myunghun Jung, Hoirin Kim*

- `1811.02736v3` - [abs](http://arxiv.org/abs/1811.02736v3) - [pdf](http://arxiv.org/pdf/1811.02736v3)

> Previous researches on acoustic word embeddings used in query-by-example spoken term detection have shown remarkable performance improvements when using a triplet network. However, the triplet network is trained using only a limited information about acoustic similarity between words. In this paper, we propose a novel architecture, phonetically associated triplet network (PATN), which aims at increasing discriminative power of acoustic word embeddings by utilizing phonetic information as well as word identity. The proposed model is learned to minimize a combined loss function that was made by introducing a cross entropy loss to the lower layer of LSTM-based triplet network. We observed that the proposed method performs significantly better than the baseline triplet network on a word discrimination task with the WSJ dataset resulting in over 20% relative improvement in recall rate at 1.0 false alarm per hour. Finally, we examined the generalization ability by conducting the out-of-domain test on the RM dataset.

</details>

<details>

<summary>2018-11-28 01:47:49 - A Visual Interaction Framework for Dimensionality Reduction Based Data Exploration</summary>

- *Marco Cavallo, Çağatay Demiralp*

- `1811.12199v1` - [abs](http://arxiv.org/abs/1811.12199v1) - [pdf](http://arxiv.org/pdf/1811.12199v1)

> Dimensionality reduction is a common method for analyzing and visualizing high-dimensional data. However, reasoning dynamically about the results of a dimensionality reduction is difficult. Dimensionality-reduction algorithms use complex optimizations to reduce the number of dimensions of a dataset, but these new dimensions often lack a clear relation to the initial data dimensions, thus making them difficult to interpret. Here we propose a visual interaction framework to improve dimensionality-reduction based exploratory data analysis. We introduce two interaction techniques, forward projection and backward projection, for dynamically reasoning about dimensionally reduced data. We also contribute two visualization techniques, prolines and feasibility maps, to facilitate the effective use of the proposed interactions. We apply our framework to PCA and autoencoder-based dimensionality reductions. Through data-exploration examples, we demonstrate how our visual interactions can improve the use of dimensionality reduction in exploratory data analysis.

</details>

<details>

<summary>2018-11-28 02:35:24 - Unsupervised Control Through Non-Parametric Discriminative Rewards</summary>

- *David Warde-Farley, Tom Van de Wiele, Tejas Kulkarni, Catalin Ionescu, Steven Hansen, Volodymyr Mnih*

- `1811.11359v1` - [abs](http://arxiv.org/abs/1811.11359v1) - [pdf](http://arxiv.org/pdf/1811.11359v1)

> Learning to control an environment without hand-crafted rewards or expert data remains challenging and is at the frontier of reinforcement learning research. We present an unsupervised learning algorithm to train agents to achieve perceptually-specified goals using only a stream of observations and actions. Our agent simultaneously learns a goal-conditioned policy and a goal achievement reward function that measures how similar a state is to the goal state. This dual optimization leads to a co-operative game, giving rise to a learned reward function that reflects similarity in controllable aspects of the environment instead of distance in the space of observations. We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -- Atari, the DeepMind Control Suite and DeepMind Lab.

</details>

<details>

<summary>2018-11-28 02:40:54 - QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation</summary>

- *Dmitry Kalashnikov, Alex Irpan, Peter Pastor, Julian Ibarz, Alexander Herzog, Eric Jang, Deirdre Quillen, Ethan Holly, Mrinal Kalakrishnan, Vincent Vanhoucke, Sergey Levine*

- `1806.10293v3` - [abs](http://arxiv.org/abs/1806.10293v3) - [pdf](http://arxiv.org/pdf/1806.10293v3)

> In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations.

</details>

<details>

<summary>2018-11-28 03:19:09 - Relational dynamic memory networks</summary>

- *Trang Pham, Truyen Tran, Svetha Venkatesh*

- `1808.04247v3` - [abs](http://arxiv.org/abs/1808.04247v3) - [pdf](http://arxiv.org/pdf/1808.04247v3)

> Neural networks excel in detecting regular patterns but are less successful in representing and manipulating complex data structures, possibly due to the lack of an external memory. This has led to the recent development of a new line of architectures known as Memory-Augmented Neural Networks (MANNs), each of which consists of a neural network that interacts with an external memory matrix. However, this RAM-like memory matrix is unstructured and thus does not naturally encode structured objects. Here we design a new MANN dubbed Relational Dynamic Memory Network (RMDN) to bridge the gap. Like existing MANNs, RMDN has a neural controller but its memory is structured as multi-relational graphs. RMDN uses the memory to represent and manipulate graph-structured data in response to query; and as a neural network, RMDN is trainable from labeled data. Thus RMDN learns to answer queries about a set of graph-structured objects without explicit programming. We evaluate the capability of RMDN on several important prediction problems, including software vulnerability, molecular bioactivity and chemical-chemical interaction. Results demonstrate the efficacy of the proposed model.

</details>

<details>

<summary>2018-11-28 03:55:48 - Neuro-memristive Circuits for Edge Computing: A review</summary>

- *Olga Krestinskaya, Alex Pappachen James, Leon O. Chua*

- `1807.00962v2` - [abs](http://arxiv.org/abs/1807.00962v2) - [pdf](http://arxiv.org/pdf/1807.00962v2)

> The volume, veracity, variability, and velocity of data produced from the ever-increasing network of sensors connected to Internet pose challenges for power management, scalability, and sustainability of cloud computing infrastructure. Increasing the data processing capability of edge computing devices at lower power requirements can reduce several overheads for cloud computing solutions. This paper provides the review of neuromorphic CMOS-memristive architectures that can be integrated into edge computing devices. We discuss why the neuromorphic architectures are useful for edge devices and show the advantages, drawbacks and open problems in the field of neuro-memristive circuits for edge computing.

</details>

<details>

<summary>2018-11-28 04:56:32 - Particle Probability Hypothesis Density Filter based on Pairwise Markov Chains</summary>

- *Jiangyi Liu, Chunping Wang, Wei Wang*

- `1811.12211v1` - [abs](http://arxiv.org/abs/1811.12211v1) - [pdf](http://arxiv.org/pdf/1811.12211v1)

> Most multi-target tracking filters assume that one target and its observation follow a Hidden Markov Chain (HMC) model, but the implicit independence assumption of HMC model is invalid in many practical applications, and a Pairwise Markov Chain (PMC) model is more universally suitable than traditional HMC model. A particle probability hypothesis density filter based on PMC model (PF-PMC-PHD) is proposed for the nonlinear multi-target tracking system. Simulation results show the effectiveness of PF-PMC-PHD filter, and that the tracking performance of PF-PMC-PHD filter is superior to the particle PHD filter based on HMC model in a scenario where we kept the local physical properties of nonlinear and Gaussian HMC models while relaxing their independence assumption.

</details>

<details>

<summary>2018-11-28 05:07:23 - Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog</summary>

- *Sang-Woo Lee, Yu-Jung Heo, Byoung-Tak Zhang*

- `1802.03881v3` - [abs](http://arxiv.org/abs/1802.03881v3) - [pdf](http://arxiv.org/pdf/1802.03881v3)

> Goal-oriented dialog has been given attention due to its numerous applications in artificial intelligence. Goal-oriented dialogue tasks occur when a questioner asks an action-oriented question and an answerer responds with the intent of letting the questioner know a correct action to take. To ask the adequate question, deep learning and reinforcement learning have been recently applied. However, these approaches struggle to find a competent recurrent neural questioner, owing to the complexity of learning a series of sentences. Motivated by theory of mind, we propose "Answerer in Questioner's Mind" (AQM), a novel information theoretic algorithm for goal-oriented dialog. With AQM, a questioner asks and infers based on an approximated probabilistic model of the answerer. The questioner figures out the answerer's intention via selecting a plausible question by explicitly calculating the information gain of the candidate intentions and possible answers to each question. We test our framework on two goal-oriented visual dialog tasks: "MNIST Counting Dialog" and "GuessWhat?!". In our experiments, AQM outperforms comparative algorithms by a large margin.

</details>

<details>

<summary>2018-11-28 07:51:21 - Semi-supervised learning with Bidirectional GANs</summary>

- *Maciej Zamorski, Maciej Zięba*

- `1811.11426v1` - [abs](http://arxiv.org/abs/1811.11426v1) - [pdf](http://arxiv.org/pdf/1811.11426v1)

> In this work we introduce a novel approach to train Bidirectional Generative Adversarial Model (BiGAN) in a semi-supervised manner. The presented method utilizes triplet loss function as an additional component of the objective function used to train discriminative data representation in the latent space of the BiGAN model. This representation can be further used as a seed for generating artificial images, but also as a good feature embedding for classification and image retrieval tasks. We evaluate the quality of the proposed method in the two mentioned challenging tasks using two benchmark datasets: CIFAR10 and SVHN.

</details>

<details>

<summary>2018-11-28 08:24:03 - Partial Evaluation of Logic Programs in Vector Spaces</summary>

- *Chiaki Sakama, Hien D. Nguyen, Taisuke Sato, Katsumi Inoue*

- `1811.11435v1` - [abs](http://arxiv.org/abs/1811.11435v1) - [pdf](http://arxiv.org/pdf/1811.11435v1)

> In this paper, we introduce methods of encoding propositional logic programs in vector spaces. Interpretations are represented by vectors and programs are represented by matrices. The least model of a definite program is computed by multiplying an interpretation vector and a program matrix. To optimize computation in vector spaces, we provide a method of partial evaluation of programs using linear algebra. Partial evaluation is done by unfolding rules in a program, and it is realized in a vector space by multiplying program matrices. We perform experiments using randomly generated programs and show that partial evaluation has potential for realizing efficient computation in huge scale of programs.

</details>

<details>

<summary>2018-11-28 10:32:36 - Single-Agent Policy Tree Search With Guarantees</summary>

- *Laurent Orseau, Levi H. S. Lelis, Tor Lattimore, Théophane Weber*

- `1811.10928v2` - [abs](http://arxiv.org/abs/1811.10928v2) - [pdf](http://arxiv.org/pdf/1811.10928v2)

> We introduce two novel tree search algorithms that use a policy to guide search. The first algorithm is a best-first enumeration that uses a cost function that allows us to prove an upper bound on the number of nodes to be expanded before reaching a goal state. We show that this best-first algorithm is particularly well suited for `needle-in-a-haystack' problems. The second algorithm is based on sampling and we prove an upper bound on the expected number of nodes it expands before reaching a set of goal states. We show that this algorithm is better suited for problems where many paths lead to a goal. We validate these tree search algorithms on 1,000 computer-generated levels of Sokoban, where the policy used to guide the search comes from a neural network trained using A3C. Our results show that the policy tree search algorithms we introduce are competitive with a state-of-the-art domain-independent planner that uses heuristic search.

</details>

<details>

<summary>2018-11-28 11:21:43 - Counting Complexity for Reasoning in Abstract Argumentation</summary>

- *Johannes K. Fichte, Markus Hecher, Arne Meier*

- `1811.11501v1` - [abs](http://arxiv.org/abs/1811.11501v1) - [pdf](http://arxiv.org/pdf/1811.11501v1)

> In this paper, we consider counting and projected model counting of extensions in abstract argumentation for various semantics. When asking for projected counts we are interested in counting the number of extensions of a given argumentation framework while multiple extensions that are identical when restricted to the projected arguments count as only one projected extension. We establish classical complexity results and parameterized complexity results when the problems are parameterized by treewidth of the undirected argumentation graph. To obtain upper bounds for counting projected extensions, we introduce novel algorithms that exploit small treewidth of the undirected argumentation graph of the input instance by dynamic programming (DP). Our algorithms run in time double or triple exponential in the treewidth depending on the considered semantics. Finally, we take the exponential time hypothesis (ETH) into account and establish lower bounds of bounded treewidth algorithms for counting extensions and projected extension.

</details>

<details>

<summary>2018-11-28 12:35:03 - Towards Decentralization of Social Media</summary>

- *Sarang Mahajan, Amey Kasar*

- `1811.11522v1` - [abs](http://arxiv.org/abs/1811.11522v1) - [pdf](http://arxiv.org/pdf/1811.11522v1)

> Facebook uses Artificial Intelligence for targeting users with advertisements based on the events in which they engage like sharing, liking, making comments, posts by a friend, a group creation, etcetera. Each user interacts with these events in different ways, thus receiving different recommendations curated by Facebook's intelligent systems. Facebook segregates its users into chambers, fragmenting them into communities. The technology has completely changed the marketing domain. It is however caught in a race for our finite attention with a motive to make more and more money. Facebook is not a neutral product. It is programmed to get users addicted to it with a goal of gaining added information about the users and optimizing the recommendations provided to the users according to his or her preferences. This paper delineates how Facebook's recommendation system works and presents three methods to safeguard human vulnerabilities exploited by Facebook and other corporations.

</details>

<details>

<summary>2018-11-28 14:43:49 - Automated Algorithm Selection: Survey and Perspectives</summary>

- *Pascal Kerschke, Holger H. Hoos, Frank Neumann, Heike Trautmann*

- `1811.11597v1` - [abs](http://arxiv.org/abs/1811.11597v1) - [pdf](http://arxiv.org/pdf/1811.11597v1)

> It has long been observed that for practically any computational problem that has been intensely studied, different instances are best solved using different algorithms. This is particularly pronounced for computationally hard problems, where in most cases, no single algorithm defines the state of the art; instead, there is a set of algorithms with complementary strengths. This performance complementarity can be exploited in various ways, one of which is based on the idea of selecting, from a set of given algorithms, for each problem instance to be solved the one expected to perform best. The task of automatically selecting an algorithm from a given set is known as the per-instance algorithm selection problem and has been intensely studied over the past 15 years, leading to major improvements in the state of the art in solving a growing number of discrete combinatorial problems, including propositional satisfiability and AI planning. Per-instance algorithm selection also shows much promise for boosting performance in solving continuous and mixed discrete/continuous optimisation problems.   This survey provides an overview of research in automated algorithm selection, ranging from early and seminal works to recent and promising application areas. Different from earlier work, it covers applications to discrete and continuous problems, and discusses algorithm selection in context with conceptually related approaches, such as algorithm configuration, scheduling or portfolio selection. Since informative and cheaply computable problem instance features provide the basis for effective per-instance algorithm selection systems, we also provide an overview of such features for discrete and continuous problems. Finally, we provide perspectives on future work in the area and discuss a number of open research challenges.

</details>

<details>

<summary>2018-11-28 15:22:03 - Large Scale Audio-Visual Video Analytics Platform for Forensic Investigations of Terroristic Attacks</summary>

- *Alexander Schindler, Martin Boyer, Andrew Lindley, David Schreiber, Thomas Philipp*

- `1811.11623v1` - [abs](http://arxiv.org/abs/1811.11623v1) - [pdf](http://arxiv.org/pdf/1811.11623v1)

> The forensic investigation of a terrorist attack poses a huge challenge to the investigative authorities, as several thousand hours of video footage need to be spotted. To assist law enforcement agencies (LEA) in identifying suspects and securing evidences, we present a platform which fuses information of surveillance cameras and video uploads from eyewitnesses. The platform integrates analytical modules for different input-modalities on a scalable architecture. Videos are analyzed according their acoustic and visual content. Specifically, Audio Event Detection is applied to index the content according to attack-specific acoustic concepts. Audio similarity search is utilized to identify similar video sequences recorded from different perspectives. Visual object detection and tracking are used to index the content according to relevant concepts. The heterogeneous results of the analytical modules are fused into a distributed index of visual and acoustic concepts to facilitate rapid start of investigations, following traits and investigating witness reports.

</details>

<details>

<summary>2018-11-28 17:51:39 - Few-Shot Generalization Across Dialogue Tasks</summary>

- *Vladimir Vlasov, Akela Drissner-Schmid, Alan Nichol*

- `1811.11707v1` - [abs](http://arxiv.org/abs/1811.11707v1) - [pdf](http://arxiv.org/pdf/1811.11707v1)

> Machine-learning based dialogue managers are able to learn complex behaviors in order to complete a task, but it is not straightforward to extend their capabilities to new domains. We investigate different policies' ability to handle uncooperative user behavior, and how well expertise in completing one task (such as restaurant reservations) can be reapplied when learning a new one (e.g. booking a hotel). We introduce the Recurrent Embedding Dialogue Policy (REDP), which embeds system actions and dialogue states in the same vector space. REDP contains a memory component and attention mechanism based on a modified Neural Turing Machine, and significantly outperforms a baseline LSTM classifier on this task. We also show that both our architecture and baseline solve the bAbI dialogue task, achieving 100% test accuracy.

</details>

<details>

<summary>2018-11-28 18:07:24 - Stochastic natural gradient descent draws posterior samples in function space</summary>

- *Samuel L. Smith, Daniel Duckworth, Semon Rezchikov, Quoc V. Le, Jascha Sohl-Dickstein*

- `1806.09597v4` - [abs](http://arxiv.org/abs/1806.09597v4) - [pdf](http://arxiv.org/pdf/1806.09597v4)

> Recent work has argued that stochastic gradient descent can approximate the Bayesian uncertainty in model parameters near local minima. In this work we develop a similar correspondence for minibatch natural gradient descent (NGD). We prove that for sufficiently small learning rates, if the model predictions on the training set approach the true conditional distribution of labels given inputs, the stationary distribution of minibatch NGD approaches a Bayesian posterior near local minima. The temperature $T = \epsilon N / (2B)$ is controlled by the learning rate $\epsilon$, training set size $N$ and batch size $B$. However minibatch NGD is not parameterisation invariant and it does not sample a valid posterior away from local minima. We therefore propose a novel optimiser, "stochastic NGD", which introduces the additional correction terms required to preserve both properties.

</details>

<details>

<summary>2018-11-28 19:00:36 - Definition and evaluation of model-free coordination of electrical vehicle charging with reinforcement learning</summary>

- *Nasrin Sadeghianpourhamami, Johannes Deleu, Chris Develder*

- `1809.10679v2` - [abs](http://arxiv.org/abs/1809.10679v2) - [pdf](http://arxiv.org/pdf/1809.10679v2)

> Initial DR studies mainly adopt model predictive control and thus require accurate models of the control problem (e.g., a customer behavior model), which are to a large extent uncertain for the EV scenario. Hence, model-free approaches, especially based on reinforcement learning (RL) are an attractive alternative. In this paper, we propose a new Markov decision process (MDP) formulation in the RL framework, to jointly coordinate a set of EV charging stations. State-of-the-art algorithms either focus on a single EV, or perform the control of an aggregate of EVs in multiple steps (e.g., aggregate load decisions in one step, then a step translating the aggregate decision to individual connected EVs). On the contrary, we propose an RL approach to jointly control the whole set of EVs at once. We contribute a new MDP formulation, with a scalable state representation that is independent of the number of EV charging stations. Further, we use a batch reinforcement learning algorithm, i.e., an instance of fitted Q-iteration, to learn the optimal charging policy. We analyze its performance using simulation experiments based on a real-world EV charging data. More specifically, we (i) explore the various settings in training the RL policy (e.g., duration of the period with training data), (ii) compare its performance to an oracle all-knowing benchmark (which provides an upper bound for performance, relying on information that is not available or at least imperfect in practice), (iii) analyze performance over time, over the course of a full year to evaluate possible performance fluctuations (e.g, across different seasons), and (iv) demonstrate the generalization capacity of a learned control policy to larger sets of charging stations.

</details>

<details>

<summary>2018-11-28 21:31:07 - Efficiently Combining Human Demonstrations and Interventions for Safe Training of Autonomous Systems in Real-Time</summary>

- *Vinicius G. Goecks, Gregory M. Gremillion, Vernon J. Lawhern, John Valasek, Nicholas R. Waytowich*

- `1810.11545v2` - [abs](http://arxiv.org/abs/1810.11545v2) - [pdf](http://arxiv.org/pdf/1810.11545v2)

> This paper investigates how to utilize different forms of human interaction to safely train autonomous systems in real-time by learning from both human demonstrations and interventions. We implement two components of the Cycle-of-Learning for Autonomous Systems, which is our framework for combining multiple modalities of human interaction. The current effort employs human demonstrations to teach a desired behavior via imitation learning, then leverages intervention data to correct for undesired behaviors produced by the imitation learner to teach novel tasks to an autonomous agent safely, after only minutes of training. We demonstrate this method in an autonomous perching task using a quadrotor with continuous roll, pitch, yaw, and throttle commands and imagery captured from a downward-facing camera in a high-fidelity simulated environment. Our method improves task completion performance for the same amount of human interaction when compared to learning from demonstrations alone, while also requiring on average 32% less data to achieve that performance. This provides evidence that combining multiple modes of human interaction can increase both the training speed and overall performance of policies for autonomous systems.

</details>

<details>

<summary>2018-11-28 23:36:50 - Predicting the Computational Cost of Deep Learning Models</summary>

- *Daniel Justus, John Brennan, Stephen Bonner, Andrew Stephen McGough*

- `1811.11880v1` - [abs](http://arxiv.org/abs/1811.11880v1) - [pdf](http://arxiv.org/pdf/1811.11880v1)

> Deep learning is rapidly becoming a go-to tool for many artificial intelligence problems due to its ability to outperform other approaches and even humans at many problems. Despite its popularity we are still unable to accurately predict the time it will take to train a deep learning network to solve a given problem. This training time can be seen as the product of the training time per epoch and the number of epochs which need to be performed to reach the desired level of accuracy. Some work has been carried out to predict the training time for an epoch -- most have been based around the assumption that the training time is linearly related to the number of floating point operations required. However, this relationship is not true and becomes exacerbated in cases where other activities start to dominate the execution time. Such as the time to load data from memory or loss of performance due to non-optimal parallel execution. In this work we propose an alternative approach in which we train a deep learning network to predict the execution time for parts of a deep learning network. Timings for these individual parts can then be combined to provide a prediction for the whole execution time. This has advantages over linear approaches as it can model more complex scenarios. But, also, it has the ability to predict execution times for scenarios unseen in the training data. Therefore, our approach can be used not only to infer the execution time for a batch, or entire epoch, but it can also support making a well-informed choice for the appropriate hardware and model.

</details>

<details>

<summary>2018-11-28 23:54:47 - Pay attention! - Robustifying a Deep Visuomotor Policy through Task-Focused Attention</summary>

- *Pooya Abolghasemi, Amir Mazaheri, Mubarak Shah, Ladislau Bölöni*

- `1809.10093v2` - [abs](http://arxiv.org/abs/1809.10093v2) - [pdf](http://arxiv.org/pdf/1809.10093v2)

> Several recent studies have demonstrated the promise of deep visuomotor policies for robot manipulator control. Despite impressive progress, these systems are known to be vulnerable to physical disturbances, such as accidental or adversarial bumps that make them drop the manipulated object. They also tend to be distracted by visual disturbances such as objects moving in the robot's field of view, even if the disturbance does not physically prevent the execution of the task. In this paper, we propose an approach for augmenting a deep visuomotor policy trained through demonstrations with Task Focused visual Attention (TFA). The manipulation task is specified with a natural language text such as `move the red bowl to the left'. This allows the visual attention component to concentrate on the current object that the robot needs to manipulate. We show that even in benign environments, the TFA allows the policy to consistently outperform a variant with no attention mechanism. More importantly, the new policy is significantly more robust: it regularly recovers from severe physical disturbances (such as bumps causing it to drop the object) from which the baseline policy, i.e. with no visual attention, almost never recovers. In addition, we show that the proposed policy performs correctly in the presence of a wide class of visual disturbances, exhibiting a behavior reminiscent of human selective visual attention experiments. Our proposed approach consists of a VAE-GAN network which encodes the visual input and feeds it to a Motor network that moves the robot joints. Also, our approach benefits from a teacher network for the TFA that leverages textual input command to robustify the visual encoder against various types of disturbances.

</details>

<details>

<summary>2018-11-29 02:12:37 - Regret Bounds for Stochastic Combinatorial Multi-Armed Bandits with Linear Space Complexity</summary>

- *Mridul Agarwal, Vaneet Aggarwal*

- `1811.11925v1` - [abs](http://arxiv.org/abs/1811.11925v1) - [pdf](http://arxiv.org/pdf/1811.11925v1)

> Many real-world problems face the dilemma of choosing best $K$ out of $N$ options at a given time instant. This setup can be modelled as combinatorial bandit which chooses $K$ out of $N$ arms at each time, with an aim to achieve an efficient tradeoff between exploration and exploitation. This is the first work for combinatorial bandit where the reward received can be a non-linear function of the chosen $K$ arms. The direct use of multi-armed bandit requires choosing among $N$-choose-$K$ options making the state space large. In this paper, we present a novel algorithm which is computationally efficient and the storage is linear in $N$. The proposed algorithm is a divide-and-conquer based strategy, that we call CMAB-SM. Further, the proposed algorithm achieves a regret bound of $\tilde O(K^\frac{1}{2}N^\frac{1}{3}T^\frac{2}{3})$ for a time horizon $T$, which is sub-linear in all parameters $T$, $N$, and $K$. The evaluation results on different reward functions and arm distribution functions show significantly improved performance as compared to standard multi-armed bandit approach with $\binom{N}{K}$ choices.

</details>

<details>

<summary>2018-11-29 03:20:18 - Understanding training and generalization in deep learning by Fourier analysis</summary>

- *Zhiqin John Xu*

- `1808.04295v4` - [abs](http://arxiv.org/abs/1808.04295v4) - [pdf](http://arxiv.org/pdf/1808.04295v4)

> Background: It is still an open research area to theoretically understand why Deep Neural Networks (DNNs)---equipped with many more parameters than training data and trained by (stochastic) gradient-based methods---often achieve remarkably low generalization error. Contribution: We study DNN training by Fourier analysis. Our theoretical framework explains: i) DNN with (stochastic) gradient-based methods often endows low-frequency components of the target function with a higher priority during the training; ii) Small initialization leads to good generalization ability of DNN while preserving the DNN's ability to fit any function. These results are further confirmed by experiments of DNNs fitting the following datasets, that is, natural images, one-dimensional functions and MNIST dataset.

</details>

<details>

<summary>2018-11-29 03:40:55 - HYPE: A High Performing NLP System for Automatically Detecting Hypoglycemia Events from Electronic Health Record Notes</summary>

- *Yonghao Jin, Fei Li, Hong Yu*

- `1811.11945v1` - [abs](http://arxiv.org/abs/1811.11945v1) - [pdf](http://arxiv.org/pdf/1811.11945v1)

> Hypoglycemia is common and potentially dangerous among those treated for diabetes. Electronic health records (EHRs) are important resources for hypoglycemia surveillance. In this study, we report the development and evaluation of deep learning-based natural language processing systems to automatically detect hypoglycemia events from the EHR narratives. Experts in Public Health annotated 500 EHR notes from patients with diabetes. We used this annotated dataset to train and evaluate HYPE, supervised NLP systems for hypoglycemia detection. In our experiment, the convolutional neural network model yielded promising performance $Precision=0.96 \pm 0.03, Recall=0.86 \pm 0.03, F1=0.91 \pm 0.03$ in a 10-fold cross-validation setting. Despite the annotated data is highly imbalanced, our CNN-based HYPE system still achieved a high performance for hypoglycemia detection. HYPE could be used for EHR-based hypoglycemia surveillance and to facilitate clinicians for timely treatment of high-risk patients.

</details>

<details>

<summary>2018-11-29 04:41:54 - Hallucinating Point Cloud into 3D Sculptural Object</summary>

- *Chun-Liang Li, Eunsu Kang, Songwei Ge, Lingyao Zhang, Austin Dill, Manzil Zaheer, Barnabas Poczos*

- `1811.05389v3` - [abs](http://arxiv.org/abs/1811.05389v3) - [pdf](http://arxiv.org/pdf/1811.05389v3)

> Our team of artists and machine learning researchers designed a creative algorithm that can generate authentic sculptural artworks. These artworks do not mimic any given forms and cannot be easily categorized into the dataset categories. Our approach extends DeepDream from images to 3D point clouds. The proposed algorithm, Amalgamated DeepDream (ADD), leverages the properties of point clouds to create objects with better quality than the naive extension. ADD presents promise for the creativity of machines, the kind of creativity that pushes artists to explore novel methods or materials and to create new genres instead of creating variations of existing forms or styles within one genre. For example, from Realism to Abstract Expressionism, or to Minimalism. Lastly, we present the sculptures that are 3D printed based on the point clouds created by ADD.

</details>

<details>

<summary>2018-11-29 07:00:09 - Deep learning for pedestrians: backpropagation in CNNs</summary>

- *Laurent Boué*

- `1811.11987v1` - [abs](http://arxiv.org/abs/1811.11987v1) - [pdf](http://arxiv.org/pdf/1811.11987v1)

> The goal of this document is to provide a pedagogical introduction to the main concepts underpinning the training of deep neural networks using gradient descent; a process known as backpropagation. Although we focus on a very influential class of architectures called "convolutional neural networks" (CNNs) the approach is generic and useful to the machine learning community as a whole. Motivated by the observation that derivations of backpropagation are often obscured by clumsy index-heavy narratives that appear somewhat mathemagical, we aim to offer a conceptually clear, vectorized description that articulates well the higher level logic. Following the principle of "writing is nature's way of letting you know how sloppy your thinking is", we try to make the calculations meticulous, self-contained and yet as intuitive as possible. Taking nothing for granted, ample illustrations serve as visual guides and an extensive bibliography is provided for further explorations.   (For the sake of clarity, long mathematical derivations and visualizations have been broken up into short "summarized views" and longer "detailed views" encoded into the PDF as optional content groups. Some figures contain animations designed to illustrate important concepts in a more engaging style. For these reasons, we advise to download the document locally and open it using Adobe Acrobat Reader. Other viewers were not tested and may not render the detailed views, animations correctly.)

</details>

<details>

<summary>2018-11-29 07:01:26 - Survey on Misbehavior Detection in Cooperative Intelligent Transportation Systems</summary>

- *Rens W. van der Heijden, Stefan Dietzel, Tim Leinmüller, Frank Kargl*

- `1610.06810v2` - [abs](http://arxiv.org/abs/1610.06810v2) - [pdf](http://arxiv.org/pdf/1610.06810v2)

> Cooperative Intelligent Transportation Systems (cITS) are a promising technology to enhance driving safety and efficiency. Vehicles communicate wirelessly with other vehicles and infrastructure, thereby creating a highly dynamic and heterogeneously managed ad-hoc network. It is these network properties that make it a challenging task to protect integrity of the data and guarantee its correctness. A major component is the problem that traditional security mechanisms like PKI-based asymmetric cryptography only exclude outsider attackers that do not possess key material. However, because attackers can be insiders within the network (i.e., possess valid key material), this approach cannot detect all possible attacks. In this survey, we present misbehavior detection mechanisms that can detect such insider attacks based on attacker behavior and information analysis. In contrast to well-known intrusion detection for classical IT systems, these misbehavior detection mechanisms analyze information semantics to detect attacks, which aligns better with highly application-tailored communication protocols foreseen for cITS. In our survey, we provide an extensive introduction to the cITS ecosystem and discuss shortcomings of PKI-based security. We derive and discuss a classification for misbehavior detection mechanisms, provide an in-depth overview of seminal papers on the topic, and highlight open issues and possible future research trends.

</details>

<details>

<summary>2018-11-29 07:05:21 - Automated Algorithm Selection on Continuous Black-Box Problems By Combining Exploratory Landscape Analysis and Machine Learning</summary>

- *Pascal Kerschke, Heike Trautmann*

- `1711.08921v3` - [abs](http://arxiv.org/abs/1711.08921v3) - [pdf](http://arxiv.org/pdf/1711.08921v3)

> In this paper, we build upon previous work on designing informative and efficient Exploratory Landscape Analysis features for characterizing problems' landscapes and show their effectiveness in automatically constructing algorithm selection models in continuous black-box optimization problems. Focussing on algorithm performance results of the COCO platform of several years, we construct a representative set of high-performing complementary solvers and present an algorithm selection model that - compared to the portfolio's single best solver - on average requires less than half of the resources for solving a given problem. Therefore, there is a huge gain in efficiency compared to classical ensemble methods combined with an increased insight into problem characteristics and algorithm properties by using informative features. Acting on the assumption that the function set of the Black-Box Optimization Benchmark is representative enough for practical applications the model allows for selecting the best suited optimization algorithm within the considered set for unseen problems prior to the optimization itself based on a small sample of function evaluations. Note that such a sample can even be reused for the initial population of an evolutionary (optimization) algorithm so that even the feature costs become negligible.

</details>

<details>

<summary>2018-11-29 09:18:38 - MOBIUS: Model-Oblivious Binarized Neural Networks</summary>

- *Hiromasa Kitai, Jason Paul Cruz, Naoto Yanai, Naohisa Nishida, Tatsumi Oba, Yuji Unagami, Tadanori Teruya, Nuttapong Attrapadung, Takahiro Matsuda, Goichiro Hanaoka*

- `1811.12028v1` - [abs](http://arxiv.org/abs/1811.12028v1) - [pdf](http://arxiv.org/pdf/1811.12028v1)

> A privacy-preserving framework in which a computational resource provider receives encrypted data from a client and returns prediction results without decrypting the data, i.e., oblivious neural network or encrypted prediction, has been studied in machine learning that provides prediction services. In this work, we present MOBIUS (Model-Oblivious BInary neUral networkS), a new system that combines Binarized Neural Networks (BNNs) and secure computation based on secret sharing as tools for scalable and fast privacy-preserving machine learning. BNNs improve computational performance by binarizing values in training to $-1$ and $+1$, while secure computation based on secret sharing provides fast and various computations under encrypted forms via modulo operations with a short bit length. However, combining these tools is not trivial because their operations have different algebraic structures and the use of BNNs downgrades prediction accuracy in general. MOBIUS uses improved procedures of BNNs and secure computation that have compatible algebraic structures without downgrading prediction accuracy. We created an implementation of MOBIUS in C++ using the ABY library (NDSS 2015). We then conducted experiments using the MNIST dataset, and the results show that MOBIUS can return a prediction within 0.76 seconds, which is six times faster than SecureML (IEEE S\&P 2017). MOBIUS allows a client to request for encrypted prediction and allows a trainer to obliviously publish an encrypted model to a cloud provided by a computational resource provider, i.e., without revealing the original model itself to the provider.

</details>

<details>

<summary>2018-11-29 14:00:12 - Game Tree Search in a Robust Multistage Optimization Framework: Exploiting Pruning Mechanisms</summary>

- *Michael Hartisch, Ulf Lorenz*

- `1811.12146v1` - [abs](http://arxiv.org/abs/1811.12146v1) - [pdf](http://arxiv.org/pdf/1811.12146v1)

> We investigate pruning in search trees of so-called quantified integer linear programs (QIPs). QIPs consist of a set of linear inequalities and a minimax objective function, where some variables are existentially and others are universally quantified. They can be interpreted as two-person zero-sum games between an existential and a universal player on the one hand, or multistage optimization problems under uncertainty on the other hand. Solutions are so-called winning strategies for the existential player that specify how to react on moves of the universal player - i.e. certain assignments of universally quantified variables - to certainly win the game.   QIPs can be solved with the help of game tree search that is enhanced with non-chronological back-jumping. We develop and theoretically substantiate pruning techniques based upon (algebraic) properties similar to pruning mechanisms known from linear programming and quantified boolean formulas. The presented Strategic Copy-Pruning mechanism allows to \textit{implicitly} deduce the existence of a strategy in linear time (by static examination of the QIP-matrix) without explicitly traversing the strategy itself. We show that the implementation of our findings can massively speed up the search process.

</details>

<details>

<summary>2018-11-29 15:08:55 - Machine Learning on Electronic Health Records: Models and Features Usages to predict Medication Non-Adherence</summary>

- *Thomas Janssoone, Clémence Bic, Dorra Kanoun, Pierre Hornus, Pierre Rinder*

- `1811.12234v1` - [abs](http://arxiv.org/abs/1811.12234v1) - [pdf](http://arxiv.org/pdf/1811.12234v1)

> Adherence can be defined as "the extent to which patients take their medications as prescribed by their healthcare providers"[Osterberg and Blaschke, 2005]. World Health Organization's reports point out that, in developed countries, only about 50% of patients with chronic diseases correctly follow their treatments. This severely compromises the efficiency of long-term therapy and increases the cost of health services. We propose in this paper different models of patient drug consumption in breast cancer treatments. The aim of these different approaches is to predict medication non-adherence while giving insights to doctors of the underlying reasons of these illegitimate drop-outs. Working with oncologists, we show the interest of Machine- Learning algorithms fined tune by the feedback of experts to estimate a risk score of a patient's non-adherence and thus improve support throughout their care path.

</details>

<details>

<summary>2018-11-29 15:11:23 - Recurrent Relational Networks</summary>

- *Rasmus Berg Palm, Ulrich Paquet, Ole Winther*

- `1711.08028v4` - [abs](http://arxiv.org/abs/1711.08028v4) - [pdf](http://arxiv.org/pdf/1711.08028v4)

> This paper is concerned with learning to solve tasks that require a chain of interdependent steps of relational inference, like answering complex questions about the relationships between objects, or solving puzzles where the smaller elements of a solution mutually constrain each other. We introduce the recurrent relational network, a general purpose module that operates on a graph representation of objects. As a generalization of Santoro et al. [2017]'s relational network, it can augment any neural network model with the capacity to do many-step relational reasoning. We achieve state of the art results on the bAbI textual question-answering dataset with the recurrent relational network, consistently solving 20/20 tasks. As bAbI is not particularly challenging from a relational reasoning point of view, we introduce Pretty-CLEVR, a new diagnostic dataset for relational reasoning. In the Pretty-CLEVR set-up, we can vary the question to control for the number of relational reasoning steps that are required to obtain the answer. Using Pretty-CLEVR, we probe the limitations of multi-layer perceptrons, relational and recurrent relational networks. Finally, we show how recurrent relational networks can learn to solve Sudoku puzzles from supervised training data, a challenging task requiring upwards of 64 steps of relational reasoning. We achieve state-of-the-art results amongst comparable methods by solving 96.6% of the hardest Sudoku puzzles.

</details>

<details>

<summary>2018-11-29 15:13:26 - Perceiving Physical Equation by Observing Visual Scenarios</summary>

- *Siyu Huang, Zhi-Qi Cheng, Xi Li, Xiao Wu, Zhongfei Zhang, Alexander Hauptmann*

- `1811.12238v1` - [abs](http://arxiv.org/abs/1811.12238v1) - [pdf](http://arxiv.org/pdf/1811.12238v1)

> Inferring universal laws of the environment is an important ability of human intelligence as well as a symbol of general AI. In this paper, we take a step toward this goal such that we introduce a new challenging problem of inferring invariant physical equation from visual scenarios. For instance, teaching a machine to automatically derive the gravitational acceleration formula by watching a free-falling object. To tackle this challenge, we present a novel pipeline comprised of an Observer Engine and a Physicist Engine by respectively imitating the actions of an observer and a physicist in the real world. Generally, the Observer Engine watches the visual scenarios and then extracting the physical properties of objects. The Physicist Engine analyses these data and then summarizing the inherent laws of object dynamics. Specifically, the learned laws are expressed by mathematical equations such that they are more interpretable than the results given by common probabilistic models. Experiments on synthetic videos have shown that our pipeline is able to discover physical equations on various physical worlds with different visual appearances.

</details>

<details>

<summary>2018-11-29 17:17:55 - Snap ML: A Hierarchical Framework for Machine Learning</summary>

- *Celestine Dünner, Thomas Parnell, Dimitrios Sarigiannis, Nikolas Ioannou, Andreea Anghel, Gummadi Ravi, Madhusudanan Kandasamy, Haralampos Pozidis*

- `1803.06333v3` - [abs](http://arxiv.org/abs/1803.06333v3) - [pdf](http://arxiv.org/pdf/1803.06333v3)

> We describe a new software framework for fast training of generalized linear models. The framework, named Snap Machine Learning (Snap ML), combines recent advances in machine learning systems and algorithms in a nested manner to reflect the hierarchical architecture of modern computing systems. We prove theoretically that such a hierarchical system can accelerate training in distributed environments where intra-node communication is cheaper than inter-node communication. Additionally, we provide a review of the implementation of Snap ML in terms of GPU acceleration, pipelining, communication patterns and software architecture, highlighting aspects that were critical for achieving high performance. We evaluate the performance of Snap ML in both single-node and multi-node environments, quantifying the benefit of the hierarchical scheme and the data streaming functionality, and comparing with other widely-used machine learning software frameworks. Finally, we present a logistic regression benchmark on the Criteo Terabyte Click Logs dataset and show that Snap ML achieves the same test loss an order of magnitude faster than any of the previously reported results, including those obtained using TensorFlow and scikit-learn.

</details>

<details>

<summary>2018-11-29 17:30:38 - Evolutionary framework for two-stage stochastic resource allocation problems</summary>

- *Pedro H. D. B. Hokama, Mário C. San Felice, Evandro C. Bracht, Fábio L. Usberti*

- `1903.01885v1` - [abs](http://arxiv.org/abs/1903.01885v1) - [pdf](http://arxiv.org/pdf/1903.01885v1)

> Resource allocation problems are a family of problems in which resources must be selected to satisfy given demands. This paper focuses on the two-stage stochastic generalization of resource allocation problems where future demands are expressed in a finite number of possible scenarios. The goal is to select cost effective resources to be acquired in the present time (first stage), and to implement a complete solution for each scenario (second stage), while minimizing the total expected cost of the choices in both stages.   We propose an evolutionary framework for solving general two-stage stochastic resource allocation problems. In each iteration of our framework, a local search algorithm selects resources to be acquired in the first stage. A genetic metaheuristic then completes the solutions for each scenario and relevant information is passed onto the next iteration, thereby supporting the acquisition of promising resources in the following first stage. Experimentation on numerous instances of the two-stage stochastic Steiner tree problem suggests that our evolutionary framework is powerful enough to address large instances of a wide variety of two-stage stochastic resource allocation problems.

</details>

<details>

<summary>2018-11-29 18:10:13 - Illuminating Generalization in Deep Reinforcement Learning through Procedural Level Generation</summary>

- *Niels Justesen, Ruben Rodriguez Torrado, Philip Bontrager, Ahmed Khalifa, Julian Togelius, Sebastian Risi*

- `1806.10729v5` - [abs](http://arxiv.org/abs/1806.10729v5) - [pdf](http://arxiv.org/pdf/1806.10729v5)

> Deep reinforcement learning (RL) has shown impressive results in a variety of domains, learning directly from high-dimensional sensory streams. However, when neural networks are trained in a fixed environment, such as a single level in a video game, they will usually overfit and fail to generalize to new levels. When RL models overfit, even slight modifications to the environment can result in poor agent performance. This paper explores how procedurally generated levels during training can increase generality. We show that for some games procedural level generation enables generalization to new levels within the same distribution. Additionally, it is possible to achieve better performance with less data by manipulating the difficulty of the levels in response to the performance of the agent. The generality of the learned behaviors is also evaluated on a set of human-designed levels. The results suggest that the ability to generalize to human-designed levels highly depends on the design of the level generators. We apply dimensionality reduction and clustering techniques to visualize the generators' distributions of levels and analyze to what degree they can produce levels similar to those designed by a human.

</details>

<details>

<summary>2018-11-29 19:49:53 - A rule-based system proposal to aid in the evaluation and decision-making in external beam radiation treatment planning</summary>

- *R. C. Fernandes, T. M. Machado, H. J. Onisto, A. D. Muñoz, R. O. Silva, L. R. Domingues, G. C. Fonseca, J. E. Bertuzzo, M. T. Pereira, B. Biazotto, E. T. Costa*

- `1811.12454v1` - [abs](http://arxiv.org/abs/1811.12454v1) - [pdf](http://arxiv.org/pdf/1811.12454v1)

> As part of a plan launched by the Ministry of Health of Brazil to increase the availability of linear accelerators for radiotherapy treatment for the whole country, for which Varian Medical Systems company has won the bidding, a technical cooperation agreement was signed inviting Brazilian Scientific and Technological Institutions to participate in a technology transfer program. As a result, jointly, the Eldorado Research Institute and the Center for Biomedical Engineering of the University of Campinas presents in this work, the concepts behind of a proposed rule engine to aid in the evaluation and decision-making in radiotherapy treatment planning. Normally, the determination of the radiation dose for a given patient is a complex and intensive procedure, which requires a lot of domain knowledge and subjective experience from the oncologists' team. In order to help them in this complex task, and additionally, provide an auxiliary tool for less experienced oncologists, it is presented a project conception of a software system that will make use of a hybrid data-oriented approach. The proposed rule engine will apply both inference mechanism and expression evaluation to verify and accredit the quality of an external beam radiation treatment plan by considering, at first, the 3D-conformal radiotherapy (3DCRT) technique.

</details>

<details>

<summary>2018-11-29 19:56:19 - Unifying Decision-Making: a Review on Evolutionary Theories on Rationality and Cognitive Biases</summary>

- *Catarina Moreira*

- `1811.12455v1` - [abs](http://arxiv.org/abs/1811.12455v1) - [pdf](http://arxiv.org/pdf/1811.12455v1)

> In this paper, we make a review on the concepts of rationality across several different fields, namely in economics, psychology and evolutionary biology and behavioural ecology. We review how processes like natural selection can help us understand the evolution of cognition and how cognitive biases might be a consequence of this natural selection. In the end we argue that humans are not irrational, but rather rationally bounded and we complement the discussion on how quantum cognitive models can contribute for the modelling and prediction of human paradoxical decisions.

</details>

<details>

<summary>2018-11-29 21:34:27 - A feasibility study for predicting optimal radiation therapy dose distributions of prostate cancer patients from patient anatomy using deep learning</summary>

- *Dan Nguyen, Troy Long, Xun Jia, Weiguo Lu, Xuejun Gu, Zohaib Iqbal, Steve Jiang*

- `1709.09233v4` - [abs](http://arxiv.org/abs/1709.09233v4) - [pdf](http://arxiv.org/pdf/1709.09233v4)

> With the advancement of treatment modalities in radiation therapy for cancer patients, outcomes have improved, but at the cost of increased treatment plan complexity and planning time. The accurate prediction of dose distributions would alleviate this issue by guiding clinical plan optimization to save time and maintain high quality plans. We have modified a convolutional deep network model, U-net (originally designed for segmentation purposes), for predicting dose from patient image contours of the planning target volume (PTV) and organs at risk (OAR). We show that, as an example, we are able to accurately predict the dose of intensity-modulated radiation therapy (IMRT) for prostate cancer patients, where the average Dice similarity coefficient is 0.91 when comparing the predicted vs. true isodose volumes between 0% and 100% of the prescription dose. The average value of the absolute differences in [max, mean] dose is found to be under 5% of the prescription dose, specifically for each structure is [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%, 0.48%](Body), [3.87%, 1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head), and [1.26%, 1.62%](Rectum) of the prescription dose. We thus managed to map a desired radiation dose distribution from a patient's PTV and OAR contours. As an additional advantage, relatively little data was used in the techniques and models described in this paper.

</details>

<details>

<summary>2018-11-29 22:06:32 - Machine Learning for Wireless Connectivity and Security of Cellular-Connected UAVs</summary>

- *Ursula Challita, Aidin Ferdowsi, Mingzhe Chen, Walid Saad*

- `1804.05348v3` - [abs](http://arxiv.org/abs/1804.05348v3) - [pdf](http://arxiv.org/pdf/1804.05348v3)

> Cellular-connected unmanned aerial vehicles (UAVs) will inevitably be integrated into future cellular networks as new aerial mobile users. Providing cellular connectivity to UAVs will enable a myriad of applications ranging from online video streaming to medical delivery. However, to enable a reliable wireless connectivity for the UAVs as well as a secure operation, various challenges need to be addressed such as interference management, mobility management and handover, cyber-physical attacks, and authentication. In this paper, the goal is to expose the wireless and security challenges that arise in the context of UAV-based delivery systems, UAV-based real-time multimedia streaming, and UAV-enabled intelligent transportation systems. To address such challenges, artificial neural network (ANN) based solution schemes are introduced. The introduced approaches enable the UAVs to adaptively exploit the wireless system resources while guaranteeing a secure operation, in real-time. Preliminary simulation results show the benefits of the introduced solutions for each of the aforementioned cellular-connected UAV application use case.

</details>

<details>

<summary>2018-11-29 22:29:53 - Generative Bridging Network in Neural Sequence Prediction</summary>

- *Wenhu Chen, Guanlin Li, Shuo Ren, Shujie Liu, Zhirui Zhang, Mu Li, Ming Zhou*

- `1706.09152v6` - [abs](http://arxiv.org/abs/1706.09152v6) - [pdf](http://arxiv.org/pdf/1706.09152v6)

> In order to alleviate data sparsity and overfitting problems in maximum likelihood estimation (MLE) for sequence prediction tasks, we propose the Generative Bridging Network (GBN), in which a novel bridge module is introduced to assist the training of the sequence prediction model (the generator network). Unlike MLE directly maximizing the conditional likelihood, the bridge extends the point-wise ground truth to a bridge distribution conditioned on it, and the generator is optimized to minimize their KL-divergence. Three different GBNs, namely uniform GBN, language-model GBN and coaching GBN, are proposed to penalize confidence, enhance language smoothness and relieve learning burden. Experiments conducted on two recognized sequence prediction tasks (machine translation and abstractive text summarization) show that our proposed GBNs can yield significant improvements over strong baselines. Furthermore, by analyzing samples drawn from different bridges, expected influences on the generator are verified.

</details>

<details>

<summary>2018-11-29 22:40:11 - State-Augmentation Transformations for Risk-Sensitive Reinforcement Learning</summary>

- *Shuai Ma, Jia Yuan Yu*

- `1804.05950v2` - [abs](http://arxiv.org/abs/1804.05950v2) - [pdf](http://arxiv.org/pdf/1804.05950v2)

> In the framework of MDP, although the general reward function takes three arguments-current state, action, and successor state; it is often simplified to a function of two arguments-current state and action. The former is called a transition-based reward function, whereas the latter is called a state-based reward function. When the objective involves the expected cumulative reward only, this simplification works perfectly. However, when the objective is risk-sensitive, this simplification leads to an incorrect value. We present state-augmentation transformations (SATs), which preserve the reward sequences as well as the reward distributions and the optimal policy in risk-sensitive reinforcement learning. In risk-sensitive scenarios, firstly we prove that, for every MDP with a stochastic transition-based reward function, there exists an MDP with a deterministic state-based reward function, such that for any given (randomized) policy for the first MDP, there exists a corresponding policy for the second MDP, such that both Markov reward processes share the same reward sequence. Secondly we illustrate that two situations require the proposed SATs in an inventory control problem. One could be using Q-learning (or other learning methods) on MDPs with transition-based reward functions, and the other could be using methods, which are for the Markov processes with a deterministic state-based reward functions, on the Markov processes with general reward functions. We show the advantage of the SATs by considering Value-at-Risk as an example, which is a risk measure on the reward distribution instead of the measures (such as mean and variance) of the distribution. We illustrate the error in the reward distribution estimation from the direct use of Q-learning, and show how the SATs enable a variance formula to work on Markov processes with general reward functions.

</details>

<details>

<summary>2018-11-29 22:50:03 - Transition-based versus State-based Reward Functions for MDPs with Value-at-Risk</summary>

- *Shuai Ma, Jia Yuan Yu*

- `1612.02088v4` - [abs](http://arxiv.org/abs/1612.02088v4) - [pdf](http://arxiv.org/pdf/1612.02088v4)

> In reinforcement learning, the reward function on current state and action is widely used. When the objective is about the expectation of the (discounted) total reward only, it works perfectly. However, if the objective involves the total reward distribution, the result will be wrong. This paper studies Value-at-Risk (VaR) problems in short- and long-horizon Markov decision processes (MDPs) with two reward functions, which share the same expectations. Firstly we show that with VaR objective, when the real reward function is transition-based (with respect to action and both current and next states), the simplified (state-based, with respect to action and current state only) reward function will change the VaR. Secondly, for long-horizon MDPs, we estimate the VaR function with the aid of spectral theory and the central limit theorem. Thirdly, since the estimation method is for a Markov reward process with the reward function on current state only, we present a transformation algorithm for the Markov reward process with the reward function on current and next states, in order to estimate the VaR function with an intact total reward distribution.

</details>

<details>

<summary>2018-11-29 23:36:25 - The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep Bayesian Active Learning</summary>

- *Jiaming Zeng, Adam Lesnikowski, Jose M. Alvarez*

- `1811.12535v1` - [abs](http://arxiv.org/abs/1811.12535v1) - [pdf](http://arxiv.org/pdf/1811.12535v1)

> One of the main challenges of deep learning tools is their inability to capture model uncertainty. While Bayesian deep learning can be used to tackle the problem, Bayesian neural networks often require more time and computational power to train than deterministic networks. Our work explores whether fully Bayesian networks are needed to successfully capture model uncertainty. We vary the number and position of Bayesian layers in a network and compare their performance on active learning with the MNIST dataset. We found that we can fully capture the model uncertainty by using only a few Bayesian layers near the output of the network, combining the advantages of deterministic and Bayesian networks.

</details>

<details>

<summary>2018-11-30 02:43:33 - Time Aggregation and Model Interpretation for Deep Multivariate Longitudinal Patient Outcome Forecasting Systems in Chronic Ambulatory Care</summary>

- *Beau Norgeot, Dmytro Lituiev, Benjamin S. Glicksberg, Atul J. Butte*

- `1811.12589v1` - [abs](http://arxiv.org/abs/1811.12589v1) - [pdf](http://arxiv.org/pdf/1811.12589v1)

> Clinical data for ambulatory care, which accounts for 90% of the nations healthcare spending, is characterized by relatively small sample sizes of longitudinal data, unequal spacing between visits for each patient, with unequal numbers of data points collected across patients. While deep learning has become state-of-the-art for sequence modeling, it is unknown which methods of time aggregation may be best suited for these challenging temporal use cases. Additionally, deep models are often considered uninterpretable by physicians which may prevent the clinical adoption, even of well performing models. We show that time-distributed-dense layers combined with GRUs produce the most generalizable models. Furthermore, we provide a framework for the clinical interpretation of the models.

</details>

<details>

<summary>2018-11-30 05:56:20 - Understanding Batch Normalization</summary>

- *Johan Bjorck, Carla Gomes, Bart Selman, Kilian Q. Weinberger*

- `1806.02375v4` - [abs](http://arxiv.org/abs/1806.02375v4) - [pdf](http://arxiv.org/pdf/1806.02375v4)

> Batch normalization (BN) is a technique to normalize activations in intermediate layers of deep neural networks. Its tendency to improve accuracy and speed up training have established BN as a favorite technique in deep learning. Yet, despite its enormous success, there remains little consensus on the exact reason and mechanism behind these improvements. In this paper we take a step towards a better understanding of BN, following an empirical approach. We conduct several experiments, and show that BN primarily enables training with larger learning rates, which is the cause for faster convergence and better generalization. For networks without BN we demonstrate how large gradient updates can result in diverging loss and activations growing uncontrollably with network depth, which limits possible learning rates. BN avoids this problem by constantly correcting activations to be zero-mean and of unit standard deviation, which enables larger gradient steps, yields faster convergence and may help bypass sharp local minima. We further show various ways in which gradients and activations of deep unnormalized networks are ill-behaved. We contrast our results against recent findings in random matrix theory, shedding new light on classical initialization schemes and their consequences.

</details>

<details>

<summary>2018-11-30 06:49:37 - Randomized Wagering Mechanisms</summary>

- *Yiling Chen, Yang Liu, Juntao Wang*

- `1809.04136v4` - [abs](http://arxiv.org/abs/1809.04136v4) - [pdf](http://arxiv.org/pdf/1809.04136v4)

> Wagering mechanisms are one-shot betting mechanisms that elicit agents' predictions of an event. For deterministic wagering mechanisms, an existing impossibility result has shown incompatibility of some desirable theoretical properties. In particular, Pareto optimality (no profitable side bet before allocation) can not be achieved together with weak incentive compatibility, weak budget balance and individual rationality. In this paper, we expand the design space of wagering mechanisms to allow randomization and ask whether there are randomized wagering mechanisms that can achieve all previously considered desirable properties, including Pareto optimality. We answer this question positively with two classes of randomized wagering mechanisms: i) one simple randomized lottery-type implementation of existing deterministic wagering mechanisms, and ii) another family of simple and randomized wagering mechanisms which we call surrogate wagering mechanisms, which are robust to noisy ground truth. This family of mechanisms builds on the idea of learning with noisy labels (Natarajan et al. 2013) as well as a recent extension of this idea to the information elicitation without verification setting (Liu and Chen 2018). We show that a broad family of randomized wagering mechanisms satisfy all desirable theoretical properties.

</details>

<details>

<summary>2018-11-30 06:58:16 - AI Neurotechnology for Aging Societies -- Task-load and Dementia EEG Digital Biomarker Development Using Information Geometry Machine Learning Methods</summary>

- *Tomasz M. Rutkowski, Qibin Zhao, Masao S. Abe, Mihoko Otake*

- `1811.12642v1` - [abs](http://arxiv.org/abs/1811.12642v1) - [pdf](http://arxiv.org/pdf/1811.12642v1)

> Dementia and especially Alzheimer's disease (AD) are the most common causes of cognitive decline in elderly people. A spread of the above mentioned mental health problems in aging societies is causing a significant medical and economic burden in many countries around the world. According to a recent World Health Organization (WHO) report, it is approximated that currently, worldwide, about 47 million people live with a dementia spectrum of neurocognitive disorders. This number is expected to triple by 2050, which calls for possible application of AI-based technologies to support an early screening for preventive interventions and a subsequent mental wellbeing monitoring as well as maintenance with so-called digital-pharma or beyond a pill therapeutical approaches. This paper discusses our attempt and preliminary results of brainwave (EEG) techniques to develop digital biomarkers for dementia progress detection and monitoring. We present an information geometry-based classification approach for automatic EEG-derived event related responses (ERPs) discrimination of low versus high task-load auditory or tactile stimuli recognition, of which amplitude and latency variabilities are similar to those in dementia. The discussed approach is a step forward to develop AI, and especially machine learning (ML) approaches, for the subsequent application to mild-cognitive impairment (MCI) and AD diagnostics.

</details>

<details>

<summary>2018-11-30 08:18:05 - Improved Crowding Distance for NSGA-II</summary>

- *Xiangxiang Chu, Xinjie Yu*

- `1811.12667v1` - [abs](http://arxiv.org/abs/1811.12667v1) - [pdf](http://arxiv.org/pdf/1811.12667v1)

> Non-dominated sorting genetic algorithm II (NSGA-II) does well in dealing with multi-objective problems. When evaluating validity of an algorithm for multi-objective problems, two kinds of indices are often considered simultaneously, i.e. the convergence to Pareto Front and the distribution characteristic. The crowding distance in the standard NSGA-II has the property that solutions within a cubic have the same crowding distance, which has no contribution to the convergence of the algorithm. Actually the closer to the Pareto Front a solution is, the higher priority it should have. In the paper, the crowding distance is redefined while keeping almost all the advantages of the original one. Moreover, the speed of converging to the Pareto Front is faster. Finally, the improvement is proved to be effective by applying it to solve nine Benchmark problems.

</details>

<details>

<summary>2018-11-30 09:48:48 - Deep Within-Class Covariance Analysis for Robust Audio Representation Learning</summary>

- *Hamid Eghbal-zadeh, Matthias Dorfer, Gerhard Widmer*

- `1711.04022v2` - [abs](http://arxiv.org/abs/1711.04022v2) - [pdf](http://arxiv.org/pdf/1711.04022v2)

> Convolutional Neural Networks (CNNs) can learn effective features, though have been shown to suffer from a performance drop when the distribution of the data changes from training to test data. In this paper we analyze the internal representations of CNNs and observe that the representations of unseen data in each class, spread more (with higher variance) in the embedding space of the CNN compared to representations of the training data. More importantly, this difference is more extreme if the unseen data comes from a shifted distribution. Based on this observation, we objectively evaluate the degree of representation's variance in each class via eigenvalue decomposition on the within-class covariance of the internal representations of CNNs and observe the same behaviour. This can be problematic as larger variances might lead to mis-classification if the sample crosses the decision boundary of its class. We apply nearest neighbor classification on the representations and empirically show that the embeddings with the high variance actually have significantly worse KNN classification performances, although this could not be foreseen from their end-to-end classification results. To tackle this problem, we propose Deep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that significantly reduces the within-class covariance of a DNN's representation, improving performance on unseen test data from a shifted distribution. We empirically evaluate DWCCA on two datasets for Acoustic Scene Classification (DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA significantly improve the network's internal representation, it also increases the end-to-end classification accuracy, especially when the test set exhibits a distribution shift. By adding DWCCA to a VGG network, we achieve around 6 percentage points improvement in the case of a distribution mismatch.

</details>

<details>

<summary>2018-11-30 10:10:05 - Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces</summary>

- *Motoya Ohnishi, Masahiro Yukawa, Mikael Johansson, Masashi Sugiyama*

- `1806.02985v3` - [abs](http://arxiv.org/abs/1806.02985v3) - [pdf](http://arxiv.org/pdf/1806.02985v3)

> Motivated by the success of reinforcement learning (RL) for discrete-time tasks such as AlphaGo and Atari games, there has been a recent surge of interest in using RL for continuous-time control of physical systems (cf. many challenging tasks in OpenAI Gym and DeepMind Control Suite). Since discretization of time is susceptible to error, it is methodologically more desirable to handle the system dynamics directly in continuous time. However, very few techniques exist for continuous-time RL and they lack flexibility in value function approximation. In this paper, we propose a novel framework for model-based continuous-time value function approximation in reproducing kernel Hilbert spaces. The resulting framework is so flexible that it can accommodate any kind of kernel-based approach, such as Gaussian processes and kernel adaptive filters, and it allows us to handle uncertainties and nonstationarity without prior knowledge about the environment or what basis functions to employ. We demonstrate the validity of the presented framework through experiments.

</details>

<details>

<summary>2018-11-30 10:38:37 - Mapping Informal Settlements in Developing Countries with Multi-resolution, Multi-spectral Data</summary>

- *Patrick Helber, Bradley Gram-Hansen, Indhu Varatharajan, Faiza Azam, Alejandro Coca-Castro, Veronika Kopackova, Piotr Bilinski*

- `1812.00812v1` - [abs](http://arxiv.org/abs/1812.00812v1) - [pdf](http://arxiv.org/pdf/1812.00812v1)

> Detecting and mapping informal settlements encompasses several of the United Nations sustainable development goals. This is because informal settlements are home to the most socially and economically vulnerable people on the planet. Thus, understanding where these settlements are is of paramount importance to both government and non-government organizations (NGOs), such as the United Nations Children's Fund (UNICEF), who can use this information to deliver effective social and economic aid. We propose two effective methods for detecting and mapping the locations of informal settlements. One uses only low-resolution (LR), freely available, Sentinel-2 multispectral satellite imagery with noisy annotations, whilst the other is a deep learning approach that uses only costly very-high-resolution (VHR) satellite imagery. To our knowledge, we are the first to map informal settlements successfully with low-resolution satellite imagery. We extensively evaluate and compare the proposed methods. Please find additional material at https://frontierdevelopmentlab.github.io/informal-settlements/.

</details>

<details>

<summary>2018-11-30 10:52:08 - Inverse Reinforcement Learning via Nonparametric Spatio-Temporal Subgoal Modeling</summary>

- *Adrian Šošić, Elmar Rueckert, Jan Peters, Abdelhak M. Zoubir, Heinz Koeppl*

- `1803.00444v3` - [abs](http://arxiv.org/abs/1803.00444v3) - [pdf](http://arxiv.org/pdf/1803.00444v3)

> Advances in the field of inverse reinforcement learning (IRL) have led to sophisticated inference frameworks that relax the original modeling assumption of observing an agent behavior that reflects only a single intention. Instead of learning a global behavioral model, recent IRL methods divide the demonstration data into parts, to account for the fact that different trajectories may correspond to different intentions, e.g., because they were generated by different domain experts. In this work, we go one step further: using the intuitive concept of subgoals, we build upon the premise that even a single trajectory can be explained more efficiently locally within a certain context than globally, enabling a more compact representation of the observed behavior. Based on this assumption, we build an implicit intentional model of the agent's goals to forecast its behavior in unobserved situations. The result is an integrated Bayesian prediction framework that significantly outperforms existing IRL solutions and provides smooth policy estimates consistent with the expert's plan. Most notably, our framework naturally handles situations where the intentions of the agent change over time and classical IRL algorithms fail. In addition, due to its probabilistic nature, the model can be straightforwardly applied in active learning scenarios to guide the demonstration process of the expert.

</details>

<details>

<summary>2018-11-30 13:31:04 - A Tutorial for Weighted Bipolar Argumentation with Continuous Dynamical Systems and the Java Library Attractor</summary>

- *Nico Potyka*

- `1811.12787v1` - [abs](http://arxiv.org/abs/1811.12787v1) - [pdf](http://arxiv.org/pdf/1811.12787v1)

> Weighted bipolar argumentation frameworks allow modeling decision problems and online discussions by defining arguments and their relationships. The strength of arguments can be computed based on an initial weight and the strength of attacking and supporting arguments. While previous approaches assumed an acyclic argumentation graph and successively set arguments' strength based on the strength of their parents, recently continuous dynamical systems have been proposed as an alternative. Continuous models update arguments' strength simultaneously and continuously. While there are currently no analytical guarantees for convergence in general graphs, experiments show that continuous models can converge quickly in large cyclic graphs with thousands of arguments. Here, we focus on the high-level ideas of this approach and explain key results and applications. We also introduce Attractor, a Java library that can be used to solve weighted bipolar argumentation problems. Attractor contains implementations of several discrete and continuous models and numerical algorithms to compute solutions. It also provides base classes that can be used to implement, to evaluate and to compare continuous models easily.

</details>

<details>

<summary>2018-11-30 14:38:05 - Runtime Analysis for Self-adaptive Mutation Rates</summary>

- *Benjamin Doerr, Carsten Witt, Jing Yang*

- `1811.12824v1` - [abs](http://arxiv.org/abs/1811.12824v1) - [pdf](http://arxiv.org/pdf/1811.12824v1)

> We propose and analyze a self-adaptive version of the $(1,\lambda)$ evolutionary algorithm in which the current mutation rate is part of the individual and thus also subject to mutation. A rigorous runtime analysis on the OneMax benchmark function reveals that a simple local mutation scheme for the rate leads to an expected optimization time (number of fitness evaluations) of $O(n\lambda/\log\lambda+n\log n)$ when $\lambda$ is at least $C \ln n$ for some constant $C > 0$. For all values of $\lambda \ge C \ln n$, this performance is asymptotically best possible among all $\lambda$-parallel mutation-based unbiased black-box algorithms.   Our result shows that self-adaptation in evolutionary computation can find complex optimal parameter settings on the fly. At the same time, it proves that a relatively complicated self-adjusting scheme for the mutation rate proposed by Doerr, Gie{\ss}en, Witt, and Yang~(GECCO~2017) can be replaced by our simple endogenous scheme.   On the technical side, the paper contributes new tools for the analysis of two-dimensional drift processes arising in the analysis of dynamic parameter choices in EAs, including bounds on occupation probabilities in processes with non-constant drift.

</details>

<details>

<summary>2018-11-30 14:47:47 - A Storm in an IoT Cup: The Emergence of Cyber-Physical Social Machines</summary>

- *Aastha Madaan, Jason R. C. Nurse, David De Roure, Kieron O'Hara, Wendy Hall, Sadie Creese*

- `1809.05904v2` - [abs](http://arxiv.org/abs/1809.05904v2) - [pdf](http://arxiv.org/pdf/1809.05904v2)

> The concept of social machines is increasingly being used to characterise various socio-cognitive spaces on the Web. Social machines are human collectives using networked digital technology which initiate real-world processes and activities including human communication, interactions and knowledge creation. As such, they continuously emerge and fade on the Web. The relationship between humans and machines is made more complex by the adoption of Internet of Things (IoT) sensors and devices. The scale, automation, continuous sensing, and actuation capabilities of these devices add an extra dimension to the relationship between humans and machines making it difficult to understand their evolution at either the systemic or the conceptual level. This article describes these new socio-technical systems, which we term Cyber-Physical Social Machines, through different exemplars, and considers the associated challenges of security and privacy.

</details>

<details>

<summary>2018-11-30 15:59:27 - Playing hard exploration games by watching YouTube</summary>

- *Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang, Nando de Freitas*

- `1805.11592v2` - [abs](http://arxiv.org/abs/1805.11592v2) - [pdf](http://arxiv.org/pdf/1805.11592v2)

> Deep reinforcement learning methods traditionally struggle with tasks where environment rewards are particularly sparse. One successful method of guiding exploration in these domains is to imitate trajectories provided by a human demonstrator. However, these demonstrations are typically collected under artificial conditions, i.e. with access to the agent's exact environment setup and the demonstrator's action and reward trajectories. Here we propose a two-stage method that overcomes these limitations by relying on noisy, unaligned footage without access to such data. First, we learn to map unaligned videos from multiple sources to a common representation using self-supervised objectives constructed over both time and modality (i.e. vision and sound). Second, we embed a single YouTube video in this representation to construct a reward function that encourages an agent to imitate human gameplay. This method of one-shot imitation allows our agent to convincingly exceed human-level performance on the infamously hard exploration games Montezuma's Revenge, Pitfall! and Private Eye for the first time, even if the agent is not presented with any environment rewards.

</details>

<details>

<summary>2018-11-30 17:01:48 - Flexible and Scalable State Tracking Framework for Goal-Oriented Dialogue Systems</summary>

- *Rahul Goel, Shachi Paul, Tagyoung Chung, Jeremie Lecomte, Arindam Mandal, Dilek Hakkani-Tur*

- `1811.12891v1` - [abs](http://arxiv.org/abs/1811.12891v1) - [pdf](http://arxiv.org/pdf/1811.12891v1)

> Goal-oriented dialogue systems typically rely on components specifically developed for a single task or domain. This limits such systems in two different ways: If there is an update in the task domain, the dialogue system usually needs to be updated or completely re-trained. It is also harder to extend such dialogue systems to different and multiple domains. The dialogue state tracker in conventional dialogue systems is one such component - it is usually designed to fit a well-defined application domain. For example, it is common for a state variable to be a categorical distribution over a manually-predefined set of entities (Henderson et al., 2013), resulting in an inflexible and hard-to-extend dialogue system. In this paper, we propose a new approach for dialogue state tracking that can generalize well over multiple domains without incorporating any domain-specific knowledge. Under this framework, discrete dialogue state variables are learned independently and the information of a predefined set of possible values for dialogue state variables is not required. Furthermore, it enables adding arbitrary dialogue context as features and allows for multiple values to be associated with a single state variable. These characteristics make it much easier to expand the dialogue state space. We evaluate our framework using the widely used dialogue state tracking challenge data set (DSTC2) and show that our framework yields competitive results with other state-of-the-art results despite incorporating little domain knowledge. We also show that this framework can benefit from widely available external resources such as pre-trained word embeddings.

</details>

<details>

<summary>2018-11-30 17:18:53 - Unsupervised Domain Adaptation using Regularized Hyper-graph Matching</summary>

- *Debasmit Das, C. S. George Lee*

- `1805.08874v2` - [abs](http://arxiv.org/abs/1805.08874v2) - [pdf](http://arxiv.org/pdf/1805.08874v2)

> Domain adaptation (DA) addresses the real-world image classification problem of discrepancy between training (source) and testing (target) data distributions. We propose an unsupervised DA method that considers the presence of only unlabelled data in the target domain. Our approach centers on finding matches between samples of the source and target domains. The matches are obtained by treating the source and target domains as hyper-graphs and carrying out a class-regularized hyper-graph matching using first-, second- and third-order similarities between the graphs. We have also developed a computationally efficient algorithm by initially selecting a subset of the samples to construct a graph and then developing a customized optimization routine for graph-matching based on Conditional Gradient and Alternating Direction Multiplier Method. This allows the proposed method to be used widely. We also performed a set of experiments on standard object recognition datasets to validate the effectiveness of our framework over state-of-the-art approaches.

</details>

<details>

<summary>2018-11-30 18:04:19 - Automated Tactical Decision Planning Model with Strategic Values Guidance for Local Action-Value-Ambiguity</summary>

- *Daniel Muller, Erez Karpas*

- `1811.12917v1` - [abs](http://arxiv.org/abs/1811.12917v1) - [pdf](http://arxiv.org/pdf/1811.12917v1)

> In many real-world planning problems, action's impact differs with a place, time and the context in which the action is applied. The same action with the same effects in a different context or states can cause a different change. In actions with incomplete precondition list, that applicable in several states and circumstances, ambiguity regarding the impact of the action is challenging even in small domains. To estimate the real impact of actions, an evaluation of the effect list will not be enough; a relative estimation is more informative and suitable for estimation of action's real impact. Recent work on Over-subscription Planning (OSP) defined the net utility of action as the net change in the state's value caused by the action. The notion of net utility of action allows for a broader perspective on value action impact and use for a more accurate evaluation of achievements of the action, considering inter-state and intra-state dependencies. To achieve value-rational decisions in complex reality often requires strategic, high level, planning with a global perspective and values, while many local tactical decisions require real-time information to estimate the impact of actions. This paper proposes an offline action-value structure analysis to exploit the compactly represented informativeness of net utility of actions to extend the scope of planning to value uncertainty scenarios and to provide a real-time value-rational decision planning tool. The result of the offline pre-processing phase is a compact decision planning model representation for flexible, local reasoning of net utility of actions with (offline) value ambiguity. The obtained flexibility is beneficial for the online planning phase and real-time execution of actions with value ambiguity. Our empirical evaluation shows the effectiveness of this approach in domains with value ambiguity in their action-value-structure.

</details>

<details>

<summary>2018-11-30 18:51:16 - Improving Traffic Safety Through Video Analysis in Jakarta, Indonesia</summary>

- *João Caldeira, Alex Fout, Aniket Kesari, Raesetje Sefala, Joseph Walsh, Katy Dupre, Muhammad Rizal Khaefi, Setiaji, George Hodge, Zakiya Aryana Pramestri, Muhammad Adib Imtiyazi*

- `1812.01106v1` - [abs](http://arxiv.org/abs/1812.01106v1) - [pdf](http://arxiv.org/pdf/1812.01106v1)

> This project presents the results of a partnership between the Data Science for Social Good fellowship, Jakarta Smart City and Pulse Lab Jakarta to create a video analysis pipeline for the purpose of improving traffic safety in Jakarta. The pipeline transforms raw traffic video footage into databases that are ready to be used for traffic analysis. By analyzing these patterns, the city of Jakarta will better understand how human behavior and built infrastructure contribute to traffic challenges and safety risks. The results of this work should also be broadly applicable to smart city initiatives around the globe as they improve urban planning and sustainability through data science approaches.

</details>

<details>

<summary>2018-11-30 19:12:04 - Modeling natural language emergence with integral transform theory and reinforcement learning</summary>

- *Bohdan Khomtchouk, Shyam Sudhakaran*

- `1812.01431v1` - [abs](http://arxiv.org/abs/1812.01431v1) - [pdf](http://arxiv.org/pdf/1812.01431v1)

> Zipf's law predicts a power-law relationship between word rank and frequency in language communication systems and has been widely reported in a variety of natural language processing applications. However, the emergence of natural language is often modeled as a function of bias between speaker and listener interests, which lacks a direct way of relating information-theoretic bias to Zipfian rank. A function of bias also serves as an unintuitive interpretation of the communicative effort exchanged between a speaker and a listener. We counter these shortcomings by proposing a novel integral transform and kernel for mapping communicative bias functions to corresponding word frequency-rank representations at any arbitrary phase transition point, resulting in a direct way to link communicative effort (modeled by speaker/listener bias) to specific vocabulary used (represented by word rank). We demonstrate the practical utility of our integral transform by showing how a change from bias to rank results in greater accuracy and performance at an image classification task for assigning word labels to images randomly subsampled from CIFAR10. We model this task as a reinforcement learning game between a speaker and listener and compare the relative impact of bias and Zipfian word rank on communicative performance (and accuracy) between the two agents.

</details>

<details>

<summary>2018-11-30 19:12:18 - Modulated Policy Hierarchies</summary>

- *Alexander Pashevich, Danijar Hafner, James Davidson, Rahul Sukthankar, Cordelia Schmid*

- `1812.00025v1` - [abs](http://arxiv.org/abs/1812.00025v1) - [pdf](http://arxiv.org/pdf/1812.00025v1)

> Solving tasks with sparse rewards is a main challenge in reinforcement learning. While hierarchical controllers are an intuitive approach to this problem, current methods often require manual reward shaping, alternating training phases, or manually defined sub tasks. We introduce modulated policy hierarchies (MPH), that can learn end-to-end to solve tasks from sparse rewards. To achieve this, we study different modulation signals and exploration for hierarchical controllers. Specifically, we find that communicating via bit-vectors is more efficient than selecting one out of multiple skills, as it enables mixing between them. To facilitate exploration, MPH uses its different time scales for temporally extended intrinsic motivation at each level of the hierarchy. We evaluate MPH on the robotics tasks of pushing and sparse block stacking, where it outperforms recent baselines.

</details>

<details>

<summary>2018-11-30 20:37:17 - Using Monte Carlo Tree Search as a Demonstrator within Asynchronous Deep RL</summary>

- *Bilal Kartal, Pablo Hernandez-Leal, Matthew E. Taylor*

- `1812.00045v1` - [abs](http://arxiv.org/abs/1812.00045v1) - [pdf](http://arxiv.org/pdf/1812.00045v1)

> Deep reinforcement learning (DRL) has achieved great successes in recent years with the help of novel methods and higher compute power. However, there are still several challenges to be addressed such as convergence to locally optimal policies and long training times. In this paper, firstly, we augment Asynchronous Advantage Actor-Critic (A3C) method with a novel self-supervised auxiliary task, i.e. \emph{Terminal Prediction}, measuring temporal closeness to terminal states, namely A3C-TP. Secondly, we propose a new framework where planning algorithms such as Monte Carlo tree search or other sources of (simulated) demonstrators can be integrated to asynchronous distributed DRL methods. Compared to vanilla A3C, our proposed methods both learn faster and converge to better policies on a two-player mini version of the Pommerman game.

</details>

<details>

<summary>2018-11-30 20:48:31 - Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger</summary>

- *Gabriel Synnaeve, Zeming Lin, Jonas Gehring, Dan Gant, Vegard Mella, Vasil Khalidov, Nicolas Carion, Nicolas Usunier*

- `1812.00054v1` - [abs](http://arxiv.org/abs/1812.00054v1) - [pdf](http://arxiv.org/pdf/1812.00054v1)

> We formulate the problem of defogging as state estimation and future state prediction from previous, partial observations in the context of real-time strategy games. We propose to employ encoder-decoder neural networks for this task, and introduce proxy tasks and baselines for evaluation to assess their ability of capturing basic game rules and high-level dynamics. By combining convolutional neural networks and recurrent networks, we exploit spatial and sequential correlations and train well-performing models on a large dataset of human games of StarCraft: Brood War. Finally, we demonstrate the relevance of our models to downstream tasks by applying them for enemy unit prediction in a state-of-the-art, rule-based StarCraft bot. We observe improvements in win rates against several strong community bots.

</details>

<details>

<summary>2018-11-30 21:16:03 - Towards Explainable Deep Learning for Credit Lending: A Case Study</summary>

- *Ceena Modarres, Mark Ibrahim, Melissa Louie, John Paisley*

- `1811.06471v2` - [abs](http://arxiv.org/abs/1811.06471v2) - [pdf](http://arxiv.org/pdf/1811.06471v2)

> Deep learning adoption in the financial services industry has been limited due to a lack of model interpretability. However, several techniques have been proposed to explain predictions made by a neural network. We provide an initial investigation into these techniques for the assessment of credit risk with neural networks.

</details>

<details>

<summary>2018-11-30 22:18:45 - Scalable Graph Learning for Anti-Money Laundering: A First Look</summary>

- *Mark Weber, Jie Chen, Toyotaro Suzumura, Aldo Pareja, Tengfei Ma, Hiroki Kanezashi, Tim Kaler, Charles E. Leiserson, Tao B. Schardl*

- `1812.00076v1` - [abs](http://arxiv.org/abs/1812.00076v1) - [pdf](http://arxiv.org/pdf/1812.00076v1)

> Organized crime inflicts human suffering on a genocidal scale: the Mexican drug cartels have murdered 150,000 people since 2006, upwards of 700,000 people per year are "exported" in a human trafficking industry enslaving an estimated 40 million people. These nefarious industries rely on sophisticated money laundering schemes to operate. Despite tremendous resources dedicated to anti-money laundering (AML) only a tiny fraction of illicit activity is prevented. The research community can help. In this brief paper, we map the structural and behavioral dynamics driving the technical challenge. We review AML methods, current and emergent. We provide a first look at scalable graph convolutional neural networks for forensic analysis of financial data, which is massive, dense, and dynamic. We report preliminary experimental results using a large synthetic graph (1M nodes, 9M edges) generated by a data simulator we created called AMLSim. We consider opportunities for high performance efficiency, in terms of computation and memory, and we share results from a simple graph compression experiment. Our results support our working hypothesis that graph deep learning for AML bears great promise in the fight against criminal financial activity.

</details>

<details>

<summary>2018-11-30 23:18:08 - BlockPuzzle - A Challenge in Physical Reasoning and Generalization for Robot Learning</summary>

- *Yixiu Zhao, Ziyin Liu*

- `1812.00091v1` - [abs](http://arxiv.org/abs/1812.00091v1) - [pdf](http://arxiv.org/pdf/1812.00091v1)

> In this work we propose a novel task framework under which a variety of physical reasoning puzzles can be constructed using very simple rules. Under sparse reward settings, most of these tasks can be very challenging for a reinforcement learning agent to learn. We build several simple environments with this task framework in Mujoco and OpenAI gym and attempt to solve them. We are able to solve the environments by designing curricula to guide the agent in learning and using imitation learning methods to transfer knowledge from a simpler environment. This is only a first step for the task framework, and further research on how to solve the harder tasks and transfer knowledge between tasks is needed.

</details>


## 2018-12

<details>

<summary>2018-12-01 01:16:24 - Explore-Exploit: A Framework for Interactive and Online Learning</summary>

- *Honglei Liu, Anuj Kumar, Wenhai Yang, Benoit Dumoulin*

- `1812.00116v1` - [abs](http://arxiv.org/abs/1812.00116v1) - [pdf](http://arxiv.org/pdf/1812.00116v1)

> Interactive user interfaces need to continuously evolve based on the interactions that a user has (or does not have) with the system. This may require constant exploration of various options that the system may have for the user and obtaining signals of user preferences on those. However, such an exploration, especially when the set of available options itself can change frequently, can lead to sub-optimal user experiences. We present Explore-Exploit: a framework designed to collect and utilize user feedback in an interactive and online setting that minimizes regressions in end-user experience. This framework provides a suite of online learning operators for various tasks such as personalization ranking, candidate selection and active learning. We demonstrate how to integrate this framework with run-time services to leverage online and interactive machine learning out-of-the-box. We also present results demonstrating the efficiencies that can be achieved using the Explore-Exploit framework.

</details>

<details>

<summary>2018-12-01 08:13:48 - A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues</summary>

- *Zhouxing Shi, Minlie Huang*

- `1812.00176v1` - [abs](http://arxiv.org/abs/1812.00176v1) - [pdf](http://arxiv.org/pdf/1812.00176v1)

> Discourse structures are beneficial for various NLP tasks such as dialogue understanding, question answering, sentiment analysis, and so on. This paper presents a deep sequential model for parsing discourse dependency structures of multi-party dialogues. The proposed model aims to construct a discourse dependency tree by predicting dependency relations and constructing the discourse structure jointly and alternately. It makes a sequential scan of the Elementary Discourse Units (EDUs) in a dialogue. For each EDU, the model decides to which previous EDU the current one should link and what the corresponding relation type is. The predicted link and relation type are then used to build the discourse structure incrementally with a structured encoder. During link prediction and relation classification, the model utilizes not only local information that represents the concerned EDUs, but also global information that encodes the EDU sequence and the discourse structure that is already built at the current step. Experiments show that the proposed model outperforms all the state-of-the-art baselines.

</details>

<details>

<summary>2018-12-01 11:30:23 - Deep Learning Application in Security and Privacy -- Theory and Practice: A Position Paper</summary>

- *Julia A. Meister, Raja Naeem Akram, Konstantinos Markantonakis*

- `1812.00190v1` - [abs](http://arxiv.org/abs/1812.00190v1) - [pdf](http://arxiv.org/pdf/1812.00190v1)

> Technology is shaping our lives in a multitude of ways. This is fuelled by a technology infrastructure, both legacy and state of the art, composed of a heterogeneous group of hardware, software, services and organisations. Such infrastructure faces a diverse range of challenges to its operations that include security, privacy, resilience, and quality of services. Among these, cybersecurity and privacy are taking the centre-stage, especially since the General Data Protection Regulation (GDPR) came into effect. Traditional security and privacy techniques are overstretched and adversarial actors have evolved to design exploitation techniques that circumvent protection. With the ever-increasing complexity of technology infrastructure, security and privacy-preservation specialists have started to look for adaptable and flexible protection methods that can evolve (potentially autonomously) as the adversarial actor changes its techniques. For this, Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) were put forward as saviours. In this paper, we look at the promises of AI, ML, and DL stated in academic and industrial literature and evaluate how realistic they are. We also put forward potential challenges a DL based security and privacy protection technique has to overcome. Finally, we conclude the paper with a discussion on what steps the DL and the security and privacy-preservation community have to take to ensure that DL is not just going to be hype, but an opportunity to build a secure, reliable, and trusted technology infrastructure on which we can rely on for so much in our lives.

</details>

<details>

<summary>2018-12-01 12:13:55 - One for All: Neural Joint Modeling of Entities and Events</summary>

- *Trung Minh Nguyen, Thien Huu Nguyen*

- `1812.00195v1` - [abs](http://arxiv.org/abs/1812.00195v1) - [pdf](http://arxiv.org/pdf/1812.00195v1)

> The previous work for event extraction has mainly focused on the predictions for event triggers and argument roles, treating entity mentions as being provided by human annotators. This is unrealistic as entity mentions are usually predicted by some existing toolkits whose errors might be propagated to the event trigger and argument role recognition. Few of the recent work has addressed this problem by jointly predicting entity mentions, event triggers and arguments. However, such work is limited to using discrete engineering features to represent contextual information for the individual tasks and their interactions. In this work, we propose a novel model to jointly perform predictions for entity mentions, event triggers and arguments based on the shared hidden representations from deep learning. The experiments demonstrate the benefits of the proposed method, leading to the state-of-the-art performance for event extraction.

</details>

<details>

<summary>2018-12-01 18:31:11 - Fuzzy expert system for prediction of prostate cancer</summary>

- *Juthika Mahanta, Subhasis Panda*

- `1812.00236v1` - [abs](http://arxiv.org/abs/1812.00236v1) - [pdf](http://arxiv.org/pdf/1812.00236v1)

> A fuzzy expert system (FES) for the prediction of prostate cancer (PC) is prescribed in this article. Age, prostate-specific antigen (PSA), prostate volume (PV) and $\%$ Free PSA ($\%$FPSA) are fed as inputs into the FES and prostate cancer risk (PCR) is obtained as the output. Using knowledge based rules in Mamdani type inference method the output is calculated. If PCR $\ge 50\%$, then the patient shall be advised to go for a biopsy test for confirmation. The efficacy of the designed FES is tested against a clinical data set. The true prediction for all the patients turns out to be $68.91\%$ whereas only for positive biopsy cases it rises to $73.77\%$. This simple yet effective FES can be used as supportive tool for decision making in medical diagnosis.

</details>

<details>

<summary>2018-12-01 20:59:03 - Towards Gaussian Bayesian Network Fusion</summary>

- *Irene Córdoba, Concha Bielza, Pedro Larrañaga*

- `1812.00262v1` - [abs](http://arxiv.org/abs/1812.00262v1) - [pdf](http://arxiv.org/pdf/1812.00262v1)

> Data sets are growing in complexity thanks to the increasing facilities we have nowadays to both generate and store data. This poses many challenges to machine learning that are leading to the proposal of new methods and paradigms, in order to be able to deal with what is nowadays referred to as Big Data. In this paper we propose a method for the aggregation of different Bayesian network structures that have been learned from separate data sets, as a first step towards mining data sets that need to be partitioned in an horizontal way, i.e. with respect to the instances, in order to be processed. Considerations that should be taken into account when dealing with this situation are discussed. Scalable learning of Bayesian networks is slowly emerging, and our method constitutes one of the first insights into Gaussian Bayesian network aggregation from different sources. Tested on synthetic data it obtains good results that surpass those from individual learning. Future research will be focused on expanding the method and testing more diverse data sets.

</details>

<details>

<summary>2018-12-01 23:22:18 - Learning Curriculum Policies for Reinforcement Learning</summary>

- *Sanmit Narvekar, Peter Stone*

- `1812.00285v1` - [abs](http://arxiv.org/abs/1812.00285v1) - [pdf](http://arxiv.org/pdf/1812.00285v1)

> Curriculum learning in reinforcement learning is a training methodology that seeks to speed up learning of a difficult target task, by first training on a series of simpler tasks and transferring the knowledge acquired to the target task. Automatically choosing a sequence of such tasks (i.e. a curriculum) is an open problem that has been the subject of much recent work in this area. In this paper, we build upon a recent method for curriculum design, which formulates the curriculum sequencing problem as a Markov Decision Process. We extend this model to handle multiple transfer learning algorithms, and show for the first time that a curriculum policy over this MDP can be learned from experience. We explore various representations that make this possible, and evaluate our approach by learning curriculum policies for multiple agents in two different domains. The results show that our method produces curricula that can train agents to perform on a target task as fast or faster than existing methods.

</details>

<details>

<summary>2018-12-02 01:32:41 - Plenoptic Monte Carlo Object Localization for Robot Grasping under Layered Translucency</summary>

- *Zheming Zhou, Zhiqiang Sui, Odest Chadwicke Jenkins*

- `1806.09769v4` - [abs](http://arxiv.org/abs/1806.09769v4) - [pdf](http://arxiv.org/pdf/1806.09769v4)

> In order to fully function in human environments, robot perception will need to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL) as a method for localizing object poses in the presence of translucency using plenoptic (light-field) observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.

</details>

<details>

<summary>2018-12-02 02:07:06 - Plan-Recognition-Driven Attention Modeling for Visual Recognition</summary>

- *Yantian Zha, Yikang Li, Tianshu Yu, Subbarao Kambhampati, Baoxin Li*

- `1812.00301v1` - [abs](http://arxiv.org/abs/1812.00301v1) - [pdf](http://arxiv.org/pdf/1812.00301v1)

> Human visual recognition of activities or external agents involves an interplay between high-level plan recognition and low-level perception. Given that, a natural question to ask is: can low-level perception be improved by high-level plan recognition? We formulate the problem of leveraging recognized plans to generate better top-down attention maps \cite{gazzaniga2009,baluch2011} to improve the perception performance. We call these top-down attention maps specifically as plan-recognition-driven attention maps. To address this problem, we introduce the Pixel Dynamics Network. Pixel Dynamics Network serves as an observation model, which predicts next states of object points at each pixel location given observation of pixels and pixel-level action feature. This is like internally learning a pixel-level dynamics model. Pixel Dynamics Network is a kind of Convolutional Neural Network (ConvNet), with specially-designed architecture. Therefore, Pixel Dynamics Network could take the advantage of parallel computation of ConvNets, while learning the pixel-level dynamics model. We further prove the equivalence between Pixel Dynamics Network as an observation model, and the belief update in partially observable Markov decision process (POMDP) framework. We evaluate our Pixel Dynamics Network in event recognition tasks. We build an event recognition system, ER-PRN, which takes Pixel Dynamics Network as a subroutine, to recognize events based on observations augmented by plan-recognition-driven attention.

</details>

<details>

<summary>2018-12-02 03:58:33 - Efficiency and robustness in Monte Carlo sampling of 3-D geophysical inversions with Obsidian v0.1.2: Setting up for success</summary>

- *Richard Scalzo, David Kohn, Hugo Olierook, Gregory Houseman, Rohitash Chandra, Mark Girolami, Sally Cripps*

- `1812.00318v1` - [abs](http://arxiv.org/abs/1812.00318v1) - [pdf](http://arxiv.org/pdf/1812.00318v1)

> The rigorous quantification of uncertainty in geophysical inversions is a challenging problem. Inversions are often ill-posed and the likelihood surface may be multi-modal; properties of any single mode become inadequate uncertainty measures, and sampling methods become inefficient for irregular posteriors or high-dimensional parameter spaces. We explore the influences of different choices made by the practitioner on the efficiency and accuracy of Bayesian geophysical inversion methods that rely on Markov chain Monte Carlo sampling to assess uncertainty, using a multi-sensor inversion of the three-dimensional structure and composition of a region in the Cooper Basin of South Australia as a case study. The inversion is performed using an updated version of the Obsidian distributed inversion software. We find that the posterior for this inversion has complex local covariance structure, hindering the efficiency of adaptive sampling methods that adjust the proposal based on the chain history. Within the context of a parallel-tempered Markov chain Monte Carlo scheme for exploring high-dimensional multi-modal posteriors, a preconditioned Crank-Nicholson proposal outperforms more conventional forms of random walk. Aspects of the problem setup, such as priors on petrophysics or on 3-D geological structure, affect the shape and separation of posterior modes, influencing sampling performance as well as the inversion results. Use of uninformative priors on sensor noise can improve inversion results by enabling optimal weighting among multiple sensors even if noise levels are uncertain. Efficiency could be further increased by using posterior gradient information within proposals, which Obsidian does not currently support, but which could be emulated using posterior surrogates.

</details>

<details>

<summary>2018-12-02 05:02:51 - A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems</summary>

- *Ling Pan, Qingpeng Cai, Zhixuan Fang, Pingzhong Tang, Longbo Huang*

- `1802.04592v4` - [abs](http://arxiv.org/abs/1802.04592v4) - [pdf](http://arxiv.org/pdf/1802.04592v4)

> Bike sharing provides an environment-friendly way for traveling and is booming all over the world. Yet, due to the high similarity of user travel patterns, the bike imbalance problem constantly occurs, especially for dockless bike sharing systems, causing significant impact on service quality and company revenue. Thus, it has become a critical task for bike sharing systems to resolve such imbalance efficiently. In this paper, we propose a novel deep reinforcement learning framework for incentivizing users to rebalance such systems. We model the problem as a Markov decision process and take both spatial and temporal features into consideration. We develop a novel deep reinforcement learning algorithm called Hierarchical Reinforcement Pricing (HRP), which builds upon the Deep Deterministic Policy Gradient algorithm. Different from existing methods that often ignore spatial information and rely heavily on accurate prediction, HRP captures both spatial and temporal dependencies using a divide-and-conquer structure with an embedded localized module. We conduct extensive experiments to evaluate HRP, based on a dataset from Mobike, a major Chinese dockless bike sharing company. Results show that HRP performs close to the 24-timeslot look-ahead optimization, and outperforms state-of-the-art methods in both service level and bike distribution. It also transfers well when applied to unseen areas.

</details>

<details>

<summary>2018-12-02 07:42:21 - Disentangled Variational Auto-Encoder for Semi-supervised Learning</summary>

- *Yang Li, Quan Pan, Suhang Wang, Haiyun Peng, Tao Yang, Erik Cambria*

- `1709.05047v2` - [abs](http://arxiv.org/abs/1709.05047v2) - [pdf](http://arxiv.org/pdf/1709.05047v2)

> Semi-supervised learning is attracting increasing attention due to the fact that datasets of many domains lack enough labeled data. Variational Auto-Encoder (VAE), in particular, has demonstrated the benefits of semi-supervised learning. The majority of existing semi-supervised VAEs utilize a classifier to exploit label information, where the parameters of the classifier are introduced to the VAE. Given the limited labeled data, learning the parameters for the classifiers may not be an optimal solution for exploiting label information. Therefore, in this paper, we develop a novel approach for semi-supervised VAE without classifier. Specifically, we propose a new model called Semi-supervised Disentangled VAE (SDVAE), which encodes the input data into disentangled representation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via the equality constraint. To further enhance the feature learning ability of the proposed VAE, we incorporate reinforcement learning to relieve the lack of data. The dynamic framework is capable of dealing with both image and text data with its corresponding encoder and decoder networks. Extensive experiments on image and text datasets demonstrate the effectiveness of the proposed framework.

</details>

<details>

<summary>2018-12-02 08:03:12 - A Study on Dialogue Reward Prediction for Open-Ended Conversational Agents</summary>

- *Heriberto Cuayáhuitl, Seonghan Ryu, Donghyeon Lee, Jihie Kim*

- `1812.00350v1` - [abs](http://arxiv.org/abs/1812.00350v1) - [pdf](http://arxiv.org/pdf/1812.00350v1)

> The amount of dialogue history to include in a conversational agent is often underestimated and/or set in an empirical and thus possibly naive way. This suggests that principled investigations into optimal context windows are urgently needed given that the amount of dialogue history and corresponding representations can play an important role in the overall performance of a conversational system. This paper studies the amount of history required by conversational agents for reliably predicting dialogue rewards. The task of dialogue reward prediction is chosen for investigating the effects of varying amounts of dialogue history and their impact on system performance. Experimental results using a dataset of 18K human-human dialogues report that lengthy dialogue histories of at least 10 sentences are preferred (25 sentences being the best in our experiments) over short ones, and that lengthy histories are useful for training dialogue reward predictors with strong positive correlations between target dialogue rewards and predicted ones.

</details>

<details>

<summary>2018-12-02 13:01:22 - Bayesian Deep Learning for Exoplanet Atmospheric Retrieval</summary>

- *Frank Soboczenski, Michael D. Himes, Molly D. O'Beirne, Simone Zorzan, Atilim Gunes Baydin, Adam D. Cobb, Yarin Gal, Daniel Angerhausen, Massimo Mascaro, Giada N. Arney, Shawn D. Domagal-Goldman*

- `1811.03390v2` - [abs](http://arxiv.org/abs/1811.03390v2) - [pdf](http://arxiv.org/pdf/1811.03390v2)

> Over the past decade, the study of extrasolar planets has evolved rapidly from plain detection and identification to comprehensive categorization and characterization of exoplanet systems and their atmospheres. Atmospheric retrieval, the inverse modeling technique used to determine an exoplanetary atmosphere's temperature structure and composition from an observed spectrum, is both time-consuming and compute-intensive, requiring complex algorithms that compare thousands to millions of atmospheric models to the observational data to find the most probable values and associated uncertainties for each model parameter. For rocky, terrestrial planets, the retrieved atmospheric composition can give insight into the surface fluxes of gaseous species necessary to maintain the stability of that atmosphere, which may in turn provide insight into the geological and/or biological processes active on the planet. These atmospheres contain many molecules, some of them biosignatures, spectral fingerprints indicative of biological activity, which will become observable with the next generation of telescopes. Runtimes of traditional retrieval models scale with the number of model parameters, so as more molecular species are considered, runtimes can become prohibitively long. Recent advances in machine learning (ML) and computer vision offer new ways to reduce the time to perform a retrieval by orders of magnitude, given a sufficient data set to train with. Here we present an ML-based retrieval framework called Intelligent exoplaNet Atmospheric RetrievAl (INARA) that consists of a Bayesian deep learning model for retrieval and a data set of 3,000,000 synthetic rocky exoplanetary spectra generated using the NASA Planetary Spectrum Generator. Our work represents the first ML retrieval model for rocky, terrestrial exoplanets and the first synthetic data set of terrestrial spectra generated at this scale.

</details>

<details>

<summary>2018-12-02 15:27:40 - Discovering Power Laws in Entity Length</summary>

- *Xiaoshi Zhong, Erik Cambria, Jagath C. Rajapakse*

- `1811.03325v3` - [abs](http://arxiv.org/abs/1811.03325v3) - [pdf](http://arxiv.org/pdf/1811.03325v3)

> This paper presents a discovery that the length of the entities in various datasets follows a family of scale-free power law distributions. The concept of entity here broadly includes the named entity, entity mention, time expression, aspect term, and domain-specific entity that are well investigated in natural language processing and related areas. The entity length denotes the number of words in an entity. The power law distributions in entity length possess the scale-free property and have well-defined means and finite variances. We explain the phenomenon of power laws in entity length by the principle of least effort in communication and the preferential mechanism.

</details>

<details>

<summary>2018-12-02 22:18:56 - Constructing Unrestricted Adversarial Examples with Generative Models</summary>

- *Yang Song, Rui Shu, Nate Kushman, Stefano Ermon*

- `1805.07894v4` - [abs](http://arxiv.org/abs/1805.07894v4) - [pdf](http://arxiv.org/pdf/1805.07894v4)

> Adversarial examples are typically constructed by perturbing an existing data point within a small matrix norm, and current defense methods are focused on guarding against this type of attack. In this paper, we propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations. Different from perturbation-based attacks, we propose to synthesize unrestricted adversarial examples entirely from scratch using conditional generative models. Specifically, we first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over data samples. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that unrestricted adversarial examples generated this way are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that unrestricted adversarial examples can bypass strong adversarial training and certified defense methods designed for traditional adversarial attacks.

</details>

<details>

<summary>2018-12-03 00:30:59 - Deep Learning Architect: Classification for Architectural Design through the Eye of Artificial Intelligence</summary>

- *Yuji Yoshimura, Bill Cai, Zhoutong Wang, Carlo Ratti*

- `1812.01714v1` - [abs](http://arxiv.org/abs/1812.01714v1) - [pdf](http://arxiv.org/pdf/1812.01714v1)

> This paper applies state-of-the-art techniques in deep learning and computer vision to measure visual similarities between architectural designs by different architects. Using a dataset consisting of web scraped images and an original collection of images of architectural works, we first train a deep convolutional neural network (DCNN) model capable of achieving 73% accuracy in classifying works belonging to 34 different architects. Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model. Using this measure, we cluster architects that are identified to be similar and compare our findings to conventional classification made by architectural historians and theorists. Our clustering of architectural designs remarkably corroborates conventional views in architectural history, and the learned architectural features also coheres with the traditional understanding of architectural designs.

</details>

<details>

<summary>2018-12-03 02:26:35 - Generalization in anti-causal learning</summary>

- *Niki Kilbertus, Giambattista Parascandolo, Bernhard Schölkopf*

- `1812.00524v1` - [abs](http://arxiv.org/abs/1812.00524v1) - [pdf](http://arxiv.org/pdf/1812.00524v1)

> The ability to learn and act in novel situations is still a prerogative of animate intelligence, as current machine learning methods mostly fail when moving beyond the standard i.i.d. setting. What is the reason for this discrepancy? Most machine learning tasks are anti-causal, i.e., we infer causes (labels) from effects (observations). Typically, in supervised learning we build systems that try to directly invert causal mechanisms. Instead, in this paper we argue that strong generalization capabilities crucially hinge on searching and validating meaningful hypotheses, requiring access to a causal model. In such a framework, we want to find a cause that leads to the observed effect. Anti-causal models are used to drive this search, but a causal model is required for validation. We investigate the fundamental differences between causal and anti-causal tasks, discuss implications for topics ranging from adversarial attacks to disentangling factors of variation, and provide extensive evidence from the literature to substantiate our view. We advocate for incorporating causal models in supervised learning to shift the paradigm from inference only, to search and validation.

</details>

<details>

<summary>2018-12-03 03:38:20 - Exploiting Wireless Channel State Information Structures Beyond Linear Correlations: A Deep Learning Approach</summary>

- *Zhiyuan Jiang, Sheng Chen, Andreas F. Molisch, Rath Vannithamby, Sheng Zhou, Zhisheng Niu*

- `1812.00541v1` - [abs](http://arxiv.org/abs/1812.00541v1) - [pdf](http://arxiv.org/pdf/1812.00541v1)

> Knowledge of information about the propagation channel in which a wireless system operates enables better, more efficient approaches for signal transmissions. Therefore, channel state information (CSI) plays a pivotal role in the system performance. The importance of CSI is in fact growing in the upcoming 5G and beyond systems, e.g., for the implementation of massive multiple-input multiple-output (MIMO). However, the acquisition of timely and accurate CSI has long been considered as a major issue, and becomes increasingly challenging due to the need for obtaining CSI of many antenna elements in massive MIMO systems. To cope with this challenge, existing works mainly focus on exploiting linear structures of CSI, such as CSI correlations in the spatial domain, to achieve dimensionality reduction. In this article, we first systematically review the state-of-the-art on CSI structure exploitation; then extend to seek for deeper structures that enable remote CSI inference wherein a data-driven deep neural network (DNN) approach is necessary due to model inadequacy. We develop specific DNN designs suitable for CSI data. Case studies are provided to demonstrate great potential in this direction for future performance enhancement.

</details>

<details>

<summary>2018-12-03 05:00:07 - SUSAN: Segment Unannotated image Structure using Adversarial Network</summary>

- *Fang Liu*

- `1812.00555v1` - [abs](http://arxiv.org/abs/1812.00555v1) - [pdf](http://arxiv.org/pdf/1812.00555v1)

> Segmentation of magnetic resonance (MR) images is a fundamental step in many medical imaging-based applications. The recent implementation of deep convolutional neural networks (CNNs) in image processing has been shown to have significant impacts on medical image segmentation. Network training of segmentation CNNs typically requires images and paired annotation data representing pixel-wise tissue labels referred to as masks. However, the supervised training of highly efficient CNNs with deeper structure and more network parameters requires a large number of training images and paired tissue masks. Thus, there is great need to develop a generalized CNN-based segmentation method which would be applicable for a wide variety of MR image datasets with different tissue contrasts. The purpose of this study was to develop and evaluate a generalized CNN-based method for fully-automated segmentation of different MR image datasets using a single set of annotated training data. A technique called cycle-consistent generative adversarial network (CycleGAN) is applied as the core of the proposed method to perform image-to-image translation between MR image datasets with different tissue contrasts. A joint segmentation network is incorporated into the adversarial network to obtain additional segmentation functionality. The proposed method was evaluated for segmenting bone and cartilage on two clinical knee MR image datasets acquired at our institution using only a single set of annotated data from a publicly available knee MR image dataset. The new technique may further improve the applicability and efficiency of CNN-based segmentation of medical images while eliminating the need for large amounts of annotated training data.

</details>

<details>

<summary>2018-12-03 06:06:25 - Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control</summary>

- *Frederik Ebert, Chelsea Finn, Sudeep Dasari, Annie Xie, Alex Lee, Sergey Levine*

- `1812.00568v1` - [abs](http://arxiv.org/abs/1812.00568v1) - [pdf](http://arxiv.org/pdf/1812.00568v1)

> Deep reinforcement learning (RL) algorithms can learn complex robotic skills from raw sensory inputs, but have yet to achieve the kind of broad generalization and applicability demonstrated by deep learning methods in supervised domains. We present a deep RL method that is practical for real-world robotics tasks, such as robotic manipulation, and generalizes effectively to never-before-seen tasks and objects. In these settings, ground truth reward signals are typically unavailable, and we therefore propose a self-supervised model-based approach, where a predictive model learns to directly predict the future from raw sensory readings, such as camera images. At test time, we explore three distinct goal specification methods: designated pixels, where a user specifies desired object manipulation tasks by selecting particular pixels in an image and corresponding goal positions, goal images, where the desired goal state is specified with an image, and image classifiers, which define spaces of goal states. Our deep predictive models are trained using data collected autonomously and continuously by a robot interacting with hundreds of objects, without human supervision. We demonstrate that visual MPC can generalize to never-before-seen objects---both rigid and deformable---and solve a range of user-defined object manipulation tasks using the same model.

</details>

<details>

<summary>2018-12-03 06:54:48 - MONAS: Multi-Objective Neural Architecture Search using Reinforcement Learning</summary>

- *Chi-Hung Hsu, Shu-Huan Chang, Jhao-Hong Liang, Hsin-Ping Chou, Chun-Hao Liu, Shih-Chieh Chang, Jia-Yu Pan, Yu-Ting Chen, Wei Wei, Da-Cheng Juan*

- `1806.10332v2` - [abs](http://arxiv.org/abs/1806.10332v2) - [pdf](http://arxiv.org/pdf/1806.10332v2)

> Recent studies on neural architecture search have shown that automatically designed neural networks perform as good as expert-crafted architectures. While most existing works aim at finding architectures that optimize the prediction accuracy, these architectures may have complexity and is therefore not suitable being deployed on certain computing environment (e.g., with limited power budgets). We propose MONAS, a framework for Multi-Objective Neural Architectural Search that employs reward functions considering both prediction accuracy and other important objectives (e.g., power consumption) when searching for neural network architectures. Experimental results showed that, compared to the state-ofthe-arts, models found by MONAS achieve comparable or better classification accuracy on computer vision applications, while satisfying the additional objectives such as peak power.

</details>

<details>

<summary>2018-12-03 07:08:37 - Binary Ensemble Neural Network: More Bits per Network or More Networks per Bit?</summary>

- *Shilin Zhu, Xin Dong, Hao Su*

- `1806.07550v2` - [abs](http://arxiv.org/abs/1806.07550v2) - [pdf](http://arxiv.org/pdf/1806.07550v2)

> Binary neural networks (BNN) have been studied extensively since they run dramatically faster at lower memory and power consumption than floating-point networks, thanks to the efficiency of bit operations. However, contemporary BNNs whose weights and activations are both single bits suffer from severe accuracy degradation. To understand why, we investigate the representation ability, speed and bias/variance of BNNs through extensive experiments. We conclude that the error of BNNs is predominantly caused by the intrinsic instability (training time) and non-robustness (train & test time). Inspired by this investigation, we propose the Binary Ensemble Neural Network (BENN) which leverages ensemble methods to improve the performance of BNNs with limited efficiency cost. While ensemble techniques have been broadly believed to be only marginally helpful for strong classifiers such as deep neural networks, our analyses and experiments show that they are naturally a perfect fit to boost BNNs. We find that our BENN, which is faster and much more robust than state-of-the-art binary networks, can even surpass the accuracy of the full-precision floating number network with the same architecture.

</details>

<details>

<summary>2018-12-03 07:11:32 - Investigating Human + Machine Complementarity for Recidivism Predictions</summary>

- *Sarah Tan, Julius Adebayo, Kori Inkpen, Ece Kamar*

- `1808.09123v2` - [abs](http://arxiv.org/abs/1808.09123v2) - [pdf](http://arxiv.org/pdf/1808.09123v2)

> When might human input help (or not) when assessing risk in fairness domains? Dressel and Farid (2018) asked Mechanical Turk workers to evaluate a subset of defendants in the ProPublica COMPAS data for risk of recidivism, and concluded that COMPAS predictions were no more accurate or fair than predictions made by humans. We delve deeper into this claim to explore differences in human and algorithmic decision making. We construct a Human Risk Score based on the predictions made by multiple Turk workers, characterize the features that determine agreement and disagreement between COMPAS and Human Scores, and construct hybrid Human+Machine models to predict recidivism. Our key finding is that on this data set, Human and COMPAS decision making differed, but not in ways that could be leveraged to significantly improve ground-truth prediction. We present the results of our analyses and suggestions for data collection best practices to leverage complementary strengths of human and machines in the fairness domain.

</details>

<details>

<summary>2018-12-03 09:10:53 - An Introduction to Deep Reinforcement Learning</summary>

- *Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G. Bellemare, Joelle Pineau*

- `1811.12560v2` - [abs](http://arxiv.org/abs/1811.12560v2) - [pdf](http://arxiv.org/pdf/1811.12560v2)

> Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.

</details>

<details>

<summary>2018-12-03 09:29:03 - Protection of an information system by artificial intelligence: a three-phase approach based on behaviour analysis to detect a hostile scenario</summary>

- *Jean-Philippe Fauvelle, Alexandre Dey, Sylvain Navers*

- `1812.00622v1` - [abs](http://arxiv.org/abs/1812.00622v1) - [pdf](http://arxiv.org/pdf/1812.00622v1)

> The analysis of the behaviour of individuals and entities (UEBA) is an area of artificial intelligence that detects hostile actions (e.g. attacks, fraud, influence, poisoning) due to the unusual nature of observed events, by affixing to a signature-based operation. A UEBA process usually involves two phases, learning and inference. Intrusion detection systems (IDS) available still suffer from bias, including over-simplification of problems, underexploitation of the AI potential, insufficient consideration of the temporality of events, and perfectible management of the memory cycle of behaviours. In addition, while an alert generated by a signature-based IDS can refer to the signature on which the detection is based, the IDS in the UEBA domain produce results, often associated with a score, whose explainable character is less obvious. Our unsupervised approach is to enrich this process by adding a third phase to correlate events (incongruities, weak signals) that are presumed to be linked together, with the benefit of a reduction of false positives and negatives. We also seek to avoid a so-called "boiled frog" bias inherent in continuous learning. Our first results are interesting and have an explainable character, both on synthetic and real data.

</details>

<details>

<summary>2018-12-03 10:34:01 - Deep Hierarchical Machine: a Flexible Divide-and-Conquer Architecture</summary>

- *Shichao Li, Xin Yang, Tim Cheng*

- `1812.00647v1` - [abs](http://arxiv.org/abs/1812.00647v1) - [pdf](http://arxiv.org/pdf/1812.00647v1)

> We propose Deep Hierarchical Machine (DHM), a model inspired from the divide-and-conquer strategy while emphasizing representation learning ability and flexibility. A stochastic routing framework as used by recent deep neural decision/regression forests is incorporated, but we remove the need to evaluate unnecessary computation paths by utilizing a different topology and introducing a probabilistic pruning technique. We also show a specified version of DHM (DSHM) for efficiency, which inherits the sparse feature extraction process as in traditional decision tree with pixel-difference feature. To achieve sparse feature extraction, we propose to utilize sparse convolution operation in DSHM and show one possibility of introducing sparse convolution kernels by using local binary convolution layer. DHM can be applied to both classification and regression problems, and we validate it on standard image classification and face alignment tasks to show its advantages over past architectures.

</details>

<details>

<summary>2018-12-03 11:03:04 - Knowledge Distillation with Feature Maps for Image Classification</summary>

- *Wei-Chun Chen, Chia-Che Chang, Chien-Yu Lu, Che-Rung Lee*

- `1812.00660v1` - [abs](http://arxiv.org/abs/1812.00660v1) - [pdf](http://arxiv.org/pdf/1812.00660v1)

> The model reduction problem that eases the computation costs and latency of complex deep learning architectures has received an increasing number of investigations owing to its importance in model deployment. One promising method is knowledge distillation (KD), which creates a fast-to-execute student model to mimic a large teacher network. In this paper, we propose a method, called KDFM (Knowledge Distillation with Feature Maps), which improves the effectiveness of KD by learning the feature maps from the teacher network. Two major techniques used in KDFM are shared classifier and generative adversarial network. Experimental results show that KDFM can use a four layers CNN to mimic DenseNet-40 and use MobileNet to mimic DenseNet-100. Both student networks have less than 1\% accuracy loss comparing to their teacher models for CIFAR-100 datasets. The student networks are 2-6 times faster than their teacher models for inference, and the model size of MobileNet is less than half of DenseNet-100's.

</details>

<details>

<summary>2018-12-03 11:10:59 - An Interpretable Machine Vision Approach to Human Activity Recognition using Photoplethysmograph Sensor Data</summary>

- *Eoin Brophy, José Juan Dominguez Veiga, Zhengwei Wang, Alan F. Smeaton, Tomas E. Ward*

- `1812.00668v1` - [abs](http://arxiv.org/abs/1812.00668v1) - [pdf](http://arxiv.org/pdf/1812.00668v1)

> The current gold standard for human activity recognition (HAR) is based on the use of cameras. However, the poor scalability of camera systems renders them impractical in pursuit of the goal of wider adoption of HAR in mobile computing contexts. Consequently, researchers instead rely on wearable sensors and in particular inertial sensors. A particularly prevalent wearable is the smart watch which due to its integrated inertial and optical sensing capabilities holds great potential for realising better HAR in a non-obtrusive way. This paper seeks to simplify the wearable approach to HAR through determining if the wrist-mounted optical sensor alone typically found in a smartwatch or similar device can be used as a useful source of data for activity recognition. The approach has the potential to eliminate the need for the inertial sensing element which would in turn reduce the cost of and complexity of smartwatches and fitness trackers. This could potentially commoditise the hardware requirements for HAR while retaining the functionality of both heart rate monitoring and activity capture all from a single optical sensor. Our approach relies on the adoption of machine vision for activity recognition based on suitably scaled plots of the optical signals. We take this approach so as to produce classifications that are easily explainable and interpretable by non-technical users. More specifically, images of photoplethysmography signal time series are used to retrain the penultimate layer of a convolutional neural network which has initially been trained on the ImageNet database. We then use the 2048 dimensional features from the penultimate layer as input to a support vector machine. Results from the experiment yielded an average classification accuracy of 92.3%. This result outperforms that of an optical and inertial sensor combined (78%) and illustrates the capability of HAR systems using...

</details>

<details>

<summary>2018-12-03 15:37:13 - Early Prediction of Course Grades: Models and Feature Selection</summary>

- *Hengxuan Li, Collin F. Lynch, Tiffany Barnes*

- `1812.00843v1` - [abs](http://arxiv.org/abs/1812.00843v1) - [pdf](http://arxiv.org/pdf/1812.00843v1)

> In this paper, we compare predictive models for students' final performance in a blended course using a set of generic features collected from the first six weeks of class. These features were extracted from students' online homework submission logs as well as other online actions. We compare the effectiveness of 5 different ML algorithms (SVMs, Support Vector Regression, Decision Tree, Naive Bayes and K-Nearest Neighbor). We found that SVMs outperform other models and improve when compared to the baseline. This study demonstrates feasible implementations for predictive models that rely on common data from blended courses that can be used to monitor students' progress and to tailor instruction.

</details>

<details>

<summary>2018-12-03 16:43:37 - Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks</summary>

- *Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, Vadim Sheinin*

- `1804.00823v4` - [abs](http://arxiv.org/abs/1804.00823v4) - [pdf](http://arxiv.org/pdf/1804.00823v4)

> The celebrated Sequence to Sequence learning (Seq2Seq) technique and its numerous variants achieve excellent performance on many tasks. However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence. To address this challenge, we introduce a novel general end-to-end graph-to-sequence neural encoder-decoder model that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors. Our method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings. We further introduce an attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs. Experimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing graph neural networks, Seq2Seq, and Tree2Seq models; using the proposed bi-directional node embedding aggregation strategy, the model can converge rapidly to the optimal performance.

</details>

<details>

<summary>2018-12-03 17:12:23 - From the User to the Medium: Neural Profiling Across Web Communities</summary>

- *Mohammad Akbari, Kunal Relia, Anas Elghafari, Rumi Chunara*

- `1812.00912v1` - [abs](http://arxiv.org/abs/1812.00912v1) - [pdf](http://arxiv.org/pdf/1812.00912v1)

> Online communities provide a unique way for individuals to access information from those in similar circumstances, which can be critical for health conditions that require daily and personalized management. As these groups and topics often arise organically, identifying the types of topics discussed is necessary to understand their needs. As well, these communities and people in them can be quite diverse, and existing community detection methods have not been extended towards evaluating these heterogeneities. This has been limited as community detection methodologies have not focused on community detection based on semantic relations between textual features of the user-generated content. Thus here we develop an approach, NeuroCom, that optimally finds dense groups of users as communities in a latent space inferred by neural representation of published contents of users. By embedding of words and messages, we show that NeuroCom demonstrates improved clustering and identifies more nuanced discussion topics in contrast to other common unsupervised learning approaches.

</details>

<details>

<summary>2018-12-03 17:15:44 - Accelerating Large Scale Knowledge Distillation via Dynamic Importance Sampling</summary>

- *Minghan Li, Tanli Zuo, Ruicheng Li, Martha White, Weishi Zheng*

- `1812.00914v1` - [abs](http://arxiv.org/abs/1812.00914v1) - [pdf](http://arxiv.org/pdf/1812.00914v1)

> Knowledge distillation is an effective technique that transfers knowledge from a large teacher model to a shallow student. However, just like massive classification, large scale knowledge distillation also imposes heavy computational costs on training models of deep neural networks, as the softmax activations at the last layer involve computing probabilities over numerous classes. In this work, we apply the idea of importance sampling which is often used in Neural Machine Translation on large scale knowledge distillation. We present a method called dynamic importance sampling, where ranked classes are sampled from a dynamic distribution derived from the interaction between the teacher and student in full distillation. We highlight the utility of our proposal prior which helps the student capture the main information in the loss function. Our approach manages to reduce the computational cost at training time while maintaining the competitive performance on CIFAR-100 and Market-1501 person re-identification datasets.

</details>

<details>

<summary>2018-12-03 17:48:11 - Conscious enactive computation</summary>

- *Daniel Estrada*

- `1812.02578v1` - [abs](http://arxiv.org/abs/1812.02578v1) - [pdf](http://arxiv.org/pdf/1812.02578v1)

> This paper looks at recent debates in the enactivist literature on computation and consciousness in order to assess major obstacles to building artificial conscious agents. We consider a proposal from Villalobos and Dewhurst (2018) for enactive computation on the basis of organizational closure. We attempt to improve the argument by reflecting on the closed paths through state space taken by finite state automata. This motivates a defense against Clark's recent criticisms of "extended consciousness", and perhaps a new perspective on living with machines.

</details>

<details>

<summary>2018-12-03 18:21:18 - Generative Adversarial Self-Imitation Learning</summary>

- *Yijie Guo, Junhyuk Oh, Satinder Singh, Honglak Lee*

- `1812.00950v1` - [abs](http://arxiv.org/abs/1812.00950v1) - [pdf](http://arxiv.org/pdf/1812.00950v1)

> This paper explores a simple regularizer for reinforcement learning by proposing Generative Adversarial Self-Imitation Learning (GASIL), which encourages the agent to imitate past good trajectories via generative adversarial imitation learning framework. Instead of directly maximizing rewards, GASIL focuses on reproducing past good trajectories, which can potentially make long-term credit assignment easier when rewards are sparse and delayed. GASIL can be easily combined with any policy gradient objective by using GASIL as a learned shaped reward function. Our experimental results show that GASIL improves the performance of proximal policy optimization on 2D Point Mass and MuJoCo environments with delayed reward and stochastic dynamics.

</details>

<details>

<summary>2018-12-03 18:43:27 - FoldingZero: Protein Folding from Scratch in Hydrophobic-Polar Model</summary>

- *Yanjun Li, Hengtong Kang, Ketian Ye, Shuyu Yin, Xiaolin Li*

- `1812.00967v1` - [abs](http://arxiv.org/abs/1812.00967v1) - [pdf](http://arxiv.org/pdf/1812.00967v1)

> De novo protein structure prediction from amino acid sequence is one of the most challenging problems in computational biology. As one of the extensively explored mathematical models for protein folding, Hydrophobic-Polar (HP) model enables thorough investigation of protein structure formation and evolution. Although HP model discretizes the conformational space and simplifies the folding energy function, it has been proven to be an NP-complete problem. In this paper, we propose a novel protein folding framework FoldingZero, self-folding a de novo protein 2D HP structure from scratch based on deep reinforcement learning. FoldingZero features the coupled approach of a two-head (policy and value heads) deep convolutional neural network (HPNet) and a regularized Upper Confidence Bounds for Trees (R-UCT). It is trained solely by a reinforcement learning algorithm, which improves HPNet and R-UCT iteratively through iterative policy optimization. Without any supervision and domain knowledge, FoldingZero not only achieves comparable results, but also learns the latent folding knowledge to stabilize the structure. Without exponential computation, FoldingZero shows promising potential to be adopted for real-world protein properties prediction.

</details>

<details>

<summary>2018-12-03 18:55:53 - Deep Reinforcement Learning for Intelligent Transportation Systems</summary>

- *Xiao-Yang Liu, Zihan Ding, Sem Borst, Anwar Walid*

- `1812.00979v1` - [abs](http://arxiv.org/abs/1812.00979v1) - [pdf](http://arxiv.org/pdf/1812.00979v1)

> Intelligent Transportation Systems (ITSs) are envisioned to play a critical role in improving traffic flow and reducing congestion, which is a pervasive issue impacting urban areas around the globe. Rapidly advancing vehicular communication and edge cloud computation technologies provide key enablers for smart traffic management. However, operating viable real-time actuation mechanisms on a practically relevant scale involves formidable challenges, e.g., policy iteration and conventional Reinforcement Learning (RL) techniques suffer from poor scalability due to state space explosion. Motivated by these issues, we explore the potential for Deep Q-Networks (DQN) to optimize traffic light control policies. As an initial benchmark, we establish that the DQN algorithms yield the "thresholding" policy in a single-intersection. Next, we examine the scalability properties of DQN algorithms and their performance in a linear network topology with several intersections along a main artery. We demonstrate that DQN algorithms produce intelligent behavior, such as the emergence of "greenwave" patterns, reflecting their ability to learn favorable traffic light actuations.

</details>

<details>

<summary>2018-12-03 19:20:25 - Embedding Models for Episodic Knowledge Graphs</summary>

- *Yunpu Ma, Volker Tresp, Erik Daxberger*

- `1807.00228v2` - [abs](http://arxiv.org/abs/1807.00228v2) - [pdf](http://arxiv.org/pdf/1807.00228v2)

> In recent years a number of large-scale triple-oriented knowledge graphs have been generated and various models have been proposed to perform learning in those graphs. Most knowledge graphs are static and reflect the world in its current state. In reality, of course, the state of the world is changing: a healthy person becomes diagnosed with a disease and a new president is inaugurated. In this paper, we extend models for static knowledge graphs to temporal knowledge graphs. This enables us to store episodic data and to generalize to new facts (inductive learning). We generalize leading learning models for static knowledge graphs (i.e., Tucker, RESCAL, HolE, ComplEx, DistMult) to temporal knowledge graphs. In particular, we introduce a new tensor model, ConT, with superior generalization performance. The performances of all proposed models are analyzed on two different datasets: the Global Database of Events, Language, and Tone (GDELT) and the database for Integrated Conflict Early Warning System (ICEWS). We argue that temporal knowledge graph embeddings might be models also for cognitive episodic memory (facts we remember and can recollect) and that a semantic memory (current facts we know) can be generated from episodic memory by a marginalization operation. We validate this episodic-to-semantic projection hypothesis with the ICEWS dataset.

</details>

<details>

<summary>2018-12-03 20:15:05 - A Hybrid Instance-based Transfer Learning Method</summary>

- *Azin Asgarian, Parinaz Sobhani, Ji Chao Zhang, Madalin Mihailescu, Ariel Sibilia, Ahmed Bilal Ashraf, Babak Taati*

- `1812.01063v1` - [abs](http://arxiv.org/abs/1812.01063v1) - [pdf](http://arxiv.org/pdf/1812.01063v1)

> In recent years, supervised machine learning models have demonstrated tremendous success in a variety of application domains. Despite the promising results, these successful models are data hungry and their performance relies heavily on the size of training data. However, in many healthcare applications it is difficult to collect sufficiently large training datasets. Transfer learning can help overcome this issue by transferring the knowledge from readily available datasets (source) to a new dataset (target). In this work, we propose a hybrid instance-based transfer learning method that outperforms a set of baselines including state-of-the-art instance-based transfer learning approaches. Our method uses a probabilistic weighting strategy to fuse information from the source domain to the model learned in the target domain. Our method is generic, applicable to multiple source domains, and robust with respect to negative transfer. We demonstrate the effectiveness of our approach through extensive experiments for two different applications.

</details>

<details>

<summary>2018-12-03 23:18:49 - 50 Years of Test (Un)fairness: Lessons for Machine Learning</summary>

- *Ben Hutchinson, Margaret Mitchell*

- `1811.10104v2` - [abs](http://arxiv.org/abs/1811.10104v2) - [pdf](http://arxiv.org/pdf/1811.10104v2)

> Quantitative definitions of what is unfair and what is fair have been introduced in multiple disciplines for well over 50 years, including in education, hiring, and machine learning. We trace how the notion of fairness has been defined within the testing communities of education and hiring over the past half century, exploring the cultural and social context in which different fairness definitions have emerged. In some cases, earlier definitions of fairness are similar or identical to definitions of fairness in current machine learning research, and foreshadow current formal work. In other cases, insights into what fairness means and how to measure it have largely gone overlooked. We compare past and current notions of fairness along several dimensions, including the fairness criteria, the focus of the criteria (e.g., a test, a model, or its use), the relationship of fairness to individuals, groups, and subgroups, and the mathematical method for measuring fairness (e.g., classification, regression). This work points the way towards future research and measurement of (un)fairness that builds from our modern understanding of fairness while incorporating insights from the past.

</details>

<details>

<summary>2018-12-03 23:49:37 - Selected Qualitative Spatio-temporal Calculi Developed for Constraint Reasoning: A Review</summary>

- *Debasis Mitra*

- `1812.02580v1` - [abs](http://arxiv.org/abs/1812.02580v1) - [pdf](http://arxiv.org/pdf/1812.02580v1)

> In this article a few of the qualitative spatio-temporal knowledge representation techniques developed by the constraint reasoning community within artificial intelligence are reviewed. The objective is to provide a broad exposure to any other interested group who may utilize these representations. The author has a particular interest in applying these calculi (in a broad sense) in topological data analysis, as these schemes are highly qualitative in nature.

</details>

<details>

<summary>2018-12-04 00:41:51 - Back to the Future for Dialogue Research: A Position Paper</summary>

- *Philip R Cohen*

- `1812.01144v1` - [abs](http://arxiv.org/abs/1812.01144v1) - [pdf](http://arxiv.org/pdf/1812.01144v1)

> This short position paper is intended to provide a critique of current approaches to dialogue, as well as a roadmap for collaborative dialogue research. It is unapologetically opinionated, but informed by 40 years of dialogue re-search. No attempt is made to be comprehensive. The paper will discuss current research into building so-called "chatbots", slot-filling dialogue systems, and plan-based dialogue systems. For further discussion of some of these issues, please see (Allen et al., in press).

</details>

<details>

<summary>2018-12-04 01:37:07 - Improving Hospital Mortality Prediction with Medical Named Entities and Multimodal Learning</summary>

- *Mengqi Jin, Mohammad Taha Bahadori, Aaron Colak, Parminder Bhatia, Busra Celikkaya, Ram Bhakta, Selvan Senthivel, Mohammed Khalilia, Daniel Navarro, Borui Zhang, Tiberiu Doman, Arun Ravi, Matthieu Liger, Taha Kass-hout*

- `1811.12276v2` - [abs](http://arxiv.org/abs/1811.12276v2) - [pdf](http://arxiv.org/pdf/1811.12276v2)

> Clinical text provides essential information to estimate the acuity of a patient during hospital stays in addition to structured clinical data. In this study, we explore how clinical text can complement a clinical predictive learning task. We leverage an internal medical natural language processing service to perform named entity extraction and negation detection on clinical notes and compose selected entities into a new text corpus to train document representations. We then propose a multimodal neural network to jointly train time series signals and unstructured clinical text representations to predict the in-hospital mortality risk for ICU patients. Our model outperforms the benchmark by 2% AUC.

</details>

<details>

<summary>2018-12-04 02:10:37 - Pre-Defined Sparse Neural Networks with Hardware Acceleration</summary>

- *Sourya Dey, Kuan-Wen Huang, Peter A. Beerel, Keith M. Chugg*

- `1812.01164v1` - [abs](http://arxiv.org/abs/1812.01164v1) - [pdf](http://arxiv.org/pdf/1812.01164v1)

> Neural networks have proven to be extremely powerful tools for modern artificial intelligence applications, but computational and storage complexity remain limiting factors. This paper presents two compatible contributions towards reducing the time, energy, computational, and storage complexities associated with multilayer perceptrons. Pre-defined sparsity is proposed to reduce the complexity during both training and inference, regardless of the implementation platform. Our results show that storage and computational complexity can be reduced by factors greater than 5X without significant performance loss. The second contribution is an architecture for hardware acceleration that is compatible with pre-defined sparsity. This architecture supports both training and inference modes and is flexible in the sense that it is not tied to a specific number of neurons. For example, this flexibility implies that various sized neural networks can be supported on various sized Field Programmable Gate Array (FPGA)s.

</details>

<details>

<summary>2018-12-04 02:59:44 - Making BREAD: Biomimetic strategies for Artificial Intelligence Now and in the Future</summary>

- *Jeffrey L. Krichmar, William Severa, Salar M. Khan, James L. Olds*

- `1812.01184v1` - [abs](http://arxiv.org/abs/1812.01184v1) - [pdf](http://arxiv.org/pdf/1812.01184v1)

> The Artificial Intelligence (AI) revolution foretold of during the 1960s is well underway in the second decade of the 21st century. Its period of phenomenal growth likely lies ahead. Still, we believe, there are crucial lessons that biology can offer that will enable a prosperous future for AI. For machines in general, and for AI's especially, operating over extended periods or in extreme environments will require energy usage orders of magnitudes more efficient than exists today. In many operational environments, energy sources will be constrained. Any plans for AI devices operating in a challenging environment must begin with the question of how they are powered, where fuel is located, how energy is stored and made available to the machine, and how long the machine can operate on specific energy units. Hence, the materials and technologies that provide the needed energy represent a critical challenge towards future use-scenarios of AI and should be integrated into their design. Here we make four recommendations for stakeholders and especially decision makers to facilitate a successful trajectory for this technology. First, that scientific societies and governments coordinate Biomimetic Research for Energy-efficient, AI Designs (BREAD); a multinational initiative and a funding strategy for investments in the future integrated design of energetics into AI. Second, that biomimetic energetic solutions be central to design consideration for future AI. Third, that a pre-competitive space be organized between stakeholder partners and fourth, that a trainee pipeline be established to ensure the human capital required for success in this area.

</details>

<details>

<summary>2018-12-04 05:36:36 - Microscope 2.0: An Augmented Reality Microscope with Real-time Artificial Intelligence Integration</summary>

- *Po-Hsuan Cameron Chen, Krishna Gadepalli, Robert MacDonald, Yun Liu, Kunal Nagpal, Timo Kohlberger, Jeffrey Dean, Greg S. Corrado, Jason D. Hipp, Martin C. Stumpe*

- `1812.00825v2` - [abs](http://arxiv.org/abs/1812.00825v2) - [pdf](http://arxiv.org/pdf/1812.00825v2)

> The brightfield microscope is instrumental in the visual examination of both biological and physical samples at sub-millimeter scales. One key clinical application has been in cancer histopathology, where the microscopic assessment of the tissue samples is used for the diagnosis and staging of cancer and thus guides clinical therapy. However, the interpretation of these samples is inherently subjective, resulting in significant diagnostic variability. Moreover, in many regions of the world, access to pathologists is severely limited due to lack of trained personnel. In this regard, Artificial Intelligence (AI) based tools promise to improve the access and quality of healthcare. However, despite significant advances in AI research, integration of these tools into real-world cancer diagnosis workflows remains challenging because of the costs of image digitization and difficulties in deploying AI solutions. Here we propose a cost-effective solution to the integration of AI: the Augmented Reality Microscope (ARM). The ARM overlays AI-based information onto the current view of the sample through the optical pathway in real-time, enabling seamless integration of AI into the regular microscopy workflow. We demonstrate the utility of ARM in the detection of lymph node metastases in breast cancer and the identification of prostate cancer with a latency that supports real-time workflows. We anticipate that ARM will remove barriers towards the use of AI in microscopic analysis and thus improve the accuracy and efficiency of cancer diagnosis. This approach is applicable to other microscopy tasks and AI algorithms in the life sciences and beyond.

</details>

<details>

<summary>2018-12-04 06:27:40 - Sample-to-Sample Correspondence for Unsupervised Domain Adaptation</summary>

- *Debasmit Das, C. S. George Lee*

- `1805.00355v3` - [abs](http://arxiv.org/abs/1805.00355v3) - [pdf](http://arxiv.org/pdf/1805.00355v3)

> The assumption that training and testing samples are generated from the same distribution does not always hold for real-world machine-learning applications. The procedure of tackling this discrepancy between the training (source) and testing (target) domains is known as domain adaptation. We propose an unsupervised version of domain adaptation that considers the presence of only unlabelled data in the target domain. Our approach centers on finding correspondences between samples of each domain. The correspondences are obtained by treating the source and target samples as graphs and using a convex criterion to match them. The criteria used are first-order and second-order similarities between the graphs as well as a class-based regularization. We have also developed a computationally efficient routine for the convex optimization, thus allowing the proposed method to be used widely. To verify the effectiveness of the proposed method, computer simulations were conducted on synthetic, image classification and sentiment classification datasets. Results validated that the proposed local sample-to-sample matching method out-performs traditional moment-matching methods and is competitive with respect to current local domain-adaptation methods.

</details>

<details>

<summary>2018-12-04 07:28:26 - Risk-averse Behavior Planning for Autonomous Driving under Uncertainty</summary>

- *Mohammad Naghshvar, Ahmed K. Sadek, Auke J. Wiggers*

- `1812.01254v1` - [abs](http://arxiv.org/abs/1812.01254v1) - [pdf](http://arxiv.org/pdf/1812.01254v1)

> Autonomous vehicles have to navigate the surrounding environment with partial observability of other objects sharing the road. Sources of uncertainty in autonomous vehicle measurements include sensor fusion errors, limited sensor range due to weather or object detection latency, occlusion, and hidden parameters such as other human driver intentions. Behavior planning must consider all sources of uncertainty in deciding future vehicle maneuvers. This paper presents a scalable framework for risk-averse behavior planning under uncertainty by incorporating QMDP, unscented transform, and Monte Carlo tree search (MCTS). It is shown that upper confidence bound (UCB) for expanding the tree results in noisy Q-value estimates by the MCTS and a degraded performance of QMDP. A modification to action selection procedure in MCTS is proposed to achieve robust performance.

</details>

<details>

<summary>2018-12-04 07:31:21 - SWRL2SPIN: A tool for transforming SWRL rule bases in OWL ontologies to object-oriented SPIN rules</summary>

- *Nick Bassiliades*

- `1801.09061v3` - [abs](http://arxiv.org/abs/1801.09061v3) - [pdf](http://arxiv.org/pdf/1801.09061v3)

> Semantic Web Rule Language (SWRL) combines OWL (Web Ontology Language) ontologies with Horn Logic rules of the Rule Markup Language (RuleML) family. Being supported by ontology editors, rule engines and ontology reasoners, it has become a very popular choice for developing rule-based applications on top of ontologies. However, SWRL is probably not go-ing to become a WWW Consortium standard, prohibiting industrial acceptance. On the other hand, SPIN (SPARQL Inferencing Notation) has become a de-facto industry standard to rep-resent SPARQL rules and constraints on Semantic Web models, building on the widespread acceptance of SPARQL (SPARQL Protocol and RDF Query Language). In this paper, we ar-gue that the life of existing SWRL rule-based ontology applications can be prolonged by con-verting them to SPIN. To this end, we have developed the SWRL2SPIN tool in Prolog that transforms SWRL rules into SPIN rules, considering the object-orientation of SPIN, i.e. linking rules to the appropriate ontology classes and optimizing them, as derived by analysing the rule conditions.

</details>

<details>

<summary>2018-12-04 07:42:33 - Hybrid Microaggregation for Privacy-Preserving Data Mining</summary>

- *Balkis Abidi, Sadok Ben Yahia, Charith Perera*

- `1812.01790v1` - [abs](http://arxiv.org/abs/1812.01790v1) - [pdf](http://arxiv.org/pdf/1812.01790v1)

> k-Anonymity by microaggregation is one of the most commonly used anonymization techniques. This success is owe to the achievement of a worth of interest tradeoff between information loss and identity disclosure risk. However, this method may have some drawbacks. On the disclosure limitation side, there is a lack of protection against attribute disclosure. On the data utility side, dealing with a real datasets is a challenging task to achieve. Indeed, the latter are characterized by their large number of attributes and the presence of noisy data, such that outliers or, even, data with missing values. Generating an anonymous individual data useful for data mining tasks, while decreasing the influence of noisy data is a compelling task to achieve. In this paper, we introduce a new microaggregation method, called HM-PFSOM, based on fuzzy possibilistic clustering. Our proposed method operates through an hybrid manner. This means that the anonymization process is applied per block of similar data. Thus, we can help to decrease the information loss during the anonymization process. The HMPFSOM approach proposes to study the distribution of confidential attributes within each sub-dataset. Then, according to the latter distribution, the privacy parameter k is determined, in such a way to preserve the diversity of confidential attributes within the anonymized microdata. This allows to decrease the disclosure risk of confidential information.

</details>

<details>

<summary>2018-12-04 07:48:00 - Tartan: A retrieval-based socialbot powered by a dynamic finite-state machine architecture</summary>

- *George Larionov, Zachary Kaden, Hima Varsha Dureddy, Gabriel Bayomi T. Kalejaiye, Mihir Kale, Srividya Pranavi Potharaju, Ankit Parag Shah, Alexander I Rudnicky*

- `1812.01260v1` - [abs](http://arxiv.org/abs/1812.01260v1) - [pdf](http://arxiv.org/pdf/1812.01260v1)

> This paper describes the Tartan conversational agent built for the 2018 Alexa Prize Competition. Tartan is a non-goal-oriented socialbot focused around providing users with an engaging and fluent casual conversation. Tartan's key features include an emphasis on structured conversation based on flexible finite-state models and an approach focused on understanding and using conversational acts. To provide engaging conversations, Tartan blends script-like yet dynamic responses with data-based generative and retrieval models. Unique to Tartan is that our dialog manager is modeled as a dynamic Finite State Machine. To our knowledge, no other conversational agent implementation has followed this specific structure.

</details>

<details>

<summary>2018-12-04 08:47:41 - Singing Voice Separation Using a Deep Convolutional Neural Network Trained by Ideal Binary Mask and Cross Entropy</summary>

- *Kin Wah Edward Lin, Balamurali B. T., Enyan Koh, Simon Lui, Dorien Herremans*

- `1812.01278v1` - [abs](http://arxiv.org/abs/1812.01278v1) - [pdf](http://arxiv.org/pdf/1812.01278v1)

> Separating a singing voice from its music accompaniment remains an important challenge in the field of music information retrieval. We present a unique neural network approach inspired by a technique that has revolutionized the field of vision: pixel-wise image classification, which we combine with cross entropy loss and pretraining of the CNN as an autoencoder on singing voice spectrograms. The pixel-wise classification technique directly estimates the sound source label for each time-frequency (T-F) bin in our spectrogram image, thus eliminating common pre- and postprocessing tasks. The proposed network is trained by using the Ideal Binary Mask (IBM) as the target output label. The IBM identifies the dominant sound source in each T-F bin of the magnitude spectrogram of a mixture signal, by considering each T-F bin as a pixel with a multi-label (for each sound source). Cross entropy is used as the training objective, so as to minimize the average probability error between the target and predicted label for each pixel. By treating the singing voice separation problem as a pixel-wise classification task, we additionally eliminate one of the commonly used, yet not easy to comprehend, postprocessing steps: the Wiener filter postprocessing.   The proposed CNN outperforms the first runner up in the Music Information Retrieval Evaluation eXchange (MIREX) 2016 and the winner of MIREX 2014 with a gain of 2.2702 ~ 5.9563 dB global normalized source to distortion ratio (GNSDR) when applied to the iKala dataset. An experiment with the DSD100 dataset on the full-tracks song evaluation task also shows that our model is able to compete with cutting-edge singing voice separation systems which use multi-channel modeling, data augmentation, and model blending.

</details>

<details>

<summary>2018-12-04 08:51:35 - State-Space Abstractions for Probabilistic Inference: A Systematic Review</summary>

- *Stefan Lüdtke, Max Schröder, Frank Krüger, Sebastian Bader, Thomas Kirste*

- `1804.06748v3` - [abs](http://arxiv.org/abs/1804.06748v3) - [pdf](http://arxiv.org/pdf/1804.06748v3)

> Tasks such as social network analysis, human behavior recognition, or modeling biochemical reactions, can be solved elegantly by using the probabilistic inference framework. However, standard probabilistic inference algorithms work at a propositional level, and thus cannot capture the symmetries and redundancies that are present in these tasks. Algorithms that exploit those symmetries have been devised in different research fields, for example by the lifted inference-, multiple object tracking-, and modeling and simulation-communities. The common idea, that we call state space abstraction, is to perform inference over compact representations of sets of symmetric states. Although they are concerned with a similar topic, the relationship between these approaches has not been investigated systematically. This survey provides the following contributions. We perform a systematic literature review to outline the state of the art in probabilistic inference methods exploiting symmetries. From an initial set of more than 4,000 papers, we identify 116 relevant papers. Furthermore, we provide new high-level categories that classify the approaches, based on common properties of the approaches. The research areas underlying each of the categories are introduced concisely. Researchers from different fields that are confronted with a state space explosion problem in a probabilistic system can use this classification to identify possible solutions. Finally, based on this conceptualization, we identify potentials for future research, as some relevant application domains are not addressed by current approaches.

</details>

<details>

<summary>2018-12-04 11:57:46 - Regularized Fuzzy Neural Networks to Aid Effort Forecasting in the Construction and Software Development</summary>

- *Paulo Vitor de Campos Souza, Augusto Junio Guimaraes, Vanessa Souza Araujo, Thiago Silva Rezende, Vinicius Jonathan Silva Araujo*

- `1812.01351v1` - [abs](http://arxiv.org/abs/1812.01351v1) - [pdf](http://arxiv.org/pdf/1812.01351v1)

> Predicting the time to build software is a very complex task for software engineering managers. There are complex factors that can directly interfere with the productivity of the development team. Factors directly related to the complexity of the system to be developed drastically change the time necessary for the completion of the works with the software factories. This work proposes the use of a hybrid system based on artificial neural networks and fuzzy systems to assist in the construction of an expert system based on rules to support in the prediction of hours destined to the development of software according to the complexity of the elements present in the same. The set of fuzzy rules obtained by the system helps the management and control of software development by providing a base of interpretable estimates based on fuzzy rules. The model was submitted to tests on a real database, and its results were promissory in the construction of an aid mechanism in the predictability of the software construction.

</details>

<details>

<summary>2018-12-04 12:38:07 - Design and implementation of smart cooking based on amazon echo</summary>

- *Lin Xiaoguang, Yang Yong, Zhang Ju*

- `1812.01375v1` - [abs](http://arxiv.org/abs/1812.01375v1) - [pdf](http://arxiv.org/pdf/1812.01375v1)

> Smart cooking based on Amazon Echo uses the internet of things and cloud computing to assist in cooking food. People may speak to Amazon Echo during the cooking in order to get the information and situation of the cooking. Amazon Echo recognizes what people say, then transfers the information to the cloud services, and speaks to people the results that cloud services make by querying the embedded cooking knowledge and achieving the information of intelligent kitchen devices online. An intelligent food thermometer and its mobile application are well-designed and implemented to monitor the temperature of cooking food.

</details>

<details>

<summary>2018-12-04 14:00:05 - CoNet: Collaborative Cross Networks for Cross-Domain Recommendation</summary>

- *Guangneng Hu, Yu Zhang, Qiang Yang*

- `1804.06769v3` - [abs](http://arxiv.org/abs/1804.06769v3) - [pdf](http://arxiv.org/pdf/1804.06769v3)

> The cross-domain recommendation technique is an effective way of alleviating the data sparse issue in recommender systems by leveraging the knowledge from relevant domains. Transfer learning is a class of algorithms underlying these techniques. In this paper, we propose a novel transfer learning approach for cross-domain recommendation by using neural networks as the base model. In contrast to the matrix factorization based cross-domain techniques, our method is deep transfer learning, which can learn complex user-item interaction relationships. We assume that hidden layers in two base networks are connected by cross mappings, leading to the collaborative cross networks (CoNet). CoNet enables dual knowledge transfer across domains by introducing cross connections from one base network to another and vice versa. CoNet is achieved in multi-layer feedforward networks by adding dual connections and joint loss functions, which can be trained efficiently by back-propagation. The proposed model is thoroughly evaluated on two large real-world datasets. It outperforms baselines by relative improvements of 7.84\% in NDCG. We demonstrate the necessity of adaptively selecting representations to transfer. Our model can reduce tens of thousands training examples comparing with non-transfer methods and still has the competitive performance with them.

</details>

<details>

<summary>2018-12-04 15:25:14 - Coordinate Descent with Bandit Sampling</summary>

- *Farnood Salehi, Patrick Thiran, L. Elisa Celis*

- `1712.03010v2` - [abs](http://arxiv.org/abs/1712.03010v2) - [pdf](http://arxiv.org/pdf/1712.03010v2)

> Coordinate descent methods usually minimize a cost function by updating a random decision variable (corresponding to one coordinate) at a time. Ideally, we would update the decision variable that yields the largest decrease in the cost function. However, finding this coordinate would require checking all of them, which would effectively negate the improvement in computational tractability that coordinate descent is intended to afford. To address this, we propose a new adaptive method for selecting a coordinate. First, we find a lower bound on the amount the cost function decreases when a coordinate is updated. We then use a multi-armed bandit algorithm to learn which coordinates result in the largest lower bound by interleaving this learning with conventional coordinate descent updates except that the coordinate is selected proportionately to the expected decrease. We show that our approach improves the convergence of coordinate descent methods both theoretically and experimentally.

</details>

<details>

<summary>2018-12-04 15:25:50 - Multivariate Time-series Similarity Assessment via Unsupervised Representation Learning and Stratified Locality Sensitive Hashing: Application to Early Acute Hypotensive Episode Detection</summary>

- *Jwala Dhamala, Emmanuel Azuh, Abdullah Al-Dujaili, Jonathan Rubin, Una-May O'Reilly*

- `1811.06106v3` - [abs](http://arxiv.org/abs/1811.06106v3) - [pdf](http://arxiv.org/pdf/1811.06106v3)

> Timely prediction of clinically critical events in Intensive Care Unit (ICU) is important for improving care and survival rate. Most of the existing approaches are based on the application of various classification methods on explicitly extracted statistical features from vital signals. In this work, we propose to eliminate the high cost of engineering hand-crafted features from multivariate time-series of physiologic signals by learning their representation with a sequence-to-sequence auto-encoder. We then propose to hash the learned representations to enable signal similarity assessment for the prediction of critical events. We apply this methodological framework to predict Acute Hypotensive Episodes (AHE) on a large and diverse dataset of vital signal recordings. Experiments demonstrate the ability of the presented framework in accurately predicting an upcoming AHE.

</details>

<details>

<summary>2018-12-04 15:28:45 - Utilizing Imbalanced Data and Classification Cost Matrix to Predict Movie Preferences</summary>

- *Haifeng Wang*

- `1812.02529v1` - [abs](http://arxiv.org/abs/1812.02529v1) - [pdf](http://arxiv.org/pdf/1812.02529v1)

> In this paper, we propose a movie genre recommendation system based on imbalanced survey data and unequal classification costs for small and medium-sized enterprises (SMEs) who need a data-based and analytical approach to stock favored movies and target marketing to young people. The dataset maintains a detailed personal profile as predictors including demographic, behavioral and preferences information for each user as well as imbalanced genre preferences. These predictors do not include the information such as actors or directors. The paper applies Gentle boost, Adaboost and Bagged tree ensembles as well as SVM machine learning algorithms to learn classification from one thousand observations and predict movie genre preferences with adjusted classification costs. The proposed recommendation system also selects important predictors to avoid overfitting and to shorten training time. This paper compares the test error among the above-mentioned algorithms that are used to recommend different movie genres. The prediction power is also indicated in a comparison of precision and recall with other state-of-the-art recommendation systems. The proposed movie genre recommendation system solves problems such as small dataset, imbalanced response, and unequal classification costs.

</details>

<details>

<summary>2018-12-04 15:33:26 - Natural Option Critic</summary>

- *Saket Tiwari, Philip S. Thomas*

- `1812.01488v1` - [abs](http://arxiv.org/abs/1812.01488v1) - [pdf](http://arxiv.org/pdf/1812.01488v1)

> The recently proposed option-critic architecture Bacon et al. provide a stochastic policy gradient approach to hierarchical reinforcement learning. Specifically, they provide a way to estimate the gradient of the expected discounted return with respect to parameters that define a finite number of temporally extended actions, called \textit{options}. In this paper we show how the option-critic architecture can be extended to estimate the natural gradient of the expected discounted return. To this end, the central questions that we consider in this paper are: 1) what is the definition of the natural gradient in this context, 2) what is the Fisher information matrix associated with an option's parameterized policy, 3) what is the Fisher information matrix associated with an option's parameterized termination function, and 4) how can a compatible function approximation approach be leveraged to obtain natural gradient estimates for both the parameterized policy and parameterized termination functions of an option with per-time-step time and space complexity linear in the total number of parameters. Based on answers to these questions we introduce the natural option critic algorithm. Experimental results showcase improvement over the vanilla gradient approach.

</details>

<details>

<summary>2018-12-04 15:38:31 - Deep unsupervised learning through spatial contrasting</summary>

- *Elad Hoffer, Itay Hubara, Nir Ailon*

- `1610.00243v2` - [abs](http://arxiv.org/abs/1610.00243v2) - [pdf](http://arxiv.org/pdf/1610.00243v2)

> Convolutional networks have marked their place over the last few years as the best performing model for various visual tasks. They are, however, most suited for supervised learning from large amounts of labeled data. Previous attempts have been made to use unlabeled data to improve model performance by applying unsupervised techniques. These attempts require different architectures and training methods. In this work we present a novel approach for unsupervised training of Convolutional networks that is based on contrasting between spatial regions within images. This criterion can be employed within conventional neural networks and trained using standard techniques such as SGD and back-propagation, thus complementing supervised methods.

</details>

<details>

<summary>2018-12-04 16:15:25 - Combating Fake News with Interpretable News Feed Algorithms</summary>

- *Sina Mohseni, Eric Ragan*

- `1811.12349v2` - [abs](http://arxiv.org/abs/1811.12349v2) - [pdf](http://arxiv.org/pdf/1811.12349v2)

> Nowadays, artificial intelligence algorithms are used for targeted and personalized content distribution in the large scale as part of the intense competition for attention in the digital media environment. Unfortunately, targeted information dissemination may result in intellectual isolation and discrimination. Further, as demonstrated in recent political events in the US and EU, malicious bots and social media users can create and propagate targeted `fake news' content in different forms for political gains. From the other direction, fake news detection algorithms attempt to combat such problems by identifying misinformation and fraudulent user profiles. This paper reviews common news feed algorithms as well as methods for fake news detection, and we discuss how news feed algorithms could be misused to promote falsified content, affect news diversity, or impact credibility. We review how news feed algorithms and recommender engines can enable confirmation bias to isolate users to certain news sources and affecting the perception of reality. As a potential solution for increasing user awareness of how content is selected or sorted, we argue for the use of interpretable and explainable news feed algorithms. We discuss how improved user awareness and system transparency could mitigate unwanted outcomes of echo chambers and bubble filters in social media.

</details>

<details>

<summary>2018-12-04 20:20:29 - Auto-tuning TensorFlow Threading Model for CPU Backend</summary>

- *Niranjan Hasabnis*

- `1812.01665v1` - [abs](http://arxiv.org/abs/1812.01665v1) - [pdf](http://arxiv.org/pdf/1812.01665v1)

> TensorFlow is a popular deep learning framework used by data scientists to solve a wide-range of machine learning and deep learning problems such as image classification and speech recognition. It also operates at a large scale and in heterogeneous environments --- it allows users to train neural network models or deploy them for inference using GPUs, CPUs and deep learning specific custom-designed hardware such as TPUs. Even though TensorFlow supports a variety of optimized backends, realizing the best performance using a backend may require additional efforts. For instance, getting the best performance from a CPU backend requires careful tuning of its threading model. Unfortunately, the best tuning approach used today is manual, tedious, time-consuming, and, more importantly, may not guarantee the best performance.   In this paper, we develop an automatic approach, called TensorTuner, to search for optimal parameter settings of TensorFlow's threading model for CPU backends. We evaluate TensorTuner on both Eigen and Intel's MKL CPU backends using a set of neural networks from TensorFlow's benchmarking suite. Our evaluation results demonstrate that the parameter settings found by TensorTuner produce 2% to 123% performance improvement for the Eigen CPU backend and 1.5% to 28% performance improvement for the MKL CPU backend over the performance obtained using their best-known parameter settings. This highlights the fact that the default parameter settings in Eigen CPU backend are not the ideal settings; and even for a carefully hand-tuned MKL backend, the settings may be sub-optimal. Our evaluations also revealed that TensorTuner is efficient at finding the optimal settings --- it is able to converge to the optimal settings quickly by pruning more than 90% of the parameter search space.

</details>

<details>

<summary>2018-12-04 23:38:54 - Cerebrovascular Network Segmentation on MRA Images with Deep Learning</summary>

- *Pedro Sanches, Cyril Meyer, Vincent Vigon, Benoît Naegel*

- `1812.01752v1` - [abs](http://arxiv.org/abs/1812.01752v1) - [pdf](http://arxiv.org/pdf/1812.01752v1)

> Deep learning has been shown to produce state of the art results in many tasks in biomedical imaging, especially in segmentation. Moreover, segmentation of the cerebrovascular structure from magnetic resonance angiography is a challenging problem because its complex geometry and topology have a large inter-patient variability. Therefore, in this work, we present a convolutional neural network approach for this problem. Particularly, a new network topology inspired by the U-net 3D and by the Inception modules, entitled Uception. In addition, a discussion about the best objective function for sparse data also guided most choices during the project. State of the art models are also implemented for a comparison purpose and final results show that the proposed architecture has the best performance in this particular context.

</details>

<details>

<summary>2018-12-05 00:05:01 - Multi$^{\mathbf{3}}$Net: Segmenting Flooded Buildings via Fusion of Multiresolution, Multisensor, and Multitemporal Satellite Imagery</summary>

- *Tim G. J. Rudner, Marc Rußwurm, Jakub Fil, Ramona Pelich, Benjamin Bischke, Veronika Kopackova, Piotr Bilinski*

- `1812.01756v1` - [abs](http://arxiv.org/abs/1812.01756v1) - [pdf](http://arxiv.org/pdf/1812.01756v1)

> We propose a novel approach for rapid segmentation of flooded buildings by fusing multiresolution, multisensor, and multitemporal satellite imagery in a convolutional neural network. Our model significantly expedites the generation of satellite imagery-based flood maps, crucial for first responders and local authorities in the early stages of flood events. By incorporating multitemporal satellite imagery, our model allows for rapid and accurate post-disaster damage assessment and can be used by governments to better coordinate medium- and long-term financial assistance programs for affected areas. The network consists of multiple streams of encoder-decoder architectures that extract spatiotemporal information from medium-resolution images and spatial information from high-resolution images before fusing the resulting representations into a single medium-resolution segmentation map of flooded buildings. We compare our model to state-of-the-art methods for building footprint segmentation as well as to alternative fusion approaches for the segmentation of flooded buildings and find that our model performs best on both tasks. We also demonstrate that our model produces highly accurate segmentation maps of flooded buildings using only publicly available medium-resolution data instead of significantly more detailed but sparsely available very high-resolution data. We release the first open-source dataset of fully preprocessed and labeled multiresolution, multispectral, and multitemporal satellite images of disaster sites along with our source code.

</details>

<details>

<summary>2018-12-05 01:01:52 - RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series</summary>

- *Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan Xu, Shenghuo Zhu*

- `1812.01767v1` - [abs](http://arxiv.org/abs/1812.01767v1) - [pdf](http://arxiv.org/pdf/1812.01767v1)

> Decomposing complex time series into trend, seasonality, and remainder components is an important task to facilitate time series anomaly detection and forecasting. Although numerous methods have been proposed, there are still many time series characteristics exhibiting in real-world data which are not addressed properly, including 1) ability to handle seasonality fluctuation and shift, and abrupt change in trend and reminder; 2) robustness on data with anomalies; 3) applicability on time series with long seasonality period. In the paper, we propose a novel and generic time series decomposition algorithm to address these challenges. Specifically, we extract the trend component robustly by solving a regression problem using the least absolute deviations loss with sparse regularization. Based on the extracted trend, we apply the the non-local seasonal filtering to extract the seasonality component. This process is repeated until accurate decomposition is obtained. Experiments on different synthetic and real-world time series datasets demonstrate that our method outperforms existing solutions.

</details>

<details>

<summary>2018-12-05 05:04:15 - Photo-Realistic Blocksworld Dataset</summary>

- *Masataro Asai*

- `1812.01818v1` - [abs](http://arxiv.org/abs/1812.01818v1) - [pdf](http://arxiv.org/pdf/1812.01818v1)

> In this report, we introduce an artificial dataset generator for Photo-realistic Blocksworld domain. Blocksworld is one of the oldest high-level task planning domain that is well defined but contains sufficient complexity, e.g., the conflicting subgoals and the decomposability into subproblems. We aim to make this dataset a benchmark for Neural-Symbolic integrated systems and accelerate the research in this area. The key advantage of such systems is the ability to obtain a symbolic model from the real-world input and perform a fast, systematic, complete algorithm for symbolic reasoning, without any supervision and the reward signal from the environment.

</details>

<details>

<summary>2018-12-05 05:47:43 - Cooperative Multi-Agent Policy Gradients with Sub-optimal Demonstration</summary>

- *Peixi Peng, Junliang Xing, Lu Pang*

- `1812.01825v1` - [abs](http://arxiv.org/abs/1812.01825v1) - [pdf](http://arxiv.org/pdf/1812.01825v1)

> Many reality tasks such as robot coordination can be naturally modelled as multi-agent cooperative system where the rewards are sparse. This paper focuses on learning decentralized policies for such tasks using sub-optimal demonstration. To learn the multi-agent cooperation effectively and tackle the sub-optimality of demonstration, a self-improving learning method is proposed: On the one hand, the centralized state-action values are initialized by the demonstration and updated by the learned decentralized policy to improve the sub-optimality. On the other hand, the Nash Equilibrium are found by the current state-action value and are used as a guide to learn the policy. The proposed method is evaluated on the combat RTS games which requires a high level of multi-agent cooperation. Extensive experimental results on various combat scenarios demonstrate that the proposed method can learn multi-agent cooperation effectively. It significantly outperforms many state-of-the-art demonstration based approaches.

</details>

<details>

<summary>2018-12-05 07:40:32 - MLIC: A MaxSAT-Based framework for learning interpretable classification rules</summary>

- *Dmitry Malioutov, Kuldeep S. Meel*

- `1812.01843v1` - [abs](http://arxiv.org/abs/1812.01843v1) - [pdf](http://arxiv.org/pdf/1812.01843v1)

> The wide adoption of machine learning approaches in the industry, government, medicine and science has renewed the interest in interpretable machine learning: many decisions are too important to be delegated to black-box techniques such as deep neural networks or kernel SVMs. Historically, problems of learning interpretable classifiers, including classification rules or decision trees, have been approached by greedy heuristic methods as essentially all the exact optimization formulations are NP-hard. Our primary contribution is a MaxSAT-based framework, called MLIC, which allows principled search for interpretable classification rules expressible in propositional logic. Our approach benefits from the revolutionary advances in the constraint satisfaction community to solve large-scale instances of such problems. In experimental evaluations over a collection of benchmarks arising from practical scenarios, we demonstrate its effectiveness: we show that the formulation can solve large classification problems with tens or hundreds of thousands of examples and thousands of features, and to provide a tunable balance of accuracy vs. interpretability. Furthermore, we show that in many problems interpretability can be obtained at only a minor cost in accuracy. The primary objective of the paper is to show that recent advances in the MaxSAT literature make it realistic to find optimal (or very high quality near-optimal) solutions to large-scale classification problems. The key goal of the paper is to excite researchers in both interpretable classification and in the CP community to take it further and propose richer formulations, and to develop bespoke solvers attuned to the problem of interpretable ML.

</details>

<details>

<summary>2018-12-05 07:41:53 - Improving Similarity Search with High-dimensional Locality-sensitive Hashing</summary>

- *Jaiyam Sharma, Saket Navlakha*

- `1812.01844v1` - [abs](http://arxiv.org/abs/1812.01844v1) - [pdf](http://arxiv.org/pdf/1812.01844v1)

> We propose a new class of data-independent locality-sensitive hashing (LSH) algorithms based on the fruit fly olfactory circuit. The fundamental difference of this approach is that, instead of assigning hashes as dense points in a low dimensional space, hashes are assigned in a high dimensional space, which enhances their separability. We show theoretically and empirically that this new family of hash functions is locality-sensitive and preserves rank similarity for inputs in any `p space. We then analyze different variations on this strategy and show empirically that they outperform existing LSH methods for nearest-neighbors search on six benchmark datasets. Finally, we propose a multi-probe version of our algorithm that achieves higher performance for the same query time, or conversely, that maintains performance of prior approaches while taking significantly less indexing time and memory. Overall, our approach leverages the advantages of separability provided by high-dimensional spaces, while still remaining computationally efficient

</details>

<details>

<summary>2018-12-05 08:39:06 - Chore division on a graph</summary>

- *Sylvain Bouveret, Katarína Cechlárová, Julien Lesca*

- `1812.01856v1` - [abs](http://arxiv.org/abs/1812.01856v1) - [pdf](http://arxiv.org/pdf/1812.01856v1)

> The paper considers fair allocation of indivisible nondisposable items that generate disutility (chores). We assume that these items are placed in the vertices of a graph and each agent's share has to form a connected subgraph of this graph. Although a similar model has been investigated before for goods, we show that the goods and chores settings are inherently different. In particular, it is impossible to derive the solution of the chores instance from the solution of its naturally associated fair division instance. We consider three common fair division solution concepts, namely proportionality, envy-freeness and equitability, and two individual disutility aggregation functions: additive and maximum based. We show that deciding the existence of a fair allocation is hard even if the underlying graph is a path or a star. We also present some efficiently solvable special cases for these graph topologies.

</details>

<details>

<summary>2018-12-05 08:50:40 - Integrating Reviews into Personalized Ranking for Cold Start Recommendation</summary>

- *Guang-Neng Hu, Xin-Yu Dai*

- `1701.08888v2` - [abs](http://arxiv.org/abs/1701.08888v2) - [pdf](http://arxiv.org/pdf/1701.08888v2)

> Item recommendation task predicts a personalized ranking over a set of items for each individual user. One paradigm is the rating-based methods that concentrate on explicit feedbacks and hence face the difficulties in collecting them. Meanwhile, the ranking-based methods are presented with rated items and then rank the rated above the unrated. This paradigm takes advantage of widely available implicit feedback. It, however, usually ignores a kind of important information: item reviews. Item reviews not only justify the preferences of users, but also help alleviate the cold-start problem that fails the collaborative filtering. In this paper, we propose two novel and simple models to integrate item reviews into Bayesian personalized ranking. In each model, we make use of text features extracted from item reviews using word embeddings. On top of text features we uncover the review dimensions that explain the variation in users' feedback and these review factors represent a prior preference of users. Experiments on six real-world data sets show the benefits of leveraging item reviews on ranking prediction. We also conduct analyses to understand the proposed models.

</details>

<details>

<summary>2018-12-05 10:08:29 - Approach for Semi-automatic Construction of Anti-infective Drug Ontology Based on Entity Linking</summary>

- *Ying Shen, Yang Deng, Kaiqi Yuan, Li Liu, Yong Liu*

- `1812.01887v1` - [abs](http://arxiv.org/abs/1812.01887v1) - [pdf](http://arxiv.org/pdf/1812.01887v1)

> Ontology can be used for the interpretation of natural language. To construct an anti-infective drug ontology, one needs to design and deploy a methodological step to carry out the entity discovery and linking. Medical synonym resources have been an important part of medical natural language processing (NLP). However, there are problems such as low precision and low recall rate. In this study, an NLP approach is adopted to generate candidate entities. Open ontology is analyzed to extract semantic relations. Six-word vector features and word-level features are selected to perform the entity linking. The extraction results of synonyms with a single feature and different combinations of features are studied. Experiments show that our selected features have achieved a precision rate of 86.77%, a recall rate of 89.03% and an F1 score of 87.89%. This paper finally presents the structure of the proposed ontology and its relevant statistical data.

</details>

<details>

<summary>2018-12-05 10:14:50 - Constructing Ontology-Based Cancer Treatment Decision Support System with Case-Based Reasoning</summary>

- *Ying Shen, Joël Colloc, Armelle Jacquet-Andrieu, Ziyi Guo, Yong Liu*

- `1812.01891v1` - [abs](http://arxiv.org/abs/1812.01891v1) - [pdf](http://arxiv.org/pdf/1812.01891v1)

> Decision support is a probabilistic and quantitative method designed for modeling problems in situations with ambiguity. Computer technology can be employed to provide clinical decision support and treatment recommendations. The problem of natural language applications is that they lack formality and the interpretation is not consistent. Conversely, ontologies can capture the intended meaning and specify modeling primitives. Disease Ontology (DO) that pertains to cancer's clinical stages and their corresponding information components is utilized to improve the reasoning ability of a decision support system (DSS). The proposed DSS uses Case-Based Reasoning (CBR) to consider disease manifestations and provides physicians with treatment solutions from similar previous cases for reference. The proposed DSS supports natural language processing (NLP) queries. The DSS obtained 84.63% accuracy in disease classification with the help of the ontology.

</details>

<details>

<summary>2018-12-05 10:16:00 - An Evolutionary Hierarchical Interval Type-2 Fuzzy Knowledge Representation System (EHIT2FKRS) for Travel Route Assignment</summary>

- *Mariam Zouari, Nesrine Baklouti, Javier Sanchez Medina, Mounir Ben Ayed, Adel M. Alimi*

- `1812.01893v1` - [abs](http://arxiv.org/abs/1812.01893v1) - [pdf](http://arxiv.org/pdf/1812.01893v1)

> Urban Traffic Networks are characterized by high dynamics of traffic flow and increased travel time, including waiting times. This leads to more complex road traffic management. The present research paper suggests an innovative advanced traffic management system based on Hierarchical Interval Type-2 Fuzzy Logic model optimized by the Particle Swarm Optimization (PSO) method. The aim of designing this system is to perform dynamic route assignment to relieve traffic congestion and limit the unexpected fluctuation effects on traffic flow. The suggested system is executed and simulated using SUMO, a well-known microscopic traffic simulator. For the present study, we have tested four large and heterogeneous metropolitan areas located in the cities of Sfax, Luxembourg, Bologna and Cologne. The experimental results proved the effectiveness of learning the Hierarchical Interval type-2 Fuzzy logic using real time particle swarm optimization technique PSO to accomplish multiobjective optimality regarding two criteria: number of vehicles that reach their destination and average travel time. The obtained results are encouraging, confirming the efficiency of the proposed system.

</details>

<details>

<summary>2018-12-05 12:24:21 - End-to-End Learning of Communications Systems Without a Channel Model</summary>

- *Fayçal Ait Aoudia, Jakob Hoydis*

- `1804.02276v3` - [abs](http://arxiv.org/abs/1804.02276v3) - [pdf](http://arxiv.org/pdf/1804.02276v3)

> The idea of end-to-end learning of communications systems through neural network -based autoencoders has the shortcoming that it requires a differentiable channel model. We present in this paper a novel learning algorithm which alleviates this problem. The algorithm iterates between supervised training of the receiver and reinforcement learning -based training of the transmitter. We demonstrate that this approach works as well as fully supervised methods on additive white Gaussian noise (AWGN) and Rayleigh block-fading (RBF) channels. Surprisingly, while our method converges slower on AWGN channels than supervised training, it converges faster on RBF channels. Our results are a first step towards learning of communications systems over any type of channel without prior assumptions.

</details>

<details>

<summary>2018-12-05 14:55:44 - Popularity-Aware Item Weighting for Long-Tail Recommendation</summary>

- *Himan Abdollahpouri, Robin Burke, Bamshad Mobasher*

- `1802.05382v3` - [abs](http://arxiv.org/abs/1802.05382v3) - [pdf](http://arxiv.org/pdf/1802.05382v3)

> Many recommender systems suffer from the popularity bias problem: popular items are being recommended frequently while less popular, niche products, are recommended rarely if not at all. However, those ignored products are exactly the products that businesses need to find customers for and their recommendations would be more beneficial. In this paper, we examine an item weighting approach to improve long-tail recommendation. Our approach works as a simple yet powerful add-on to existing recommendation algorithms for making a tunable trade-off between accuracy and long-tail coverage.

</details>

<details>

<summary>2018-12-05 20:41:02 - Consistency for 0-1 Programming</summary>

- *Danial Davarnia, J. N. Hooker*

- `1812.02215v1` - [abs](http://arxiv.org/abs/1812.02215v1) - [pdf](http://arxiv.org/pdf/1812.02215v1)

> Concepts of consistency have long played a key role in constraint programming but never developed in integer programming (IP). Consistency nonetheless plays a role in IP as well. For example, cutting planes can reduce backtracking by achieving various forms of consistency as well as by tightening the linear programming (LP) relaxation. We introduce a type of consistency that is particularly suited for 0-1 programming and develop the associated theory. We define a 0-1 constraint set as LP-consistent when any partial assignment that is consistent with its linear programming relaxation is consistent with the original 0-1 constraint set. We prove basic properties of LP-consistency, including its relationship with Chvatal-Gomory cuts and the integer hull. We show that a weak form of LP-consistency can reduce or eliminate backtracking in a way analogous to k-consistency but is easier to achieve. In so doing, we identify a class of valid inequalities that can be more effective than traditional cutting planes at cutting off infeasible 0-1 partial assignments.

</details>

<details>

<summary>2018-12-05 20:47:11 - Truly Autonomous Machines Are Ethical</summary>

- *John Hooker*

- `1812.02217v1` - [abs](http://arxiv.org/abs/1812.02217v1) - [pdf](http://arxiv.org/pdf/1812.02217v1)

> While many see the prospect of autonomous machines as threatening, autonomy may be exactly what we want in a superintelligent machine. There is a sense of autonomy, deeply rooted in the ethical literature, in which an autonomous machine is necessarily an ethical one. Development of the theory underlying this idea not only reveals the advantages of autonomy, but it sheds light on a number of issues in the ethics of artificial intelligence. It helps us to understand what sort of obligations we owe to machines, and what obligations they owe to us. It clears up the issue of assigning responsibility to machines or their creators. More generally, a concept of autonomy that is adequate to both human and artificial intelligence can lead to a more adequate ethical theory for both.

</details>

<details>

<summary>2018-12-05 21:21:09 - Towards a Definition of Disentangled Representations</summary>

- *Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende, Alexander Lerchner*

- `1812.02230v1` - [abs](http://arxiv.org/abs/1812.02230v1) - [pdf](http://arxiv.org/pdf/1812.02230v1)

> How can intelligent agents solve a diverse set of tasks in a data-efficient manner? The disentangled representation learning approach posits that such an agent would benefit from separating out (disentangling) the underlying structure of the world into disjoint parts of its representation. However, there is no generally agreed-upon definition of disentangling, not least because it is unclear how to formalise the notion of world structure beyond toy datasets with a known ground truth generative process. Here we propose that a principled solution to characterising disentangled representations can be found by focusing on the transformation properties of the world. In particular, we suggest that those transformations that change only some properties of the underlying world state, while leaving all other properties invariant, are what gives exploitable structure to any kind of data. Similar ideas have already been successfully applied in physics, where the study of symmetry transformations has revolutionised the understanding of the world structure. By connecting symmetry transformations to vector representations using the formalism of group and representation theory we arrive at the first formal definition of disentangled representations. Our new definition is in agreement with many of the current intuitions about disentangling, while also providing principled resolutions to a number of previous points of contention. While this work focuses on formally defining disentangling - as opposed to solving the learning problem - we believe that the shift in perspective to studying data transformations can stimulate the development of better representation learning algorithms.

</details>

<details>

<summary>2018-12-05 22:14:04 - Grounding Language for Transfer in Deep Reinforcement Learning</summary>

- *Karthik Narasimhan, Regina Barzilay, Tommi Jaakkola*

- `1708.00133v2` - [abs](http://arxiv.org/abs/1708.00133v2) - [pdf](http://arxiv.org/pdf/1708.00133v2)

> In this paper, we explore the utilization of natural language to drive transfer for reinforcement learning (RL). Despite the wide-spread application of deep RL techniques, learning generalized policy representations that work across domains remains a challenging problem. We demonstrate that textual descriptions of environments provide a compact intermediate channel to facilitate effective policy transfer. Specifically, by learning to ground the meaning of text to the dynamics of the environment such as transitions and rewards, an autonomous agent can effectively bootstrap policy learning on a new domain given its description. We employ a model-based RL approach consisting of a differentiable planning module, a model-free component and a factorized state representation to effectively use entity descriptions. Our model outperforms prior work on both transfer and multi-task scenarios in a variety of different environments. For instance, we achieve up to 14% and 11.5% absolute improvement over previously existing models in terms of average and initial rewards, respectively.

</details>

<details>

<summary>2018-12-05 23:41:04 - Efficient Counterfactual Learning from Bandit Feedback</summary>

- *Yusuke Narita, Shota Yasui, Kohei Yata*

- `1809.03084v3` - [abs](http://arxiv.org/abs/1809.03084v3) - [pdf](http://arxiv.org/pdf/1809.03084v3)

> What is the most statistically efficient way to do off-policy evaluation and optimization with batch data from bandit feedback? For log data generated by contextual bandit algorithms, we consider offline estimators for the expected reward from a counterfactual policy. Our estimators are shown to have lowest variance in a wide class of estimators, achieving variance reduction relative to standard estimators. We then apply our estimators to improve advertisement design by a major advertisement company. Consistent with the theoretical result, our estimators allow us to improve on the existing bandit algorithm with more statistical confidence compared to a state-of-the-art benchmark.

</details>

<details>

<summary>2018-12-06 03:31:29 - On Uncensored Mean First-Passage-Time Performance Experiments with Multiwalk in $\mathbb{R}^p$: a New Stochastic Optimization Algorithm</summary>

- *Franc Brglez*

- `1812.03075v1` - [abs](http://arxiv.org/abs/1812.03075v1) - [pdf](http://arxiv.org/pdf/1812.03075v1)

> A rigorous empirical comparison of two stochastic solvers is important when one of the solvers is a prototype of a new algorithm such as multiwalk (MWA). When searching for global minima in $\mathbb{R}^p$, the key data structures of MWA include: $p$ rulers with each ruler assigned $m$ marks and a set of $p$ neighborhood matrices of size up to $m(m-2)$, where each entry represents absolute values of pairwise differences between $m$ marks. Before taking the next step, a controller links the tableau of neighborhood matrices and computes new and improved positions for each of the $m$ marks. The number of columns in each neighborhood matrix is denoted as the neighborhood radius $r_n \le m-2$. Any variant of the DEA (differential evolution algorithm) has an effective population neighborhood of radius not larger than 1. Uncensored first-passage-time performance experiments that vary the neighborhood radius of a MW-solver can thus be readily compared to existing variants of DE-solvers. The paper considers seven test cases of increasing complexity and demonstrates, under uncensored first-passage-time performance experiments: (1) significant variability in convergence rate for seven DE-based solver configurations, and (2) consistent, monotonic, and significantly faster rate of convergence for the MW-solver prototype as we increase the neighborhood radius from 4 to its maximum value.

</details>

<details>

<summary>2018-12-06 06:17:16 - Environments for Lifelong Reinforcement Learning</summary>

- *Khimya Khetarpal, Shagun Sodhani, Sarath Chandar, Doina Precup*

- `1811.10732v2` - [abs](http://arxiv.org/abs/1811.10732v2) - [pdf](http://arxiv.org/pdf/1811.10732v2)

> To achieve general artificial intelligence, reinforcement learning (RL) agents should learn not only to optimize returns for one specific task but also to constantly build more complex skills and scaffold their knowledge about the world, without forgetting what has already been learned. In this paper, we discuss the desired characteristics of environments that can support the training and evaluation of lifelong reinforcement learning agents, review existing environments from this perspective, and propose recommendations for devising suitable environments in the future.

</details>

<details>

<summary>2018-12-06 11:33:00 - The Role of Normware in Trustworthy and Explainable AI</summary>

- *Giovanni Sileno, Alexander Boer, Tom van Engers*

- `1812.02471v1` - [abs](http://arxiv.org/abs/1812.02471v1) - [pdf](http://arxiv.org/pdf/1812.02471v1)

> For being potentially destructive, in practice incomprehensible and for the most unintelligible, contemporary technology is setting high challenges on our society. New conception methods are urgently required. Reorganizing ideas and discussions presented in AI and related fields, this position paper aims to highlight the importance of normware--that is, computational artifacts specifying norms--with respect to these issues, and argues for its irreducibility with respect to software by making explicit its neglected ecological dimension in the decision-making cycle.

</details>

<details>

<summary>2018-12-06 12:09:16 - Sim-to-Real Optimization of Complex Real World Mobile Network with Imperfect Information via Deep Reinforcement Learning from Self-play</summary>

- *Yongxi Tan, Jin Yang, Xin Chen, Qitao Song, Yunjun Chen, Zhangxiang Ye, Zhenqiang Su*

- `1802.06416v3` - [abs](http://arxiv.org/abs/1802.06416v3) - [pdf](http://arxiv.org/pdf/1802.06416v3)

> Mobile network that millions of people use every day is one of the most complex systems in the world. Optimization of mobile network to meet exploding customer demand and reduce capital/operation expenditures poses great challenges. Despite recent progress, application of deep reinforcement learning (DRL) to complex real world problem still remains unsolved, given data scarcity, partial observability, risk and complex rules/dynamics in real world, as well as the huge reality gap between simulation and real world. To bridge the reality gap, we introduce a Sim-to-Real framework to directly transfer learning from simulation to real world via graph convolutional neural network (CNN) - by abstracting partially observable mobile network into graph, then distilling domain-variant irregular graph into domain-invariant tensor in locally Euclidean space as input to CNN -, domain randomization and multi-task learning. We use a novel self-play mechanism to encourage competition among DRL agents for best record on multiple tasks via simulated annealing, just like athletes compete for world record in decathlon. We also propose a decentralized multi-agent, competitive and cooperative DRL method to coordinate the actions of multi-cells to maximize global reward and minimize negative impact to neighbor cells. Using 6 field trials on commercial mobile networks, we demonstrate for the first time that a DRL agent can successfully transfer learning from simulation to complex real world problem with imperfect information, complex rules/dynamics, huge state/action space, and multi-agent interactions, without any training in the real world.

</details>

<details>

<summary>2018-12-06 15:57:41 - Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs</summary>

- *Dinesh Acharya, Zhiwu Huang, Danda Pani Paudel, Luc Van Gool*

- `1810.02419v2` - [abs](http://arxiv.org/abs/1810.02419v2) - [pdf](http://arxiv.org/pdf/1810.02419v2)

> The extension of image generation to video generation turns out to be a very difficult task, since the temporal dimension of videos introduces an extra challenge during the generation process. Besides, due to the limitation of memory and training stability, the generation becomes increasingly challenging with the increase of the resolution/duration of videos. In this work, we exploit the idea of progressive growing of Generative Adversarial Networks (GANs) for higher resolution video generation. In particular, we begin to produce video samples of low-resolution and short-duration, and then progressively increase both resolution and duration alone (or jointly) by adding new spatiotemporal convolutional layers to the current networks. Starting from the learning on a very raw-level spatial appearance and temporal movement of the video distribution, the proposed progressive method learns spatiotemporal information incrementally to generate higher resolution videos. Furthermore, we introduce a sliced version of Wasserstein GAN (SWGAN) loss to improve the distribution learning on the video data of high-dimension and mixed-spatiotemporal distribution. SWGAN loss replaces the distance between joint distributions by that of one-dimensional marginal distributions, making the loss easier to compute. We evaluate the proposed model on our collected face video dataset of 10,900 videos to generate photorealistic face videos of 256x256x32 resolution. In addition, our model also reaches a record inception score of 14.57 in unsupervised action recognition dataset UCF-101.

</details>

<details>

<summary>2018-12-06 16:13:43 - Active Deep Q-learning with Demonstration</summary>

- *Si-An Chen, Voot Tangkaratt, Hsuan-Tien Lin, Masashi Sugiyama*

- `1812.02632v1` - [abs](http://arxiv.org/abs/1812.02632v1) - [pdf](http://arxiv.org/pdf/1812.02632v1)

> Recent research has shown that although Reinforcement Learning (RL) can benefit from expert demonstration, it usually takes considerable efforts to obtain enough demonstration. The efforts prevent training decent RL agents with expert demonstration in practice. In this work, we propose Active Reinforcement Learning with Demonstration (ARLD), a new framework to streamline RL in terms of demonstration efforts by allowing the RL agent to query for demonstration actively during training. Under the framework, we propose Active Deep Q-Network, a novel query strategy which adapts to the dynamically-changing distributions during the RL training process by estimating the uncertainty of recent states. The expert demonstration data within Active DQN are then utilized by optimizing supervised max-margin loss in addition to temporal difference loss within usual DQN training. We propose two methods of estimating the uncertainty based on two state-of-the-art DQN models, namely the divergence of bootstrapped DQN and the variance of noisy DQN. The empirical results validate that both methods not only learn faster than other passive expert demonstration methods with the same amount of demonstration and but also reach super-expert level of performance across four different tasks.

</details>

<details>

<summary>2018-12-06 16:15:24 - Traversing Latent Space using Decision Ferns</summary>

- *Yan Zuo, Gil Avraham, Tom Drummond*

- `1812.02636v1` - [abs](http://arxiv.org/abs/1812.02636v1) - [pdf](http://arxiv.org/pdf/1812.02636v1)

> The practice of transforming raw data to a feature space so that inference can be performed in that space has been popular for many years. Recently, rapid progress in deep neural networks has given both researchers and practitioners enhanced methods that increase the richness of feature representations, be it from images, text or speech. In this work we show how a constructed latent space can be explored in a controlled manner and argue that this complements well founded inference methods. For constructing the latent space a Variational Autoencoder is used. We present a novel controller module that allows for smooth traversal in the latent space and construct an end-to-end trainable framework. We explore the applicability of our method for performing spatial transformations as well as kinematics for predicting future latent vectors of a video sequence.

</details>

<details>

<summary>2018-12-06 16:36:20 - Deep Reinforcement Learning and the Deadly Triad</summary>

- *Hado van Hasselt, Yotam Doron, Florian Strub, Matteo Hessel, Nicolas Sonnerat, Joseph Modayil*

- `1812.02648v1` - [abs](http://arxiv.org/abs/1812.02648v1) - [pdf](http://arxiv.org/pdf/1812.02648v1)

> We know from reinforcement learning theory that temporal difference learning can fail in certain cases. Sutton and Barto (2018) identify a deadly triad of function approximation, bootstrapping, and off-policy learning. When these three properties are combined, learning can diverge with the value estimates becoming unbounded. However, several algorithms successfully combine these three properties, which indicates that there is at least a partial gap in our understanding. In this work, we investigate the impact of the deadly triad in practice, in the context of a family of popular deep reinforcement learning models - deep Q-networks trained with experience replay - analysing how the components of this system play a role in the emergence of the deadly triad, and in the agent's performance

</details>

<details>

<summary>2018-12-06 17:05:28 - Scope of Research on Particle Swarm Optimization Based Data Clustering</summary>

- *Vishakha A Metre, Mr Pramod B Deshmukh*

- `1903.12073v1` - [abs](http://arxiv.org/abs/1903.12073v1) - [pdf](http://arxiv.org/pdf/1903.12073v1)

> Optimization is nothing but a mathematical technique which finds maxima or minima of any function of concern in some realistic region. Different optimization techniques are proposed which are competing for the best solution. Particle Swarm Optimization (PSO) is a new, advanced, and most powerful optimization methodology that performs empirically well on several optimization problems. It is the extensively used Swarm Intelligence (SI) inspired optimization algorithm used for finding the global optimal solution in a multifaceted search region. Data clustering is one of the challenging real world applications that invite the eminent research works in variety of fields. Applicability of different PSO variants to data clustering is studied in the literature, and the analyzed research work shows that, PSO variants give poor results for multidimensional data. This paper describes the different challenges associated with multidimensional data clustering and scope of research on optimizing the clustering problems using PSO. We also propose a strategy to use hybrid PSO variant for clustering multidimensional numerical, text and image data.

</details>

<details>

<summary>2018-12-06 18:57:52 - Project Rosetta: A Childhood Social, Emotional, and Behavioral Developmental Ontology</summary>

- *Alyson Maslowski, Halim Abbas, Kelley Abrams, Sharief Taraman, Ford Garberson, Susan Segar*

- `1812.02722v1` - [abs](http://arxiv.org/abs/1812.02722v1) - [pdf](http://arxiv.org/pdf/1812.02722v1)

> There is a wide array of existing instruments used to assess childhood behavior and development for the evaluation of social, emotional and behavioral disorders. Many of these instruments either focus on one diagnostic category or encompass a broad set of childhood behaviors. We built an extensive ontology of the questions associated with key features that have diagnostic relevance for child behavioral conditions, such as Autism Spectrum Disorder (ASD), attention-deficit/hyperactivity disorder (ADHD), and anxiety, by incorporating a subset of existing child behavioral instruments and categorizing each question into clinical domains. Each existing question and set of question responses were then mapped to a new unique Rosetta question and set of answer codes encompassing the semantic meaning and identified concept(s) of as many existing questions as possible. This resulted in 1274 existing instrument questions mapping to 209 Rosetta questions creating a minimal set of questions that are comprehensive of each topic and subtopic. This resulting ontology can be used to create more concise instruments across various ages and conditions, as well as create more robust overlapping datasets for both clinical and research use.

</details>

<details>

<summary>2018-12-06 20:26:42 - Beyond imitation: Zero-shot task transfer on robots by learning concepts as cognitive programs</summary>

- *Miguel Lázaro-Gredilla, Dianhuan Lin, J. Swaroop Guntupalli, Dileep George*

- `1812.02788v1` - [abs](http://arxiv.org/abs/1812.02788v1) - [pdf](http://arxiv.org/pdf/1812.02788v1)

> Humans can infer concepts from image pairs and apply those in the physical world in a completely different setting, enabling tasks like IKEA assembly from diagrams. If robots could represent and infer high-level concepts, it would significantly improve their ability to understand our intent and to transfer tasks between different environments. To that end, we introduce a computational framework that replicates aspects of human concept learning. Concepts are represented as programs on a novel computer architecture consisting of a visual perception system, working memory, and action controller. The instruction set of this "cognitive computer" has commands for parsing a visual scene, directing gaze and attention, imagining new objects, manipulating the contents of a visual working memory, and controlling arm movement. Inferring a concept corresponds to inducing a program that can transform the input to the output. Some concepts require the use of imagination and recursion. Previously learned concepts simplify the learning of subsequent more elaborate concepts, and create a hierarchy of abstractions. We demonstrate how a robot can use these abstractions to interpret novel concepts presented to it as schematic images, and then apply those concepts in dramatically different situations. By bringing cognitive science ideas on mental imagery, perceptual symbols, embodied cognition, and deictic mechanisms into the realm of machine learning, our work brings us closer to the goal of building robots that have interpretable representations and commonsense.

</details>

<details>

<summary>2018-12-06 23:32:05 - Ranked Reward: Enabling Self-Play Reinforcement Learning for Combinatorial Optimization</summary>

- *Alexandre Laterre, Yunguan Fu, Mohamed Khalil Jabri, Alain-Sam Cohen, David Kas, Karl Hajjar, Torbjorn S. Dahl, Amine Kerkeni, Karim Beguir*

- `1807.01672v3` - [abs](http://arxiv.org/abs/1807.01672v3) - [pdf](http://arxiv.org/pdf/1807.01672v3)

> Adversarial self-play in two-player games has delivered impressive results when used with reinforcement learning algorithms that combine deep neural networks and tree search. Algorithms like AlphaZero and Expert Iteration learn tabula-rasa, producing highly informative training data on the fly. However, the self-play training strategy is not directly applicable to single-player games. Recently, several practically important combinatorial optimisation problems, such as the travelling salesman problem and the bin packing problem, have been reformulated as reinforcement learning problems, increasing the importance of enabling the benefits of self-play beyond two-player games. We present the Ranked Reward (R2) algorithm which accomplishes this by ranking the rewards obtained by a single agent over multiple games to create a relative performance metric. Results from applying the R2 algorithm to instances of a two-dimensional and three-dimensional bin packing problems show that it outperforms generic Monte Carlo tree search, heuristic algorithms and integer programming solvers. We also present an analysis of the ranked reward mechanism, in particular, the effects of problem instances with varying difficulty and different ranking thresholds.

</details>

<details>

<summary>2018-12-07 01:17:25 - Convolutional Neural Network Architectures for Signals Supported on Graphs</summary>

- *Fernando Gama, Antonio G. Marques, Geert Leus, Alejandro Ribeiro*

- `1805.00165v2` - [abs](http://arxiv.org/abs/1805.00165v2) - [pdf](http://arxiv.org/pdf/1805.00165v2)

> Two architectures that generalize convolutional neural networks (CNNs) for the processing of signals supported on graphs are introduced. We start with the selection graph neural network (GNN), which replaces linear time invariant filters with linear shift invariant graph filters to generate convolutional features and reinterprets pooling as a possibly nonlinear subsampling stage where nearby nodes pool their information in a set of preselected sample nodes. A key component of the architecture is to remember the position of sampled nodes to permit computation of convolutional features at deeper layers. The second architecture, dubbed aggregation GNN, diffuses the signal through the graph and stores the sequence of diffused components observed by a designated node. This procedure effectively aggregates all components into a stream of information having temporal structure to which the convolution and pooling stages of regular CNNs can be applied. A multinode version of aggregation GNNs is further introduced for operation in large scale graphs. An important property of selection and aggregation GNNs is that they reduce to conventional CNNs when particularized to time signals reinterpreted as graph signals in a circulant graph. Comparative numerical analyses are performed in a source localization application over synthetic and real-world networks. Performance is also evaluated for an authorship attribution problem and text category classification. Multinode aggregation GNNs are consistently the best performing GNN architecture.

</details>

<details>

<summary>2018-12-07 02:02:29 - A new multilayer optical film optimal method based on deep q-learning</summary>

- *Anqing Jiang, Osamu Yoshie, LiangYao Chen*

- `1812.02873v1` - [abs](http://arxiv.org/abs/1812.02873v1) - [pdf](http://arxiv.org/pdf/1812.02873v1)

> Multi-layer optical film has been found to afford important applications in optical communication, optical absorbers, optical filters, etc. Different algorithms of multi-layer optical film design has been developed, as simplex method, colony algorithm, genetic algorithm. These algorithms rapidly promote the design and manufacture of multi-layer films. However, traditional numerical algorithms of converge to local optimum. This means that the algorithms can not give a global optimal solution to the material researchers. In recent years, due to the rapid development to far artificial intelligence, to optimize optical film structure using AI algorithm has become possible. In this paper, we will introduce a new optical film design algorithm based on the deep Q learning. This model can converge the global optimum of the optical thin film structure, this will greatly improve the design efficiency of multi-layer films.

</details>

<details>

<summary>2018-12-07 08:33:26 - On Marginally Correct Approximations of Dempster-Shafer Belief Functions from Data</summary>

- *Mieczysław A. Kłopotek, Sławomir T. Wierzchoń*

- `1812.02942v1` - [abs](http://arxiv.org/abs/1812.02942v1) - [pdf](http://arxiv.org/pdf/1812.02942v1)

> Mathematical Theory of Evidence (MTE), a foundation for reasoning under partial ignorance, is blamed to leave frequencies outside (or aside of) its framework. The seriousness of this accusation is obvious: no experiment may be run to compare the performance of MTE-based models of real world processes against real world data.   In this paper we consider this problem from the point of view of conditioning in the MTE. We describe the class of belief functions for which marginal consistency with observed frequencies may be achieved and conditional belief functions are proper belief functions,%\ and deal with implications for (marginal) approximation of general belief functions by this class of belief functions and for inference models in MTE.

</details>

<details>

<summary>2018-12-07 09:18:01 - Building Ethics into Artificial Intelligence</summary>

- *Han Yu, Zhiqi Shen, Chunyan Miao, Cyril Leung, Victor R. Lesser, Qiang Yang*

- `1812.02953v1` - [abs](http://arxiv.org/abs/1812.02953v1) - [pdf](http://arxiv.org/pdf/1812.02953v1)

> As artificial intelligence (AI) systems become increasingly ubiquitous, the topic of AI governance for ethical decision-making by AI has captured public imagination. Within the AI research community, this topic remains less familiar to many researchers. In this paper, we complement existing surveys, which largely focused on the psychological, social and legal discussions of the topic, with an analysis of recent advances in technical solutions for AI governance. By reviewing publications in leading AI conferences including AAAI, AAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four areas: 1) exploring ethical dilemmas; 2) individual ethical decision frameworks; 3) collective ethical decision frameworks; and 4) ethics in human-AI interactions. We highlight the intuitions and key techniques used in each approach, and discuss promising future research directions towards successful integration of ethical AI systems into human societies.

</details>

<details>

<summary>2018-12-07 10:07:20 - Evolutionary Data Measures: Understanding the Difficulty of Text Classification Tasks</summary>

- *Edward Collins, Nikolai Rozanov, Bingbing Zhang*

- `1811.01910v2` - [abs](http://arxiv.org/abs/1811.01910v2) - [pdf](http://arxiv.org/pdf/1811.01910v2)

> Classification tasks are usually analysed and improved through new model architectures or hyperparameter optimisation but the underlying properties of datasets are discovered on an ad-hoc basis as errors occur. However, understanding the properties of the data is crucial in perfecting models. In this paper we analyse exactly which characteristics of a dataset best determine how difficult that dataset is for the task of text classification. We then propose an intuitive measure of difficulty for text classification datasets which is simple and fast to calculate. We show that this measure generalises to unseen data by comparing it to state-of-the-art datasets and results. This measure can be used to analyse the precise source of errors in a dataset and allows fast estimation of how difficult a dataset is to learn. We searched for this measure by training 12 classical and neural network based models on 78 real-world datasets, then use a genetic algorithm to discover the best measure of difficulty. Our difficulty-calculating code ( https://github.com/Wluper/edm ) and datasets ( http://data.wluper.com ) are publicly available.

</details>

<details>

<summary>2018-12-07 11:34:23 - Interval type-2 Beta Fuzzy Near set based approach to content based image retrieval</summary>

- *Yosr Ghozzi, Nesrine Baklouti, Hani Hagras, Mounir Ben Ayed, Adel M. Alimi*

- `1812.07098v1` - [abs](http://arxiv.org/abs/1812.07098v1) - [pdf](http://arxiv.org/pdf/1812.07098v1)

> In an automated search system, similarity is a key concept in solving a human task. Indeed, human process is usually a natural categorization that underlies many natural abilities such as image recovery, language comprehension, decision making, or pattern recognition. In the image search axis, there are several ways to measure the similarity between images in an image database, to a query image. Image search by content is based on the similarity of the visual characteristics of the images. The distance function used to evaluate the similarity between images depends on the criteria of the search but also on the representation of the characteristics of the image; this is the main idea of the near and fuzzy sets approaches. In this article, we introduce a new category of beta type-2 fuzzy sets for the description of image characteristics as well as the near sets approach for image recovery. Finally, we illustrate our work with examples of image recovery problems used in the real world.

</details>

<details>

<summary>2018-12-07 12:50:47 - The Modeling of SDL Aiming at Knowledge Acquisition in Automatic Driving</summary>

- *Zecang Gu, Yin Liang, Zhaoxi Zhang*

- `1812.03007v1` - [abs](http://arxiv.org/abs/1812.03007v1) - [pdf](http://arxiv.org/pdf/1812.03007v1)

> In this paper we proposed an ultimate theory to solve the multi-target control problem through its introduction to the machine learning framework in automatic driving, which explored the implementation of excellent drivers' knowledge acquisition. Nowadays there exist some core problems that have not been fully realized by the researchers in automatic driving, such as the optimal way to control the multi-target objective functions of energy saving, safe driving, headway distance control and comfort driving, as well as the resolvability of the networks that automatic driving relied on and the high-performance chips like GPU on the complex driving environments. According to these problems, we developed a new theory to map multitarget objective functions in different spaces into the same one and thus introduced a machine learning framework of SDL(Super Deep Learning) for optimal multi-targetcontrol based on knowledge acquisition. We will present in this paper the optimal multi-target control by combining the fuzzy relationship of each multi-target objective function and the implementation of excellent drivers' knowledge acquired by machine learning. Theoretically, the impact of this method will exceed that of the fuzzy control method used in automatic train.

</details>

<details>

<summary>2018-12-07 17:36:50 - Transferable Natural Language Interface to Structured Queries aided by Adversarial Generation</summary>

- *Hongyu Xiong, Ruixiao Sun*

- `1812.01245v2` - [abs](http://arxiv.org/abs/1812.01245v2) - [pdf](http://arxiv.org/pdf/1812.01245v2)

> A natural language interface (NLI) to structured query is intriguing due to its wide industrial applications and high economical values. In this work, we tackle the problem of domain adaptation for NLI with limited data on target domain. Two important approaches are considered: (a) effective general-knowledge-learning on source domain semantic parsing, and (b) data augmentation on target domain. We present a Structured Query Inference Network (SQIN) to enhance learning for domain adaptation, by separating schema information from NL and decoding SQL in a more structural-aware manner; we also propose a GAN-based augmentation technique (AugmentGAN) to mitigate the issue of lacking target domain data. We report solid results on GeoQuery, Overnight, and WikiSQL to demonstrate state-of-the-art performances for both in-domain and domain-transfer tasks.

</details>

<details>

<summary>2018-12-07 17:38:46 - Taking the Scenic Route: Automatic Exploration for Videogames</summary>

- *Zeping Zhan, Batu Aytemiz, Adam M. Smith*

- `1812.03125v1` - [abs](http://arxiv.org/abs/1812.03125v1) - [pdf](http://arxiv.org/pdf/1812.03125v1)

> Machine playtesting tools and game moment search engines require exposure to the diversity of a game's state space if they are to report on or index the most interesting moments of possible play. Meanwhile, mobile app distribution services would like to quickly determine if a freshly-uploaded game is fit to be published. Having access to a semantic map of reachable states in the game would enable efficient inference in these applications. However, human gameplay data is expensive to acquire relative to the coverage of a game that it provides. We show that off-the-shelf automatic exploration strategies can explore with an effectiveness comparable to human gameplay on the same timescale. We contribute generic methods for quantifying exploration quality as a function of time and demonstrate our metric on several elementary techniques and human players on a collection of commercial games sampled from multiple game platforms (from Atari 2600 to Nintendo 64). Emphasizing the diversity of states reached and the semantic map extracted, this work makes productive contrast with the focus on finding a behavior policy or optimizing game score used in most automatic game playing research.

</details>

<details>

<summary>2018-12-07 18:02:42 - Research on Limited Buffer Scheduling Problems in Flexible Flow Shops with Setup Times</summary>

- *Zhonghua Han, Quan Zhang, Haibo Shi, Yuanwei Qi, Liangliang Sun*

- `1812.08586v1` - [abs](http://arxiv.org/abs/1812.08586v1) - [pdf](http://arxiv.org/pdf/1812.08586v1)

> In order to solve the limited buffer scheduling problems in flexible flow shops with setup times, this paper proposes an improved whale optimization algorithm (IWOA) as a global optimization algorithm. Firstly, this paper presents a mathematic programming model for limited buffer in flexible flow shops with setup times, and applies the IWOA algorithm as the global optimization algorithm. Based on the whale optimization algorithm (WOA), the improved algorithm uses Levy flight, opposition-based learning strategy and simulated annealing to expand the search range, enhance the ability for jumping out of local extremum, and improve the continuous evolution of the algorithm. To verify the improvement of the proposed algorithm on the optimization ability of the standard WOA algorithm, the IWOA algorithm is tested by verification examples of small-scale and large-scale flexible flow shop scheduling problems, and the imperialist competitive algorithm (ICA), bat algorithm (BA), and whale optimization algorithm (WOA) are used for comparision. Based on the instance data of bus manufacturer, simulation tests are made on the four algorithms under variouis of practical evalucation scenarios. The simulation results show that the IWOA algorithm can better solve this type of limited buffer scheduling problem in flexible flow shops with setup times compared with the state of the art algorithms.

</details>

<details>

<summary>2018-12-08 00:10:05 - Efficient Concept Induction for Description Logics</summary>

- *Md Kamruzzaman Sarker, Pascal Hitzler*

- `1812.03243v1` - [abs](http://arxiv.org/abs/1812.03243v1) - [pdf](http://arxiv.org/pdf/1812.03243v1)

> Concept Induction refers to the problem of creating complex Description Logic class descriptions (i.e., TBox axioms) from instance examples (i.e., ABox data). In this paper we look particularly at the case where both a set of positive and a set of negative instances are given, and complex class expressions are sought under which the positive but not the negative examples fall. Concept induction has found applications in ontology engineering, but existing algorithms have fundamental performance issues in some scenarios, mainly because a high number of invokations of an external Description Logic reasoner is usually required. In this paper we present a new algorithm for this problem which drastically reduces the number of reasoner invokations needed. While this comes at the expense of a more limited traversal of the search space, we show that our approach improves execution times by up to several orders of magnitude, while output correctness, measured in the amount of correct coverage of the input instances, remains reasonably high in many cases. Our approach thus should provide a strong alternative to existing systems, in particular in settings where other systems are prohibitively slow.

</details>

<details>

<summary>2018-12-08 11:00:13 - On effective human robot interaction based on recognition and association</summary>

- *Avinash Kumar Singh*

- `1812.07100v1` - [abs](http://arxiv.org/abs/1812.07100v1) - [pdf](http://arxiv.org/pdf/1812.07100v1)

> Faces play a magnificent role in human robot interaction, as they do in our daily life. The inherent ability of the human mind facilitates us to recognize a person by exploiting various challenges such as bad illumination, occlusions, pose variation etc. which are involved in face recognition. But it is a very complex task in nature to identify a human face by humanoid robots. The recent literatures on face biometric recognition are extremely rich in its application on structured environment for solving human identification problem. But the application of face biometric on mobile robotics is limited for its inability to produce accurate identification in uneven circumstances. The existing face recognition problem has been tackled with our proposed component based fragmented face recognition framework. The proposed framework uses only a subset of the full face such as eyes, nose and mouth to recognize a person. It's less searching cost, encouraging accuracy and ability to handle various challenges of face recognition offers its applicability on humanoid robots. The second problem in face recognition is the face spoofing, in which a face recognition system is not able to distinguish between a person and an imposter (photo/video of the genuine user). The problem will become more detrimental when robots are used as an authenticator. A depth analysis method has been investigated in our research work to test the liveness of imposters to discriminate them from the legitimate users. The implication of the previous earned techniques has been used with respect to criminal identification with NAO robot. An eyewitness can interact with NAO through a user interface. NAO asks several questions about the suspect, such as age, height, her/his facial shape and size etc., and then making a guess about her/his face.

</details>

<details>

<summary>2018-12-08 20:16:16 - Learning Montezuma's Revenge from a Single Demonstration</summary>

- *Tim Salimans, Richard Chen*

- `1812.03381v1` - [abs](http://arxiv.org/abs/1812.03381v1) - [pdf](http://arxiv.org/pdf/1812.03381v1)

> We propose a new method for learning from a single demonstration to solve hard exploration tasks like the Atari game Montezuma's Revenge. Instead of imitating human demonstrations, as proposed in other recent works, our approach is to maximize rewards directly. Our agent is trained using off-the-shelf reinforcement learning, but starts every episode by resetting to a state from a demonstration. By starting from such demonstration states, the agent requires much less exploration to learn a game compared to when it starts from the beginning of the game at every episode. We analyze reinforcement learning for tasks with sparse rewards in a simple toy environment, where we show that the run-time of standard RL methods scales exponentially in the number of states between rewards. Our method reduces this to quadratic scaling, opening up many tasks that were previously infeasible. We then apply our method to Montezuma's Revenge, for which we present a trained agent achieving a high-score of 74,500, better than any previously published result.

</details>

<details>

<summary>2018-12-08 22:56:10 - GAN Dissection: Visualizing and Understanding Generative Adversarial Networks</summary>

- *David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T. Freeman, Antonio Torralba*

- `1811.10597v2` - [abs](http://arxiv.org/abs/1811.10597v2) - [pdf](http://arxiv.org/pdf/1811.10597v2)

> Generative Adversarial Networks (GANs) have recently achieved impressive results for many real-world applications, and many GAN variants have emerged with improvements in sample quality and training stability. However, they have not been well visualized or understood. How does a GAN represent our visual world internally? What causes the artifacts in GAN results? How do architectural choices affect GAN learning? Answering such questions could enable us to develop new insights and better models.   In this work, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. We first identify a group of interpretable units that are closely related to object concepts using a segmentation-based network dissection method. Then, we quantify the causal effect of interpretable units by measuring the ability of interventions to control objects in the output. We examine the contextual relationship between these units and their surroundings by inserting the discovered object concepts into new images. We show several practical applications enabled by our framework, from comparing internal representations across different layers, models, and datasets, to improving GANs by locating and removing artifact-causing units, to interactively manipulating objects in a scene. We provide open source interpretation tools to help researchers and practitioners better understand their GAN models.

</details>

<details>

<summary>2018-12-09 16:05:43 - Dialogue Generation: From Imitation Learning to Inverse Reinforcement Learning</summary>

- *Ziming Li, Julia Kiseleva, Maarten de Rijke*

- `1812.03509v1` - [abs](http://arxiv.org/abs/1812.03509v1) - [pdf](http://arxiv.org/pdf/1812.03509v1)

> The performance of adversarial dialogue generation models relies on the quality of the reward signal produced by the discriminator. The reward signal from a poor discriminator can be very sparse and unstable, which may lead the generator to fall into a local optimum or to produce nonsense replies. To alleviate the first problem, we first extend a recently proposed adversarial dialogue generation method to an adversarial imitation learning solution. Then, in the framework of adversarial inverse reinforcement learning, we propose a new reward model for dialogue generation that can provide a more accurate and precise reward signal for generator training. We evaluate the performance of the resulting model with automatic metrics and human evaluations in two annotation settings. Our experimental results demonstrate that our model can generate more high-quality responses and achieve higher overall performance than the state-of-the-art.

</details>

<details>

<summary>2018-12-09 16:44:56 - Deep-Net: Deep Neural Network for Cyber Security Use Cases</summary>

- *Vinayakumar R, Barathi Ganesh HB, Prabaharan Poornachandran, Anand Kumar M, Soman KP*

- `1812.03519v1` - [abs](http://arxiv.org/abs/1812.03519v1) - [pdf](http://arxiv.org/pdf/1812.03519v1)

> Deep neural networks (DNNs) have witnessed as a powerful approach in this year by solving long-standing Artificial intelligence (AI) supervised and unsupervised tasks exists in natural language processing, speech processing, computer vision and others. In this paper, we attempt to apply DNNs on three different cyber security use cases: Android malware classification, incident detection and fraud detection. The data set of each use case contains real known benign and malicious activities samples. The efficient network architecture for DNN is chosen by conducting various trails of experiments for network parameters and network structures. The experiments of such chosen efficient configurations of DNNs are run up to 1000 epochs with learning rate set in the range [0.01-0.5]. Experiments of DNN performed well in comparison to the classical machine learning algorithms in all cases of experiments of cyber security use cases. This is due to the fact that DNNs implicitly extract and build better features, identifies the characteristics of the data that lead to better accuracy. The best accuracy obtained by DNN and XGBoost on Android malware classification 0.940 and 0.741, incident detection 1.00 and 0.997 fraud detection 0.972 and 0.916 respectively.

</details>

<details>

<summary>2018-12-09 18:03:46 - On balanced clustering with tree-like structures over clusters</summary>

- *Mark Sh. Levin*

- `1812.03535v1` - [abs](http://arxiv.org/abs/1812.03535v1) - [pdf](http://arxiv.org/pdf/1812.03535v1)

> The article addresses balanced clustering problems with an additional requirement as a tree-like structure over the obtained balanced clusters. This kind of clustering problems can be useful in some applications (e.g., network design, management and routing). Various types of the initial elements are considered. Four basic greedy-like solving strategies (design framework) are considered: balancing-spanning strategy, spanning-balancing strategy, direct strategy, and design of layered structures with balancing. An extended description of the spanning-balancing strategy is presented including four solving schemes and an illustrative numerical example.

</details>

<details>

<summary>2018-12-09 19:46:00 - Artificial Intelligence Assisted Infrastructure Assessment Using Mixed Reality Systems</summary>

- *Enes Karaaslan, Ulas Bagci, F. Necati Catbas*

- `1812.05659v1` - [abs](http://arxiv.org/abs/1812.05659v1) - [pdf](http://arxiv.org/pdf/1812.05659v1)

> Conventional methods for visual assessment of civil infrastructures have certain limitations, such as subjectivity of the collected data, long inspection time, and high cost of labor. Although some new technologies i.e. robotic techniques that are currently in practice can collect objective, quantified data, the inspectors own expertise is still critical in many instances since these technologies are not designed to work interactively with human inspector. This study aims to create a smart, human centered method that offers significant contributions to infrastructure inspection, maintenance, management practice, and safety for the bridge owners. By developing a smart Mixed Reality framework, which can be integrated into a wearable holographic headset device, a bridge inspector, for example, can automatically analyze a certain defect such as a crack that he or she sees on an element, display its dimension information in real-time along with the condition state. Such systems can potentially decrease the time and cost of infrastructure inspections by accelerating essential tasks of the inspector such as defect measurement, condition assessment and data processing to management systems. The human centered artificial intelligence will help the inspector collect more quantified and objective data while incorporating inspectors professional judgement. This study explains in detail the described system and related methodologies of implementing attention guided semi supervised deep learning into mixed reality technology, which interacts with the human inspector during assessment. Thereby, the inspector and the AI will collaborate or communicate for improved visual inspection.

</details>

<details>

<summary>2018-12-10 04:17:27 - Diversified Late Acceptance Search</summary>

- *Majid Namazi, Conrad Sanderson, M. A. Hakim Newton, M. M. A. Polash, Abdul Sattar*

- `1806.09328v3` - [abs](http://arxiv.org/abs/1806.09328v3) - [pdf](http://arxiv.org/pdf/1806.09328v3)

> The well-known Late Acceptance Hill Climbing (LAHC) search aims to overcome the main downside of traditional Hill Climbing (HC) search, which is often quickly trapped in a local optimum due to strictly accepting only non-worsening moves within each iteration. In contrast, LAHC also accepts worsening moves, by keeping a circular array of fitness values of previously visited solutions and comparing the fitness values of candidate solutions against the least recent element in the array. While this straightforward strategy has proven effective, there are nevertheless situations where LAHC can unfortunately behave in a similar manner to HC. For example, when a new local optimum is found, often the same fitness value is stored many times in the array. To address this shortcoming, we propose new acceptance and replacement strategies to take into account worsening, improving, and sideways movement scenarios with the aim to improve the diversity of values in the array. Compared to LAHC, the proposed Diversified Late Acceptance Search approach is shown to lead to better quality solutions that are obtained with a lower number of iterations on benchmark Travelling Salesman Problems and Quadratic Assignment Problems.

</details>

<details>

<summary>2018-12-10 05:10:31 - A context-based geoprocessing framework for optimizing meetup location of multiple moving objects along road networks</summary>

- *Shaohua Wang, Song Gao, Xin Feng, Alan T. Murray, Yuan Zeng*

- `1812.03625v1` - [abs](http://arxiv.org/abs/1812.03625v1) - [pdf](http://arxiv.org/pdf/1812.03625v1)

> Given different types of constraints on human life, people must make decisions that satisfy social activity needs. Minimizing costs (i.e., distance, time, or money) associated with travel plays an important role in perceived and realized social quality of life. Identifying optimal interaction locations on road networks when there are multiple moving objects (MMO) with space-time constraints remains a challenge. In this research, we formalize the problem of finding dynamic ideal interaction locations for MMO as a spatial optimization model and introduce a context-based geoprocessing heuristic framework to address this problem. As a proof of concept, a case study involving identification of a meetup location for multiple people under traffic conditions is used to validate the proposed geoprocessing framework. Five heuristic methods with regard to efficient shortest-path search space have been tested. We find that the R* tree-based algorithm performs the best with high quality solutions and low computation time. This framework is implemented in a GIS environment to facilitate integration with external geographic contextual information, e.g., temporary road barriers, points of interest (POI), and real-time traffic information, when dynamically searching for ideal meetup sites. The proposed method can be applied in trip planning, carpooling services, collaborative interaction, and logistics management.

</details>

<details>

<summary>2018-12-10 09:53:04 - Taxi Demand-Supply Forecasting: Impact of Spatial Partitioning on the Performance of Neural Networks</summary>

- *Neema Davis, Gaurav Raina, Krishna Jagannathan*

- `1812.03699v1` - [abs](http://arxiv.org/abs/1812.03699v1) - [pdf](http://arxiv.org/pdf/1812.03699v1)

> In this paper, we investigate the significance of choosing an appropriate tessellation strategy for a spatio-temporal taxi demand-supply modeling framework. Our study compares (i) the variable-sized polygon based Voronoi tessellation, and (ii) the fixed-sized grid based Geohash tessellation, using taxi demand-supply GPS data for the cities of Bengaluru, India and New York, USA. Long Short-Term Memory (LSTM) networks are used for modeling and incorporating information from spatial neighbors into the model. We find that the LSTM model based on input features extracted from a variable-sized polygon tessellation yields superior performance over the LSTM model based on fixed-sized grid tessellation. Our study highlights the need to explore multiple spatial partitioning techniques for improving the prediction performance in neural network models.

</details>

<details>

<summary>2018-12-10 17:08:57 - Character-Level Language Modeling with Deeper Self-Attention</summary>

- *Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, Llion Jones*

- `1808.04444v2` - [abs](http://arxiv.org/abs/1808.04444v2) - [pdf](http://arxiv.org/pdf/1808.04444v2)

> LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.

</details>

<details>

<summary>2018-12-10 18:09:10 - Improving Model-Based Control and Active Exploration with Reconstruction Uncertainty Optimization</summary>

- *Norman Di Palo, Harri Valpola*

- `1812.03955v1` - [abs](http://arxiv.org/abs/1812.03955v1) - [pdf](http://arxiv.org/pdf/1812.03955v1)

> Model based predictions of future trajectories of a dynamical system often suffer from inaccuracies, forcing model based control algorithms to re-plan often, thus being computationally expensive, suboptimal and not reliable. In this work, we propose a model agnostic method for estimating the uncertainty of a model?s predictions based on reconstruction error, using it in control and exploration. As our experiments show, this uncertainty estimation can be used to improve control performance on a wide variety of environments by choosing predictions of which the model is confident. It can also be used for active learning to explore more efficiently the environment by planning for trajectories with high uncertainty, allowing faster model learning.

</details>

<details>

<summary>2018-12-10 18:21:47 - Guided Dropout</summary>

- *Rohit Keshari, Richa Singh, Mayank Vatsa*

- `1812.03965v1` - [abs](http://arxiv.org/abs/1812.03965v1) - [pdf](http://arxiv.org/pdf/1812.03965v1)

> Dropout is often used in deep neural networks to prevent over-fitting. Conventionally, dropout training invokes \textit{random drop} of nodes from the hidden layers of a Neural Network. It is our hypothesis that a guided selection of nodes for intelligent dropout can lead to better generalization as compared to the traditional dropout. In this research, we propose "guided dropout" for training deep neural network which drop nodes by measuring the strength of each node. We also demonstrate that conventional dropout is a specific case of the proposed guided dropout. Experimental evaluation on multiple datasets including MNIST, CIFAR10, CIFAR100, SVHN, and Tiny ImageNet demonstrate the efficacy of the proposed guided dropout.

</details>

<details>

<summary>2018-12-10 18:37:30 - Mapping Navigation Instructions to Continuous Control Actions with Position-Visitation Prediction</summary>

- *Valts Blukis, Dipendra Misra, Ross A. Knepper, Yoav Artzi*

- `1811.04179v2` - [abs](http://arxiv.org/abs/1811.04179v2) - [pdf](http://arxiv.org/pdf/1811.04179v2)

> We propose an approach for mapping natural language instructions and raw observations to continuous control of a quadcopter drone. Our model predicts interpretable position-visitation distributions indicating where the agent should go during execution and where it should stop, and uses the predicted distributions to select the actions to execute. This two-step model decomposition allows for simple and efficient training using a combination of supervised learning and imitation learning. We evaluate our approach with a realistic drone simulator, and demonstrate absolute task-completion accuracy improvements of 16.85% over two state-of-the-art instruction-following methods.

</details>

<details>

<summary>2018-12-10 18:58:05 - Building Ethically Bounded AI</summary>

- *Francesca Rossi, Nicholas Mattei*

- `1812.03980v1` - [abs](http://arxiv.org/abs/1812.03980v1) - [pdf](http://arxiv.org/pdf/1812.03980v1)

> The more AI agents are deployed in scenarios with possibly unexpected situations, the more they need to be flexible, adaptive, and creative in achieving the goal we have given them. Thus, a certain level of freedom to choose the best path to the goal is inherent in making AI robust and flexible enough. At the same time, however, the pervasive deployment of AI in our life, whether AI is autonomous or collaborating with humans, raises several ethical challenges. AI agents should be aware and follow appropriate ethical principles and should thus exhibit properties such as fairness or other virtues. These ethical principles should define the boundaries of AI's freedom and creativity. However, it is still a challenge to understand how to specify and reason with ethical boundaries in AI agents and how to combine them appropriately with subjective preferences and goal specifications. Some initial attempts employ either a data-driven example-based approach for both, or a symbolic rule-based approach for both. We envision a modular approach where any AI technique can be used for any of these essential ingredients in decision making or decision support systems, paired with a contextual approach to define their combination and relative weight. In a world where neither humans nor AI systems work in isolation, but are tightly interconnected, e.g., the Internet of Things, we also envision a compositional approach to building ethically bounded AI, where the ethical properties of each component can be fruitfully exploited to derive those of the overall system. In this paper we define and motivate the notion of ethically-bounded AI, we describe two concrete examples, and we outline some outstanding challenges.

</details>

<details>

<summary>2018-12-10 19:02:53 - Auto-Meta: Automated Gradient Based Meta Learner Search</summary>

- *Jaehong Kim, Sangyeul Lee, Sungwan Kim, Moonsu Cha, Jung Kwon Lee, Youngduck Choi, Yongseok Choi, Dong-Yeon Cho, Jiwon Kim*

- `1806.06927v2` - [abs](http://arxiv.org/abs/1806.06927v2) - [pdf](http://arxiv.org/pdf/1806.06927v2)

> Fully automating machine learning pipelines is one of the key challenges of current artificial intelligence research, since practical machine learning often requires costly and time-consuming human-powered processes such as model design, algorithm development, and hyperparameter tuning. In this paper, we verify that automated architecture search synergizes with the effect of gradient-based meta learning. We adopt the progressive neural architecture search \cite{liu:pnas_google:DBLP:journals/corr/abs-1712-00559} to find optimal architectures for meta-learners. The gradient based meta-learner whose architecture was automatically found achieved state-of-the-art results on the 5-shot 5-way Mini-ImageNet classification problem with $74.65\%$ accuracy, which is $11.54\%$ improvement over the result obtained by the first gradient-based meta-learner called MAML \cite{finn:maml:DBLP:conf/icml/FinnAL17}. To our best knowledge, this work is the first successful neural architecture search implementation in the context of meta learning.

</details>

<details>

<summary>2018-12-10 20:53:49 - Visual Depth Mapping from Monocular Images using Recurrent Convolutional Neural Networks</summary>

- *John Mern, Kyle Julian, Rachael E. Tompa, Mykel J. Kochenderfer*

- `1812.04082v1` - [abs](http://arxiv.org/abs/1812.04082v1) - [pdf](http://arxiv.org/pdf/1812.04082v1)

> A reliable sense-and-avoid system is critical to enabling safe autonomous operation of unmanned aircraft. Existing sense-and-avoid methods often require specialized sensors that are too large or power intensive for use on small unmanned vehicles. This paper presents a method to estimate object distances based on visual image sequences, allowing for the use of low-cost, on-board monocular cameras as simple collision avoidance sensors. We present a deep recurrent convolutional neural network and training method to generate depth maps from video sequences. Our network is trained using simulated camera and depth data generated with Microsoft's AirSim simulator. Empirically, we show that our model achieves superior performance compared to models generated using prior methods.We further demonstrate that the method can be used for sense-and-avoid of obstacles in simulation.

</details>

<details>

<summary>2018-12-11 03:25:02 - Investigating performance of neural networks and gradient boosting models approximating microscopic traffic simulations in traffic optimization tasks</summary>

- *Paweł Gora, Maciej Brzeski, Marcin Możejko, Arkadiusz Klemenko, Adrian Kochański*

- `1812.00401v3` - [abs](http://arxiv.org/abs/1812.00401v3) - [pdf](http://arxiv.org/pdf/1812.00401v3)

> We analyze the accuracy of traffic simulations metamodels based on neural networks and gradient boosting models (LightGBM), applied to traffic optimization as fitness functions of genetic algorithms. Our metamodels approximate outcomes of traffic simulations (the total time of waiting on a red signal) taking as an input different traffic signal settings, in order to efficiently find (sub)optimal settings. Their accuracy was proven to be very good on randomly selected test sets, but it turned out that the accuracy may drop in case of settings expected (according to genetic algorithms) to be close to local optima, which makes the traffic optimization process more difficult. In this work, we investigate 16 different metamodels and 20 settings of genetic algorithms, in order to understand what are the reasons of this phenomenon, what is its scale, how it can be mitigated and what can be potentially done to design better real-time traffic optimization methods.

</details>

<details>

<summary>2018-12-11 04:35:02 - Privacy-preserving data aggregation in resource-constrained sensor nodes in Internet of Things: A review</summary>

- *Inayat Ali, Sonia Sabir, Eraj Khan*

- `1812.04216v1` - [abs](http://arxiv.org/abs/1812.04216v1) - [pdf](http://arxiv.org/pdf/1812.04216v1)

> Privacy problems are lethal and getting more attention than any other issue with the notion of the Internet of Things (IoT). Since IoT has many application areas including smart home, smart grids, smart healthcare system, smart and intelligent transportation and many more. Most of these applications are fueled by the resource-constrained sensor network, such as Smart healthcare system is powered by Wireless Body Area Network (WBAN) and Smart home and weather monitoring systems are fueled by Wireless Sensor Networks (WSN). In the mentioned application areas sensor node life is a very important aspect of these technologies as it explicitly effects the network life and performance. Data aggregation techniques are used to increase sensor node life by decreasing communication overhead. However, when the data is aggregated at intermediate nodes to reduce communication overhead, data privacy problems becomes more vulnerable. Different Privacy-Preserving Data Aggregation (PPDA) techniques have been proposed to ensure data privacy during data aggregation in resource-constrained sensor nodes. We provide a review and comparative analysis of the state of the art PPDA techniques in this paper. The comparative analysis is based on Computation Cost, Communication overhead, Privacy Level, resistance against malicious aggregator, sensor node life and energy consumption by the sensor node. We have studied the most recent techniques and provide in-depth analysis of the minute steps involved in these techniques. To the best of our knowledge, this survey is the most recent and comprehensive study of PPDA techniques.

</details>

<details>

<summary>2018-12-11 06:48:59 - Intelligence-based Cybersecurity Awareness Training- an Exploratory Project</summary>

- *Tam n. Nguyen, Lydia Sbityakov, Samantha Scoggins*

- `1812.04234v1` - [abs](http://arxiv.org/abs/1812.04234v1) - [pdf](http://arxiv.org/pdf/1812.04234v1)

> Cybersecurity training should be adaptable to evolving the cyber threat landscape, cost effective and integrated well with other enterprise management components. Unfortunately, very few cybersecurity training platforms can satisfy such requirements. This paper proposes a new and novel model for conducting cybersecurity training with three main objectives: (i) training should be initiated by emerging relevant threats and delivered first to the most vulnerable members (ii) the process has to be agile (iii) training results must be able to provide actionable intelligence. For the first time, this paper establishes a type system (ontology and associated relationships) that links the domain of cybersecurity awareness training with that of cyber threat intelligence. Powered by IBM Watson Knowledge Studio platform, the proposed method was found to be practical and scalable. Main contributions such as exports of the type system, the manually annotated corpus of 100 threat reports and 127 cybersecurity assessment results, the dictionaries for pre-annotation, etc were made publicly available.

</details>

<details>

<summary>2018-12-11 07:04:44 - Machine Translation : From Statistical to modern Deep-learning practices</summary>

- *Siddhant Srivastava, Anupam Shukla, Ritu Tiwari*

- `1812.04238v1` - [abs](http://arxiv.org/abs/1812.04238v1) - [pdf](http://arxiv.org/pdf/1812.04238v1)

> Machine translation (MT) is an area of study in Natural Language processing which deals with the automatic translation of human language, from one language to another by the computer. Having a rich research history spanning nearly three decades, Machine translation is one of the most sought after area of research in the linguistics and computational community. In this paper, we investigate the models based on deep learning that have achieved substantial progress in recent years and becoming the prominent method in MT. We shall discuss the two main deep-learning based Machine Translation methods, one at component or domain level which leverages deep learning models to enhance the efficacy of Statistical Machine Translation (SMT) and end-to-end deep learning models in MT which uses neural networks to find correspondence between the source and target languages using the encoder-decoder architecture. We conclude this paper by providing a time line of the major research problems solved by the researchers and also provide a comprehensive overview of present areas of research in Neural Machine Translation.

</details>

<details>

<summary>2018-12-11 08:58:10 - Solving Pictorial Jigsaw Puzzle by Stigmergy-inspired Internet-based Human Collective Intelligence</summary>

- *Bo Shen, Wei Zhang, Haiyan Zhao, Zhi Jin, Yanhong Wu*

- `1812.02559v2` - [abs](http://arxiv.org/abs/1812.02559v2) - [pdf](http://arxiv.org/pdf/1812.02559v2)

> The pictorial jigsaw (PJ) puzzle is a well-known leisure game for humans. Usually, a PJ puzzle game is played by one or several human players face-to-face in the physical space. In this paper, we focus on how to solve PJ puzzles in the cyberspace by a group of physically distributed human players. We propose an approach to solving PJ puzzle by stigmergy-inspired Internet-based human collective intelligence. The core of the approach is a continuously executing loop, named the EIF loop, which consists of three activities: exploration, integration, and feedback. In exploration, each player tries to solve the PJ puzzle alone, without direct interactions with other players. At any time, the result of a player's exploration is a partial solution to the PJ puzzle, and a set of rejected neighboring relation between pieces. The results of all players' exploration are integrated in real time through integration, with the output of a continuously updated collective opinion graph (COG). And through feedback, each player is provided with personalized feedback information based on the current COG and the player's exploration result, in order to accelerate his/her puzzle-solving process. Exploratory experiments show that: (1) supported by this approach, the time to solve PJ puzzle is nearly linear to the reciprocal of the number of players, and shows better scalability to puzzle size than that of face-to-face collaboration for 10-player groups; (2) for groups with 2 to 10 players, the puzzle-solving time decreases 31.36%-64.57% on average, compared with the best single players in the experiments.

</details>

<details>

<summary>2018-12-11 10:33:54 - Finding dissimilar explanations in Bayesian networks: Complexity results</summary>

- *Johan Kwisthout*

- `1810.11391v2` - [abs](http://arxiv.org/abs/1810.11391v2) - [pdf](http://arxiv.org/pdf/1810.11391v2)

> Finding the most probable explanation for observed variables in a Bayesian network is a notoriously intractable problem, particularly if there are hidden variables in the network. In this paper we examine the complexity of a related problem, that is, the problem of finding a set of sufficiently dissimilar, yet all plausible, explanations. Applications of this problem are, e.g., in search query results (you won't want 10 results that all link to the same website) or in decision support systems. We show that the problem of finding a 'good enough' explanation that differs in structure from the best explanation is at least as hard as finding the best explanation itself.

</details>

<details>

<summary>2018-12-11 13:10:14 - Reading Industrial Inspection Sheets by Inferring Visual Relations</summary>

- *Rohit Rahul, Arindam Chowdhury, Animesh, Samarth Mittal, Lovekesh Vig*

- `1812.07104v1` - [abs](http://arxiv.org/abs/1812.07104v1) - [pdf](http://arxiv.org/pdf/1812.07104v1)

> The traditional mode of recording faults in heavy factory equipment has been via hand marked inspection sheets, wherein a machine engineer manually marks the faulty machine regions on a paper outline of the machine. Over the years, millions of such inspection sheets have been recorded and the data within these sheets has remained inaccessible. However, with industries going digital and waking up to the potential value of fault data for machine health monitoring, there is an increased impetus towards digitization of these hand marked inspection records. To target this digitization, we propose a novel visual pipeline combining state of the art deep learning models, with domain knowledge and low level vision techniques, followed by inference of visual relationships. Our framework is robust to the presence of both static and non-static background in the document, variability in the machine template diagrams, unstructured shape of graphical objects to be identified and variability in the strokes of handwritten text. The proposed pipeline incorporates a capsule and spatial transformer network based classifier for accurate text reading, and a customized CTPN network for text detection in addition to hybrid techniques for arrow detection and dialogue cloud removal. We have tested our approach on a real world dataset of 50 inspection sheets for large containers and boilers. The results are visually appealing and the pipeline achieved an accuracy of 87.1% for text detection and 94.6% for text reading.

</details>

<details>

<summary>2018-12-11 13:17:52 - Measuring and Characterizing Generalization in Deep Reinforcement Learning</summary>

- *Sam Witty, Jun Ki Lee, Emma Tosch, Akanksha Atrey, Michael Littman, David Jensen*

- `1812.02868v2` - [abs](http://arxiv.org/abs/1812.02868v2) - [pdf](http://arxiv.org/pdf/1812.02868v2)

> Deep reinforcement-learning methods have achieved remarkable performance on challenging control tasks. Observations of the resulting behavior give the impression that the agent has constructed a generalized representation that supports insightful action decisions. We re-examine what is meant by generalization in RL, and propose several definitions based on an agent's performance in on-policy, off-policy, and unreachable states. We propose a set of practical methods for evaluating agents with these definitions of generalization. We demonstrate these techniques on a common benchmark task for deep RL, and we show that the learned networks make poor decisions for states that differ only slightly from on-policy states, even though those states are not selected adversarially. Taken together, these results call into question the extent to which deep Q-networks learn generalized representations, and suggest that more experimentation and analysis is necessary before claims of representation learning can be supported.

</details>

<details>

<summary>2018-12-11 16:51:58 - End-to-End Refinement Guided by Pre-trained Prototypical Classifier</summary>

- *Junwen Bai, Zihang Lai, Runzhe Yang, Yexiang Xue, John Gregoire, Carla Gomes*

- `1805.08698v2` - [abs](http://arxiv.org/abs/1805.08698v2) - [pdf](http://arxiv.org/pdf/1805.08698v2)

> Many real-world tasks involve identifying patterns from data satisfying background or prior knowledge. In domains like materials discovery, due to the flaws and biases in raw experimental data, the identification of X-ray diffraction patterns (XRD) often requires a huge amount of manual work in finding refined phases that are similar to the ideal theoretical ones. Automatically refining the raw XRDs utilizing the simulated theoretical data is thus desirable. We propose imitation refinement, a novel approach to refine imperfect input patterns, guided by a pre-trained classifier incorporating prior knowledge from simulated theoretical data, such that the refined patterns imitate the ideal data. The classifier is trained on the ideal simulated data to classify patterns and learns an embedding space where each class is represented by a prototype. The refiner learns to refine the imperfect patterns with small modifications, such that their embeddings are closer to the corresponding prototypes. We show that the refiner can be trained in both supervised and unsupervised fashions. We further illustrate the effectiveness of the proposed approach both qualitatively and quantitatively in a digit refinement task and an X-ray diffraction pattern refinement task in materials discovery.

</details>

<details>

<summary>2018-12-11 18:43:52 - Diagnostic Visualization for Deep Neural Networks Using Stochastic Gradient Langevin Dynamics</summary>

- *Biye Jiang, David M. Chan, Tianhao Zhang, John F. Canny*

- `1812.04604v1` - [abs](http://arxiv.org/abs/1812.04604v1) - [pdf](http://arxiv.org/pdf/1812.04604v1)

> The internal states of most deep neural networks are difficult to interpret, which makes diagnosis and debugging during training challenging. Activation maximization methods are widely used, but lead to multiple optima and are hard to interpret (appear noise-like) for complex neurons. Image-based methods use maximally-activating image regions which are easier to interpret, but do not provide pixel-level insight into why the neuron responds to them. In this work we introduce an MCMC method: Langevin Dynamics Activation Maximization (LDAM), which is designed for diagnostic visualization. LDAM provides two affordances in combination: the ability to explore the set of maximally activating pre-images, and the ability to trade-off interpretability and pixel-level accuracy using a GAN-style discriminator as a regularizer. We present case studies on MNIST, CIFAR and ImageNet datasets exploring these trade-offs. Finally we show that diagnostic visualization using LDAM leads to a novel insight into the parameter averaging method for deep net training.

</details>

<details>

<summary>2018-12-11 22:57:04 - Approximate Dynamic Programming for Planning a Ride-Sharing System using Autonomous Fleets of Electric Vehicles</summary>

- *Lina Al-Kanj, Juliana Nascimento, Warren B. Powell*

- `1810.08124v2` - [abs](http://arxiv.org/abs/1810.08124v2) - [pdf](http://arxiv.org/pdf/1810.08124v2)

> Within a decade, almost every major auto company, along with fleet operators such as Uber, have announced plans to put autonomous vehicles on the road. At the same time, electric vehicles are quickly emerging as a next-generation technology that is cost effective, in addition to offering the benefits of reducing the carbon footprint. The combination of a centrally managed fleet of driverless vehicles, along with the operating characteristics of electric vehicles, is creating a transformative new technology that offers significant cost savings with high service levels. This problem involves a dispatch problem for assigning riders to cars, a surge pricing problem for deciding on the price per trip and a planning problem for deciding on the fleet size. We use approximate dynamic programming to develop high-quality operational dispatch strategies to determine which car is best for a particular trip, when a car should be recharged, and when it should be re-positioned to a different zone which offers a higher density of trips. We prove that the value functions are monotone in the battery and time dimensions and use hierarchical aggregation to get better estimates of the value functions with a small number of observations. Then, surge pricing is discussed using an adaptive learning approach to decide on the price for each trip. Finally, we discuss the fleet size problem which depends on the previous two problems.

</details>

<details>

<summary>2018-12-12 00:36:17 - Gradient Descent Happens in a Tiny Subspace</summary>

- *Guy Gur-Ari, Daniel A. Roberts, Ethan Dyer*

- `1812.04754v1` - [abs](http://arxiv.org/abs/1812.04754v1) - [pdf](http://arxiv.org/pdf/1812.04754v1)

> We show that in a variety of large-scale deep learning scenarios the gradient dynamically converges to a very small subspace after a short period of training. The subspace is spanned by a few top eigenvectors of the Hessian (equal to the number of classes in the dataset), and is mostly preserved over long periods of training. A simple argument then suggests that gradient descent may happen mostly in this subspace. We give an example of this effect in a solvable model of classification, and we comment on possible implications for optimization and learning.

</details>

<details>

<summary>2018-12-12 01:40:51 - Designing Artificial Cognitive Architectures: Brain Inspired or Biologically Inspired?</summary>

- *Emanuel Diamant*

- `1812.04769v1` - [abs](http://arxiv.org/abs/1812.04769v1) - [pdf](http://arxiv.org/pdf/1812.04769v1)

> Artificial Neural Networks (ANNs) were devised as a tool for Artificial Intelligence design implementations. However, it was soon became obvious that they are unable to fulfill their duties. The fully autonomous way of ANNs working, precluded from any human intervention or supervision, deprived of any theoretical underpinning, leads to a strange state of affairs, when ANN designers cannot explain why and how they achieve their amazing and remarkable results. Therefore, contemporary Artificial Intelligence R&D looks more like a Modern Alchemy enterprise rather than a respected scientific or technological undertaking. On the other hand, modern biological science posits that intelligence can be distinguished not only in human brains. Intelligence today is considered as a fundamental property of each and every living being. Therefore, lower simplified forms of natural intelligence are more suitable for investigation and further replication in artificial cognitive architectures.

</details>

<details>

<summary>2018-12-12 05:43:57 - Linking Artificial Intelligence Principles</summary>

- *Yi Zeng, Enmeng Lu, Cunqing Huangfu*

- `1812.04814v1` - [abs](http://arxiv.org/abs/1812.04814v1) - [pdf](http://arxiv.org/pdf/1812.04814v1)

> Artificial Intelligence principles define social and ethical considerations to develop future AI. They come from research institutes, government organizations and industries. All versions of AI principles are with different considerations covering different perspectives and making different emphasis. None of them can be considered as complete and can cover the rest AI principle proposals. Here we introduce LAIP, an effort and platform for linking and analyzing different Artificial Intelligence Principles. We want to explicitly establish the common topics and links among AI Principles proposed by different organizations and investigate on their uniqueness. Based on these efforts, for the long-term future of AI, instead of directly adopting any of the AI principles, we argue for the necessity of incorporating various AI Principles into a comprehensive framework and focusing on how they can interact and complete each other.

</details>

<details>

<summary>2018-12-12 06:33:45 - Hu-Fu: Hardware and Software Collaborative Attack Framework against Neural Networks</summary>

- *Wenshuo Li, Jincheng Yu, Xuefei Ning, Pengjun Wang, Qi Wei, Yu Wang, Huazhong Yang*

- `1805.05098v2` - [abs](http://arxiv.org/abs/1805.05098v2) - [pdf](http://arxiv.org/pdf/1805.05098v2)

> Recently, Deep Learning (DL), especially Convolutional Neural Network (CNN), develops rapidly and is applied to many tasks, such as image classification, face recognition, image segmentation, and human detection. Due to its superior performance, DL-based models have a wide range of application in many areas, some of which are extremely safety-critical, e.g. intelligent surveillance and autonomous driving. Due to the latency and privacy problem of cloud computing, embedded accelerators are popular in these safety-critical areas. However, the robustness of the embedded DL system might be harmed by inserting hardware/software Trojans into the accelerator and the neural network model, since the accelerator and deploy tool (or neural network model) are usually provided by third-party companies. Fortunately, inserting hardware Trojans can only achieve inflexible attack, which means that hardware Trojans can easily break down the whole system or exchange two outputs, but can't make CNN recognize unknown pictures as targets. Though inserting software Trojans has more freedom of attack, it often requires tampering input images, which is not easy for attackers. So, in this paper, we propose a hardware-software collaborative attack framework to inject hidden neural network Trojans, which works as a back-door without requiring manipulating input images and is flexible for different scenarios. We test our attack framework for image classification and face recognition tasks, and get attack success rate of 92.6% and 100% on CIFAR10 and YouTube Faces, respectively, while keeping almost the same accuracy as the unattacked model in the normal mode. In addition, we show a specific attack scenario in which a face recognition system is attacked and gives a specific wrong answer.

</details>

<details>

<summary>2018-12-12 07:30:02 - Clustering Player Strategies from Variable-Length Game Logs in Dominion</summary>

- *Henry Bendekgey*

- `1811.11273v2` - [abs](http://arxiv.org/abs/1811.11273v2) - [pdf](http://arxiv.org/pdf/1811.11273v2)

> We present a method for encoding game logs as numeric features in the card game Dominion. We then run the manifold learning algorithm t-SNE on these encodings to visualize the landscape of player strategies. By quantifying game states as the relative prevalence of cards in a player's deck, we create visualizations that capture qualitative differences in player strategies. Different ways of deviating from the starting game state appear as different rays in the visualization, giving it an intuitive explanation. This is a promising new direction for understanding player strategies across games that vary in length.

</details>

<details>

<summary>2018-12-12 09:56:40 - DeepProbLog: Neural Probabilistic Logic Programming</summary>

- *Robin Manhaeve, Sebastijan Dumančić, Angelika Kimmig, Thomas Demeester, Luc De Raedt*

- `1805.10872v2` - [abs](http://arxiv.org/abs/1805.10872v2) - [pdf](http://arxiv.org/pdf/1805.10872v2)

> We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports both symbolic and subsymbolic representations and inference, 1) program induction, 2) probabilistic (logic) programming, and 3) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.

</details>

<details>

<summary>2018-12-12 11:39:38 - On the potential for open-endedness in neural networks</summary>

- *Nicholas Guttenberg, Nathaniel Virgo, Alexandra Penn*

- `1812.04907v1` - [abs](http://arxiv.org/abs/1812.04907v1) - [pdf](http://arxiv.org/pdf/1812.04907v1)

> Natural evolution gives the impression of leading to an open-ended process of increasing diversity and complexity. If our goal is to produce such open-endedness artificially, this suggests an approach driven by evolutionary metaphor. On the other hand, techniques from machine learning and artificial intelligence are often considered too narrow to provide the sort of exploratory dynamics associated with evolution. In this paper, we hope to bridge that gap by reviewing common barriers to open-endedness in the evolution-inspired approach and how they are dealt with in the evolutionary case - collapse of diversity, saturation of complexity, and failure to form new kinds of individuality. We then show how these problems map onto similar issues in the machine learning approach, and discuss how the same insights and solutions which alleviated those barriers in evolutionary approaches can be ported over. At the same time, the form these issues take in the machine learning formulation suggests new ways to analyze and resolve barriers to open-endedness. Ultimately, we hope to inspire researchers to be able to interchangeably use evolutionary and gradient-descent-based machine learning methods to approach the design and creation of open-ended systems.

</details>

<details>

<summary>2018-12-12 12:10:45 - EasiCSDeep: A deep learning model for Cervical Spondylosis Identification using surface electromyography signal</summary>

- *Nana Wang, Li Cui, Xi Huang, Yingcong Xiang, Jing Xiao*

- `1812.04912v1` - [abs](http://arxiv.org/abs/1812.04912v1) - [pdf](http://arxiv.org/pdf/1812.04912v1)

> Cervical spondylosis (CS) is a common chronic disease that affects up to two-thirds of the population and poses a serious burden on individuals and society. The early identification has significant value in improving cure rate and reducing costs. However, the pathology is complex, and the mild symptoms increase the difficulty of the diagnosis, especially in the early stage. Besides, the time-consuming and costliness of hospital medical service reduces the attention to the CS identification. Thus, a convenient, low-cost intelligent CS identification method is imperious demanded. In this paper, we present an intelligent method based on the deep learning to identify CS, using the surface electromyography (sEMG) signal. Faced with the complex, high dimensionality and weak usability of the sEMG signal, we proposed and developed a multi-channel EasiCSDeep algorithm based on the convolutional neural network, which consists of the feature extraction, spatial relationship representation and classification algorithm. To the best of our knowledge, this EasiCSDeep is the first effort to employ the deep learning and the sEMG data to identify CS. Compared with previous state-of-the-art algorithm, our algorithm achieves a significant improvement.

</details>

<details>

<summary>2018-12-12 12:24:04 - Persistence paths and signature features in topological data analysis</summary>

- *Ilya Chevyrev, Vidit Nanda, Harald Oberhauser*

- `1806.00381v2` - [abs](http://arxiv.org/abs/1806.00381v2) - [pdf](http://arxiv.org/pdf/1806.00381v2)

> We introduce a new feature map for barcodes that arise in persistent homology computation. The main idea is to first realize each barcode as a path in a convenient vector space, and to then compute its path signature which takes values in the tensor algebra of that vector space. The composition of these two operations - barcode to path, path to tensor series - results in a feature map that has several desirable properties for statistical learning, such as universality and characteristicness, and achieves state-of-the-art results on common classification benchmarks.

</details>

<details>

<summary>2018-12-12 14:42:10 - Towards Ophthalmologist Level Accurate Deep Learning System for OCT Screening and Diagnosis</summary>

- *Mrinal Haloi*

- `1812.07105v1` - [abs](http://arxiv.org/abs/1812.07105v1) - [pdf](http://arxiv.org/pdf/1812.07105v1)

> In this work, we propose an advanced AI based grading system for OCT images. The proposed system is a very deep fully convolutional attentive classification network trained with end to end advanced transfer learning with online random augmentation. It uses quasi random augmentation that outputs confidence values for diseases prevalence during inference. Its a fully automated retinal OCT analysis AI system capable of pathological lesions understanding without any offline preprocessing/postprocessing step or manual feature extraction. We present a state of the art performance on the publicly available Mendeley OCT dataset.

</details>

<details>

<summary>2018-12-12 18:13:41 - Recent Advances in Autoencoder-Based Representation Learning</summary>

- *Michael Tschannen, Olivier Bachem, Mario Lucic*

- `1812.05069v1` - [abs](http://arxiv.org/abs/1812.05069v1) - [pdf](http://arxiv.org/pdf/1812.05069v1)

> Learning useful representations with little or no supervision is a key challenge in artificial intelligence. We provide an in-depth review of recent advances in representation learning with a focus on autoencoder-based models. To organize these results we make use of meta-priors believed useful for downstream tasks, such as disentanglement and hierarchical organization of features. In particular, we uncover three main mechanisms to enforce such properties, namely (i) regularizing the (approximate or aggregate) posterior distribution, (ii) factorizing the encoding and decoding distribution, or (iii) introducing a structured prior distribution. While there are some promising results, implicit or explicit supervision remains a key enabler and all current methods use strong inductive biases and modeling assumptions. Finally, we provide an analysis of autoencoder-based representation learning through the lens of rate-distortion theory and identify a clear tradeoff between the amount of prior knowledge available about the downstream tasks, and how useful the representation is for this task.

</details>

<details>

<summary>2018-12-12 18:14:06 - Enhancing Selection Hyper-heuristics via Feature Transformations</summary>

- *I. Amaya, J. C. Ortiz-Bayliss, A. Rosales-Pérez, A. E. Gutiérrez-Rodríguez, S. E. Conant-Pablos, H. Terashima-Marín, C. A. Coello Coello*

- `1812.05070v1` - [abs](http://arxiv.org/abs/1812.05070v1) - [pdf](http://arxiv.org/pdf/1812.05070v1)

> Hyper-heuristics are a novel tool. They deal with complex optimization problems where standalone solvers exhibit varied performance. Among such a tool reside selection hyper-heuristics. By combining the strengths of each solver, this kind of hyper-heuristic offers a more robust tool. However, their effectiveness is highly dependent on the 'features' used to link them with the problem that is being solved. Aiming at enhancing selection hyper-heuristics, in this paper we propose two types of transformation: explicit and implicit. The first one directly changes the distribution of critical points within the feature domain while using a Euclidean distance to measure proximity. The second one operates indirectly by preserving the distribution of critical points but changing the distance metric through a kernel function. We focus on analyzing the effect of each kind of transformation, and of their combinations. We test our ideas in the domain of constraint satisfaction problems because of their popularity and many practical applications. In this work, we compare the performance of our proposals against those of previously published data. Furthermore, we expand on previous research by increasing the number of analyzed features. We found that, by incorporating transformations into the model of selection hyper-heuristics, overall performance can be improved, yielding more stable results. However, combining implicit and explicit transformations was not as fruitful. Additionally, we ran some confirmatory tests on the domain of knapsack problems. Again, we observed improved stability, leading to the generation of hyper-heuristics whose profit had a standard deviation between 20% and 30% smaller.

</details>

<details>

<summary>2018-12-13 00:52:56 - Conditional Graph Neural Processes: A Functional Autoencoder Approach</summary>

- *Marcel Nassar, Xin Wang, Evren Tumer*

- `1812.05212v1` - [abs](http://arxiv.org/abs/1812.05212v1) - [pdf](http://arxiv.org/pdf/1812.05212v1)

> We introduce a novel encoder-decoder architecture to embed functional processes into latent vector spaces. This embedding can then be decoded to sample the encoded functions over any arbitrary domain. This autoencoder generalizes the recently introduced Conditional Neural Process (CNP) model of random processes. Our architecture employs the latest advances in graph neural networks to process irregularly sampled functions. Thus, we refer to our model as Conditional Graph Neural Process (CGNP). Graph neural networks can effectively exploit `local' structures of the metric spaces over which the functions/processes are defined. The contributions of this paper are twofold: (i) a novel graph-based encoder-decoder architecture for functional and process embeddings, and (ii) a demonstration of the importance of using the structure of metric spaces for this type of representations.

</details>

<details>

<summary>2018-12-13 01:57:26 - Next Hit Predictor - Self-exciting Risk Modeling for Predicting Next Locations of Serial Crimes</summary>

- *Yunyi Li, Tong Wang*

- `1812.05224v1` - [abs](http://arxiv.org/abs/1812.05224v1) - [pdf](http://arxiv.org/pdf/1812.05224v1)

> Our goal is to predict the location of the next crime in a crime series, based on the identified previous offenses in the series. We build a predictive model called Next Hit Predictor (NHP) that finds the most likely location of the next serial crime via a carefully designed risk model. The risk model follows the paradigm of a self-exciting point process which consists of a background crime risk and triggered risks stimulated by previous offenses in the series. Thus, NHP creates a risk map for a crime series at hand. To train the risk model, we formulate a convex learning objective that considers pairwise rankings of locations and use stochastic gradient descent to learn the optimal parameters. Next Hit Predictor incorporates both spatial-temporal features and geographical characteristics of prior crime locations in the series. Next Hit Predictor has demonstrated promising results on decades' worth of serial crime data collected by the Crime Analysis Unit of the Cambridge Police Department in Massachusetts, USA.

</details>

<details>

<summary>2018-12-13 01:59:01 - Deep Learning Framework for Wireless Systems: Applications to Optical Wireless Communications</summary>

- *Hoon Lee, Sang Hyun Lee, Tony Q. S. Quek, Inkyu Lee*

- `1812.05227v1` - [abs](http://arxiv.org/abs/1812.05227v1) - [pdf](http://arxiv.org/pdf/1812.05227v1)

> Optical wireless communication (OWC) is a promising technology for future wireless communications owing to its potentials for cost-effective network deployment and high data rate. There are several implementation issues in the OWC which have not been encountered in radio frequency wireless communications. First, practical OWC transmitters need an illumination control on color, intensity, and luminance, etc., which poses complicated modulation design challenges. Furthermore, signal-dependent properties of optical channels raise non-trivial challenges both in modulation and demodulation of the optical signals. To tackle such difficulties, deep learning (DL) technologies can be applied for optical wireless transceiver design. This article addresses recent efforts on DL-based OWC system designs. A DL framework for emerging image sensor communication is proposed and its feasibility is verified by simulation. Finally, technical challenges and implementation issues for the DL-based optical wireless technology are discussed.

</details>

<details>

<summary>2018-12-13 02:46:44 - Code Failure Prediction and Pattern Extraction using LSTM Networks</summary>

- *Mahdi Hajiaghayi, Ehsan Vahedi*

- `1812.05237v1` - [abs](http://arxiv.org/abs/1812.05237v1) - [pdf](http://arxiv.org/pdf/1812.05237v1)

> In this paper, we use a well-known Deep Learning technique called Long Short Term Memory (LSTM) recurrent neural networks to find sessions that are prone to code failure in applications that rely on telemetry data for system health monitoring. We also use LSTM networks to extract telemetry patterns that lead to a specific code failure. For code failure prediction, we treat the telemetry events, sequence of telemetry events and the outcome of each sequence as words, sentence and sentiment in the context of sentiment analysis, respectively. Our proposed method is able to process a large set of data and can automatically handle edge cases in code failure prediction. We take advantage of Bayesian optimization technique to find the optimal hyper parameters as well as the type of LSTM cells that leads to the best prediction performance. We then introduce the Contributors and Blockers concepts. In this paper, contributors are the set of events that cause a code failure, while blockers are the set of events that each of them individually prevents a code failure from happening, even in presence of one or multiple contributor(s). Once the proposed LSTM model is trained, we use a greedy approach to find the contributors and blockers. To develop and test our proposed method, we use synthetic (simulated) data in the first step. The synthetic data is generated using a number of rules for code failures, as well as a number of rules for preventing a code failure from happening. The trained LSTM model shows over 99% accuracy for detecting code failures in the synthetic data. The results from the proposed method outperform the classical learning models such as Decision Tree and Random Forest. Using the proposed greedy method, we are able to find the contributors and blockers in the synthetic data in more than 90% of the cases, with a performance better than sequential rule and pattern mining algorithms.

</details>

<details>

<summary>2018-12-13 04:26:01 - Learning to Communicate: A Machine Learning Framework for Heterogeneous Multi-Agent Robotic Systems</summary>

- *Hyung-Jin Yoon, Huaiyu Chen, Kehan Long, Heling Zhang, Aditya Gahlawat, Donghwan Lee, Naira Hovakimyan*

- `1812.05256v1` - [abs](http://arxiv.org/abs/1812.05256v1) - [pdf](http://arxiv.org/pdf/1812.05256v1)

> We present a machine learning framework for multi-agent systems to learn both the optimal policy for maximizing the rewards and the encoding of the high dimensional visual observation. The encoding is useful for sharing local visual observations with other agents under communication resource constraints. The actor-encoder encodes the raw images and chooses an action based on local observations and messages sent by the other agents. The machine learning agent generates not only an actuator command to the physical device, but also a communication message to the other agents. We formulate a reinforcement learning problem, which extends the action space to consider the communication action as well. The feasibility of the reinforcement learning framework is demonstrated using a 3D simulation environment with two collaborating agents. The environment provides realistic visual observations to be used and shared between the two agents.

</details>

<details>

<summary>2018-12-13 09:36:17 - Evaluating Architectural Choices for Deep Learning Approaches for Question Answering over Knowledge Bases</summary>

- *Sherzod Hakimov, Soufian Jebbara, Philipp Cimiano*

- `1812.02536v2` - [abs](http://arxiv.org/abs/1812.02536v2) - [pdf](http://arxiv.org/pdf/1812.02536v2)

> The task of answering natural language questions over knowledge bases has received wide attention in recent years. Various deep learning architectures have been proposed for this task. However, architectural design choices are typically not systematically compared nor evaluated under the same conditions. In this paper, we contribute to a better understanding of the impact of architectural design choices by evaluating four different architectures under the same conditions. We address the task of answering simple questions, consisting in predicting the subject and predicate of a triple given a question. In order to provide a fair comparison of different architectures, we evaluate them under the same strategy for inferring the subject, and compare different architectures for inferring the predicate. The architecture for inferring the subject is based on a standard LSTM model trained to recognize the span of the subject in the question and on a linking component that links the subject span to an entity in the knowledge base. The architectures for predicate inference are based on i) a standard softmax classifier ranging over all predicates as output, iii) a model that predicts a low-dimensional encoding of the property given entity representation and question, iii) a model that learns to score a pair of subject and predicate given the question as well as iv) a model based on the well-known FastText model. The comparison of architectures shows that FastText provides better results than other architectures.

</details>

<details>

<summary>2018-12-13 09:49:58 - DeepCruiser: Automated Guided Testing for Stateful Deep Learning Systems</summary>

- *Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Jianjun Zhao, Yang Liu*

- `1812.05339v1` - [abs](http://arxiv.org/abs/1812.05339v1) - [pdf](http://arxiv.org/pdf/1812.05339v1)

> Deep learning (DL) defines a data-driven programming paradigm that automatically composes the system decision logic from the training data. In company with the data explosion and hardware acceleration during the past decade, DL achieves tremendous success in many cutting-edge applications. However, even the state-of-the-art DL systems still suffer from quality and reliability issues. It was only until recently that some preliminary progress was made in testing feed-forward DL systems. In contrast to feed-forward DL systems, recurrent neural networks (RNN) follow a very different architectural design, implementing temporal behaviors and memory with loops and internal states. Such stateful nature of RNN contributes to its success in handling sequential inputs such as audio, natural languages and video processing, but also poses new challenges for quality assurance.   In this paper, we initiate the very first step towards testing RNN-based stateful DL systems. We model RNN as an abstract state transition system, based on which we define a set of test coverage criteria specialized for stateful DL systems. Moreover, we propose an automated testing framework, DeepCruiser, which systematically generates tests in large scale to uncover defects of stateful DL systems with coverage guidance. Our in-depth evaluation on a state-of-the-art speech-to-text DL system demonstrates the effectiveness of our technique in improving quality and reliability of stateful DL systems.

</details>

<details>

<summary>2018-12-13 12:45:26 - Interaction Design for Explainable AI: Workshop Proceedings</summary>

- *Prashan Madumal, Ronal Singh, Joshua Newn, Frank Vetere*

- `1812.08597v1` - [abs](http://arxiv.org/abs/1812.08597v1) - [pdf](http://arxiv.org/pdf/1812.08597v1)

> As artificial intelligence (AI) systems become increasingly complex and ubiquitous, these systems will be responsible for making decisions that directly affect individuals and society as a whole. Such decisions will need to be justified due to ethical concerns as well as trust, but achieving this has become difficult due to the `black-box' nature many AI models have adopted. Explainable AI (XAI) can potentially address this problem by explaining its actions, decisions and behaviours of the system to users. However, much research in XAI is done in a vacuum using only the researchers' intuition of what constitutes a `good' explanation while ignoring the interaction and the human aspect. This workshop invites researchers in the HCI community and related fields to have a discourse about human-centred approaches to XAI rooted in interaction and to shed light and spark discussion on interaction design challenges in XAI.

</details>

<details>

<summary>2018-12-13 13:13:23 - Abstractive Text Summarization by Incorporating Reader Comments</summary>

- *Shen Gao, Xiuying Chen, Piji Li, Zhaochun Ren, Lidong Bing, Dongyan Zhao, Rui Yan*

- `1812.05407v1` - [abs](http://arxiv.org/abs/1812.05407v1) - [pdf](http://arxiv.org/pdf/1812.05407v1)

> In neural abstractive summarization field, conventional sequence-to-sequence based models often suffer from summarizing the wrong aspect of the document with respect to the main aspect. To tackle this problem, we propose the task of reader-aware abstractive summary generation, which utilizes the reader comments to help the model produce better summary about the main aspect. Unlike traditional abstractive summarization task, reader-aware summarization confronts two main challenges: (1) Comments are informal and noisy; (2) jointly modeling the news document and the reader comments is challenging. To tackle the above challenges, we design an adversarial learning model named reader-aware summary generator (RASG), which consists of four components: (1) a sequence-to-sequence based summary generator; (2) a reader attention module capturing the reader focused aspects; (3) a supervisor modeling the semantic gap between the generated summary and reader focused aspects; (4) a goal tracker producing the goal for each generation step. The supervisor and the goal tacker are used to guide the training of our framework in an adversarial manner. Extensive experiments are conducted on our large-scale real-world text summarization dataset, and the results show that RASG achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations. The experimental results also demonstrate the effectiveness of each module in our framework. We release our large-scale dataset for further research.

</details>

<details>

<summary>2018-12-13 16:41:41 - Defending Against Machine Learning Model Stealing Attacks Using Deceptive Perturbations</summary>

- *Taesung Lee, Benjamin Edwards, Ian Molloy, Dong Su*

- `1806.00054v4` - [abs](http://arxiv.org/abs/1806.00054v4) - [pdf](http://arxiv.org/pdf/1806.00054v4)

> Machine learning models are vulnerable to simple model stealing attacks if the adversary can obtain output labels for chosen inputs. To protect against these attacks, it has been proposed to limit the information provided to the adversary by omitting probability scores, significantly impacting the utility of the provided service. In this work, we illustrate how a service provider can still provide useful, albeit misleading, class probability information, while significantly limiting the success of the attack. Our defense forces the adversary to discard the class probabilities, requiring significantly more queries before they can train a model with comparable performance. We evaluate several attack strategies, model architectures, and hyperparameters under varying adversarial models, and evaluate the efficacy of our defense against the strongest adversary. Finally, we quantify the amount of noise injected into the class probabilities to mesure the loss in utility, e.g., adding 1.26 nats per query on CIFAR-10 and 3.27 on MNIST. Our evaluation shows our defense can degrade the accuracy of the stolen model at least 20%, or require up to 64 times more queries while keeping the accuracy of the protected model almost intact.

</details>

<details>

<summary>2018-12-14 01:57:44 - An IoT Analytics Embodied Agent Model based on Context-Aware Machine Learning</summary>

- *Nathalia Nascimento, Paulo Alencar, Carlos Lucena, Donald Cowan*

- `1812.06791v1` - [abs](http://arxiv.org/abs/1812.06791v1) - [pdf](http://arxiv.org/pdf/1812.06791v1)

> Agent-based Internet of Things (IoT) applications have recently emerged as applications that can involve sensors, wireless devices, machines and software that can exchange data and be accessed remotely. Such applications have been proposed in several domains including health care, smart cities and agriculture. However, despite their increased adoption, deploying these applications in specific settings has been very challenging because of the complex static and dynamic variability of the physical devices such as sensors and actuators, the software application behavior and the environment in which the application is embedded. In this paper, we propose a modeling approach for IoT analytics based on learning embodied agents (i.e. situated agents). The approach involves: (i) a variability model of IoT embodied agents; (ii) feedback evaluative machine learning; and (iii) reconfiguration of a group of agents in accordance with environmental context. The proposed approach advances the state of the art in that it facilitates the development of Agent-based IoT applications by explicitly capturing their complex and dynamic variabilities and supporting their self-configuration based on an context-aware and machine learning-based approach.

</details>

<details>

<summary>2018-12-14 02:32:45 - Helix: Holistic Optimization for Accelerating Iterative Machine Learning</summary>

- *Doris Xin, Stephen Macke, Litian Ma, Jialin Liu, Shuchen Song, Aditya Parameswaran*

- `1812.05762v1` - [abs](http://arxiv.org/abs/1812.05762v1) - [pdf](http://arxiv.org/pdf/1812.05762v1)

> Machine learning workflow development is a process of trial-and-error: developers iterate on workflows by testing out small modifications until the desired accuracy is achieved. Unfortunately, existing machine learning systems focus narrowly on model training---a small fraction of the overall development time---and neglect to address iterative development. We propose Helix, a machine learning system that optimizes the execution across iterations---intelligently caching and reusing, or recomputing intermediates as appropriate. Helix captures a wide variety of application needs within its Scala DSL, with succinct syntax defining unified processes for data preprocessing, model specification, and learning. We demonstrate that the reuse problem can be cast as a Max-Flow problem, while the caching problem is NP-Hard. We develop effective lightweight heuristics for the latter. Empirical evaluation shows that Helix is not only able to handle a wide variety of use cases in one unified workflow but also much faster, providing run time reductions of up to 19x over state-of-the-art systems, such as DeepDive or KeystoneML, on four real-world applications in natural language processing, computer vision, social and natural sciences.

</details>

<details>

<summary>2018-12-14 15:35:33 - Quantum Memristors in Quantum Photonics</summary>

- *M. Sanz, L. Lamata, E. Solano*

- `1709.07808v2` - [abs](http://arxiv.org/abs/1709.07808v2) - [pdf](http://arxiv.org/pdf/1709.07808v2)

> We propose a method to build quantum memristors in quantum photonic platforms. We firstly design an effective beam splitter, which is tunable in real-time, by means of a Mach-Zehnder-type array with two equal 50:50 beam splitters and a tunable retarder, which allows us to control its reflectivity. Then, we show that this tunable beam splitter, when equipped with weak measurements and classical feedback, behaves as a quantum memristor. Indeed, in order to prove its quantumness, we show how to codify quantum information in the coherent beams. Moreover, we estimate the memory capability of the quantum memristor. Finally, we show the feasibility of the proposed setup in integrated quantum photonics.

</details>

<details>

<summary>2018-12-14 15:39:34 - Measuring Similarity: Computationally Reproducing the Scholar's Interests</summary>

- *Ashley Lee, Jo Guldi, Andras Zsom*

- `1812.05984v1` - [abs](http://arxiv.org/abs/1812.05984v1) - [pdf](http://arxiv.org/pdf/1812.05984v1)

> Computerized document classification already orders the news articles that Apple's "News" app or Google's "personalized search" feature groups together to match a reader's interests. The invisible and therefore illegible decisions that go into these tailored searches have been the subject of a critique by scholars who emphasize that our intelligence about documents is only as good as our ability to understand the criteria of search. This article will attempt to unpack the procedures used in computational classification of texts, translating them into term legible to humanists, and examining opportunities to render the computational text classification process subject to expert critique and improvement.

</details>

<details>

<summary>2018-12-14 16:47:03 - More Effective Ontology Authoring with Test-Driven Development</summary>

- *C. Maria Keet, Kieren Davies, Agnieszka Lawrynowicz*

- `1812.06015v1` - [abs](http://arxiv.org/abs/1812.06015v1) - [pdf](http://arxiv.org/pdf/1812.06015v1)

> Ontology authoring is a complex process, where commonly the automated reasoner is invoked for verification of newly introduced changes, therewith amounting to a time-consuming test-last approach. Test-Driven Development (TDD) for ontology authoring is a recent {\em test-first} approach that aims to reduce authoring time and increase authoring efficiency. Current TDD testing falls short on coverage of OWL features and possible test outcomes, the rigorous foundation thereof, and evaluations to ascertain its effectiveness.   We aim to address these issues in one instantiation of TDD for ontology authoring. We first propose a succinct, logic-based model of TDD testing and present novel TDD algorithms so as to cover also any OWL 2 class expression for the TBox and for the principal ABox assertions, and prove their correctness. The algorithms use methods from the OWL API directly such that reclassification is not necessary for test execution, therewith reducing ontology authoring time. The algorithms were implemented in TDDonto2, a Prot\'eg\'e plugin. TDDonto2 was evaluated on editing efficiency and by users. The editing efficiency study demonstrated that it is faster than a typical ontology authoring interface, especially for medium size and large ontologies. The user evaluation demonstrated that modellers make significantly less errors with TDDonto2 compared to the standard Prot\'eg\'e interface and complete their tasks better using less time. Thus, the results indicate that Test-Driven Development is a promising approach in an ontology development methodology.

</details>

<details>

<summary>2018-12-14 17:05:59 - Factorization of Dempster-Shafer Belief Functions Based on Data</summary>

- *Andrzej Matuszewski, Mieczysław A. Kłopotek*

- `1812.06028v1` - [abs](http://arxiv.org/abs/1812.06028v1) - [pdf](http://arxiv.org/pdf/1812.06028v1)

> One important obstacle in applying Dempster-Shafer Theory (DST) is its relationship to frequencies. In particular, there exist serious difficulties in finding factorizations of belief functions from data.   In probability theory factorizations are usually related to notion of (conditional) independence and their possibility tested accordingly. However, in DST conditional belief distributions prove to be non-proper belief functions (that is ones connected with negative "frequencies"). This makes statistical testing of potential conditional independencies practically impossible, as no coherent interpretation could be found so far for negative belief function values.   In this paper a novel attempt is made to overcome this difficulty. In the proposal no conditional beliefs are calculated, but instead a new measure F is introduced within the framework of DST, closely related to conditional independence, allowing to apply conventional statistical tests for detection of dependence/independence.

</details>

<details>

<summary>2018-12-14 19:03:38 - Dopamine: A Research Framework for Deep Reinforcement Learning</summary>

- *Pablo Samuel Castro, Subhodeep Moitra, Carles Gelada, Saurabh Kumar, Marc G. Bellemare*

- `1812.06110v1` - [abs](http://arxiv.org/abs/1812.06110v1) - [pdf](http://arxiv.org/pdf/1812.06110v1)

> Deep reinforcement learning (deep RL) research has grown significantly in recent years. A number of software offerings now exist that provide stable, comprehensive implementations for benchmarking. At the same time, recent deep RL research has become more diverse in its goals. In this paper we introduce Dopamine, a new research framework for deep RL that aims to support some of that diversity. Dopamine is open-source, TensorFlow-based, and provides compact and reliable implementations of some state-of-the-art deep RL agents. We complement this offering with a taxonomy of the different research objectives in deep RL research. While by no means exhaustive, our analysis highlights the heterogeneity of research in the field, and the value of frameworks such as ours.

</details>

<details>

<summary>2018-12-14 19:39:43 - ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models</summary>

- *Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal Berrang, Mario Fritz, Michael Backes*

- `1806.01246v2` - [abs](http://arxiv.org/abs/1806.01246v2) - [pdf](http://arxiv.org/pdf/1806.01246v2)

> Machine learning (ML) has become a core component of many real-world applications and training data is a key factor that drives current progress. This huge success has led Internet companies to deploy machine learning as a service (MLaaS). Recently, the first membership inference attack has shown that extraction of information on the training set is possible in such MLaaS settings, which has severe security and privacy implications.   However, the early demonstrations of the feasibility of such attacks have many assumptions on the adversary, such as using multiple so-called shadow models, knowledge of the target model structure, and having a dataset from the same distribution as the target model's training data. We relax all these key assumptions, thereby showing that such attacks are very broadly applicable at low cost and thereby pose a more severe risk than previously thought. We present the most comprehensive study so far on this emerging and developing threat using eight diverse datasets which show the viability of the proposed attacks across domains.   In addition, we propose the first effective defense mechanisms against such broader class of membership inference attacks that maintain a high level of utility of the ML model.

</details>

<details>

<summary>2018-12-14 20:47:54 - Specification-Guided Safety Verification for Feedforward Neural Networks</summary>

- *Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson*

- `1812.06161v1` - [abs](http://arxiv.org/abs/1812.06161v1) - [pdf](http://arxiv.org/pdf/1812.06161v1)

> This paper presents a specification-guided safety verification method for feedforward neural networks with general activation functions. As such feedforward networks are memoryless, they can be abstractly represented as mathematical functions, and the reachability analysis of the neural network amounts to interval analysis problems. In the framework of interval analysis, a computationally efficient formula which can quickly compute the output interval sets of a neural network is developed. Then, a specification-guided reachability algorithm is developed. Specifically, the bisection process in the verification algorithm is completely guided by a given safety specification. Due to the employment of the safety specification, unnecessary computations are avoided and thus the computational cost can be reduced significantly. Experiments show that the proposed method enjoys much more efficiency in safety verification with significantly less computational cost.

</details>

<details>

<summary>2018-12-14 21:32:40 - Bootstrapping Conversational Agents With Weak Supervision</summary>

- *Neil Mallinar, Abhishek Shah, Rajendra Ugrani, Ayush Gupta, Manikandan Gurusankar, Tin Kam Ho, Q. Vera Liao, Yunfeng Zhang, Rachel K. E. Bellamy, Robert Yates, Chris Desmarais, Blake McGregor*

- `1812.06176v1` - [abs](http://arxiv.org/abs/1812.06176v1) - [pdf](http://arxiv.org/pdf/1812.06176v1)

> Many conversational agents in the market today follow a standard bot development framework which requires training intent classifiers to recognize user input. The need to create a proper set of training examples is often the bottleneck in the development process. In many occasions agent developers have access to historical chat logs that can provide a good quantity as well as coverage of training examples. However, the cost of labeling them with tens to hundreds of intents often prohibits taking full advantage of these chat logs. In this paper, we present a framework called \textit{search, label, and propagate} (SLP) for bootstrapping intents from existing chat logs using weak supervision. The framework reduces hours to days of labeling effort down to minutes of work by using a search engine to find examples, then relies on a data programming approach to automatically expand the labels. We report on a user study that shows positive user feedback for this new approach to build conversational agents, and demonstrates the effectiveness of using data programming for auto-labeling. While the system is developed for training conversational agents, the framework has broader application in significantly reducing labeling effort for training text classifiers.

</details>

<details>

<summary>2018-12-15 00:31:52 - Causal Identification under Markov Equivalence</summary>

- *Amin Jaber, Jiji Zhang, Elias Bareinboim*

- `1812.06209v1` - [abs](http://arxiv.org/abs/1812.06209v1) - [pdf](http://arxiv.org/pdf/1812.06209v1)

> Assessing the magnitude of cause-and-effect relations is one of the central challenges found throughout the empirical sciences. The problem of identification of causal effects is concerned with determining whether a causal effect can be computed from a combination of observational data and substantive knowledge about the domain under investigation, which is formally expressed in the form of a causal graph. In many practical settings, however, the knowledge available for the researcher is not strong enough so as to specify a unique causal graph. Another line of investigation attempts to use observational data to learn a qualitative description of the domain called a Markov equivalence class, which is the collection of causal graphs that share the same set of observed features. In this paper, we marry both approaches and study the problem of causal identification from an equivalence class, represented by a partial ancestral graph (PAG). We start by deriving a set of graphical properties of PAGs that are carried over to its induced subgraphs. We then develop an algorithm to compute the effect of an arbitrary set of variables on an arbitrary outcome set. We show that the algorithm is strictly more powerful than the current state of the art found in the literature.

</details>

<details>

<summary>2018-12-15 05:15:40 - Integrating Artificial Intelligence with Real-time Intracranial EEG Monitoring to Automate Interictal Identification of Seizure Onset Zones in Focal Epilepsy</summary>

- *Yogatheesan Varatharajah, Brent Berry, Jan Cimbalnik, Vaclav Kremen, Jamie Van Gompel, Matt Stead, Benjamin Brinkmann, Ravishankar Iyer, Gregory Worrell*

- `1812.06234v1` - [abs](http://arxiv.org/abs/1812.06234v1) - [pdf](http://arxiv.org/pdf/1812.06234v1)

> An ability to map seizure-generating brain tissue, i.e., the seizure onset zone (SOZ), without recording actual seizures could reduce the duration of invasive EEG monitoring for patients with drug-resistant epilepsy. A widely-adopted practice in the literature is to compare the incidence (events/time) of putative pathological electrophysiological biomarkers associated with epileptic brain tissue with the SOZ determined from spontaneous seizures recorded with intracranial EEG, primarily using a single biomarker. Clinical translation of the previous efforts suffers from their inability to generalize across multiple patients because of (a) the inter-patient variability and (b) the temporal variability in the epileptogenic activity. Here, we report an artificial intelligence-based approach for combining multiple interictal electrophysiological biomarkers and their temporal characteristics as a way of accounting for the above barriers and show that it can reliably identify seizure onset zones in a study cohort of 82 patients who underwent evaluation for drug-resistant epilepsy. Our investigation provides evidence that utilizing the complementary information provided by multiple electrophysiological biomarkers and their temporal characteristics can significantly improve the localization potential compared to previously published single-biomarker incidence-based approaches, resulting in an average area under ROC curve (AUC) value of 0.73 in a cohort of 82 patients. Our results also suggest that recording durations between ninety minutes and two hours are sufficient to localize SOZs with accuracies that may prove clinically relevant. The successful validation of our approach on a large cohort of 82 patients warrants future investigation on the feasibility of utilizing intra-operative EEG monitoring and artificial intelligence to localize epileptogenic brain tissue.

</details>

<details>

<summary>2018-12-15 07:02:44 - Flatten-T Swish: a thresholded ReLU-Swish-like activation function for deep learning</summary>

- *Hock Hung Chieng, Noorhaniza Wahid, Pauline Ong, Sai Raj Kishore Perla*

- `1812.06247v1` - [abs](http://arxiv.org/abs/1812.06247v1) - [pdf](http://arxiv.org/pdf/1812.06247v1)

> Activation functions are essential for deep learning methods to learn and perform complex tasks such as image classification. Rectified Linear Unit (ReLU) has been widely used and become the default activation function across the deep learning community since 2012. Although ReLU has been popular, however, the hard zero property of the ReLU has heavily hindered the negative values from propagating through the network. Consequently, the deep neural network has not been benefited from the negative representations. In this work, an activation function called Flatten-T Swish (FTS) that leverage the benefit of the negative values is proposed. To verify its performance, this study evaluates FTS with ReLU and several recent activation functions. Each activation function is trained using MNIST dataset on five different deep fully connected neural networks (DFNNs) with depth vary from five to eight layers. For a fair evaluation, all DFNNs are using the same configuration settings. Based on the experimental results, FTS with a threshold value, T=-0.20 has the best overall performance. As compared with ReLU, FTS (T=-0.20) improves MNIST classification accuracy by 0.13%, 0.70%, 0.67%, 1.07% and 1.15% on wider 5 layers, slimmer 5 layers, 6 layers, 7 layers and 8 layers DFNNs respectively. Apart from this, the study also noticed that FTS converges twice as fast as ReLU. Although there are other existing activation functions are also evaluated, this study elects ReLU as the baseline activation function.

</details>

<details>

<summary>2018-12-15 08:29:21 - Deep Neural Network Compression with Single and Multiple Level Quantization</summary>

- *Yuhui Xu, Yongzhuang Wang, Aojun Zhou, Weiyao Lin, Hongkai Xiong*

- `1803.03289v2` - [abs](http://arxiv.org/abs/1803.03289v2) - [pdf](http://arxiv.org/pdf/1803.03289v2)

> Network quantization is an effective solution to compress deep neural networks for practical usage. Existing network quantization methods cannot sufficiently exploit the depth information to generate low-bit compressed network. In this paper, we propose two novel network quantization approaches, single-level network quantization (SLQ) for high-bit quantization and multi-level network quantization (MLQ) for extremely low-bit quantization (ternary).We are the first to consider the network quantization from both width and depth level. In the width level, parameters are divided into two parts: one for quantization and the other for re-training to eliminate the quantization loss. SLQ leverages the distribution of the parameters to improve the width level. In the depth level, we introduce incremental layer compensation to quantize layers iteratively which decreases the quantization loss in each iteration. The proposed approaches are validated with extensive experiments based on the state-of-the-art neural networks including AlexNet, VGG-16, GoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.

</details>

<details>

<summary>2018-12-15 12:38:13 - Proactive Resource Management for LTE in Unlicensed Spectrum: A Deep Learning Perspective</summary>

- *Ursula Challita, Li Dong, Walid Saad*

- `1702.07031v2` - [abs](http://arxiv.org/abs/1702.07031v2) - [pdf](http://arxiv.org/pdf/1702.07031v2)

> LTE in unlicensed spectrum using licensed assisted access LTE (LTE-LAA) is a promising approach to overcome the wireless spectrum scarcity. However, to reap the benefits of LTE-LAA, a fair coexistence mechanism with other incumbent WiFi deployments is required. In this paper, a novel deep learning approach is proposed for modeling the resource allocation problem of LTE-LAA small base stations (SBSs). The proposed approach enables multiple SBSs to proactively perform dynamic channel selection, carrier aggregation, and fractional spectrum access while guaranteeing fairness with existing WiFi networks and other LTE-LAA operators. Adopting a proactive coexistence mechanism enables future delay-tolerant LTE-LAA data demands to be served within a given prediction window ahead of their actual arrival time thus avoiding the underutilization of the unlicensed spectrum during off-peak hours while maximizing the total served LTE-LAA traffic load. To this end, a noncooperative game model is formulated in which SBSs are modeled as Homo Egualis agents that aim at predicting a sequence of future actions and thus achieving long-term equal weighted fairness with WLAN and other LTE-LAA operators over a given time horizon. The proposed deep learning algorithm is then shown to reach a mixed-strategy Nash equilibrium (NE), when it converges. Simulation results using real data traces show that the proposed scheme can yield up to 28% and 11% gains over a conventional reactive approach and a proportional fair coexistence mechanism, respectively. The results also show that the proposed framework prevents WiFi performance degradation for a densely deployed LTE-LAA network.

</details>

<details>

<summary>2018-12-15 19:39:04 - Evidence Transfer for Improving Clustering Tasks Using External Categorical Evidence</summary>

- *Athanasios Davvetas, Iraklis A. Klampanos, Vangelis Karkaletsis*

- `1811.03909v2` - [abs](http://arxiv.org/abs/1811.03909v2) - [pdf](http://arxiv.org/pdf/1811.03909v2)

> In this paper we introduce evidence transfer for clustering, a deep learning method that can incrementally manipulate the latent representations of an autoencoder, according to external categorical evidence, in order to improve a clustering outcome. By evidence transfer we define the process by which the categorical outcome of an external, auxiliary task is exploited to improve a primary task, in this case representation learning for clustering. Our proposed method makes no assumptions regarding the categorical evidence presented, nor the structure of the latent space. We compare our method, against the baseline solution by performing k-means clustering before and after its deployment. Experiments with three different kinds of evidence show that our method effectively manipulates the latent representations when introduced with real corresponding evidence, while remaining robust when presented with low quality evidence.

</details>

<details>

<summary>2018-12-15 20:55:25 - Lifelong Path Planning with Kinematic Constraints for Multi-Agent Pickup and Delivery</summary>

- *Hang Ma, Wolfgang Hönig, T. K. Satish Kumar, Nora Ayanian, Sven Koenig*

- `1812.06355v1` - [abs](http://arxiv.org/abs/1812.06355v1) - [pdf](http://arxiv.org/pdf/1812.06355v1)

> The Multi-Agent Pickup and Delivery (MAPD) problem models applications where a large number of agents attend to a stream of incoming pickup-and-delivery tasks. Token Passing (TP) is a recent MAPD algorithm that is efficient and effective. We make TP even more efficient and effective by using a novel combinatorial search algorithm, called Safe Interval Path Planning with Reservation Table (SIPPwRT), for single-agent path planning. SIPPwRT uses an advanced data structure that allows for fast updates and lookups of the current paths of all agents in an online setting. The resulting MAPD algorithm TP-SIPPwRT takes kinematic constraints of real robots into account directly during planning, computes continuous agent movements with given velocities that work on non-holonomic robots rather than discrete agent movements with uniform velocity, and is complete for well-formed MAPD instances. We demonstrate its benefits for automated warehouses using both an agent simulator and a standard robot simulator. For example, we demonstrate that it can compute paths for hundreds of agents and thousands of tasks in seconds and is more efficient and effective than existing MAPD algorithms that use a post-processing step to adapt their paths to continuous agent movements with given velocities.

</details>

<details>

<summary>2018-12-15 21:00:17 - Searching with Consistent Prioritization for Multi-Agent Path Finding</summary>

- *Hang Ma, Daniel Harabor, Peter J. Stuckey, Jiaoyang Li, Sven Koenig*

- `1812.06356v1` - [abs](http://arxiv.org/abs/1812.06356v1) - [pdf](http://arxiv.org/pdf/1812.06356v1)

> We study prioritized planning for Multi-Agent Path Finding (MAPF). Existing prioritized MAPF algorithms depend on rule-of-thumb heuristics and random assignment to determine a fixed total priority ordering of all agents a priori. We instead explore the space of all possible partial priority orderings as part of a novel systematic and conflict-driven combinatorial search framework. In a variety of empirical comparisons, we demonstrate state-of-the-art solution qualities and success rates, often with similar runtimes to existing algorithms. We also develop new theoretical results that explore the limitations of prioritized planning, in terms of completeness and optimality, for the first time.

</details>

<details>

<summary>2018-12-15 21:48:46 - Perturbation Analysis of Learning Algorithms: A Unifying Perspective on Generation of Adversarial Examples</summary>

- *Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar*

- `1812.07385v1` - [abs](http://arxiv.org/abs/1812.07385v1) - [pdf](http://arxiv.org/pdf/1812.07385v1)

> Despite the tremendous success of deep neural networks in various learning problems, it has been observed that adding an intentionally designed adversarial perturbation to inputs of these architectures leads to erroneous classification with high confidence in the prediction. In this work, we propose a general framework based on the perturbation analysis of learning algorithms which consists of convex programming and is able to recover many current adversarial attacks as special cases. The framework can be used to propose novel attacks against learning algorithms for classification and regression tasks under various new constraints with closed form solutions in many instances. In particular we derive new attacks against classification algorithms which are shown to achieve comparable performances to notable existing attacks. The framework is then used to generate adversarial perturbations for regression tasks which include single pixel and single subset attacks. By applying this method to autoencoding and image colorization tasks, it is shown that adversarial perturbations can effectively perturb the output of regression tasks as well.

</details>

<details>

<summary>2018-12-15 22:03:04 - Low-rank semidefinite programming for the MAX2SAT problem</summary>

- *Po-Wei Wang, J. Zico Kolter*

- `1812.06362v1` - [abs](http://arxiv.org/abs/1812.06362v1) - [pdf](http://arxiv.org/pdf/1812.06362v1)

> This paper proposes a new algorithm for solving MAX2SAT problems based on combining search methods with semidefinite programming approaches. Semidefinite programming techniques are well-known as a theoretical tool for approximating maximum satisfiability problems, but their application has traditionally been very limited by their speed and randomized nature. Our approach overcomes this difficult by using a recent approach to low-rank semidefinite programming, specialized to work in an incremental fashion suitable for use in an exact search algorithm. The method can be used both within complete or incomplete solver, and we demonstrate on a variety of problems from recent competitions. Our experiments show that the approach is faster (sometimes by orders of magnitude) than existing state-of-the-art complete and incomplete solvers, representing a substantial advance in search methods specialized for MAX2SAT problems.

</details>

<details>

<summary>2018-12-16 02:44:20 - Efficient Super Resolution Using Binarized Neural Network</summary>

- *Yinglan Ma, Hongyu Xiong, Zhe Hu, Lizhuang Ma*

- `1812.06378v1` - [abs](http://arxiv.org/abs/1812.06378v1) - [pdf](http://arxiv.org/pdf/1812.06378v1)

> Deep convolutional neural networks (DCNNs) have recently demonstrated high-quality results in single-image super-resolution (SR). DCNNs often suffer from over-parametrization and large amounts of redundancy, which results in inefficient inference and high memory usage, preventing massive applications on mobile devices. As a way to significantly reduce model size and computation time, binarized neural network has only been shown to excel on semantic-level tasks such as image classification and recognition. However, little effort of network quantization has been spent on image enhancement tasks like SR, as network quantization is usually assumed to sacrifice pixel-level accuracy. In this work, we explore an network-binarization approach for SR tasks without sacrificing much reconstruction accuracy. To achieve this, we binarize the convolutional filters in only residual blocks, and adopt a learnable weight for each binary filter. We evaluate this idea on several state-of-the-art DCNN-based architectures, and show that binarized SR networks achieve comparable qualitative and quantitative results as their real-weight counterparts. Moreover, the proposed binarized strategy could help reduce model size by 80% when applying on SRResNet, and could potentially speed up inference by 5 times.

</details>

<details>

<summary>2018-12-16 02:52:31 - Embedding Push and Pull Search in the Framework of Differential Evolution for Solving Constrained Single-objective Optimization Problems</summary>

- *Zhun Fan, Wenji Li, Zhaojun Wang, Yutong Yuan, Fuzan Sun, Zhi Yang, Jie Ruan, Zhaocheng Li, Erik Goodman*

- `1812.06381v1` - [abs](http://arxiv.org/abs/1812.06381v1) - [pdf](http://arxiv.org/pdf/1812.06381v1)

> This paper proposes a push and pull search method in the framework of differential evolution (PPS-DE) to solve constrained single-objective optimization problems (CSOPs). More specifically, two sub-populations, including the top and bottom sub-populations, are collaborated with each other to search global optimal solutions efficiently. The top sub-population adopts the pull and pull search (PPS) mechanism to deal with constraints, while the bottom sub-population use the superiority of feasible solutions (SF) technique to deal with constraints. In the top sub-population, the search process is divided into two different stages --- push and pull stages.An adaptive DE variant with three trial vector generation strategies is employed in the proposed PPS-DE. In the top sub-population, all the three trial vector generation strategies are used to generate offsprings, just like in CoDE. In the bottom sub-population, a strategy adaptation, in which the trial vector generation strategies are periodically self-adapted by learning from their experiences in generating promising solutions in the top sub-population, is used to choose a suitable trial vector generation strategy to generate one offspring. Furthermore, a parameter adaptation strategy from LSHADE44 is employed in both sup-populations to generate scale factor $F$ and crossover rate $CR$ for each trial vector generation strategy. Twenty-eight CSOPs with 10-, 30-, and 50-dimensional decision variables provided in the CEC2018 competition on real parameter single objective optimization are optimized by the proposed PPS-DE. The experimental results demonstrate that the proposed PPS-DE has the best performance compared with the other seven state-of-the-art algorithms, including AGA-PPS, LSHADE44, LSHADE44+IDE, UDE, IUDE, $\epsilon$MAg-ES and C$^2$oDE.

</details>

<details>

<summary>2018-12-16 03:45:56 - A Unified View of Causal and Non-causal Feature Selection</summary>

- *Kui Yu, Lin Liu, Jiuyong Li*

- `1802.05844v4` - [abs](http://arxiv.org/abs/1802.05844v4) - [pdf](http://arxiv.org/pdf/1802.05844v4)

> In this paper, we aim to develop a unified view of causal and non-causal feature selection methods. The unified view will fill in the gap in the research of the relation between the two types of methods. Based on the Bayesian network framework and information theory, we first show that causal and non-causal feature selection methods share the same objective. That is to find the Markov blanket of a class attribute, the theoretically optimal feature set for classification. We then examine the assumptions made by causal and non-causal feature selection methods when searching for the optimal feature set, and unify the assumptions by mapping them to the restrictions on the structure of the Bayesian network model of the studied problem. We further analyze in detail how the structural assumptions lead to the different levels of approximations employed by the methods in their search, which then result in the approximations in the feature sets found by the methods with respect to the optimal feature set. With the unified view, we are able to interpret the output of non-causal methods from a causal perspective and derive the error bounds of both types of methods. Finally, we present practical understanding of the relation between causal and non-causal methods using extensive experiments with synthetic data and various types of real-word data.

</details>

<details>

<summary>2018-12-16 06:12:45 - What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions</summary>

- *Ehsan Abbasnejad, Qi Wu, Javen Shi, Anton van den Hengel*

- `1812.06401v1` - [abs](http://arxiv.org/abs/1812.06401v1) - [pdf](http://arxiv.org/pdf/1812.06401v1)

> One of the core challenges in Visual Dialogue problems is asking the question that will provide the most useful information towards achieving the required objective. Encouraging an agent to ask the right questions is difficult because we don't know a-priori what information the agent will need to achieve its task, and we don't have an explicit model of what it knows already. We propose a solution to this problem based on a Bayesian model of the uncertainty in the implicit model maintained by the visual dialogue agent, and in the function used to select an appropriate output. By selecting the question that minimises the predicted regret with respect to this implicit model the agent actively reduces ambiguity. The Bayesian model of uncertainty also enables a principled method for identifying when enough information has been acquired, and an action should be selected. We evaluate our approach on two goal-oriented dialogue datasets, one for visual-based collaboration task and the other for a negotiation-based task. Our uncertainty-aware information-seeking model outperforms its counterparts in these two challenging problems.

</details>

<details>

<summary>2018-12-16 08:23:55 - Scalable Coordinated Exploration in Concurrent Reinforcement Learning</summary>

- *Maria Dimakopoulou, Ian Osband, Benjamin Van Roy*

- `1805.08948v2` - [abs](http://arxiv.org/abs/1805.08948v2) - [pdf](http://arxiv.org/pdf/1805.08948v2)

> We consider a team of reinforcement learning agents that concurrently operate in a common environment, and we develop an approach to efficient coordinated exploration that is suitable for problems of practical scale. Our approach builds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value function learning (Osband et al., 2016). We demonstrate that, for simple tabular contexts, the approach is competitive with previously proposed tabular model learning methods (Dimakopoulou and Van Roy, 2018). With a higher-dimensional problem and a neural network value function representation, the approach learns quickly with far fewer agents than alternative exploration schemes.

</details>

<details>

<summary>2018-12-16 09:05:44 - Auto-tuning Neural Network Quantization Framework for Collaborative Inference Between the Cloud and Edge</summary>

- *Guangli Li, Lei Liu, Xueying Wang, Xiao Dong, Peng Zhao, Xiaobing Feng*

- `1812.06426v1` - [abs](http://arxiv.org/abs/1812.06426v1) - [pdf](http://arxiv.org/pdf/1812.06426v1)

> Recently, deep neural networks (DNNs) have been widely applied in mobile intelligent applications. The inference for the DNNs is usually performed in the cloud. However, it leads to a large overhead of transmitting data via wireless network. In this paper, we demonstrate the advantages of the cloud-edge collaborative inference with quantization. By analyzing the characteristics of layers in DNNs, an auto-tuning neural network quantization framework for collaborative inference is proposed. We study the effectiveness of mixed-precision collaborative inference of state-of-the-art DNNs by using ImageNet dataset. The experimental results show that our framework can generate reasonable network partitions and reduce the storage on mobile devices with trivial loss of accuracy.

</details>

<details>

<summary>2018-12-16 12:36:15 - Embedding Cardinality Constraints in Neural Link Predictors</summary>

- *Emir Muñoz, Pasquale Minervini, Matthias Nickles*

- `1812.06455v1` - [abs](http://arxiv.org/abs/1812.06455v1) - [pdf](http://arxiv.org/pdf/1812.06455v1)

> Neural link predictors learn distributed representations of entities and relations in a knowledge graph. They are remarkably powerful in the link prediction and knowledge base completion tasks, mainly due to the learned representations that capture important statistical dependencies in the data. Recent works in the area have focused on either designing new scoring functions or incorporating extra information into the learning process to improve the representations. Yet the representations are mostly learned from the observed links between entities, ignoring commonsense or schema knowledge associated with the relations in the graph. A fundamental aspect of the topology of relational data is the cardinality information, which bounds the number of predictions given for a relation between a minimum and maximum frequency. In this paper, we propose a new regularisation approach to incorporate relation cardinality constraints to any existing neural link predictor without affecting their efficiency or scalability. Our regularisation term aims to impose boundaries on the number of predictions with high probability, thus, structuring the embeddings space to respect commonsense cardinality assumptions resulting in better representations. Experimental results on Freebase, WordNet and YAGO show that, given suitable prior knowledge, the proposed method positively impacts the predictive accuracy of downstream link prediction tasks.

</details>

<details>

<summary>2018-12-16 13:15:26 - Ensemble of Learning Project Productivity in Software Effort Based on Use Case Points</summary>

- *Mohammad Azzeh, Ali Bou Nassif, Shadi Banitaan, Cuauhtemoc Lopez-Martin*

- `1812.06459v1` - [abs](http://arxiv.org/abs/1812.06459v1) - [pdf](http://arxiv.org/pdf/1812.06459v1)

> It is well recognized that the project productivity is a key driver in estimating software project effort from Use Case Point size metric at early software development stages. Although, there are few proposed models for predicting productivity, there is no consistent conclusion regarding which model is the superior. Therefore, instead of building a new productivity prediction model, this paper presents a new ensemble construction mechanism applied for software project productivity prediction. Ensemble is an effective technique when performance of base models is poor. We proposed a weighted mean method to aggregate predicted productivities based on average of errors produced by training model. The obtained results show that the using ensemble is a good alternative approach when accuracies of base models are not consistently accurate over different datasets, and when models behave diversely.

</details>

<details>

<summary>2018-12-16 13:23:28 - Wayeb: a Tool for Complex Event Forecasting</summary>

- *Elias Alevizos, Alexander Artikis, Georgios Paliouras*

- `1901.01826v1` - [abs](http://arxiv.org/abs/1901.01826v1) - [pdf](http://arxiv.org/pdf/1901.01826v1)

> Complex Event Processing (CEP) systems have appeared in abundance during the last two decades. Their purpose is to detect in real-time interesting patterns upon a stream of events and to inform an analyst for the occurrence of such patterns in a timely manner. However, there is a lack of methods for forecasting when a pattern might occur before such an occurrence is actually detected by a CEP engine. We present Wayeb, a tool that attempts to address the issue of Complex Event Forecasting. Wayeb employs symbolic automata as a computational model for pattern detection and Markov chains for deriving a probabilistic description of a symbolic automaton.

</details>

<details>

<summary>2018-12-16 15:01:55 - A near Pareto optimal approach to student-supervisor allocation with two sided preferences and workload balance</summary>

- *Victor Sanchez-Anguix, Rithin Chalumuri, Reyhan Aydogan, Vicente Julian*

- `1812.06474v1` - [abs](http://arxiv.org/abs/1812.06474v1) - [pdf](http://arxiv.org/pdf/1812.06474v1)

> The problem of allocating students to supervisors for the development of a personal project or a dissertation is a crucial activity in the higher education environment, as it enables students to get feedback on their work from an expert and improve their personal, academic, and professional abilities. In this article, we propose a multi-objective and near Pareto optimal genetic algorithm for the allocation of students to supervisors. The allocation takes into consideration the students and supervisors' preferences on research/project topics, the lower and upper supervision quotas of supervisors, as well as the workload balance amongst supervisors. We introduce novel mutation and crossover operators for the student-supervisor allocation problem. The experiments carried out show that the components of the genetic algorithm are more apt for the problem than classic components, and that the genetic algorithm is capable of producing allocations that are near Pareto optimal in a reasonable time.

</details>

<details>

<summary>2018-12-16 17:57:16 - The limit of artificial intelligence: Can machines be rational?</summary>

- *Tshilidzi Marwala*

- `1812.06510v1` - [abs](http://arxiv.org/abs/1812.06510v1) - [pdf](http://arxiv.org/pdf/1812.06510v1)

> This paper studies the question on whether machines can be rational. It observes the existing reasons why humans are not rational which is due to imperfect and limited information, limited and inconsistent processing power through the brain and the inability to optimize decisions and achieve maximum utility. It studies whether these limitations of humans are transferred to the limitations of machines. The conclusion reached is that even though machines are not rational advances in technological developments make these machines more rational. It also concludes that machines can be more rational than humans.

</details>

<details>

<summary>2018-12-16 22:19:43 - Towards Robust Human Activity Recognition from RGB Video Stream with Limited Labeled Data</summary>

- *Krishanu Sarker, Mohamed Masoud, Saeid Belkasim, Shihao Ji*

- `1812.06544v1` - [abs](http://arxiv.org/abs/1812.06544v1) - [pdf](http://arxiv.org/pdf/1812.06544v1)

> Human activity recognition based on video streams has received numerous attentions in recent years. Due to lack of depth information, RGB video based activity recognition performs poorly compared to RGB-D video based solutions. On the other hand, acquiring depth information, inertia etc. is costly and requires special equipment, whereas RGB video streams are available in ordinary cameras. Hence, our goal is to investigate whether similar or even higher accuracy can be achieved with RGB-only modality. In this regard, we propose a novel framework that couples skeleton data extracted from RGB video and deep Bidirectional Long Short Term Memory (BLSTM) model for activity recognition. A big challenge of training such a deep network is the limited training data, and exploring RGB-only stream significantly exaggerates the difficulty. We therefore propose a set of algorithmic techniques to train this model effectively, e.g., data augmentation, dynamic frame dropout and gradient injection. The experiments demonstrate that our RGB-only solution surpasses the state-of-the-art approaches that all exploit RGB-D video streams by a notable margin. This makes our solution widely deployable with ordinary cameras.

</details>

<details>

<summary>2018-12-17 02:07:23 - Artificial Intelligent Diagnosis and Monitoring in Manufacturing</summary>

- *Ye Yuan, Guijun Ma, Cheng Cheng, Beitong Zhou, Huan Zhao, Hai-Tao Zhang, Han Ding*

- `1901.02057v1` - [abs](http://arxiv.org/abs/1901.02057v1) - [pdf](http://arxiv.org/pdf/1901.02057v1)

> The manufacturing sector is heavily influenced by artificial intelligence-based technologies with the extraordinary increases in computational power and data volumes. It has been reported that 35% of US manufacturers are currently collecting data from sensors for manufacturing processes enhancement. Nevertheless, many are still struggling to achieve the 'Industry 4.0', which aims to achieve nearly 50% reduction in maintenance cost and total machine downtime by proper health management. For increasing productivity and reducing operating costs, a central challenge lies in the detection of faults or wearing parts in machining operations. Here we propose a data-driven, end-to-end framework for monitoring of manufacturing systems. This framework, derived from deep learning techniques, evaluates fused sensory measurements to detect and even predict faults and wearing conditions. This work exploits the predictive power of deep learning to extract hidden degradation features from noisy data. We demonstrate the proposed framework on several representative experimental manufacturing datasets drawn from a wide variety of applications, ranging from mechanical to electrical systems. Results reveal that the framework performs well in all benchmark applications examined and can be applied in diverse contexts, indicating its potential for use as a critical corner stone in smart manufacturing.

</details>

<details>

<summary>2018-12-17 08:49:34 - The Entropy of Artificial Intelligence and a Case Study of AlphaZero from Shannon's Perspective</summary>

- *Bo Zhang, Bin Chen, Jin-lin Peng*

- `1812.05794v2` - [abs](http://arxiv.org/abs/1812.05794v2) - [pdf](http://arxiv.org/pdf/1812.05794v2)

> The recently released AlphaZero algorithm achieves superhuman performance in the games of chess, shogi and Go, which raises two open questions. Firstly, as there is a finite number of possibilities in the game, is there a quantifiable intelligence measurement for evaluating intelligent systems, e.g. AlphaZero? Secondly, AlphaZero introduces sophisticated reinforcement learning and self-play to efficiently encode the possible states, is there a simple information-theoretic model to represent the learning process and offer more insights in fostering strong AI systems?   This paper explores the above two questions by proposing a simple variance of Shannon's communication model, the concept of intelligence entropy and the Unified Intelligence-Communication Model is proposed, which provide an information-theoretic metric for investigating the intelligence level and also provide an bound for intelligent agents in the form of Shannon's capacity, namely, the intelligence capacity. This paper then applies the concept and model to AlphaZero as a case study and explains the learning process of intelligent agent as turbo-like iterative decoding, so that the learning performance of AlphaZero may be quantitatively evaluated. Finally, conclusions are provided along with theoretical and practical remarks.

</details>

<details>

<summary>2018-12-17 10:01:59 - Robust Graph Learning from Noisy Data</summary>

- *Zhao Kang, Haiqi Pan, Steven C. H. Hoi, Zenglin Xu*

- `1812.06673v1` - [abs](http://arxiv.org/abs/1812.06673v1) - [pdf](http://arxiv.org/pdf/1812.06673v1)

> Learning graphs from data automatically has shown encouraging performance on clustering and semisupervised learning tasks. However, real data are often corrupted, which may cause the learned graph to be inexact or unreliable. In this paper, we propose a novel robust graph learning scheme to learn reliable graphs from real-world noisy data by adaptively removing noise and errors in the raw data. We show that our proposed model can also be viewed as a robust version of manifold regularized robust PCA, where the quality of the graph plays a critical role. The proposed model is able to boost the performance of data clustering, semisupervised classification, and data recovery significantly, primarily due to two key factors: 1) enhanced low-rank recovery by exploiting the graph smoothness assumption, 2) improved graph construction by exploiting clean data recovered by robust PCA. Thus, it boosts the clustering, semi-supervised classification, and data recovery performance overall. Extensive experiments on image/document clustering, object recognition, image shadow removal, and video background subtraction reveal that our model outperforms the previous state-of-the-art methods.

</details>

<details>

<summary>2018-12-17 11:26:42 - Conditional BERT Contextual Augmentation</summary>

- *Xing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han, Songlin Hu*

- `1812.06705v1` - [abs](http://arxiv.org/abs/1812.06705v1) - [pdf](http://arxiv.org/pdf/1812.06705v1)

> We propose a novel data augmentation method for labeled sentences called conditional BERT contextual augmentation. Data augmentation methods are often applied to prevent overfitting and improve generalization of deep neural network models. Recently proposed contextual augmentation augments labeled sentences by randomly replacing words with more varied substitutions predicted by language model. BERT demonstrates that a deep bidirectional language model is more powerful than either an unidirectional language model or the shallow concatenation of a forward and backward model. We retrofit BERT to conditional BERT by introducing a new conditional masked language model\footnote{The term "conditional masked language model" appeared once in original BERT paper, which indicates context-conditional, is equivalent to term "masked language model". In our paper, "conditional masked language model" indicates we apply extra label-conditional constraint to the "masked language model".} task. The well trained conditional BERT can be applied to enhance contextual augmentation. Experiments on six various different text classification tasks show that our method can be easily applied to both convolutional or recurrent neural networks classifier to obtain obvious improvement.

</details>

<details>

<summary>2018-12-17 11:28:05 - Not Using the Car to See the Sidewalk: Quantifying and Controlling the Effects of Context in Classification and Segmentation</summary>

- *Rakshith Shetty, Bernt Schiele, Mario Fritz*

- `1812.06707v1` - [abs](http://arxiv.org/abs/1812.06707v1) - [pdf](http://arxiv.org/pdf/1812.06707v1)

> Importance of visual context in scene understanding tasks is well recognized in the computer vision community. However, to what extent the computer vision models for image classification and semantic segmentation are dependent on the context to make their predictions is unclear. A model overly relying on context will fail when encountering objects in context distributions different from training data and hence it is important to identify these dependencies before we can deploy the models in the real-world. We propose a method to quantify the sensitivity of black-box vision models to visual context by editing images to remove selected objects and measuring the response of the target models. We apply this methodology on two tasks, image classification and semantic segmentation, and discover undesirable dependency between objects and context, for example that "sidewalk" segmentation relies heavily on "cars" being present in the image. We propose an object removal based data augmentation solution to mitigate this dependency and increase the robustness of classification and segmentation models to contextual variations. Our experiments show that the proposed data augmentation helps these models improve the performance in out-of-context scenarios, while preserving the performance on regular data.

</details>

<details>

<summary>2018-12-17 11:59:53 - TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph</summary>

- *Feiliang Ren, Yining Hou, Yan Li, Linfeng Pan, Yi Zhang, Xiaobo Liang, Yongkang Liu, Yu Guo, Rongsheng Zhao, Ruicheng Ming, Huiming Wu*

- `1812.06722v1` - [abs](http://arxiv.org/abs/1812.06722v1) - [pdf](http://arxiv.org/pdf/1812.06722v1)

> Knowledge graph is a kind of valuable knowledge base which would benefit lots of AI-related applications. Up to now, lots of large-scale knowledge graphs have been built. However, most of them are non-Chinese and designed for general purpose. In this work, we introduce TechKG, a large scale Chinese knowledge graph that is technology-oriented. It is built automatically from massive technical papers that are published in Chinese academic journals of different research domains. Some carefully designed heuristic rules are used to extract high quality entities and relations. Totally, it comprises of over 260 million triplets that are built upon more than 52 million entities which come from 38 research domains. Our preliminary ex-periments indicate that TechKG has high adaptability and can be used as a dataset for many diverse AI-related applications. We released TechKG at: http://www.techkg.cn.

</details>

<details>

<summary>2018-12-17 12:19:52 - Using a Game Engine to Simulate Critical Incidents and Data Collection by Autonomous Drones</summary>

- *David L. Smyth, Frank G. Glavin, Michael G. Madden*

- `1808.10784v2` - [abs](http://arxiv.org/abs/1808.10784v2) - [pdf](http://arxiv.org/pdf/1808.10784v2)

> Using a game engine, we have developed a virtual environment which models important aspects of critical incident scenarios. We focused on modelling phenomena relating to the identification and gathering of key forensic evidence, in order to develop and test a system which can handle chemical, biological, radiological/nuclear or explosive (CBRNe) events autonomously. This allows us to build and validate AI-based technologies, which can be trained and tested in our custom virtual environment before being deployed in real-world scenarios. We have used our virtual scenario to rapidly prototype a system which can use simulated Remote Aerial Vehicles (RAVs) to gather images from the environment for the purpose of mapping. Our environment provides us with an effective medium through which we can develop and test various AI methodologies for critical incident scene assessment, in a safe and controlled manner

</details>

<details>

<summary>2018-12-17 13:12:03 - Trichotomic Argumentation Representation</summary>

- *Merlin Göttlinger, Lutz Schröder*

- `1812.06745v1` - [abs](http://arxiv.org/abs/1812.06745v1) - [pdf](http://arxiv.org/pdf/1812.06745v1)

> The Aristotelian trichotomy distinguishes three aspects of argumentation: Logos, Ethos, and Pathos. Even rich argumentation representations like the Argument Interchange Format (AIF) are only concerned with capturing the Logos aspect. Inference Anchoring Theory (IAT) adds the possibility to represent ethical requirements on the illocutionary force edges linking locutions to illocutions, thereby allowing to capture some aspects of ethos. With the recent extensions AIF+ and Social Argument Interchange Format (S-AIF), which embed dialogue and speakers into the AIF argumentation representation, the basis for representing all three aspects identified by Aristotle was formed. In the present work, we develop the Trichotomic Argument Interchange Format (T-AIF), building on the idea from S-AIF of adding the speakers to the argumentation graph. We capture Logos in the usual known from AIF+, Ethos in form of weighted edges between actors representing trust, and Pathos via weighted edges from actors to illocutions representing their level of commitment to the propositions. This extended structured argumentation representation opens up new possibilities of defining semantic properties on this rich graph in order to characterize and profile the reasoning patterns of the participating actors.

</details>

<details>

<summary>2018-12-17 14:29:45 - Proceedings of the 2018 XCSP3 Competition</summary>

- *Christophe Lecoutre, Olivier Roussel*

- `1901.01830v1` - [abs](http://arxiv.org/abs/1901.01830v1) - [pdf](http://arxiv.org/pdf/1901.01830v1)

> This document represents the proceedings of the 2018 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'18, the 24th International Conference on Principles and Practice of Constraint Programming, held in Lille, France from 27th August 2018 to 31th August, 2018.

</details>

<details>

<summary>2018-12-17 15:16:02 - Two-stream convolutional networks for end-to-end learning of self-driving cars</summary>

- *Nelson Fernandez*

- `1811.05785v2` - [abs](http://arxiv.org/abs/1811.05785v2) - [pdf](http://arxiv.org/pdf/1811.05785v2)

> We propose a methodology to extend the concept of Two-Stream Convolutional Networks to perform end-to-end learning for self-driving cars with temporal cues. The system has the ability to learn spatiotemporal features by simultaneously mapping raw images and pre-calculated optical flows directly to steering commands. Although optical flows encode temporal-rich information, we found that 2D-CNNs are prone to capturing features only as spatial representations. We show how the use of Multitask Learning favors the learning of temporal features via inductive transfer from a shared spatiotemporal representation. Preliminary results demonstrate a competitive improvement of 30% in prediction accuracy and stability compared to widely used regression methods trained on the Comma.ai dataset.

</details>

<details>

<summary>2018-12-17 15:52:01 - Bayesian Optimization in AlphaGo</summary>

- *Yutian Chen, Aja Huang, Ziyu Wang, Ioannis Antonoglou, Julian Schrittwieser, David Silver, Nando de Freitas*

- `1812.06855v1` - [abs](http://arxiv.org/abs/1812.06855v1) - [pdf](http://arxiv.org/pdf/1812.06855v1)

> During the development of AlphaGo, its many hyper-parameters were tuned with Bayesian optimization multiple times. This automatic tuning process resulted in substantial improvements in playing strength. For example, prior to the match with Lee Sedol, we tuned the latest AlphaGo agent and this improved its win-rate from 50% to 66.5% in self-play games. This tuned version was deployed in the final match. Of course, since we tuned AlphaGo many times during its development cycle, the compounded contribution was even higher than this percentage. It is our hope that this brief case study will be of interest to Go fans, and also provide Bayesian optimization practitioners with some insights and inspiration.

</details>

<details>

<summary>2018-12-17 15:56:18 - Using deceased-donor kidneys to initiate chains of living donor kidney paired donations: algorithms and experimentation</summary>

- *Cristina Cornelio, Lucrezia Furian, Antonio Nicolo', Francesca Rossi*

- `1901.02420v1` - [abs](http://arxiv.org/abs/1901.02420v1) - [pdf](http://arxiv.org/pdf/1901.02420v1)

> We design a flexible algorithm that exploits deceased donor kidneys to initiate chains of living donor kidney paired donations, combining deceased and living donor allocation mechanisms to improve the quantity and quality of kidney transplants. The advantages of this approach have been measured using retrospective data on the pool of donor/recipient incompatible and desensitized pairs at the Padua University Hospital, the largest center for living donor kidney transplants in Italy. The experiments show a remarkable improvement on the number of patients with incompatible donor who could be transplanted, a decrease in the number of desensitization procedures, and an increase in the number of UT patients (that is, patients unlikely to be transplanted for immunological reasons) in the waiting list who could receive an organ.

</details>

<details>

<summary>2018-12-17 16:15:13 - Analogy Search Engine: Finding Analogies in Cross-Domain Research Papers</summary>

- *Jieli Zhou, Yuntao Zhou, Yi Xu*

- `1812.06974v1` - [abs](http://arxiv.org/abs/1812.06974v1) - [pdf](http://arxiv.org/pdf/1812.06974v1)

> In recent years, with the rapid proliferation of research publications in the field of Artificial Intelligence, it is becoming increasingly difficult for researchers to effectively keep up with all the latest research in one's own domains. However, history has shown that scientific breakthroughs often come from collaborations of researchers from different domains. Traditional search algorithms like Lexical search, which look for literal matches or synonyms and variants of the query words, are not effective for discovering cross-domain research papers and meeting the needs of researchers in this age of information overflow. In this paper, we developed and tested an innovative semantic search engine, Analogy Search Engine (ASE), for 2000 AI research paper abstracts across domains like Language Technologies, Robotics, Machine Learning, Computational Biology, Human Computer Interactions, etc. ASE combines recent theories and methods from Computational Analogy and Natural Language Processing to go beyond keyword-based lexical search and discover the deeper analogical relationships among research paper abstracts. We experimentally show that ASE is capable of finding more interesting and useful research papers than baseline elasticsearch. Furthermore, we believe that the methods used in ASE go beyond academic paper and will benefit many other document search tasks.

</details>

<details>

<summary>2018-12-17 16:22:47 - Learning Common Representation from RGB and Depth Images</summary>

- *Giorgio Giannone, Boris Chidlovskii*

- `1812.06873v1` - [abs](http://arxiv.org/abs/1812.06873v1) - [pdf](http://arxiv.org/pdf/1812.06873v1)

> We propose a new deep learning architecture for the tasks of semantic segmentation and depth prediction from RGB-D images. We revise the state of art based on the RGB and depth feature fusion, where both modalities are assumed to be available at train and test time. We propose a new architecture where the feature fusion is replaced with a common deep representation. Combined with an encoder-decoder type of the network, the architecture can jointly learn models for semantic segmentation and depth estimation based on their common representation. This representation, inspired by multi-view learning, offers several important advantages, such as using one modality available at test time to reconstruct the missing modality. In the RGB-D case, this enables the cross-modality scenarios, such as using depth data for semantically segmentation and the RGB images for depth estimation. We demonstrate the effectiveness of the proposed network on two publicly available RGB-D datasets. The experimental results show that the proposed method works well in both semantic segmentation and depth estimation tasks.

</details>

<details>

<summary>2018-12-17 17:26:16 - User Association and Load Balancing for Massive MIMO through Deep Learning</summary>

- *Alessio Zappone, Luca Sanguinetti, Merouane Debbah*

- `1812.06905v1` - [abs](http://arxiv.org/abs/1812.06905v1) - [pdf](http://arxiv.org/pdf/1812.06905v1)

> This work investigates the use of deep learning to perform user cell association for sum-rate maximization in Massive MIMO networks. It is shown how a deep neural network can be trained to approach the optimal association rule with a much more limited computational complexity, thus enabling to update the association rule in real-time, on the basis of the mobility patterns of users. In particular, the proposed neural network design requires as input only the users' geographical positions. Numerical results show that it guarantees the same performance of traditional optimization-oriented methods.

</details>

<details>

<summary>2018-12-17 19:41:37 - From FiLM to Video: Multi-turn Question Answering with Multi-modal Context</summary>

- *Dat Tien Nguyen, Shikhar Sharma, Hannes Schulz, Layla El Asri*

- `1812.07023v1` - [abs](http://arxiv.org/abs/1812.07023v1) - [pdf](http://arxiv.org/pdf/1812.07023v1)

> Understanding audio-visual content and the ability to have an informative conversation about it have both been challenging areas for intelligent systems. The Audio Visual Scene-aware Dialog (AVSD) challenge, organized as a track of the Dialog System Technology Challenge 7 (DSTC7), proposes a combined task, where a system has to answer questions pertaining to a video given a dialogue with previous question-answer pairs and the video itself. We propose for this task a hierarchical encoder-decoder model which computes a multi-modal embedding of the dialogue context. It first embeds the dialogue history using two LSTMs. We extract video and audio frames at regular intervals and compute semantic features using pre-trained I3D and VGGish models, respectively. Before summarizing both modalities into fixed-length vectors using LSTMs, we use FiLM blocks to condition them on the embeddings of the current question, which allows us to reduce the dimensionality considerably. Finally, we use an LSTM decoder that we train with scheduled sampling and evaluate using beam search. Compared to the modality-fusing baseline model released by the AVSD challenge organizers, our model achieves a relative improvements of more than 16%, scoring 0.36 BLEU-4 and more than 33%, scoring 0.997 CIDEr.

</details>

<details>

<summary>2018-12-17 19:57:43 - Fuzzy Controller of Reward of Reinforcement Learning For Handwritten Digit Recognition</summary>

- *Saber Malekzadeh*

- `1812.07028v1` - [abs](http://arxiv.org/abs/1812.07028v1) - [pdf](http://arxiv.org/pdf/1812.07028v1)

> Recognition of human environment with computer systems always was a big deal in artificial intelligence. In this area handwriting recognition and conceptualization of it to computer is an important area in it. In the past years with growth of machine learning in artificial intelligence, efforts to using this technique increased. In this paper is tried to using fuzzy controller, to optimizing amount of reward of reinforcement learning for recognition of handwritten digits. For this aim first a sample of every digit with 10 standard computer fonts, given to actor and then actor is trained. In the next level is tried to test the actor with dataset and then results show improvement of recognition when using fuzzy controller of reinforcement learning.

</details>

<details>

<summary>2018-12-17 22:25:47 - A Roadmap for the Development of the "SP Machine" for Artificial Intelligence</summary>

- *J Gerard Wolff*

- `1707.00614v3` - [abs](http://arxiv.org/abs/1707.00614v3) - [pdf](http://arxiv.org/pdf/1707.00614v3)

> This paper describes a roadmap for the development of the "SP Machine", based on the "SP Theory of Intelligence" and its realisation in the "SP Computer Model". The SP Machine will be developed initially as a software virtual machine with high levels of parallel processing, hosted on a high-performance computer. The system should help users visualise knowledge structures and processing. Research is needed into how the system may discover low-level features in speech and in images. Strengths of the SP System in the processing of natural language may be augmented, in conjunction with the further development of the SP System's strengths in unsupervised learning. Strengths of the SP System in pattern recognition may be developed for computer vision. Work is needed on the representation of numbers and the performance of arithmetic processes. A computer model is needed of "SP-Neural", the version of the SP Theory expressed in terms of neurons and their inter-connections. The SP Machine has potential in many areas of application, several of which may be realised on short-to-medium timescales.

</details>

<details>

<summary>2018-12-17 22:30:45 - Rethinking Epistemic Logic with Belief Bases</summary>

- *Emiliano Lorini*

- `1812.07079v1` - [abs](http://arxiv.org/abs/1812.07079v1) - [pdf](http://arxiv.org/pdf/1812.07079v1)

> We introduce a new semantics for a logic of explicit and implicit beliefs based on the concept of multi-agent belief base. Differently from existing Kripke-style semantics for epistemic logic in which the notions of possible world and doxastic/epistemic alternative are primitive, in our semantics they are non-primitive but are defined from the concept of belief base. We provide a complete axiomatization and prove decidability for our logic via a finite model argument. We also provide a polynomial embedding of our logic into Fagin & Halpern's logic of general awareness and establish a complexity result for our logic via the embedding.

</details>

<details>

<summary>2018-12-17 22:33:45 - A Review of Meta-Reinforcement Learning for Deep Neural Networks Architecture Search</summary>

- *Yesmina Jaafra, Jean Luc Laurent, Aline Deruyver, Mohamed Saber Naceur*

- `1812.07995v1` - [abs](http://arxiv.org/abs/1812.07995v1) - [pdf](http://arxiv.org/pdf/1812.07995v1)

> Deep Neural networks are efficient and flexible models that perform well for a variety of tasks such as image, speech recognition and natural language understanding. In particular, convolutional neural networks (CNN) generate a keen interest among researchers in computer vision and more specifically in classification tasks. CNN architecture and related hyperparameters are generally correlated to the nature of the processed task as the network extracts complex and relevant characteristics allowing the optimal convergence. Designing such architectures requires significant human expertise, substantial computation time and doesn't always lead to the optimal network. Model configuration topic has been extensively studied in machine learning without leading to a standard automatic method. This survey focuses on reviewing and discussing the current progress in automating CNN architecture search.

</details>

<details>

<summary>2018-12-18 02:06:46 - Globalness Detection in Online Social Network</summary>

- *Yu-Cheng Lin, Chun-Ming Lai, S. Felix Wu, George A. Barnett*

- `1812.07135v1` - [abs](http://arxiv.org/abs/1812.07135v1) - [pdf](http://arxiv.org/pdf/1812.07135v1)

> Classification problems have made significant progress due to the maturity of artificial intelligence (AI). However, differentiating items from categories without noticeable boundaries is still a huge challenge for machines -- which is also crucial for machines to be intelligent.   In order to study the fuzzy concept on classification, we define and propose a globalness detection with the four-stage operational flow. We then demonstrate our framework on Facebook public pages inter-like graph with their geo-location. Our prediction algorithm achieves high precision (89%) and recall (88%) of local pages. We evaluate the results on both states and countries level, finding that the global node ratios are relatively high in those states (NY, CA) having large and international cities. Several global nodes examples have also been shown and studied in this paper.   It is our hope that our results unveil the perfect value from every classification problem and provide a better understanding of global and local nodes in Online Social Networks (OSNs).

</details>

<details>

<summary>2018-12-18 05:08:54 - Toward Multimodal Model-Agnostic Meta-Learning</summary>

- *Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim*

- `1812.07172v1` - [abs](http://arxiv.org/abs/1812.07172v1) - [pdf](http://arxiv.org/pdf/1812.07172v1)

> Gradient-based meta-learners such as MAML are able to learn a meta-prior from similar tasks to adapt to novel tasks from the same distribution with few gradient updates. One important limitation of such frameworks is that they seek a common initialization shared across the entire task distribution, substantially limiting the diversity of the task distributions that they are able to learn from. In this paper, we augment MAML with the capability to identify tasks sampled from a multimodal task distribution and adapt quickly through gradient updates. Specifically, we propose a multimodal MAML algorithm that is able to modulate its meta-learned prior according to the identified task, allowing faster adaptation. We evaluate the proposed model on a diverse set of problems including regression, few-shot image classification, and reinforcement learning. The results demonstrate the effectiveness of our model in modulating the meta-learned prior in response to the characteristics of tasks sampled from a multimodal distribution.

</details>

<details>

<summary>2018-12-18 08:06:06 - Smart Contracts for Multiagent Plan Execution in Untrusted Cyber-physical Systems</summary>

- *Anshu Shukla, Swarup Kumar Mohalik, Ramamurthy Badrinath*

- `1812.07219v1` - [abs](http://arxiv.org/abs/1812.07219v1) - [pdf](http://arxiv.org/pdf/1812.07219v1)

> Intelligent Cyber-physical systems can be modelled as multi-agent systems with planning capability to impart adaptivity for changing contexts. In such multi-agent systems, the protocol for plan execution must result in the proper completion and ordering of actions in spite of their distributed execution. However, in untrusted scenarios, there is a possibility of agents not respecting the protocol either due to faults or due to malicious reasons thereby resulting in plan failure. In order to prevent such situations, we propose to implement the execution of agents through smart contracts. This points to a generic architecture seamlessly integrating intelligent planning-based CPS and smart-contracts.

</details>

<details>

<summary>2018-12-18 08:11:00 - Continuous Trajectory Planning Based on Learning Optimization in High Dimensional Input Space for Serial Manipulators</summary>

- *Shiyu Zhang, Shuling Dai*

- `1812.07221v1` - [abs](http://arxiv.org/abs/1812.07221v1) - [pdf](http://arxiv.org/pdf/1812.07221v1)

> To continuously generate trajectories for serial manipulators with high dimensional degrees of freedom (DOF) in the dynamic environment, a real-time optimal trajectory generation method based on machine learning aiming at high dimensional inputs is presented in this paper. First, a learning optimization (LO) framework is established, and implementations with different sub-methods are discussed. Additionally, multiple criteria are defined to evaluate the performance of LO models. Furthermore, aiming at high dimensional inputs, a database generation method based on input space dimension-reducing mapping is proposed. At last, this method is validated on motion planning for haptic feedback manipulators (HFM) in virtual reality systems. Results show that the input space dimension-reducing method can significantly elevate the efficiency and quality of database generation and consequently improve the performance of the LO. Moreover, using this LO method, real-time trajectory generation with high dimensional inputs can be achieved, which lays a foundation for continuous trajectory planning for high-DOF-robots in complex environments.

</details>

<details>

<summary>2018-12-18 09:48:26 - Learning Multilingual Word Embeddings in Latent Metric Space: A Geometric Approach</summary>

- *Pratik Jawanpuria, Arjun Balgovind, Anoop Kunchukuttan, Bamdev Mishra*

- `1808.08773v3` - [abs](http://arxiv.org/abs/1808.08773v3) - [pdf](http://arxiv.org/pdf/1808.08773v3)

> We propose a novel geometric approach for learning bilingual mappings given monolingual embeddings and a bilingual dictionary. Our approach decouples learning the transformation from the source language to the target language into (a) learning rotations for language-specific embeddings to align them to a common space, and (b) learning a similarity metric in the common space to model similarities between the embeddings. We model the bilingual mapping problem as an optimization problem on smooth Riemannian manifolds. We show that our approach outperforms previous approaches on the bilingual lexicon induction and cross-lingual word similarity tasks. We also generalize our framework to represent multiple languages in a common latent space. In particular, the latent space representations for several languages are learned jointly, given bilingual dictionaries for multiple language pairs. We illustrate the effectiveness of joint learning for multiple languages in zero-shot word translation setting. Our implementation is available at https://github.com/anoopkunchukuttan/geomm .

</details>

<details>

<summary>2018-12-18 11:08:31 - Continual Match Based Training in Pommerman: Technical Report</summary>

- *Peng Peng, Liang Pang, Yufeng Yuan, Chao Gao*

- `1812.07297v1` - [abs](http://arxiv.org/abs/1812.07297v1) - [pdf](http://arxiv.org/pdf/1812.07297v1)

> Continual learning is the ability of agents to improve their capacities throughout multiple tasks continually. While recent works in the literature of continual learning mostly focused on developing either particular loss functions or specialized structures of neural network explaining the episodic memory or neural plasticity, we study continual learning from the perspective of the training mechanism. Specifically, we propose a COnitnual Match BAsed Training (COMBAT) framework for training a population of advantage-actor-critic (A2C) agents in Pommerman, a partially observable multi-agent environment with no communication. Following the COMBAT framework, we trained an agent, namely, Navocado, that won the title of the top 1 learning agent in the NeurIPS 2018 Pommerman Competition. Two critical features of our agent are worth mentioning. Firstly, our agent did not learn from any demonstrations. Secondly, our agent is highly reproducible. As a technical report, we articulate the design of state space, action space, reward, and most importantly, the COMBAT framework for our Pommerman agent. We show in the experiments that Pommerman is a perfect environment for studying continual learning, and the agent can improve its performance by continually learning new skills without forgetting the old ones. Finally, the result in the Pommerman Competition verifies the robustness of our agent when competing with various opponents.

</details>

<details>

<summary>2018-12-18 14:04:59 - Intelligent Autonomous Agents are Key to Cyber Defense of the Future Army Networks</summary>

- *Alexander Kott*

- `1812.08014v1` - [abs](http://arxiv.org/abs/1812.08014v1) - [pdf](http://arxiv.org/pdf/1812.08014v1)

> Intelligent autonomous agents will be widely present on the battlefield of the future. The proliferation of intelligent agents is the emerging reality of warfare, and they will form an ever growing fraction of total military assets. By necessity, intelligent autonomous cyber defense agents are likely to become primary cyber fighters on the future battlefield. Initial explorations have identified the key functions, components and their interactions for a potential reference architecture of such an agent. However, it is beyond the current state of AI to support an agent that could operate intelligently in an environment as complex as the real battlefield. A number of difficult challenges are yet to be overcome. At the same time, a growing body of research in Government and academia demonstrates promising steps towards solving some of the challenges. The industry is beginning to embrace approaches that may contribute to technologies of autonomous intelligent agents for cyber defense of the Army networks.

</details>

<details>

<summary>2018-12-18 14:49:54 - Multi-Fidelity Recursive Behavior Prediction</summary>

- *Mihir Jain, Kyle Brown, Ahmed K. Sadek*

- `1901.01831v1` - [abs](http://arxiv.org/abs/1901.01831v1) - [pdf](http://arxiv.org/pdf/1901.01831v1)

> Predicting the behavior of surrounding vehicles is a critical problem in automated driving. We present a novel game theoretic behavior prediction model that achieves state of the art prediction accuracy by explicitly reasoning about possible future interaction between agents. We evaluate our approach on the NGSIM vehicle trajectory data set and demonstrate lower root mean square error than state-of-the-art methods.

</details>

<details>

<summary>2018-12-18 16:08:57 - Domain Adaptation for Reinforcement Learning on the Atari</summary>

- *Thomas Carr, Maria Chli, George Vogiatzis*

- `1812.07452v1` - [abs](http://arxiv.org/abs/1812.07452v1) - [pdf](http://arxiv.org/pdf/1812.07452v1)

> Deep reinforcement learning agents have recently been successful across a variety of discrete and continuous control tasks; however, they can be slow to train and require a large number of interactions with the environment to learn a suitable policy. This is borne out by the fact that a reinforcement learning agent has no prior knowledge of the world, no pre-existing data to depend on and so must devote considerable time to exploration. Transfer learning can alleviate some of the problems by leveraging learning done on some source task to help learning on some target task. Our work presents an algorithm for initialising the hidden feature representation of the target task. We propose a domain adaptation method to transfer state representations and demonstrate transfer across domains, tasks and action spaces. We utilise adversarial domain adaptation ideas combined with an adversarial autoencoder architecture. We align our new policies' representation space with a pre-trained source policy, taking target task data generated from a random policy. We demonstrate that this initialisation step provides significant improvement when learning a new reinforcement learning task, which highlights the wide applicability of adversarial adaptation methods; even as the task and label/action space also changes.

</details>

<details>

<summary>2018-12-18 16:50:32 - Scale-invariant temporal history (SITH): optimal slicing of the past in an uncertain world</summary>

- *Tyler A. Spears, Brandon G. Jacques, Marc W. Howard, Per B. Sederberg*

- `1712.07165v3` - [abs](http://arxiv.org/abs/1712.07165v3) - [pdf](http://arxiv.org/pdf/1712.07165v3)

> In both the human brain and any general artificial intelligence (AI), a representation of the past is necessary to predict the future. However, perfect storage of all experiences is not feasible. One approach utilized in many applications, including reward prediction in reinforcement learning, is to retain recently active features of experience in a buffer. Despite its prior successes, we show that the fixed length buffer renders Deep Q-learning Networks (DQNs) fragile to changes in the scale over which information can be learned. To enable learning when the relevant temporal scales in the environment are not known *a priori*, recent advances in psychology and neuroscience suggest that the brain maintains a compressed representation of the past. Here we introduce a neurally-plausible, scale-free memory representation we call Scale-Invariant Temporal History (SITH) for use with artificial agents. This representation covers an exponentially large period of time by sacrificing temporal accuracy for events further in the past. We demonstrate the utility of this representation by comparing the performance of agents given SITH, buffer, and exponential decay representations in learning to play video games at different levels of complexity. In these environments, SITH exhibits better learning performance by storing information for longer timescales than a fixed-size buffer, and representing this information more clearly than a set of exponentially decayed features. Finally, we discuss how the application of SITH, along with other human-inspired models of cognition, could improve reinforcement and machine learning algorithms in general.

</details>

<details>

<summary>2018-12-18 16:59:23 - A Factorial Mixture Prior for Compositional Deep Generative Models</summary>

- *Ulrich Paquet, Sumedh K. Ghaisas, Olivier Tieleman*

- `1812.07480v1` - [abs](http://arxiv.org/abs/1812.07480v1) - [pdf](http://arxiv.org/pdf/1812.07480v1)

> We assume that a high-dimensional datum, like an image, is a compositional expression of a set of properties, with a complicated non-linear relationship between the datum and its properties. This paper proposes a factorial mixture prior for capturing latent properties, thereby adding structured compositionality to deep generative models. The prior treats a latent vector as belonging to Cartesian product of subspaces, each of which is quantized separately with a Gaussian mixture model. Some mixture components can be set to represent properties as observed random variables whenever labeled properties are present. Through a combination of stochastic variational inference and gradient descent, a method for learning how to infer discrete properties in an unsupervised or semi-supervised way is outlined and empirically evaluated.

</details>

<details>

<summary>2018-12-18 17:26:47 - Toward Cognitive and Immersive Systems: Experiments in a Cognitive Microworld</summary>

- *Matthew Peveler, Naveen Sundar Govindarajulu, Selmer Bringsjord, Biplav Srivastava, Kartik Talamadupula, Hui Su*

- `1709.05958v2` - [abs](http://arxiv.org/abs/1709.05958v2) - [pdf](http://arxiv.org/pdf/1709.05958v2)

> As computational power has continued to increase, and sensors have become more accurate, the corresponding advent of systems that are at once cognitive and immersive has arrived. These \textit{cognitive and immersive systems} (CAISs) fall squarely into the intersection of AI with HCI/HRI: such systems interact with and assist the human agents that enter them, in no small part because such systems are infused with AI able to understand and reason about these humans and their knowledge, beliefs, goals, communications, plans, etc. We herein explain our approach to engineering CAISs. We emphasize the capacity of a CAIS to develop and reason over a `theory of the mind' of its human partners. This capacity entails that the AI in question has a sophisticated model of the beliefs, knowledge, goals, desires, emotions, etc.\ of these humans. To accomplish this engineering, a formal framework of very high expressivity is needed. In our case, this framework is a \textit{cognitive event calculus}, a particular kind of quantified multi-operator modal logic, and a matching high-expressivity automated reasoner and planner. To explain, advance, and to a degree validate our approach, we show that a calculus of this type satisfies a set of formal requirements, and can enable a CAIS to understand a psychologically tricky scenario couched in what we call the \textit{cognitive polysolid framework} (CPF). We also formally show that a room that satisfies these requirements can have a useful property we term \emph{expectation of usefulness}. CPF, a sub-class of \textit{cognitive microworlds}, includes machinery able to represent and plan over not merely blocks and actions (such as seen in the primitive `blocks worlds' of old), but also over agents and their mental attitudes about both other agents and inanimate objects.

</details>

<details>

<summary>2018-12-18 17:29:23 - Iterative annotation to ease neural network training: Specialized machine learning in medical image analysis</summary>

- *Brendon Lutnick, Brandon Ginley, Darshana Govind, Sean D. McGarry, Peter S. LaViolette, Rabi Yacoub, Sanjay Jain, John E. Tomaszewski, Kuang-Yu Jen, Pinaki Sarder*

- `1812.07509v1` - [abs](http://arxiv.org/abs/1812.07509v1) - [pdf](http://arxiv.org/pdf/1812.07509v1)

> Neural networks promise to bring robust, quantitative analysis to medical fields, but adoption is limited by the technicalities of training these networks. To address this translation gap between medical researchers and neural networks in the field of pathology, we have created an intuitive interface which utilizes the commonly used whole slide image (WSI) viewer, Aperio ImageScope (Leica Biosystems Imaging, Inc.), for the annotation and display of neural network predictions on WSIs. Leveraging this, we propose the use of a human-in-the-loop strategy to reduce the burden of WSI annotation. We track network performance improvements as a function of iteration and quantify the use of this pipeline for the segmentation of renal histologic findings on WSIs. More specifically, we present network performance when applied to segmentation of renal micro compartments, and demonstrate multi-class segmentation in human and mouse renal tissue slides. Finally, to show the adaptability of this technique to other medical imaging fields, we demonstrate its ability to iteratively segment human prostate glands from radiology imaging data.

</details>

<details>

<summary>2018-12-18 17:32:39 - NIPS - Not Even Wrong? A Systematic Review of Empirically Complete Demonstrations of Algorithmic Effectiveness in the Machine Learning and Artificial Intelligence Literature</summary>

- *Franz J Király, Bilal Mateen, Raphael Sonabend*

- `1812.07519v1` - [abs](http://arxiv.org/abs/1812.07519v1) - [pdf](http://arxiv.org/pdf/1812.07519v1)

> Objective: To determine the completeness of argumentative steps necessary to conclude effectiveness of an algorithm in a sample of current ML/AI supervised learning literature.   Data Sources: Papers published in the Neural Information Processing Systems (NeurIPS, n\'ee NIPS) journal where the official record showed a 2017 year of publication.   Eligibility Criteria: Studies reporting a (semi-)supervised model, or pre-processing fused with (semi-)supervised models for tabular data.   Study Appraisal: Three reviewers applied the assessment criteria to determine argumentative completeness. The criteria were split into three groups, including: experiments (e.g real and/or synthetic data), baselines (e.g uninformed and/or state-of-art) and quantitative comparison (e.g. performance quantifiers with confidence intervals and formal comparison of the algorithm against baselines).   Results: Of the 121 eligible manuscripts (from the sample of 679 abstracts), 99\% used real-world data and 29\% used synthetic data. 91\% of manuscripts did not report an uninformed baseline and 55\% reported a state-of-art baseline. 32\% reported confidence intervals for performance but none provided references or exposition for how these were calculated. 3\% reported formal comparisons.   Limitations: The use of one journal as the primary information source may not be representative of all ML/AI literature. However, the NeurIPS conference is recognised to be amongst the top tier concerning ML/AI studies, so it is reasonable to consider its corpus to be representative of high-quality research.   Conclusion: Using the 2017 sample of the NeurIPS supervised learning corpus as an indicator for the quality and trustworthiness of current ML/AI research, it appears that complete argumentative chains in demonstrations of algorithmic effectiveness are rare.

</details>

<details>

<summary>2018-12-18 17:43:47 - M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search</summary>

- *Yelong Shen, Jianshu Chen, Po-Sen Huang, Yuqing Guo, Jianfeng Gao*

- `1802.04394v5` - [abs](http://arxiv.org/abs/1802.04394v5) - [pdf](http://arxiv.org/pdf/1802.04394v5)

> Learning to walk over a graph towards a target node for a given query and a source node is an important problem in applications such as knowledge base completion (KBC). It can be formulated as a reinforcement learning (RL) problem with a known state transition model. To overcome the challenge of sparse rewards, we develop a graph-walking agent called M-Walk, which consists of a deep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS). The RNN encodes the state (i.e., history of the walked path) and maps it separately to a policy and Q-values. In order to effectively train the agent from sparse rewards, we combine MCTS with the neural policy to generate trajectories yielding more positive rewards. From these trajectories, the network is improved in an off-policy manner using Q-learning, which modifies the RNN policy via parameter sharing. Our proposed RL algorithm repeatedly applies this policy-improvement step to learn the model. At test time, MCTS is combined with the neural policy to predict the target node. Experimental results on several graph-walking benchmarks show that M-Walk is able to learn better policies than other RL-based methods, which are mainly based on policy gradients. M-Walk also outperforms traditional KBC baselines.

</details>

<details>

<summary>2018-12-18 20:01:41 - Universal Successor Features Approximators</summary>

- *Diana Borsa, André Barreto, John Quan, Daniel Mankowitz, Rémi Munos, Hado van Hasselt, David Silver, Tom Schaul*

- `1812.07626v1` - [abs](http://arxiv.org/abs/1812.07626v1) - [pdf](http://arxiv.org/pdf/1812.07626v1)

> The ability of a reinforcement learning (RL) agent to learn about many reward functions at the same time has many potential benefits, such as the decomposition of complex tasks into simpler ones, the exchange of information between tasks, and the reuse of skills. We focus on one aspect in particular, namely the ability to generalise to unseen tasks. Parametric generalisation relies on the interpolation power of a function approximator that is given the task description as input; one of its most common form are universal value function approximators (UVFAs). Another way to generalise to new tasks is to exploit structure in the RL problem itself. Generalised policy improvement (GPI) combines solutions of previous tasks into a policy for the unseen task; this relies on instantaneous policy evaluation of old policies under the new reward function, which is made possible through successor features (SFs). Our proposed universal successor features approximators (USFAs) combine the advantages of all of these, namely the scalability of UVFAs, the instant inference of SFs, and the strong generalisation of GPI. We discuss the challenges involved in training a USFA, its generalisation properties and demonstrate its practical benefits and transfer abilities on a large-scale domain in which the agent has to navigate in a first-person perspective three-dimensional environment.

</details>

<details>

<summary>2018-12-18 20:07:56 - Clustering-Oriented Representation Learning with Attractive-Repulsive Loss</summary>

- *Kian Kenyon-Dean, Andre Cianflone, Lucas Page-Caccia, Guillaume Rabusseau, Jackie Chi Kit Cheung, Doina Precup*

- `1812.07627v1` - [abs](http://arxiv.org/abs/1812.07627v1) - [pdf](http://arxiv.org/pdf/1812.07627v1)

> The standard loss function used to train neural network classifiers, categorical cross-entropy (CCE), seeks to maximize accuracy on the training data; building useful representations is not a necessary byproduct of this objective. In this work, we propose clustering-oriented representation learning (COREL) as an alternative to CCE in the context of a generalized attractive-repulsive loss framework. COREL has the consequence of building latent representations that collectively exhibit the quality of natural clustering within the latent space of the final hidden layer, according to a predefined similarity function. Despite being simple to implement, COREL variants outperform or perform equivalently to CCE in a variety of scenarios, including image and news article classification using both feed-forward and convolutional neural networks. Analysis of the latent spaces created with different similarity functions facilitates insights on the different use cases COREL variants can satisfy, where the Cosine-COREL variant makes a consistently clusterable latent space, while Gaussian-COREL consistently obtains better classification accuracy than CCE.

</details>

<details>

<summary>2018-12-18 23:16:48 - A Voting-Based System for Ethical Decision Making</summary>

- *Ritesh Noothigattu, Snehalkumar 'Neil' S. Gaikwad, Edmond Awad, Sohan Dsouza, Iyad Rahwan, Pradeep Ravikumar, Ariel D. Procaccia*

- `1709.06692v2` - [abs](http://arxiv.org/abs/1709.06692v2) - [pdf](http://arxiv.org/pdf/1709.06692v2)

> We present a general approach to automating ethical decisions, drawing on machine learning and computational social choice. In a nutshell, we propose to learn a model of societal preferences, and, when faced with a specific ethical dilemma at runtime, efficiently aggregate those preferences to identify a desirable choice. We provide a concrete algorithm that instantiates our approach; some of its crucial steps are informed by a new theory of swap-dominance efficient voting rules. Finally, we implement and evaluate a system for ethical decision making in the autonomous vehicle domain, using preference data collected from 1.3 million people through the Moral Machine website.

</details>

<details>

<summary>2018-12-19 00:41:53 - Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization</summary>

- *German I. Parisi, Jun Tani, Cornelius Weber, Stefan Wermter*

- `1805.10966v4` - [abs](http://arxiv.org/abs/1805.10966v4) - [pdf](http://arxiv.org/pdf/1805.10966v4)

> Artificial autonomous agents and robots interacting in complex environments are required to continually acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous streams of information is referred to as lifelong learning and represents a long-standing challenge for neural network models due to catastrophic forgetting. Computational models of lifelong learning typically alleviate catastrophic forgetting in experimental scenarios with given datasets of static images and limited complexity, thereby differing significantly from the conditions artificial agents are exposed to. In more natural settings, sequential information may become progressively available over time and access to previous experience may be restricted. In this paper, we propose a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture comprises two growing recurrent networks with the complementary tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing networks can expand in response to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals to regulate structural plasticity levels and develop more compact representations from episodic experience. For the consolidation of knowledge in the absence of external sensory input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate the proposed model on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly outperform current methods of lifelong learning in three different incremental learning scenarios

</details>

<details>

<summary>2018-12-19 10:01:57 - Motivations, Classification and Model Trial of Conversational Agents for Insurance Companies</summary>

- *Falko Koetter, Matthias Blohm, Monika Kochanowski, Joscha Goetzer, Daniel Graziotin, Stefan Wagner*

- `1812.07339v2` - [abs](http://arxiv.org/abs/1812.07339v2) - [pdf](http://arxiv.org/pdf/1812.07339v2)

> Advances in artificial intelligence have renewed interest in conversational agents. So-called chatbots have reached maturity for industrial applications. German insurance companies are interested in improving their customer service and digitizing their business processes. In this work we investigate the potential use of conversational agents in insurance companies by determining which classes of agents are of interest to insurance companies, finding relevant use cases and requirements, and developing a prototype for an exemplary insurance scenario. Based on this approach, we derive key findings for conversational agent implementation in insurance companies.

</details>

<details>

<summary>2018-12-19 10:33:00 - A Novel Variational Autoencoder with Applications to Generative Modelling, Classification, and Ordinal Regression</summary>

- *Joel Jaskari, Jyri J. Kivinen*

- `1812.07352v2` - [abs](http://arxiv.org/abs/1812.07352v2) - [pdf](http://arxiv.org/pdf/1812.07352v2)

> We develop a novel probabilistic generative model based on the variational autoencoder approach. Notable aspects of our architecture are: a novel way of specifying the latent variables prior, and the introduction of an ordinality enforcing unit. We describe how to do supervised, unsupervised and semi-supervised learning, and nominal and ordinal classification, with the model. We analyze generative properties of the approach, and the classification effectiveness under nominal and ordinal classification, using two benchmark datasets. Our results show that our model can achieve comparable results with relevant baselines in both of the classification tasks.

</details>

<details>

<summary>2018-12-19 11:32:46 - Hierarchical Macro Strategy Model for MOBA Game AI</summary>

- *Bin Wu, Qiang Fu, Jing Liang, Peng Qu, Xiaoqian Li, Liang Wang, Wei Liu, Wei Yang, Yongsheng Liu*

- `1812.07887v1` - [abs](http://arxiv.org/abs/1812.07887v1) - [pdf](http://arxiv.org/pdf/1812.07887v1)

> The next challenge of game AI lies in Real Time Strategy (RTS) games. RTS games provide partially observable gaming environments, where agents interact with one another in an action space much larger than that of GO. Mastering RTS games requires both strong macro strategies and delicate micro level execution. Recently, great progress has been made in micro level execution, while complete solutions for macro strategies are still lacking. In this paper, we propose a novel learning-based Hierarchical Macro Strategy model for mastering MOBA games, a sub-genre of RTS games. Trained by the Hierarchical Macro Strategy model, agents explicitly make macro strategy decisions and further guide their micro level execution. Moreover, each of the agents makes independent strategy decisions, while simultaneously communicating with the allies through leveraging a novel imitated cross-agent communication mechanism. We perform comprehensive evaluations on a popular 5v5 Multiplayer Online Battle Arena (MOBA) game. Our 5-AI team achieves a 48% winning rate against human player teams which are ranked top 1% in the player ranking system.

</details>

<details>

<summary>2018-12-19 11:58:19 - Interpretable preference learning: a game theoretic framework for large margin on-line feature and rule learning</summary>

- *Mirko Polato, Fabio Aiolli*

- `1812.07895v1` - [abs](http://arxiv.org/abs/1812.07895v1) - [pdf](http://arxiv.org/pdf/1812.07895v1)

> A large body of research is currently investigating on the connection between machine learning and game theory. In this work, game theory notions are injected into a preference learning framework. Specifically, a preference learning problem is seen as a two-players zero-sum game. An algorithm is proposed to incrementally include new useful features into the hypothesis. This can be particularly important when dealing with a very large number of potential features like, for instance, in relational learning and rule extraction. A game theoretical analysis is used to demonstrate the convergence of the algorithm. Furthermore, leveraging on the natural analogy between features and rules, the resulting models can be easily interpreted by humans. An extensive set of experiments on classification tasks shows the effectiveness of the proposed method in terms of interpretability and feature selection quality, with accuracy at the state-of-the-art.

</details>

<details>

<summary>2018-12-19 12:06:58 - An Empirical Evaluation of Sketched SVD and its Application to Leverage Score Ordering</summary>

- *Hui Han Chin, Paul Pu Liang*

- `1812.07903v1` - [abs](http://arxiv.org/abs/1812.07903v1) - [pdf](http://arxiv.org/pdf/1812.07903v1)

> The power of randomized algorithms in numerical methods have led to fast solutions which use the Singular Value Decomposition (SVD) as a core routine. However, given the large data size of modern and the modest runtime of SVD, most practical algorithms would require some form of approximation, such as sketching, when running SVD. While these approximation methods satisfy many theoretical guarantees, we provide the first algorithmic implementations for sketch-and-solve SVD problems on real-world, large-scale datasets. We provide a comprehensive empirical evaluation of these algorithms and provide guidelines on how to ensure accurate deployment to real-world data. As an application of sketched SVD, we present Sketched Leverage Score Ordering, a technique for determining the ordering of data in the training of neural networks. Our technique is based on the distributed computation of leverage scores using random projections. These computed leverage scores provide a flexible and efficient method to determine the optimal ordering of training data without manual intervention or annotations. We present empirical results on an extensive set of experiments across image classification, language sentiment analysis, and multi-modal sentiment analysis. Our method is faster compared to standard randomized projection algorithms and shows improvements in convergence and results.

</details>

<details>

<summary>2018-12-19 12:28:47 - An Empirical Study of Generative Models with Encoders</summary>

- *Paul K. Rubenstein, Yunpeng Li, Dominik Roblek*

- `1812.07909v1` - [abs](http://arxiv.org/abs/1812.07909v1) - [pdf](http://arxiv.org/pdf/1812.07909v1)

> Generative adversarial networks (GANs) are capable of producing high quality image samples. However, unlike variational autoencoders (VAEs), GANs lack encoders that provide the inverse mapping for the generators, i.e., encode images back to the latent space. In this work, we consider adversarially learned generative models that also have encoders. We evaluate models based on their ability to produce high quality samples and reconstructions of real images. Our main contributions are twofold: First, we find that the baseline Bidirectional GAN (BiGAN) can be improved upon with the addition of an autoencoder loss, at the expense of an extra hyper-parameter to tune. Second, we show that comparable performance to BiGAN can be obtained by simply training an encoder to invert the generator of a normal GAN.

</details>

<details>

<summary>2018-12-19 15:39:58 - Speeding-up the decision making of a learning agent using an ion trap quantum processor</summary>

- *Theeraphot Sriarunothai, Sabine Wölk, Gouri Shankar Giri, Nicolai Friis, Vedran Dunjko, Hans J. Briegel, Christof Wunderlich*

- `1709.01366v3` - [abs](http://arxiv.org/abs/1709.01366v3) - [pdf](http://arxiv.org/pdf/1709.01366v3)

> We report a proof-of-principle experimental demonstration of the quantum speed-up for learning agents utilizing a small-scale quantum information processor based on radiofrequency-driven trapped ions. The decision-making process of a quantum learning agent within the projective simulation paradigm for machine learning is implemented in a system of two qubits. The latter are realized using hyperfine states of two frequency-addressed atomic ions exposed to a static magnetic field gradient. We show that the deliberation time of this quantum learning agent is quadratically improved with respect to comparable classical learning agents. The performance of this quantum-enhanced learning agent highlights the potential of scalable quantum processors taking advantage of machine learning.

</details>

<details>

<summary>2018-12-19 15:54:41 - Semantic Frame Parsing for Information Extraction : the CALOR corpus</summary>

- *Gabriel Marzinotto, Jeremy Auguste, Frederic Bechet, Géraldine Damnati, Alexis Nasr*

- `1812.08039v1` - [abs](http://arxiv.org/abs/1812.08039v1) - [pdf](http://arxiv.org/pdf/1812.08039v1)

> This paper presents a publicly available corpus of French encyclopedic history texts annotated according to the Berkeley FrameNet formalism. The main difference in our approach compared to previous works on semantic parsing with FrameNet is that we are not interested here in full text parsing but rather on partial parsing. The goal is to select from the FrameNet resources the minimal set of frames that are going to be useful for the applicative framework targeted, in our case Information Extraction from encyclopedic documents. Such an approach leverages the manual annotation of larger corpora than those obtained through full text parsing and therefore opens the door to alternative methods for Frame parsing than those used so far on the FrameNet 1.5 benchmark corpus. The approaches compared in this study rely on an integrated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The models compared are CRFs and multitasks bi-LSTMs.

</details>

<details>

<summary>2018-12-19 16:02:08 - Cyberbullying Detection in Social Networks Using Deep Learning Based Models; A Reproducibility Study</summary>

- *Maral Dadvar, Kai Eckert*

- `1812.08046v1` - [abs](http://arxiv.org/abs/1812.08046v1) - [pdf](http://arxiv.org/pdf/1812.08046v1)

> Cyberbullying is a disturbing online misbehaviour with troubling consequences. It appears in different forms, and in most of the social networks, it is in textual format. Automatic detection of such incidents requires intelligent systems. Most of the existing studies have approached this problem with conventional machine learning models and the majority of the developed models in these studies are adaptable to a single social network at a time. In recent studies, deep learning based models have found their way in the detection of cyberbullying incidents, claiming that they can overcome the limitations of the conventional models, and improve the detection performance. In this paper, we investigate the findings of a recent literature in this regard. We successfully reproduced the findings of this literature and validated their findings using the same datasets, namely Wikipedia, Twitter, and Formspring, used by the authors. Then we expanded our work by applying the developed methods on a new YouTube dataset (~54k posts by ~4k users) and investigated the performance of the models in new social media platforms. We also transferred and evaluated the performance of the models trained on one platform to another platform. Our findings show that the deep learning based models outperform the machine learning models previously applied to the same YouTube dataset. We believe that the deep learning based models can also benefit from integrating other sources of information and looking into the impact of profile information of the users in social networks.

</details>

<details>

<summary>2018-12-19 17:13:20 - Shallow Cue Guided Deep Visual Tracking via Mixed Models</summary>

- *Fangwen Tu, Shuzhi Sam Ge, Chang Chieh Hang*

- `1812.08094v1` - [abs](http://arxiv.org/abs/1812.08094v1) - [pdf](http://arxiv.org/pdf/1812.08094v1)

> In this paper, a robust visual tracking approach via mixed model based convolutional neural networks (SDT) is developed. In order to handle abrupt or fast motion, a prior map is generated to facilitate the localization of region of interest (ROI) before the deep tracker is performed. A top-down saliency model with nineteen shallow cues are employed to construct the prior map with online learnt combination weights. Moreover, apart from a holistic deep learner, four local networks are also trained to learn different components of the target. The generated four local heat maps will facilitate to rectify the holistic map by eliminating the distracters to avoid drifting. Furthermore, to guarantee the instance for online update of high quality, a prioritised update strategy is implemented by casting the problem into a label noise problem. The selection probability is designed by considering both confidence values and bio-inspired memory for temporal information integration. Experiments are conducted qualitatively and quantitatively on a set of challenging image sequences. Comparative study demonstrates that the proposed algorithm outperforms other state-of-the-art methods.

</details>

<details>

<summary>2018-12-19 20:53:24 - A Novel Large-scale Ordinal Regression Model</summary>

- *Yong Shi, Huadong Wang, Xin Shen, Lingfeng Niu*

- `1812.08237v1` - [abs](http://arxiv.org/abs/1812.08237v1) - [pdf](http://arxiv.org/pdf/1812.08237v1)

> Ordinal regression (OR) is a special multiclass classification problem where an order relation exists among the labels. Recent years, people share their opinions and sentimental judgments conveniently with social networks and E-Commerce so that plentiful large-scale OR problems arise. However, few studies have focused on this kind of problems. Nonparallel Support Vector Ordinal Regression (NPSVOR) is a SVM-based OR model, which learns a hyperplane for each rank by solving a series of independent sub-optimization problems and then ensembles those learned hyperplanes to predict. The previous studies are focused on its nonlinear case and got a competitive testing performance, but its training is time consuming, particularly for large-scale data. In this paper, we consider NPSVOR's linear case and design an efficient training method based on the dual coordinate descent method (DCD). To utilize the order information among labels in prediction, a new prediction function is also proposed. Extensive contrast experiments on the text OR datasets indicate that the carefully implemented DCD is very suitable for training large data.

</details>

<details>

<summary>2018-12-19 22:16:26 - Deep Predictive Models in Interactive Music</summary>

- *Charles P. Martin, Kai Olav Ellefsen, Jim Torresen*

- `1801.10492v3` - [abs](http://arxiv.org/abs/1801.10492v3) - [pdf](http://arxiv.org/pdf/1801.10492v3)

> Musical performance requires prediction to operate instruments, to perform in groups and to improvise. In this paper, we investigate how a number of digital musical instruments (DMIs), including two of our own, have applied predictive machine learning models that assist users by predicting unknown states of musical processes. We characterise these predictions as focussed within a musical instrument, at the level of individual performers, and between members of an ensemble. These models can connect to existing frameworks for DMI design and have parallels in the cognitive predictions of human musicians.   We discuss how recent advances in deep learning highlight the role of prediction in DMIs, by allowing data-driven predictive models with a long memory of past states. The systems we review are used to motivate musical use-cases where prediction is a necessary component, and to highlight a number of challenges for DMI designers seeking to apply deep predictive models in interactive music systems of the future.

</details>

<details>

<summary>2018-12-20 01:58:04 - Iterated Belief Revision Under Resource Constraints: Logic as Geometry</summary>

- *Dan P. Guralnik, Daniel E. Koditschek*

- `1812.08313v1` - [abs](http://arxiv.org/abs/1812.08313v1) - [pdf](http://arxiv.org/pdf/1812.08313v1)

> We propose a variant of iterated belief revision designed for settings with limited computational resources, such as mobile autonomous robots. The proposed memory architecture---called the {\em universal memory architecture} (UMA)---maintains an epistemic state in the form of a system of default rules similar to those studied by Pearl and by Goldszmidt and Pearl (systems $Z$ and $Z^+$). A duality between the category of UMA representations and the category of the corresponding model spaces, extending the Sageev-Roller duality between discrete poc sets and discrete median algebras provides a two-way dictionary from inference to geometry, leading to immense savings in computation, at a cost in the quality of representation that can be quantified in terms of topological invariants. Moreover, the same framework naturally enables comparisons between different model spaces, making it possible to analyze the deficiencies of one model space in comparison to others. This paper develops the formalism underlying UMA, analyzes the complexity of maintenance and inference operations in UMA, and presents some learning guarantees for different UMA-based learners. Finally, we present simulation results to illustrate the viability of the approach, and close with a discussion of the strengths, weaknesses, and potential development of UMA-based learners.

</details>

<details>

<summary>2018-12-20 02:12:17 - Artificial Intelligence-aided OFDM Receiver: Design and Experimental Results</summary>

- *Peiwen Jiang, Tianqi Wang, Bin Han, Xuanxuan Gao, Jing Zhang, Chao-Kai Wen, Shi Jin, Geoffrey Ye Li*

- `1812.06638v2` - [abs](http://arxiv.org/abs/1812.06638v2) - [pdf](http://arxiv.org/pdf/1812.06638v2)

> Orthogonal frequency division multiplexing (OFDM) is one of the key technologies that are widely applied in current communication systems. Recently, artificial intelligence (AI)-aided OFDM receivers have been brought to the forefront to break the bottleneck of the traditional OFDM systems. In this paper, we investigate two AI-aided OFDM receivers, data-driven fully connected-deep neural network (FC-DNN) receiver and model-driven ComNet receiver, respectively. We first study their performance under different channel models through simulation and then establish a real-time video transmission system using a 5G rapid prototyping (RaPro) system for over-the-air (OTA) test. To address the performance gap between the simulation and the OTA test caused by the discrepancy between the channel model for offline training and real environments, we develop a novel online training strategy, called SwitchNet receiver. The SwitchNet receiver is with a flexible and extendable architecture and can adapts to real channel by training one parameter online. The OTA test verifies its feasibility and robustness to real environments and indicates its potential for future communications systems. At the end of this paper, we discuss some challenges to inspire future research.

</details>

<details>

<summary>2018-12-20 04:37:37 - Scalable Recollections for Continual Lifelong Learning</summary>

- *Matthew Riemer, Tim Klinger, Djallel Bouneffouf, Michele Franceschini*

- `1711.06761v4` - [abs](http://arxiv.org/abs/1711.06761v4) - [pdf](http://arxiv.org/pdf/1711.06761v4)

> Given the recent success of Deep Learning applied to a variety of single tasks, it is natural to consider more human-realistic settings. Perhaps the most difficult of these settings is that of continual lifelong learning, where the model must learn online over a continuous stream of non-stationary data. A successful continual lifelong learning system must have three key capabilities: it must learn and adapt over time, it must not forget what it has learned, and it must be efficient in both training time and memory. Recent techniques have focused their efforts primarily on the first two capabilities while questions of efficiency remain largely unexplored. In this paper, we consider the problem of efficient and effective storage of experiences over very large time-frames. In particular we consider the case where typical experiences are O(n) bits and memories are limited to O(k) bits for k << n. We present a novel scalable architecture and training algorithm in this challenging domain and provide an extensive evaluation of its performance. Our results show that we can achieve considerable gains on top of state-of-the-art methods such as GEM.

</details>

<details>

<summary>2018-12-20 04:58:10 - Joint Mapping and Calibration via Differentiable Sensor Fusion</summary>

- *Jonathan P. Chen, Fritz Obermeyer, Vladimir Lyapunov, Lionel Gueguen, Noah D. Goodman*

- `1812.00880v2` - [abs](http://arxiv.org/abs/1812.00880v2) - [pdf](http://arxiv.org/pdf/1812.00880v2)

> We leverage automatic differentiation (AD) and probabilistic programming to develop an end-to-end optimization algorithm for batch triangulation of a large number of unknown objects. Given noisy detections extracted from noisily geo-located street level imagery without depth information, we jointly estimate the number and location of objects of different types, together with parameters for sensor noise characteristics and prior distribution of objects conditioned on side information. The entire algorithm is framed as nested stochastic variational inference. An inner loop solves a soft data association problem via loopy belief propagation; a middle loop performs soft EM clustering using a regularized Newton solver (leveraging an AD framework); an outer loop backpropagates through the inner loops to train global parameters. We place priors over sensor parameters for different traffic object types, and demonstrate improvements with richer priors incorporating knowledge of the environment.   We test our algorithm on detections of road signs observed by cars with mounted cameras, though in practice this technique can be used for any geo-tagged images. The detections were extracted by neural image detectors and classifiers, and we independently triangulate each type of sign (e.g. stop, traffic light). We find that our model is more robust to DNN misclassifications than current methods, generalizes across sign types, and can use geometric information to increase precision. Our algorithm outperforms our current production baseline based on k-means clustering. We show that variational inference training allows generalization by learning sign-specific parameters.

</details>

<details>

<summary>2018-12-20 06:59:22 - Theory of Cognitive Relativity: A Promising Paradigm for True AI</summary>

- *Yujian Li*

- `1812.00136v3` - [abs](http://arxiv.org/abs/1812.00136v3) - [pdf](http://arxiv.org/pdf/1812.00136v3)

> The rise of deep learning has brought artificial intelligence (AI) to the forefront. The ultimate goal of AI is to realize machines with human mind and consciousness, but existing achievements mainly simulate intelligent behavior on computer platforms. These achievements all belong to weak AI rather than strong AI. How to achieve strong AI is not known yet in the field of intelligence science. Currently, this field is calling for a new paradigm, especially Theory of Cognitive Relativity (TCR). The TCR aims to summarize a simple and elegant set of first principles about the nature of intelligence, at least including the Principle of World's Relativity and the Principle of Symbol's Relativity. The Principle of World's Relativity states that the subjective world an intelligent agent can observe is strongly constrained by the way it perceives the objective world. The Principle of Symbol's Relativity states that an intelligent agent can use any physical symbol system to express what it observes in its subjective world. The two principles are derived from scientific facts and life experience. Thought experiments show that they are important to understand high-level intelligence and necessary to establish a scientific theory of mind and consciousness. Rather than brain-like intelligence, the TCR indeed advocates a promising change in direction to realize true AI, i.e. artificial general intelligence or artificial consciousness, particularly different from humans' and animals'. Furthermore, a TCR creed has been presented and extended to reveal the secrets of consciousness and to guide realization of conscious machines. In the sense that true AI could be diversely implemented in a brain-different way, the TCR would probably drive an intelligence revolution in combination with some additional first principles.

</details>

<details>

<summary>2018-12-20 07:12:45 - Kappa Learning: A New Method for Measuring Similarity Between Educational Items Using Performance Data</summary>

- *Tanya Nazaretsky, Sara Hershkovitz, Giora Alexandron*

- `1812.08390v1` - [abs](http://arxiv.org/abs/1812.08390v1) - [pdf](http://arxiv.org/pdf/1812.08390v1)

> Sequencing items in adaptive learning systems typically relies on a large pool of interactive assessment items (questions) that are analyzed into a hierarchy of skills or Knowledge Components (KCs). Educational data mining techniques can be used to analyze students performance data in order to optimize the mapping of items to KCs. Standard methods that map items into KCs using item-similarity measures make the implicit assumption that students performance on items that depend on the same skill should be similar. This assumption holds if the latent trait (mastery of the underlying skill) is relatively fixed during students activity, as in the context of testing, which is the primary context in which these measures were developed and applied. However, in adaptive learning systems that aim for learning, and address subject matters such as K6 Math that consist of multiple sub-skills, this assumption does not hold. In this paper we propose a new item-similarity measure, termed Kappa Learning (KL), which aims to address this gap. KL identifies similarity between items under the assumption of learning, namely, that learners mastery of the underlying skills changes as they progress through the items. We evaluate Kappa Learning on data from a computerized tutor that teaches Fractions for 4th grade, with experts tagging as ground truth, and on simulated data. Our results show that clustering that is based on Kappa Learning outperforms clustering that is based on commonly used similarity measures (Cohen Kappa, Yule, and Pearson).

</details>

<details>

<summary>2018-12-20 08:05:54 - Context, Attention and Audio Feature Explorations for Audio Visual Scene-Aware Dialog</summary>

- *Shachi H Kumar, Eda Okur, Saurav Sahay, Juan Jose Alvarado Leanos, Jonathan Huang, Lama Nachman*

- `1812.08407v1` - [abs](http://arxiv.org/abs/1812.08407v1) - [pdf](http://arxiv.org/pdf/1812.08407v1)

> With the recent advancements in AI, Intelligent Virtual Assistants (IVA) have become a ubiquitous part of every home. Going forward, we are witnessing a confluence of vision, speech and dialog system technologies that are enabling the IVAs to learn audio-visual groundings of utterances and have conversations with users about the objects, activities and events surrounding them. As a part of the 7th Dialog System Technology Challenges (DSTC7), for Audio Visual Scene-Aware Dialog (AVSD) track, We explore `topics' of the dialog as an important contextual feature into the architecture along with explorations around multimodal Attention. We also incorporate an end-to-end audio classification ConvNet, AclNet, into our models. We present detailed analysis of the experiments and show that some of our model variations outperform the baseline system presented for this task.

</details>

<details>

<summary>2018-12-20 08:56:52 - A Survey of Hierarchy Identification in Social Networks</summary>

- *Denys Katerenchuk*

- `1812.08425v1` - [abs](http://arxiv.org/abs/1812.08425v1) - [pdf](http://arxiv.org/pdf/1812.08425v1)

> Humans are social by nature. Throughout history, people have formed communities and built relationships. Most relationships with coworkers, friends, and family are developed during face-to-face interactions. These relationships are established through explicit means of communications such as words and implicit such as intonation, body language, etc. By analyzing human interactions we can derive information about the relationships and influence among conversation participants. However, with the development of the Internet, people started to communicate through text in online social networks. Interestingly, they brought their communicational habits to the Internet. Many social network users form relationships with each other and establish communities with leaders and followers. Recognizing these hierarchical relationships is an important task because it will help to understand social networks and predict future trends, improve recommendations, better target advertisement, and improve national security by identifying leaders of anonymous terror groups. In this work, I provide an overview of current research in this area and present the state-of-the-art approaches to deal with the problem of identifying hierarchical relationships in social networks.

</details>

<details>

<summary>2018-12-20 12:35:19 - SMILK, linking natural language and data from the web</summary>

- *Cédric Lopez, Molka Dhouib, Elena Cabrio, Catherine Faron Zucker, Fabien Gandon, Frédérique Segond*

- `1901.02055v1` - [abs](http://arxiv.org/abs/1901.02055v1) - [pdf](http://arxiv.org/pdf/1901.02055v1)

> As part of the SMILK Joint Lab, we studied the use of Natural Language Processing to: (1) enrich knowledge bases and link data on the web, and conversely (2) use this linked data to contribute to the improvement of text analysis and the annotation of textual content, and to support knowledge extraction. The evaluation focused on brand-related information retrieval in the field of cosmetics. This article describes each step of our approach: the creation of ProVoc, an ontology to describe products and brands; the automatic population of a knowledge base mainly based on ProVoc from heterogeneous textual resources; and the evaluation of an application which that takes the form of a browser plugin providing additional knowledge to users browsing the web.

</details>

<details>

<summary>2018-12-20 18:06:57 - Heteroscedastic Gaussian processes for uncertainty modeling in large-scale crowdsourced traffic data</summary>

- *Filipe Rodrigues, Francisco C. Pereira*

- `1812.08733v1` - [abs](http://arxiv.org/abs/1812.08733v1) - [pdf](http://arxiv.org/pdf/1812.08733v1)

> Accurately modeling traffic speeds is a fundamental part of efficient intelligent transportation systems. Nowadays, with the widespread deployment of GPS-enabled devices, it has become possible to crowdsource the collection of speed information to road users (e.g. through mobile applications or dedicated in-vehicle devices). Despite its rather wide spatial coverage, crowdsourced speed data also brings very important challenges, such as the highly variable measurement noise in the data due to a variety of driving behaviors and sample sizes. When not properly accounted for, this noise can severely compromise any application that relies on accurate traffic data. In this article, we propose the use of heteroscedastic Gaussian processes (HGP) to model the time-varying uncertainty in large-scale crowdsourced traffic data. Furthermore, we develop a HGP conditioned on sample size and traffic regime (SRC-HGP), which makes use of sample size information (probe vehicles per minute) as well as previous observed speeds, in order to more accurately model the uncertainty in observed speeds. Using 6 months of crowdsourced traffic data from Copenhagen, we empirically show that the proposed heteroscedastic models produce significantly better predictive distributions when compared to current state-of-the-art methods for both speed imputation and short-term forecasting tasks.

</details>

<details>

<summary>2018-12-20 18:37:35 - A Bayesian Additive Model for Understanding Public Transport Usage in Special Events</summary>

- *Filipe Rodrigues, Stanislav S. Borysov, Bernardete Ribeiro, Francisco C. Pereira*

- `1812.08755v1` - [abs](http://arxiv.org/abs/1812.08755v1) - [pdf](http://arxiv.org/pdf/1812.08755v1)

> Public special events, like sports games, concerts and festivals are well known to create disruptions in transportation systems, often catching the operators by surprise. Although these are usually planned well in advance, their impact is difficult to predict, even when organisers and transportation operators coordinate. The problem highly increases when several events happen concurrently. To solve these problems, costly processes, heavily reliant on manual search and personal experience, are usual practice in large cities like Singapore, London or Tokyo. This paper presents a Bayesian additive model with Gaussian process components that combines smart card records from public transport with context information about events that is continuously mined from the Web. We develop an efficient approximate inference algorithm using expectation propagation, which allows us to predict the total number of public transportation trips to the special event areas, thereby contributing to a more adaptive transportation system. Furthermore, for multiple concurrent event scenarios, the proposed algorithm is able to disaggregate gross trip counts into their most likely components related to specific events and routine behavior. Using real data from Singapore, we show that the presented model outperforms the best baseline model by up to 26% in R2 and also has explanatory power for its individual components.

</details>

<details>

<summary>2018-12-20 22:07:16 - Relevant Attributes in Formal Contexts</summary>

- *Tom Hanika, Maren Koyda, Gerd Stumme*

- `1812.08868v1` - [abs](http://arxiv.org/abs/1812.08868v1) - [pdf](http://arxiv.org/pdf/1812.08868v1)

> Computing conceptual structures, like formal concept lattices, is in the age of massive data sets a challenging task. There are various approaches to deal with this, e.g., random sampling, parallelization, or attribute extraction. A so far not investigated method in the realm of formal concept analysis is attribute selection, as done in machine learning. Building up on this we introduce a method for attribute selection in formal contexts. To this end, we propose the notion of relevant attributes which enables us to define a relative relevance function, reflecting both the order structure of the concept lattice as well as distribution of objects on it. Finally, we overcome computational challenges for computing the relative relevance through an approximation approach based on information entropy.

</details>

<details>

<summary>2018-12-20 22:13:05 - Dialog-based Interactive Image Retrieval</summary>

- *Xiaoxiao Guo, Hui Wu, Yu Cheng, Steven Rennie, Gerald Tesauro, Rogerio Schmidt Feris*

- `1805.00145v3` - [abs](http://arxiv.org/abs/1805.00145v3) - [pdf](http://arxiv.org/pdf/1805.00145v3)

> Existing methods for interactive image retrieval have demonstrated the merit of integrating user feedback, improving retrieval results. However, most current systems rely on restricted forms of user feedback, such as binary relevance responses, or feedback based on a fixed set of relative attributes, which limits their impact. In this paper, we introduce a new approach to interactive image search that enables users to provide feedback via natural language, allowing for more natural and effective interaction. We formulate the task of dialog-based interactive image retrieval as a reinforcement learning problem, and reward the dialog system for improving the rank of the target image during each dialog turn. To mitigate the cumbersome and costly process of collecting human-machine conversations as the dialog system learns, we train our system with a user simulator, which is itself trained to describe the differences between target and candidate images. The efficacy of our approach is demonstrated in a footwear retrieval application. Experiments on both simulated and real-world data show that 1) our proposed learning framework achieves better accuracy than other supervised and reinforcement learning baselines and 2) user feedback based on natural language rather than pre-specified attributes leads to more effective retrieval results, and a more natural and expressive communication interface.

</details>

<details>

<summary>2018-12-20 22:53:33 - Variational Cross-domain Natural Language Generation for Spoken Dialogue Systems</summary>

- *Bo-Hsiang Tseng, Florian Kreyssig, Pawel Budzianowski, Inigo Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gasic*

- `1812.08879v1` - [abs](http://arxiv.org/abs/1812.08879v1) - [pdf](http://arxiv.org/pdf/1812.08879v1)

> Cross-domain natural language generation (NLG) is still a difficult task within spoken dialogue modelling. Given a semantic representation provided by the dialogue manager, the language generator should generate sentences that convey desired information. Traditional template-based generators can produce sentences with all necessary information, but these sentences are not sufficiently diverse. With RNN-based models, the diversity of the generated sentences can be high, however, in the process some information is lost. In this work, we improve an RNN-based generator by considering latent information at the sentence level during generation using the conditional variational autoencoder architecture. We demonstrate that our model outperforms the original RNN-based generator, while yielding highly diverse sentences. In addition, our model performs better when the training data is limited.

</details>

<details>

<summary>2018-12-21 01:10:06 - Pre-training with Non-expert Human Demonstration for Deep Reinforcement Learning</summary>

- *Gabriel V. de la Cruz, Yunshu Du, Matthew E. Taylor*

- `1812.08904v1` - [abs](http://arxiv.org/abs/1812.08904v1) - [pdf](http://arxiv.org/pdf/1812.08904v1)

> Deep reinforcement learning (deep RL) has achieved superior performance in complex sequential tasks by using deep neural networks as function approximators to learn directly from raw input images. However, learning directly from raw images is data inefficient. The agent must learn feature representation of complex states in addition to learning a policy. As a result, deep RL typically suffers from slow learning speeds and often requires a prohibitively large amount of training time and data to reach reasonable performance, making it inapplicable to real-world settings where data is expensive. In this work, we improve data efficiency in deep RL by addressing one of the two learning goals, feature learning. We leverage supervised learning to pre-train on a small set of non-expert human demonstrations and empirically evaluate our approach using the asynchronous advantage actor-critic algorithms (A3C) in the Atari domain. Our results show significant improvements in learning speed, even when the provided demonstration is noisy and of low quality.

</details>

<details>

<summary>2018-12-21 01:28:14 - Feedforward Neural Network for Time Series Anomaly Detection</summary>

- *Zhang Rong, Dong Shandong, Nie Xin, Xiao Shiguang*

- `1812.08389v2` - [abs](http://arxiv.org/abs/1812.08389v2) - [pdf](http://arxiv.org/pdf/1812.08389v2)

> Time series anomaly detection is usually formulated as finding outlier data points relative to some usual data, which is also an important problem in industry and academia. To ensure systems working stably, internet companies, banks and other companies need to monitor time series, which is called KPI (Key Performance Indicators), such as CPU used, number of orders, number of online users and so on. However, millions of time series have several shapes (e.g. seasonal KPIs, KPIs of timed tasks and KPIs of CPU used), so that it is very difficult to use a simple statistical model to detect anomaly for all kinds of time series. Although some anomaly detectors have developed many years and some supervised models are also available in this field, we find many methods have their own disadvantages. In this paper, we present our system, which is based on deep feedforward neural network and detect anomaly points of time series. The main difference between our system and other systems based on supervised models is that we do not need feature engineering of time series to train deep feedforward neural network in our system, which is essentially an end-to-end system.

</details>

<details>

<summary>2018-12-21 02:03:52 - Biologically-plausible learning algorithms can scale to large datasets</summary>

- *Will Xiao, Honglin Chen, Qianli Liao, Tomaso Poggio*

- `1811.03567v3` - [abs](http://arxiv.org/abs/1811.03567v3) - [pdf](http://arxiv.org/pdf/1811.03567v3)

> The backpropagation (BP) algorithm is often thought to be biologically implausible in the brain. One of the main reasons is that BP requires symmetric weight matrices in the feedforward and feedback pathways. To address this "weight transport problem" (Grossberg, 1987), two more biologically plausible algorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax BP's weight symmetry requirements and demonstrate comparable learning capabilities to that of BP on small datasets. However, a recent study by Bartunov et al. (2018) evaluate variants of target-propagation (TP) and feedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that although many of the proposed algorithms perform well on MNIST and CIFAR, they perform significantly worse than BP on ImageNet. Here, we additionally evaluate the sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and FA in that the feedback and feedforward weights share signs but not magnitudes. We examine the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using different network architectures (ResNet-18 and AlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained with sign-symmetry can attain classification performance approaching that of BP-trained networks. These results complement the study by Bartunov et al. (2018), and establish a new benchmark for future biologically plausible learning algorithms on more difficult datasets and more complex architectures.

</details>

<details>

<summary>2018-12-21 03:36:48 - Slimmable Neural Networks</summary>

- *Jiahui Yu, Linjie Yang, Ning Xu, Jianchao Yang, Thomas Huang*

- `1812.08928v1` - [abs](http://arxiv.org/abs/1812.08928v1) - [pdf](http://arxiv.org/pdf/1812.08928v1)

> We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks

</details>

<details>

<summary>2018-12-21 05:02:02 - Enhancing Person-Job Fit for Talent Recruitment: An Ability-aware Neural Network Approach</summary>

- *Chuan Qin, Hengshu Zhu, Tong Xu, Chen Zhu, Liang Jiang, Enhong Chen, Hui Xiong*

- `1812.08947v1` - [abs](http://arxiv.org/abs/1812.08947v1) - [pdf](http://arxiv.org/pdf/1812.08947v1)

> The wide spread use of online recruitment services has led to information explosion in the job market. As a result, the recruiters have to seek the intelligent ways for Person Job Fit, which is the bridge for adapting the right job seekers to the right positions. Existing studies on Person Job Fit have a focus on measuring the matching degree between the talent qualification and the job requirements mainly based on the manual inspection of human resource experts despite of the subjective, incomplete, and inefficient nature of the human judgement. To this end, in this paper, we propose a novel end to end Ability aware Person Job Fit Neural Network model, which has a goal of reducing the dependence on manual labour and can provide better interpretation about the fitting results. The key idea is to exploit the rich information available at abundant historical job application data. Specifically, we propose a word level semantic representation for both job requirements and job seekers' experiences based on Recurrent Neural Network. Along this line, four hierarchical ability aware attention strategies are designed to measure the different importance of job requirements for semantic representation, as well as measuring the different contribution of each job experience to a specific ability requirement. Finally, extensive experiments on a large scale real world data set clearly validate the effectiveness and interpretability of the APJFNN framework compared with several baselines.

</details>

<details>

<summary>2018-12-21 05:23:56 - Reinforcement Learning for Adaptive Caching with Dynamic Storage Pricing</summary>

- *Alireza Sadeghi, Fatemeh Sheikholeslami, Antonio G. Marques, Georgios B. Giannakis*

- `1812.08593v2` - [abs](http://arxiv.org/abs/1812.08593v2) - [pdf](http://arxiv.org/pdf/1812.08593v2)

> Small base stations (SBs) of fifth-generation (5G) cellular networks are envisioned to have storage devices to locally serve requests for reusable and popular contents by \emph{caching} them at the edge of the network, close to the end users. The ultimate goal is to shift part of the predictable load on the back-haul links, from on-peak to off-peak periods, contributing to a better overall network performance and service experience. To enable the SBs with efficient \textit{fetch-cache} decision-making schemes operating in dynamic settings, this paper introduces simple but flexible generic time-varying fetching and caching costs, which are then used to formulate a constrained minimization of the aggregate cost across files and time. Since caching decisions per time slot influence the content availability in future slots, the novel formulation for optimal fetch-cache decisions falls into the class of dynamic programming. Under this generic formulation, first by considering stationary distributions for the costs and file popularities, an efficient reinforcement learning-based solver known as value iteration algorithm can be used to solve the emerging optimization problem. Later, it is shown that practical limitations on cache capacity can be handled using a particular instance of the generic dynamic pricing formulation. Under this setting, to provide a light-weight online solver for the corresponding optimization, the well-known reinforcement learning algorithm, $Q$-learning, is employed to find optimal fetch-cache decisions. Numerical tests corroborating the merits of the proposed approach wrap up the paper.

</details>

<details>

<summary>2018-12-21 05:43:13 - On the Relative Expressiveness of Bayesian and Neural Networks</summary>

- *Arthur Choi, Ruocheng Wang, Adnan Darwiche*

- `1812.08957v1` - [abs](http://arxiv.org/abs/1812.08957v1) - [pdf](http://arxiv.org/pdf/1812.08957v1)

> A neural network computes a function. A central property of neural networks is that they are "universal approximators:" for a given continuous function, there exists a neural network that can approximate it arbitrarily well, given enough neurons (and some additional assumptions). In contrast, a Bayesian network is a model, but each of its queries can be viewed as computing a function. In this paper, we identify some key distinctions between the functions computed by neural networks and those by marginal Bayesian network queries, showing that the former are more expressive than the latter. Moreover, we propose a simple augmentation to Bayesian networks (a testing operator), which enables their marginal queries to become "universal approximators."

</details>

<details>

<summary>2018-12-21 05:53:47 - Lifelong Testing of Smart Autonomous Systems by Shepherding a Swarm of Watchdog Artificial Intelligence Agents</summary>

- *Hussein Abbass, John Harvey, Kate Yaxley*

- `1812.08960v1` - [abs](http://arxiv.org/abs/1812.08960v1) - [pdf](http://arxiv.org/pdf/1812.08960v1)

> Artificial Intelligence (AI) technologies could be broadly categorised into Analytics and Autonomy. Analytics focuses on algorithms offering perception, comprehension, and projection of knowledge gleaned from sensorial data. Autonomy revolves around decision making, and influencing and shaping the environment through action production. A smart autonomous system (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously. To be useful, SAS must be trusted and that requires testing. Lifelong learning of a SAS compounds the testing process. In the remote chance that it is possible to fully test and certify the system pre-release, which is theoretically an undecidable problem, it is near impossible to predict the future behaviours that these systems, alone or collectively, will exhibit. While it may be feasible to severely restrict such systems\textquoteright \ learning abilities to limit the potential unpredictability of their behaviours, an undesirable consequence may be severely limiting their utility. In this paper, we propose the architecture for a watchdog AI (WAI) agent dedicated to lifelong functional testing of SAS. We further propose system specifications including a level of abstraction whereby humans shepherd a swarm of WAI agents to oversee an ecosystem made of humans and SAS. The discussion extends to the challenges, pros, and cons of the proposed concept.

</details>

<details>

<summary>2018-12-21 07:03:31 - Multi-component Image Translation for Deep Domain Generalization</summary>

- *Mohammad Mahfujur Rahman, Clinton Fookes, Mahsa Baktashmotlagh, Sridha Sridharan*

- `1812.08974v1` - [abs](http://arxiv.org/abs/1812.08974v1) - [pdf](http://arxiv.org/pdf/1812.08974v1)

> Domain adaption (DA) and domain generalization (DG) are two closely related methods which are both concerned with the task of assigning labels to an unlabeled data set. The only dissimilarity between these approaches is that DA can access the target data during the training phase, while the target data is totally unseen during the training phase in DG. The task of DG is challenging as we have no earlier knowledge of the target samples. If DA methods are applied directly to DG by a simple exclusion of the target data from training, poor performance will result for a given task. In this paper, we tackle the domain generalization challenge in two ways. In our first approach, we propose a novel deep domain generalization architecture utilizing synthetic data generated by a Generative Adversarial Network (GAN). The discrepancy between the generated images and synthetic images is minimized using existing domain discrepancy metrics such as maximum mean discrepancy or correlation alignment. In our second approach, we introduce a protocol for applying DA methods to a DG scenario by excluding the target data from the training phase, splitting the source data to training and validation parts, and treating the validation data as target data for DA. We conduct extensive experiments on four cross-domain benchmark datasets. Experimental results signify our proposed model outperforms the current state-of-the-art methods for DG.

</details>

<details>

<summary>2018-12-21 12:00:27 - Validity of Clusters Produced By kernel-$k$-means With Kernel-Trick</summary>

- *Mieczysław A. Kłopotek*

- `1701.05335v3` - [abs](http://arxiv.org/abs/1701.05335v3) - [pdf](http://arxiv.org/pdf/1701.05335v3)

> This paper corrects the proof of the Theorem 2 from the Gower's paper \cite[page 5]{Gower:1982} as well as corrects the Theorem 7 from Gower's paper \cite{Gower:1986}. The first correction is needed in order to establish the existence of the kernel function used commonly in the kernel trick e.g. for $k$-means clustering algorithm, on the grounds of distance matrix. The correction encompasses the missing if-part proof and dropping unnecessary conditions. The second correction deals with transformation of the kernel matrix into a one embeddable in Euclidean space.

</details>

<details>

<summary>2018-12-21 12:29:48 - Dreaming neural networks: rigorous results</summary>

- *Elena Agliari, Francesco Alemanno, Adriano Barra, Alberto Fachechi*

- `1812.09077v1` - [abs](http://arxiv.org/abs/1812.09077v1) - [pdf](http://arxiv.org/pdf/1812.09077v1)

> Recently a daily routine for associative neural networks has been proposed: the network Hebbian-learns during the awake state (thus behaving as a standard Hopfield model), then, during its sleep state, optimizing information storage, it consolidates pure patterns and removes spurious ones: this forces the synaptic matrix to collapse to the projector one (ultimately approaching the Kanter-Sompolinksy model). This procedure keeps the learning Hebbian-based (a biological must) but, by taking advantage of a (properly stylized) sleep phase, still reaches the maximal critical capacity (for symmetric interactions). So far this emerging picture (as well as the bulk of papers on unlearning techniques) was supported solely by mathematically-challenging routes, e.g. mainly replica-trick analysis and numerical simulations: here we rely extensively on Guerra's interpolation techniques developed for neural networks and, in particular, we extend the generalized stochastic stability approach to the case. Confining our description within the replica symmetric approximation (where the previous ones lie), the picture painted regarding this generalization (and the previously existing variations on theme) is here entirely confirmed. Further, still relying on Guerra's schemes, we develop a systematic fluctuation analysis to check where ergodicity is broken (an analysis entirely absent in previous investigations). We find that, as long as the network is awake, ergodicity is bounded by the Amit-Gutfreund-Sompolinsky critical line (as it should), but, as the network sleeps, sleeping destroys spin glass states by extending both the retrieval as well as the ergodic region: after an entire sleeping session the solely surviving regions are retrieval and ergodic ones and this allows the network to achieve the perfect retrieval regime (the number of storable patterns equals the number of neurons in the network).

</details>

<details>

<summary>2018-12-21 12:41:00 - Reasoning and Facts Explanation in Valuation Based Systems</summary>

- *S. T. Wierzchoń, M. A. Kłopotek, M. Michalewicz*

- `1812.09086v1` - [abs](http://arxiv.org/abs/1812.09086v1) - [pdf](http://arxiv.org/pdf/1812.09086v1)

> In the literature, the optimization problem to identify a set of composite hypotheses H, which will yield the $k$ largest $P(H|S_e)$ where a composite hypothesis is an instantiation of all the nodes in the network except the evidence nodes \cite{KSy:93} is of significant interest. This problem is called "finding the $k$ Most Plausible Explanation (MPE) of a given evidence $S_e$ in a Bayesian belief network".   The problem of finding $k$ most probable hypotheses is generally NP-hard \cite{Cooper:90}. Therefore in the past various simplifications of the task by restricting $k$ (to 1 or 2), restricting the structure (e.g. to singly connected networks), or shifting the complexity to spatial domain have been investigated.   A genetic algorithm is proposed in this paper to overcome some of these restrictions while stepping out from probabilistic domain onto the general Valuation based System (VBS) framework is also proposed by generalizing the genetic algorithm approach to the realm of Dempster-Shafer belief calculus.

</details>

<details>

<summary>2018-12-21 13:35:32 - Generative Models from the perspective of Continual Learning</summary>

- *Timothée Lesort, Hugo Caselles-Dupré, Michael Garcia-Ortiz, Andrei Stoian, David Filliat*

- `1812.09111v1` - [abs](http://arxiv.org/abs/1812.09111v1) - [pdf](http://arxiv.org/pdf/1812.09111v1)

> Which generative model is the most suitable for Continual Learning? This paper aims at evaluating and comparing generative models on disjoint sequential image generation tasks. We investigate how several models learn and forget, considering various strategies: rehearsal, regularization, generative replay and fine-tuning. We used two quantitative metrics to estimate the generation quality and memory ability. We experiment with sequential tasks on three commonly used benchmarks for Continual Learning (MNIST, Fashion MNIST and CIFAR10). We found that among all models, the original GAN performs best and among Continual Learning strategies, generative replay outperforms all other methods. Even if we found satisfactory combinations on MNIST and Fashion MNIST, training generative models sequentially on CIFAR10 is particularly instable, and remains a challenge. Our code is available online \footnote{\url{https://github.com/TLESORT/Generative\_Continual\_Learning}}.

</details>

<details>

<summary>2018-12-21 13:56:03 - Optimizing Agent Behavior over Long Time Scales by Transporting Value</summary>

- *Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza, Federico Carnevale, Arun Ahuja, Greg Wayne*

- `1810.06721v2` - [abs](http://arxiv.org/abs/1810.06721v2) - [pdf](http://arxiv.org/pdf/1810.06721v2)

> Humans spend a remarkable fraction of waking life engaged in acts of "mental time travel". We dwell on our actions in the past and experience satisfaction or regret. More than merely autobiographical storytelling, we use these event recollections to change how we will act in similar scenarios in the future. This process endows us with a computationally important ability to link actions and consequences across long spans of time, which figures prominently in addressing the problem of long-term temporal credit assignment; in artificial intelligence (AI) this is the question of how to evaluate the utility of the actions within a long-duration behavioral sequence leading to success or failure in a task. Existing approaches to shorter-term credit assignment in AI cannot solve tasks with long delays between actions and consequences. Here, we introduce a new paradigm for reinforcement learning where agents use recall of specific memories to credit actions from the past, allowing them to solve problems that are intractable for existing algorithms. This paradigm broadens the scope of problems that can be investigated in AI and offers a mechanistic account of behaviors that may inspire computational models in neuroscience, psychology, and behavioral economics.

</details>

<details>

<summary>2018-12-21 14:13:07 - A Multiscale Image Denoising Algorithm Based On Dilated Residual Convolution Network</summary>

- *Chang Liu, Zhaowei Shang, Anyong Qin*

- `1812.09131v1` - [abs](http://arxiv.org/abs/1812.09131v1) - [pdf](http://arxiv.org/pdf/1812.09131v1)

> Image denoising is a classical problem in low level computer vision. Model-based optimization methods and deep learning approaches have been the two main strategies for solving the problem. Model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming. In contrast, deep learning methods have fast testing speed but the performance of these CNNs is still inferior. To address this issue, here we propose a novel deep residual learning model that combines the dilated residual convolution and multi-scale convolution groups. Due to the complex patterns and structures of inside an image, the multiscale convolution group is utilized to learn those patterns and enlarge the receptive field. Specifically, the residual connection and batch normalization are utilized to speed up the training process and maintain the denoising performance. In order to decrease the gridding artifacts, we integrate the hybrid dilated convolution design into our model. To this end, this paper aims to train a lightweight and effective denoiser based on multiscale convolution group. Experimental results have demonstrated that the enhanced denoiser can not only achieve promising denoising results, but also become a strong competitor in practical application.

</details>

<details>

<summary>2018-12-21 15:30:17 - Sources of Complexity in Semantic Frame Parsing for Information Extraction</summary>

- *Gabriel Marzinotto, Frédéric Béchet, Géraldine Damnati, Alexis Nasr*

- `1812.09193v1` - [abs](http://arxiv.org/abs/1812.09193v1) - [pdf](http://arxiv.org/pdf/1812.09193v1)

> This paper describes a Semantic Frame parsing System based on sequence labeling methods, precisely BiLSTM models with highway connections, for performing information extraction on a corpus of French encyclopedic history texts annotated according to the Berkeley FrameNet formalism. The approach proposed in this study relies on an integrated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The purpose of this study is to analyze the task complexity, to highlight the factors that make Semantic Frame parsing a difficult task and to provide detailed evaluations of the performance on different types of frames and sentences.

</details>

<details>

<summary>2018-12-21 15:54:34 - Solution Dominance over Constraint Satisfaction Problems</summary>

- *Tias Guns, Peter J. Stuckey, Guido Tack*

- `1812.09207v1` - [abs](http://arxiv.org/abs/1812.09207v1) - [pdf](http://arxiv.org/pdf/1812.09207v1)

> Constraint Satisfaction Problems (CSPs) typically have many solutions that satisfy all constraints. Often though, some solutions are preferred over others, that is, some solutions dominate other solutions. We present solution dominance as a formal framework to reason about such settings. We define Constraint Dominance Problems (CDPs) as CSPs with a dominance relation, that is, a preorder over the solutions of the CSP. This framework captures many well-known variants of constraint satisfaction, including optimization, multi-objective optimization, Max-CSP, minimal models, minimum correction subsets as well as optimization over CP-nets and arbitrary dominance relations. We extend MiniZinc, a declarative language for modeling CSPs, to CDPs by introducing dominance nogoods; these can be derived from dominance relations in a principled way. A generic method for solving arbitrary CDPs incrementally calls a CSP solver and is compatible with any existing solver that supports MiniZinc. This encourages experimenting with different solution dominance relations for a problem, as well as comparing different solvers without having to modify their implementations.

</details>

<details>

<summary>2018-12-21 18:11:20 - Machine learning and AI research for Patient Benefit: 20 Critical Questions on Transparency, Replicability, Ethics and Effectiveness</summary>

- *Sebastian Vollmer, Bilal A. Mateen, Gergo Bohner, Franz J Király, Rayid Ghani, Pall Jonsson, Sarah Cumbers, Adrian Jonas, Katherine S. L. McAllister, Puja Myles, David Granger, Mark Birse, Richard Branson, Karel GM Moons, Gary S Collins, John P. A. Ioannidis, Chris Holmes, Harry Hemingway*

- `1812.10404v1` - [abs](http://arxiv.org/abs/1812.10404v1) - [pdf](http://arxiv.org/pdf/1812.10404v1)

> Machine learning (ML), artificial intelligence (AI) and other modern statistical methods are providing new opportunities to operationalize previously untapped and rapidly growing sources of data for patient benefit. Whilst there is a lot of promising research currently being undertaken, the literature as a whole lacks: transparency; clear reporting to facilitate replicability; exploration for potential ethical concerns; and, clear demonstrations of effectiveness. There are many reasons for why these issues exist, but one of the most important that we provide a preliminary solution for here is the current lack of ML/AI- specific best practice guidance. Although there is no consensus on what best practice looks in this field, we believe that interdisciplinary groups pursuing research and impact projects in the ML/AI for health domain would benefit from answering a series of questions based on the important issues that exist when undertaking work of this nature. Here we present 20 questions that span the entire project life cycle, from inception, data analysis, and model evaluation, to implementation, as a means to facilitate project planning and post-hoc (structured) independent evaluation. By beginning to answer these questions in different settings, we can start to understand what constitutes a good answer, and we expect that the resulting discussion will be central to developing an international consensus framework for transparent, replicable, ethical and effective research in artificial intelligence (AI-TREE) for health.

</details>

<details>

<summary>2018-12-21 18:37:30 - GamePad: A Learning Environment for Theorem Proving</summary>

- *Daniel Huang, Prafulla Dhariwal, Dawn Song, Ilya Sutskever*

- `1806.00608v2` - [abs](http://arxiv.org/abs/1806.00608v2) - [pdf](http://arxiv.org/pdf/1806.00608v2)

> In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.

</details>

<details>

<summary>2018-12-21 19:00:54 - Attention Based Natural Language Grounding by Navigating Virtual Environment</summary>

- *Akilesh B, Abhishek Sinha, Mausoom Sarkar, Balaji Krishnamurthy*

- `1804.08454v2` - [abs](http://arxiv.org/abs/1804.08454v2) - [pdf](http://arxiv.org/pdf/1804.08454v2)

> In this work, we focus on the problem of grounding language by training an agent to follow a set of natural language instructions and navigate to a target object in an environment. The agent receives visual information through raw pixels and a natural language instruction telling what task needs to be achieved and is trained in an end-to-end way. We develop an attention mechanism for multi-modal fusion of visual and textual modalities that allows the agent to learn to complete the task and achieve language grounding. Our experimental results show that our attention mechanism outperforms the existing multi-modal fusion mechanisms proposed for both 2D and 3D environments in order to solve the above-mentioned task in terms of both speed and success rate. We show that the learnt textual representations are semantically meaningful as they follow vector arithmetic in the embedding space. The effectiveness of our attention approach over the contemporary fusion mechanisms is also highlighted from the textual embeddings learnt by the different approaches. We also show that our model generalizes effectively to unseen scenarios and exhibit zero-shot generalization capabilities both in 2D and 3D environments. The code for our 2D environment as well as the models that we developed for both 2D and 3D are available at https://github.com/rl-lang-grounding/rl-lang-ground.

</details>

<details>

<summary>2018-12-21 19:42:56 - A Hybrid Genetic Algorithm for the Traveling Salesman Problem with Drone</summary>

- *Quang Minh Ha, Yves Deville, Quang Dung Pham, Minh Hoàng Hà*

- `1812.09351v1` - [abs](http://arxiv.org/abs/1812.09351v1) - [pdf](http://arxiv.org/pdf/1812.09351v1)

> This paper addresses the Traveling Salesman Problem with Drone (TSP-D), in which a truck and drone are used to deliver parcels to customers. The objective of this problem is to either minimize the total operational cost (min-cost TSP-D) or minimize the completion time for the truck and drone (min-time TSP-D). This problem has gained a lot of attention in the last few years since it is matched with the recent trends in a new delivery method among logistics companies. To solve the TSP-D, we propose a hybrid genetic search with dynamic population management and adaptive diversity control based on a split algorithm, problem-tailored crossover and local search operators, a new restore method to advance the convergence and an adaptive penalization mechanism to dynamically balance the search between feasible/infeasible solutions. The computational results show that the proposed algorithm outperforms existing methods in terms of solution quality and improves best known solutions found in the literature. Moreover, various analyses on the impacts of crossover choice and heuristic components have been conducted to analysis further their sensitivity to the performance of our method.

</details>

<details>

<summary>2018-12-21 19:51:47 - What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models</summary>

- *Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, Anthony Bau, James Glass*

- `1812.09355v1` - [abs](http://arxiv.org/abs/1812.09355v1) - [pdf](http://arxiv.org/pdf/1812.09355v1)

> Despite the remarkable evolution of deep neural networks in natural language processing (NLP), their interpretability remains a challenge. Previous work largely focused on what these models learn at the representation level. We break this analysis down further and study individual dimensions (neurons) in the vector representation learned by end-to-end neural models in NLP tasks. We propose two methods: Linguistic Correlation Analysis, based on a supervised method to extract the most relevant neurons with respect to an extrinsic task, and Cross-model Correlation Analysis, an unsupervised method to extract salient neurons w.r.t. the model itself. We evaluate the effectiveness of our techniques by ablating the identified neurons and reevaluating the network's performance for two tasks: neural machine translation (NMT) and neural language modeling (NLM). We further present a comprehensive analysis of neurons with the aim to address the following questions: i) how localized or distributed are different linguistic properties in the models? ii) are certain neurons exclusive to some properties and not others? iii) is the information more or less distributed in NMT vs. NLM? and iv) how important are the neurons identified through the linguistic correlation method to the overall task? Our code is publicly available as part of the NeuroX toolkit (Dalvi et al. 2019).

</details>

<details>

<summary>2018-12-21 20:20:26 - NeuroX: A Toolkit for Analyzing Individual Neurons in Neural Networks</summary>

- *Fahim Dalvi, Avery Nortonsmith, D. Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, James Glass*

- `1812.09359v1` - [abs](http://arxiv.org/abs/1812.09359v1) - [pdf](http://arxiv.org/pdf/1812.09359v1)

> We present a toolkit to facilitate the interpretation and understanding of neural network models. The toolkit provides several methods to identify salient neurons with respect to the model itself or an external task. A user can visualize selected neurons, ablate them to measure their effect on the model accuracy, and manipulate them to control the behavior of the model at the test time. Such an analysis has a potential to serve as a springboard in various research directions, such as understanding the model, better architectural choices, model distillation and controlling data biases.

</details>

<details>

<summary>2018-12-21 20:41:20 - Whittemore: An embedded domain specific language for causal programming</summary>

- *Joshua Brulé*

- `1812.11918v1` - [abs](http://arxiv.org/abs/1812.11918v1) - [pdf](http://arxiv.org/pdf/1812.11918v1)

> This paper introduces Whittemore, a language for causal programming. Causal programming is based on the theory of structural causal models and consists of two primary operations: identification, which finds formulas that compute causal queries, and estimation, which applies formulas to transform probability distributions to other probability distribution. Causal programming provides abstractions to declare models, queries, and distributions with syntax similar to standard mathematical notation, and conducts rigorous causal inference, without requiring detailed knowledge of the underlying algorithms. Examples of causal inference with real data are provided, along with discussion of the implementation and possibilities for future extension.

</details>

<details>

<summary>2018-12-21 21:28:11 - Human-AI Learning Performance in Multi-Armed Bandits</summary>

- *Ravi Pandya, Sandy H. Huang, Dylan Hadfield-Menell, Anca D. Dragan*

- `1812.09376v1` - [abs](http://arxiv.org/abs/1812.09376v1) - [pdf](http://arxiv.org/pdf/1812.09376v1)

> People frequently face challenging decision-making problems in which outcomes are uncertain or unknown. Artificial intelligence (AI) algorithms exist that can outperform humans at learning such tasks. Thus, there is an opportunity for AI agents to assist people in learning these tasks more effectively. In this work, we use a multi-armed bandit as a controlled setting in which to explore this direction. We pair humans with a selection of agents and observe how well each human-agent team performs. We find that team performance can beat both human and agent performance in isolation. Interestingly, we also find that an agent's performance in isolation does not necessarily correlate with the human-agent team's performance. A drop in agent performance can lead to a disproportionately large drop in team performance, or in some settings can even improve team performance. Pairing a human with an agent that performs slightly better than them can make them perform much better, while pairing them with an agent that performs the same can make them them perform much worse. Further, our results suggest that people have different exploration strategies and might perform better with agents that match their strategy. Overall, optimizing human-agent team performance requires going beyond optimizing agent performance, to understanding how the agent's suggestions will influence human decision-making.

</details>

<details>

<summary>2018-12-22 00:33:59 - Exploiting Problem Structure in Combinatorial Landscapes: A Case Study on Pure Mathematics Application</summary>

- *Xiao-Feng Xie, Zun-Jing Wang*

- `1812.09421v1` - [abs](http://arxiv.org/abs/1812.09421v1) - [pdf](http://arxiv.org/pdf/1812.09421v1)

> In this paper, we present a method using AI techniques to solve a case of pure mathematics applications for finding narrow admissible tuples. The original problem is formulated into a combinatorial optimization problem. In particular, we show how to exploit the local search structure to formulate the problem landscape for dramatic reductions in search space and for non-trivial elimination in search barriers, and then to realize intelligent search strategies for effectively escaping from local minima. Experimental results demonstrate that the proposed method is able to efficiently find best known solutions. This research sheds light on exploiting the local problem structure for an efficient search in combinatorial landscapes as an application of AI to a new problem domain.

</details>

<details>

<summary>2018-12-22 09:07:32 - Structure-Preserving Transformation: Generating Diverse and Transferable Adversarial Examples</summary>

- *Dan Peng, Zizhan Zheng, Xiaofeng Zhang*

- `1809.02786v3` - [abs](http://arxiv.org/abs/1809.02786v3) - [pdf](http://arxiv.org/pdf/1809.02786v3)

> Adversarial examples are perturbed inputs designed to fool machine learning models. Most recent works on adversarial examples for image classification focus on directly modifying pixels with minor perturbations. A common requirement in all these works is that the malicious perturbations should be small enough (measured by an L_p norm for some p) so that they are imperceptible to humans. However, small perturbations can be unnecessarily restrictive and limit the diversity of adversarial examples generated. Further, an L_p norm based distance metric ignores important structure patterns hidden in images that are important to human perception. Consequently, even the minor perturbation introduced in recent works often makes the adversarial examples less natural to humans. More importantly, they often do not transfer well and are therefore less effective when attacking black-box models especially for those protected by a defense mechanism. In this paper, we propose a structure-preserving transformation (SPT) for generating natural and diverse adversarial examples with extremely high transferability. The key idea of our approach is to allow perceptible deviation in adversarial examples while keeping structure patterns that are central to a human classifier. Empirical results on the MNIST and the fashion-MNIST datasets show that adversarial examples generated by our approach can easily bypass strong adversarial training. Further, they transfer well to other target models with no loss or little loss of successful attack rate.

</details>

<details>

<summary>2018-12-22 12:29:20 - Escape Room: A Configurable Testbed for Hierarchical Reinforcement Learning</summary>

- *Jacob Menashe, Peter Stone*

- `1812.09521v1` - [abs](http://arxiv.org/abs/1812.09521v1) - [pdf](http://arxiv.org/pdf/1812.09521v1)

> Recent successes in Reinforcement Learning have encouraged a fast-growing network of RL researchers and a number of breakthroughs in RL research. As the RL community and the body of RL work grows, so does the need for widely applicable benchmarks that can fairly and effectively evaluate a variety of RL algorithms.   This need is particularly apparent in the realm of Hierarchical Reinforcement Learning (HRL). While many existing test domains may exhibit hierarchical action or state structures, modern RL algorithms still exhibit great difficulty in solving domains that necessitate hierarchical modeling and action planning, even when such domains are seemingly trivial. These difficulties highlight both the need for more focus on HRL algorithms themselves, and the need for new testbeds that will encourage and validate HRL research.   Existing HRL testbeds exhibit a Goldilocks problem; they are often either too simple (e.g. Taxi) or too complex (e.g. Montezuma's Revenge from the Arcade Learning Environment). In this paper we present the Escape Room Domain (ERD), a new flexible, scalable, and fully implemented testing domain for HRL that bridges the "moderate complexity" gap left behind by existing alternatives. ERD is open-source and freely available through GitHub, and conforms to widely-used public testing interfaces for simple integration and testing with a variety of public RL agent implementations. We show that the ERD presents a suite of challenges with scalable difficulty to provide a smooth learning gradient from Taxi to the Arcade Learning Environment.

</details>

<details>

<summary>2018-12-22 13:49:32 - Learning through Probing: a decentralized reinforcement learning architecture for social dilemmas</summary>

- *Nicolas Anastassacos, Mirco Musolesi*

- `1809.10007v2` - [abs](http://arxiv.org/abs/1809.10007v2) - [pdf](http://arxiv.org/pdf/1809.10007v2)

> Multi-agent reinforcement learning has received significant interest in recent years notably due to the advancements made in deep reinforcement learning which have allowed for the developments of new architectures and learning algorithms. Using social dilemmas as the training ground, we present a novel learning architecture, Learning through Probing (LTP), where agents utilize a probing mechanism to incorporate how their opponent's behavior changes when an agent takes an action. We use distinct training phases and adjust rewards according to the overall outcome of the experiences accounting for changes to the opponents behavior. We introduce a parameter eta to determine the significance of these future changes to opponent behavior. When applied to the Iterated Prisoner's Dilemma (IPD), LTP agents demonstrate that they can learn to cooperate with each other, achieving higher average cumulative rewards than other reinforcement learning methods while also maintaining good performance in playing against static agents that are present in Axelrod tournaments. We compare this method with traditional reinforcement learning algorithms and agent-tracking techniques to highlight key differences and potential applications. We also draw attention to the differences between solving games and societal-like interactions and analyze the training of Q-learning agents in makeshift societies. This is to emphasize how cooperation may emerge in societies and demonstrate this using environments where interactions with opponents are determined through a random encounter format of the IPD.

</details>

<details>

<summary>2018-12-22 17:01:03 - Artificial Intelligence-Defined 5G Radio Access Networks</summary>

- *Miao Yao, Munawwar Sohul, Vuk Marojevic, Jeffrey H. Reed*

- `1811.08792v2` - [abs](http://arxiv.org/abs/1811.08792v2) - [pdf](http://arxiv.org/pdf/1811.08792v2)

> Massive multiple-input multiple-output antenna systems, millimeter wave communications, and ultra-dense networks have been widely perceived as the three key enablers that facilitate the development and deployment of 5G systems. This article discusses the intelligent agent in 5G base station which combines sensing, learning, understanding and optimizing to facilitate these enablers. We present a flexible, rapidly deployable, and cross-layer artificial intelligence (AI)-based framework to enable the imminent and future demands on 5G and beyond infrastructure. We present example AI-enabled 5G use cases that accommodate important 5G-specific capabilities and discuss the value of AI for enabling beyond 5G network evolution.

</details>

<details>

<summary>2018-12-22 18:33:43 - Risk-Aware Resource Allocation for URLLC: Challenges and Strategies with Machine Learning</summary>

- *Amin Azari, Mustafa Ozger, Cicek Cavdar*

- `1901.04292v1` - [abs](http://arxiv.org/abs/1901.04292v1) - [pdf](http://arxiv.org/pdf/1901.04292v1)

> Supporting ultra-reliable low-latency communications (URLLC) is a major challenge of 5G wireless networks. Stringent delay and reliability requirements need to be satisfied for both scheduled and non-scheduled URLLC traffic to enable a diverse set of 5G applications. Although physical and media access control layer solutions have been investigated to satisfy only scheduled URLLC traffic, there is a lack of study on enabling transmission of non-scheduled URLLC traffic, especially in coexistence with the scheduled URLLC traffic. Machine learning (ML) is an important enabler for such a co-existence scenario due to its ability to exploit spatial/temporal correlation in user behaviors and use of radio resources. Hence, in this paper, we first study the coexistence design challenges, especially the radio resource management (RRM) problem and propose a distributed risk-aware ML solution for RRM. The proposed solution benefits from hybrid orthogonal/non-orthogonal radio resource slicing, and proactively regulates the spectrum needed for satisfying delay/reliability requirement of each URLLC traffic type. A case study is introduced to investigate the potential of the proposed RRM in serving coexisting URLLC traffic types. The results further provide insights on the benefits of leveraging intelligent RRM, e.g. a 75% increase in data rate with respect to the conservative design approach for the scheduled traffic is achieved, while the 99.99% reliability of both scheduled and nonscheduled traffic types is satisfied.

</details>

<details>

<summary>2018-12-23 00:40:44 - Intelligent Tutoring Systems: A Comprehensive Historical Survey with Recent Developments</summary>

- *Ali Alkhatlan, Jugal Kalita*

- `1812.09628v1` - [abs](http://arxiv.org/abs/1812.09628v1) - [pdf](http://arxiv.org/pdf/1812.09628v1)

> This paper provides interested beginners with an updated and detailed introduction to the field of Intelligent Tutoring Systems (ITS). ITSs are computer programs that use artificial intelligence techniques to enhance and personalize automation in teaching. This paper is a literature review that provides the following: First, a review of the history of ITS along with a discussion on the interface between human learning and computer tutors and how effective ITSs are in contemporary education. Second, the traditional architectural components of an ITS and their functions are discussed along with approaches taken by various ITSs. Finally, recent innovative ideas in ITS systems are presented. This paper concludes with some of the author's views regarding future work in the field of intelligent tutoring systems.

</details>

<details>

<summary>2018-12-23 02:56:45 - Competitive Inner-Imaging Squeeze and Excitation for Residual Network</summary>

- *Yang Hu, Guihua Wen, Mingnan Luo, Dan Dai, Jiajiong Ma, Zhiwen Yu*

- `1807.08920v4` - [abs](http://arxiv.org/abs/1807.08920v4) - [pdf](http://arxiv.org/pdf/1807.08920v4)

> Residual networks, which use a residual unit to supplement the identity mappings, enable very deep convolutional architecture to operate well, however, the residual architecture has been proved to be diverse and redundant, which may leads to low-efficient modeling. In this work, we propose a competitive squeeze-excitation (SE) mechanism for the residual network. Re-scaling the value for each channel in this structure will be determined by the residual and identity mappings jointly, and this design enables us to expand the meaning of channel relationship modeling in residual blocks. Modeling of the competition between residual and identity mappings cause the identity flow to control the complement of the residual feature maps for itself. Furthermore, we design a novel inner-imaging competitive SE block to shrink the consumption and re-image the global features of intermediate network structure, by using the inner-imaging mechanism, we can model the channel-wise relations with convolution in spatial. We carry out experiments on the CIFAR, SVHN, and ImageNet datasets, and the proposed method can challenge state-of-the-art results.

</details>

<details>

<summary>2018-12-23 03:44:03 - A Cross-Architecture Instruction Embedding Model for Natural Language Processing-Inspired Binary Code Analysis</summary>

- *Kimberly Redmond, Lannan Luo, Qiang Zeng*

- `1812.09652v1` - [abs](http://arxiv.org/abs/1812.09652v1) - [pdf](http://arxiv.org/pdf/1812.09652v1)

> Given a closed-source program, such as most of proprietary software and viruses, binary code analysis is indispensable for many tasks, such as code plagiarism detection and malware analysis. Today, source code is very often compiled for various architectures, making cross-architecture binary code analysis increasingly important. A binary, after being disassembled, is expressed in an assembly languages. Thus, recent work starts exploring Natural Language Processing (NLP) inspired binary code analysis. In NLP, words are usually represented in high-dimensional vectors (i.e., embeddings) to facilitate further processing, which is one of the most common and critical steps in many NLP tasks. We regard instructions as words in NLP-inspired binary code analysis, and aim to represent instructions as embeddings as well.   To facilitate cross-architecture binary code analysis, our goal is that similar instructions, regardless of their architectures, have embeddings close to each other. To this end, we propose a joint learning approach to generating instruction embeddings that capture not only the semantics of instructions within an architecture, but also their semantic relationships across architectures. To the best of our knowledge, this is the first work on building cross-architecture instruction embedding model. As a showcase, we apply the model to resolving one of the most fundamental problems for binary code similarity comparison---semantics-based basic block comparison, and the solution outperforms the code statistics based approach. It demonstrates that it is promising to apply the model to other cross-architecture binary code analysis tasks.

</details>

<details>

<summary>2018-12-23 05:08:24 - Artificial neural networks condensation: A strategy to facilitate adaption of machine learning in medical settings by reducing computational burden</summary>

- *Dianbo Liu, Nestor Sepulveda, Ming Zheng*

- `1812.09659v1` - [abs](http://arxiv.org/abs/1812.09659v1) - [pdf](http://arxiv.org/pdf/1812.09659v1)

> Machine Learning (ML) applications on healthcare can have a great impact on people's lives helping deliver better and timely treatment to those in need. At the same time, medical data is usually big and sparse requiring important computational resources. Although it might not be a problem for wide-adoption of ML tools in developed nations, availability of computational resource can very well be limited in third-world nations. This can prevent the less favored people from benefiting of the advancement in ML applications for healthcare. In this project we explored methods to increase computational efficiency of ML algorithms, in particular Artificial Neural Nets (NN), while not compromising the accuracy of the predicted results. We used in-hospital mortality prediction as our case analysis based on the MIMIC III publicly available dataset. We explored three methods on two different NN architectures. We reduced the size of recurrent neural net (RNN) and dense neural net (DNN) by applying pruning of "unused" neurons. Additionally, we modified the RNN structure by adding a hidden-layer to the LSTM cell allowing to use less recurrent layers for the model. Finally, we implemented quantization on DNN forcing the weights to be 8-bits instead of 32-bits. We found that all our methods increased computational efficiency without compromising accuracy and some of them even achieved higher accuracy than the pre-condensed baseline models.

</details>

<details>

<summary>2018-12-23 10:58:04 - Inference in Graded Bayesian Networks</summary>

- *Robert Leppert, Karl-Heinz Zimmermann*

- `1901.01837v1` - [abs](http://arxiv.org/abs/1901.01837v1) - [pdf](http://arxiv.org/pdf/1901.01837v1)

> Machine learning provides algorithms that can learn from data and make inferences or predictions on data. Bayesian networks are a class of graphical models that allow to represent a collection of random variables and their condititional dependencies by directed acyclic graphs. In this paper, an inference algorithm for the hidden random variables of a Bayesian network is given by using the tropicalization of the marginal distribution of the observed variables. By restricting the topological structure to graded networks, an inference algorithm for graded Bayesian networks will be established that evaluates the hidden random variables rank by rank and in this way yields the most probable states of the hidden variables. This algorithm can be viewed as a generalized version of the Viterbi algorithm for graded Bayesian networks.

</details>

<details>

<summary>2018-12-23 14:57:28 - Parallelized Interactive Machine Learning on Autonomous Vehicles</summary>

- *Xi Chen, Caylin Hickey*

- `1812.09724v1` - [abs](http://arxiv.org/abs/1812.09724v1) - [pdf](http://arxiv.org/pdf/1812.09724v1)

> Deep reinforcement learning (deep RL) has achieved superior performance in complex sequential tasks by learning directly from image input. A deep neural network is used as a function approximator and requires no specific state information. However, one drawback of using only images as input is that this approach requires a prohibitively large amount of training time and data for the model to learn the state feature representation and approach reasonable performance. This is not feasible in real-world applications, especially when the data are expansive and training phase could introduce disasters that affect human safety. In this work, we use a human demonstration approach to speed up training for learning features and use the resulting pre-trained model to replace the neural network in the deep RL Deep Q-Network (DQN), followed by human interaction to further refine the model. We empirically evaluate our approach by using only a human demonstration model and modified DQN with human demonstration model included in the Microsoft AirSim car simulator. Our results show that (1) pre-training with human demonstration in a supervised learning approach is better and much faster at discovering features than DQN alone, (2) initializing the DQN with a pre-trained model provides a significant improvement in training time and performance even with limited human demonstration, and (3) providing the ability for humans to supply suggestions during DQN training can speed up the network's convergence on an optimal policy, as well as allow it to learn more complex policies that are harder to discover by random exploration.

</details>

<details>

<summary>2018-12-23 15:09:29 - Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets</summary>

- *Zhiming Zhou, Yuxuan Song, Lantao Yu, Hongwei Wang, Jiadong Liang, Weinan Zhang, Zhihua Zhang, Yong Yu*

- `1807.00751v6` - [abs](http://arxiv.org/abs/1807.00751v6) - [pdf](http://arxiv.org/pdf/1807.00751v6)

> In this paper, we investigate the underlying factor that leads to failure and success in the training of GANs. We study the property of the optimal discriminative function and show that in many GANs, the gradient from the optimal discriminative function is not reliable, which turns out to be the fundamental cause of failure in training of GANs. We further demonstrate that a well-defined distance metric does not necessarily guarantee the convergence of GANs. Finally, we prove in this paper that Lipschitz-continuity condition is a general solution to make the gradient of the optimal discriminative function reliable, and characterized the necessary condition where Lipschitz-continuity ensures the convergence, which leads to a broad family of valid GAN objectives under Lipschitz-continuity condition, where Wasserstein distance is one special case. We experiment with several new objectives, which are sound according to our theorems, and we found that, compared with Wasserstein distance, the outputs of the discriminator with new objectives are more stable and the final qualities of generated samples are also consistently higher than those produced by Wasserstein distance.

</details>

<details>

<summary>2018-12-23 19:07:36 - Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks</summary>

- *Amanpreet Singh, Tushar Jain, Sainbayar Sukhbaatar*

- `1812.09755v1` - [abs](http://arxiv.org/abs/1812.09755v1) - [pdf](http://arxiv.org/pdf/1812.09755v1)

> Learning when to communicate and doing that effectively is essential in multi-agent tasks. Recent works show that continuous communication allows efficient training with back-propagation in multi-agent scenarios, but have been restricted to fully-cooperative tasks. In this paper, we present Individualized Controlled Continuous Communication Model (IC3Net) which has better training efficiency than simple continuous communication model, and can be applied to semi-cooperative and competitive settings along with the cooperative settings. IC3Net controls continuous communication with a gating mechanism and uses individualized rewards foreach agent to gain better performance and scalability while fixing credit assignment issues. Using variety of tasks including StarCraft BroodWars explore and combat scenarios, we show that our network yields improved performance and convergence rates than the baselines as the scale increases. Our results convey that IC3Net agents learn when to communicate based on the scenario and profitability.

</details>

<details>

<summary>2018-12-23 22:42:59 - Talk the Walk: Navigating New York City through Grounded Dialogue</summary>

- *Harm de Vries, Kurt Shuster, Dhruv Batra, Devi Parikh, Jason Weston, Douwe Kiela*

- `1807.03367v3` - [abs](http://arxiv.org/abs/1807.03367v3) - [pdf](http://arxiv.org/pdf/1807.03367v3)

> We introduce "Talk The Walk", the first large-scale dialogue dataset grounded in action and perception. The task involves two agents (a "guide" and a "tourist") that communicate via natural language in order to achieve a common goal: having the tourist navigate to a given target location. The task and dataset, which are described in detail, are challenging and their full solution is an open problem that we pose to the community. We (i) focus on the task of tourist localization and develop the novel Masked Attention for Spatial Convolutions (MASC) mechanism that allows for grounding tourist utterances into the guide's map, (ii) show it yields significant improvements for both emergent and natural language communication, and (iii) using this method, we establish non-trivial baselines on the full task.

</details>

<details>

<summary>2018-12-23 23:16:54 - Deep Learning for Inferring the Surface Solar Irradiance from Sky Imagery</summary>

- *Mehdi Zakroum, Mounir Ghogho, Mustapha Faqir, Mohamed Aymane Ahajjam*

- `1812.09793v1` - [abs](http://arxiv.org/abs/1812.09793v1) - [pdf](http://arxiv.org/pdf/1812.09793v1)

> We present a novel approach to perform ground-based estimation and prediction of the surface solar irradiance with the view to predicting photovoltaic energy production. We propose the use of mini-batch k-means clustering to extract features, referred to as per cluster number of pixels (PCNP), from sky images taken by a low-cost fish eye camera. These features are first used to classify the sky as clear or cloudy using a single hidden layer neural network; the classification accuracy achieves 99.7%. If the sky is classified as cloudy, we propose to use a deep neural network having as input features the PCNP to predict intra-hour variability of the solar irradiance. Toward this objective, in this paper, we focus on estimating the deep neural network model relating the PCNP features and the solar irradiance, which is an important step before performing the prediction task. The proposed deep learning-based estimation approach is shown to have an accuracy of 95%.

</details>

<details>

<summary>2018-12-24 00:58:29 - On the loss landscape of a class of deep neural networks with no bad local valleys</summary>

- *Quynh Nguyen, Mahesh Chandra Mukkamala, Matthias Hein*

- `1809.10749v2` - [abs](http://arxiv.org/abs/1809.10749v2) - [pdf](http://arxiv.org/pdf/1809.10749v2)

> We identify a class of over-parameterized deep neural networks with standard activation functions and cross-entropy loss which provably have no bad local valley, in the sense that from any point in parameter space there exists a continuous path on which the cross-entropy loss is non-increasing and gets arbitrarily close to zero. This implies that these networks have no sub-optimal strict local minima.

</details>

<details>

<summary>2018-12-24 01:42:07 - Supervised Policy Update for Deep Reinforcement Learning</summary>

- *Quan Vuong, Yiming Zhang, Keith W. Ross*

- `1805.11706v4` - [abs](http://arxiv.org/abs/1805.11706v4) - [pdf](http://arxiv.org/pdf/1805.11706v4)

> We propose a new sample-efficient methodology, called Supervised Policy Update (SPU), for deep reinforcement learning. Starting with data generated by the current policy, SPU formulates and solves a constrained optimization problem in the non-parameterized proximal policy space. Using supervised regression, it then converts the optimal non-parameterized policy to a parameterized policy, from which it draws new samples. The methodology is general in that it applies to both discrete and continuous action spaces, and can handle a wide variety of proximity constraints for the non-parameterized optimization problem. We show how the Natural Policy Gradient and Trust Region Policy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization (PPO) problem can be addressed by this methodology. The SPU implementation is much simpler than TRPO. In terms of sample efficiency, our extensive experiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and outperforms PPO in Atari video game tasks.

</details>

<details>

<summary>2018-12-24 02:41:29 - Risk-Sensitive Generative Adversarial Imitation Learning</summary>

- *Jonathan Lacotte, Mohammad Ghavamzadeh, Yinlam Chow, Marco Pavone*

- `1808.04468v2` - [abs](http://arxiv.org/abs/1808.04468v2) - [pdf](http://arxiv.org/pdf/1808.04468v2)

> We study risk-sensitive imitation learning where the agent's goal is to perform at least as well as the expert in terms of a risk profile. We first formulate our risk-sensitive imitation learning setting. We consider the generative adversarial approach to imitation learning (GAIL) and derive an optimization problem for our formulation, which we call it risk-sensitive GAIL (RS-GAIL). We then derive two different versions of our RS-GAIL optimization problem that aim at matching the risk profiles of the agent and the expert w.r.t. Jensen-Shannon (JS) divergence and Wasserstein distance, and develop risk-sensitive generative adversarial imitation learning algorithms based on these optimization problems. We evaluate the performance of our algorithms and compare them with GAIL and the risk-averse imitation learning (RAIL) algorithms in two MuJoCo and two OpenAI classical control tasks.

</details>

<details>

<summary>2018-12-24 02:48:26 - A generalized concept-cognitive learning: A machine learning viewpoint</summary>

- *Yunlong Mi, Yong Shi, Jinhai Li*

- `1801.02334v3` - [abs](http://arxiv.org/abs/1801.02334v3) - [pdf](http://arxiv.org/pdf/1801.02334v3)

> Concept-cognitive learning (CCL) is a hot topic in recent years, and it has attracted much attention from the communities of formal concept analysis, granular computing and cognitive computing. However, the relationship among cognitive computing (CC), concept-cognitive computing (CCC), CCL and concept-cognitive learning model (CCLM) is not clearly described. To this end, we first explain the relationship of CC, CCC, CCL and CCLM. Then, we propose a generalized concept-cognitive learning (GCCL) from the point of view of machine learning. Finally, experiments on some data sets are conducted to verify the feasibility of concept formation and concept-cognitive process of GCCL.

</details>

<details>

<summary>2018-12-24 12:05:42 - PatientEG Dataset: Bringing Event Graph Model with Temporal Relations to Electronic Medical Records</summary>

- *Xuli Liu, Jihao Jin, Qi Wang, Tong Ruan, Yangming Zhou, Daqi Gao, Yichao Yin*

- `1812.09905v1` - [abs](http://arxiv.org/abs/1812.09905v1) - [pdf](http://arxiv.org/pdf/1812.09905v1)

> Medical activities, such as diagnoses, medicine treatments, and laboratory tests, as well as temporal relations between these activities are the basic concepts in clinical research. However, existing relational data model on electronic medical records (EMRs) lacks explicit and accurate semantic definitions of these concepts. It leads to the inconvenience of query construction and the inefficiency of query execution where multi-table join queries are frequently required. In this paper, we propose a patient event graph (PatientEG) model to capture the characteristics of EMRs. We respectively define five types of medical entities, five types of medical events and five types of temporal relations. Based on the proposed model, we also construct a PatientEG dataset with 191,294 events, 3,429 distinct entities, and 545,993 temporal relations using EMRs from Shanghai Shuguang hospital. To help to normalize entity values which contain synonyms, hyponymies, and abbreviations, we link them with the Chinese biomedical knowledge graph. With the help of PatientEG dataset, we are able to conveniently perform complex queries for clinical research such as auxiliary diagnosis and therapeutic effectiveness analysis. In addition, we provide a SPARQL endpoint to access PatientEG dataset and the dataset is also publicly available online. Also, we list several illustrative SPARQL queries on our website.

</details>

<details>

<summary>2018-12-24 19:25:23 - VMAV-C: A Deep Attention-based Reinforcement Learning Algorithm for Model-based Control</summary>

- *Xingxing Liang, Qi Wang, Yanghe Feng, Zhong Liu, Jincai Huang*

- `1812.09968v1` - [abs](http://arxiv.org/abs/1812.09968v1) - [pdf](http://arxiv.org/pdf/1812.09968v1)

> Recent breakthroughs in Go play and strategic games have witnessed the great potential of reinforcement learning in intelligently scheduling in uncertain environment, but some bottlenecks are also encountered when we generalize this paradigm to universal complex tasks. Among them, the low efficiency of data utilization in model-free reinforcement algorithms is of great concern. In contrast, the model-based reinforcement learning algorithms can reveal underlying dynamics in learning environments and seldom suffer the data utilization problem. To address the problem, a model-based reinforcement learning algorithm with attention mechanism embedded is proposed as an extension of World Models in this paper. We learn the environment model through Mixture Density Network Recurrent Network(MDN-RNN) for agents to interact, with combinations of variational auto-encoder(VAE) and attention incorporated in state value estimates during the process of learning policy. In this way, agent can learn optimal policies through less interactions with actual environment, and final experiments demonstrate the effectiveness of our model in control problem.

</details>

<details>

<summary>2018-12-25 04:08:27 - A Novel Framework for Robustness Analysis of Visual QA Models</summary>

- *Jia-Hong Huang, Cuong Duc Dao, Modar Alfadly, Bernard Ghanem*

- `1711.06232v3` - [abs](http://arxiv.org/abs/1711.06232v3) - [pdf](http://arxiv.org/pdf/1711.06232v3)

> Deep neural networks have been playing an essential role in many computer vision tasks including Visual Question Answering (VQA). Until recently, the study of their accuracy was the main focus of research but now there is a trend toward assessing the robustness of these models against adversarial attacks by evaluating their tolerance to varying noise levels. In VQA, adversarial attacks can target the image and/or the proposed main question and yet there is a lack of proper analysis of the later. In this work, we propose a flexible framework that focuses on the language part of VQA that uses semantically relevant questions, dubbed basic questions, acting as controllable noise to evaluate the robustness of VQA models. We hypothesize that the level of noise is positively correlated to the similarity of a basic question to the main question. Hence, to apply noise on any given main question, we rank a pool of basic questions based on their similarity by casting this ranking task as a LASSO optimization problem. Then, we propose a novel robustness measure, R_score, and two large-scale basic question datasets (BQDs) in order to standardize robustness analysis for VQA models.

</details>

<details>

<summary>2018-12-25 09:30:46 - Goal-based Course Recommendation</summary>

- *Weijie Jiang, Zachary A. Pardos, Qiang Wei*

- `1812.10078v1` - [abs](http://arxiv.org/abs/1812.10078v1) - [pdf](http://arxiv.org/pdf/1812.10078v1)

> With cross-disciplinary academic interests increasing and academic advising resources over capacity, the importance of exploring data-assisted methods to support student decision making has never been higher. We build on the findings and methodologies of a quickly developing literature around prediction and recommendation in higher education and develop a novel recurrent neural network-based recommendation system for suggesting courses to help students prepare for target courses of interest, personalized to their estimated prior knowledge background and zone of proximal development. We validate the model using tests of grade prediction and the ability to recover prerequisite relationships articulated by the university. In the third validation, we run the fully personalized recommendation for students the semester before taking a historically difficult course and observe differential overlap with our would-be suggestions. While not proof of causal effectiveness, these three evaluation perspectives on the performance of the goal-based model build confidence and bring us one step closer to deployment of this personalized course preparation affordance in the wild.

</details>

<details>

<summary>2018-12-25 10:13:53 - SOSA: A Lightweight Ontology for Sensors, Observations, Samples, and Actuators</summary>

- *Krzysztof Janowicz, Armin Haller, Simon J D Cox, Danh Le Phuoc, Maxime Lefrancois*

- `1805.09979v2` - [abs](http://arxiv.org/abs/1805.09979v2) - [pdf](http://arxiv.org/pdf/1805.09979v2)

> The Sensor, Observation, Sample, and Actuator (SOSA) ontology provides a formal but lightweight general-purpose specification for modeling the interaction between the entities involved in the acts of observation, actuation, and sampling. SOSA is the result of rethinking the W3C-XG Semantic Sensor Network (SSN) ontology based on changes in scope and target audience, technical developments, and lessons learned over the past years. SOSA also acts as a replacement of SSN's Stimulus Sensor Observation (SSO) core. It has been developed by the first joint working group of the Open Geospatial Consortium (OGC) and the World Wide Web Consortium (W3C) on \emph{Spatial Data on the Web}. In this work, we motivate the need for SOSA, provide an overview of the main classes and properties, and briefly discuss its integration with the new release of the SSN ontology as well as various other alignments to specifications such as OGC's Observations and Measurements (O\&M), Dolce-Ultralite (DUL), and other prominent ontologies. We will also touch upon common modeling problems and application areas related to publishing and searching observation, sampling, and actuation data on the Web. The SOSA ontology and standard can be accessed at \url{https://www.w3.org/TR/vocab-ssn/}.

</details>

<details>

<summary>2018-12-25 12:21:42 - Tensor-Train Long Short-Term Memory for Monaural Speech Enhancement</summary>

- *Suman Samui, Indrajit Chakrabarti, Soumya K. Ghosh*

- `1812.10095v1` - [abs](http://arxiv.org/abs/1812.10095v1) - [pdf](http://arxiv.org/pdf/1812.10095v1)

> In recent years, Long Short-Term Memory (LSTM) has become a popular choice for speech separation and speech enhancement task. The capability of LSTM network can be enhanced by widening and adding more layers. However, this would introduce millions of parameters in the network and also increase the requirement of computational resources. These limitations hinders the efficient implementation of RNN models in low-end devices such as mobile phones and embedded systems with limited memory. To overcome these issues, we proposed to use an efficient alternative approach of reducing parameters by representing the weight matrix parameters of LSTM based on Tensor-Train (TT) format. We called this Tensor-Train factorized LSTM as TT-LSTM model. Based on this TT-LSTM units, we proposed a deep TensorNet model for single-channel speech enhancement task. Experimental results in various test conditions and in terms of standard speech quality and intelligibility metrics, demonstrated that the proposed deep TT-LSTM based speech enhancement framework can achieve competitive performances with the state-of-the-art uncompressed RNN model, even though the proposed model architecture is orders of magnitude less complex.

</details>

<details>

<summary>2018-12-25 12:37:32 - Trip Prediction by Leveraging Trip Histories from Neighboring Users</summary>

- *Yuxin Chen, Morteza Haghir Chehreghani*

- `1812.10097v1` - [abs](http://arxiv.org/abs/1812.10097v1) - [pdf](http://arxiv.org/pdf/1812.10097v1)

> We propose a novel approach for trip prediction by analyzing user's trip histories. We augment users' (self-) trip histories by adding 'similar' trips from other users, which could be informative and useful for predicting future trips for a given user. This also helps to cope with noisy or sparse trip histories, where the self-history by itself does not provide a reliable prediction of future trips. We show empirical evidence that by enriching the users' trip histories with additional trips, one can improve the prediction error by 15%-40%, evaluated on multiple subsets of the Nancy2012 dataset. This real-world dataset is collected from public transportation ticket validations in the city of Nancy, France. Our prediction tool is a central component of a trip simulator system designed to analyze the functionality of public transportation in the city of Nancy.

</details>

<details>

<summary>2018-12-25 17:52:39 - Can rationality be measured?</summary>

- *Tshilidzi Marwala*

- `1812.10144v1` - [abs](http://arxiv.org/abs/1812.10144v1) - [pdf](http://arxiv.org/pdf/1812.10144v1)

> This paper studies whether rationality can be computed. Rationality is defined as the use of complete information, which is processed with a perfect biological or physical brain, in an optimized fashion. To compute rationality one needs to quantify how complete is the information, how perfect is the physical or biological brain and how optimized is the entire decision making system. The rationality of a model (i.e. physical or biological brain) is measured by the expected accuracy of the model. The rationality of the optimization procedure is measured as the ratio of the achieved objective (i.e. utility) to the global objective. The overall rationality of a decision is measured as the product of the rationality of the model and the rationality of the optimization procedure. The conclusion reached is that rationality can be computed for convex optimization problems.

</details>

<details>

<summary>2018-12-26 05:17:03 - Learning to Refine Source Representations for Neural Machine Translation</summary>

- *Xinwei Geng, Longyue Wang, Xing Wang, Bing Qin, Ting Liu, Zhaopeng Tu*

- `1812.10230v1` - [abs](http://arxiv.org/abs/1812.10230v1) - [pdf](http://arxiv.org/pdf/1812.10230v1)

> Neural machine translation (NMT) models generally adopt an encoder-decoder architecture for modeling the entire translation process. The encoder summarizes the representation of input sentence from scratch, which is potentially a problem if the sentence is ambiguous. When translating a text, humans often create an initial understanding of the source sentence and then incrementally refine it along the translation on the target side. Starting from this intuition, we propose a novel encoder-refiner-decoder framework, which dynamically refines the source representations based on the generated target-side information at each decoding step. Since the refining operations are time-consuming, we propose a strategy, leveraging the power of reinforcement learning models, to decide when to refine at specific decoding steps. Experimental results on both Chinese-English and English-German translation tasks show that the proposed approach significantly and consistently improves translation performance over the standard encoder-decoder framework. Furthermore, when refining strategy is applied, results still show reasonable improvement over the baseline without much decrease in decoding speed.

</details>

<details>

<summary>2018-12-26 05:55:42 - A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling</summary>

- *Yu Wang, Yilin Shen, Hongxia Jin*

- `1812.10235v1` - [abs](http://arxiv.org/abs/1812.10235v1) - [pdf](http://arxiv.org/pdf/1812.10235v1)

> Intent detection and slot filling are two main tasks for building a spoken language understanding(SLU) system. Multiple deep learning based models have demonstrated good results on these tasks . The most effective algorithms are based on the structures of sequence to sequence models (or "encoder-decoder" models), and generate the intents and semantic tags either using separate models or a joint model. Most of the previous studies, however, either treat the intent detection and slot filling as two separate parallel tasks, or use a sequence to sequence model to generate both semantic tags and intent. Most of these approaches use one (joint) NN based model (including encoder-decoder structure) to model two tasks, hence may not fully take advantage of the cross-impact between them. In this paper, new Bi-model based RNN semantic frame parsing network structures are designed to perform the intent detection and slot filling tasks jointly, by considering their cross-impact to each other using two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a decoder achieves state-of-the-art result on the benchmark ATIS data, with about 0.5$\%$ intent accuracy improvement and 0.9 $\%$ slot filling improvement.

</details>

<details>

<summary>2018-12-26 11:09:40 - Reward Constrained Policy Optimization</summary>

- *Chen Tessler, Daniel J. Mankowitz, Shie Mannor*

- `1805.11074v3` - [abs](http://arxiv.org/abs/1805.11074v3) - [pdf](http://arxiv.org/pdf/1805.11074v3)

> Solving tasks in Reinforcement Learning is no easy feat. As the goal of the agent is to maximize the accumulated reward, it often learns to exploit loopholes and misspecifications in the reward signal resulting in unwanted behavior. While constraints may solve this issue, there is no closed form solution for general constraints. In this work we present a novel multi-timescale approach for constrained policy optimization, called `Reward Constrained Policy Optimization' (RCPO), which uses an alternative penalty signal to guide the policy towards a constraint satisfying one. We prove the convergence of our approach and provide empirical evidence of its ability to train constraint satisfying policies.

</details>

<details>

<summary>2018-12-26 14:55:57 - Nearly-tight bounds on linear regions of piecewise linear neural networks</summary>

- *Qiang Hu, Hao Zhang*

- `1810.13192v4` - [abs](http://arxiv.org/abs/1810.13192v4) - [pdf](http://arxiv.org/pdf/1810.13192v4)

> The developments of deep neural networks (DNN) in recent years have ushered a brand new era of artificial intelligence. DNNs are proved to be excellent in solving very complex problems, e.g., visual recognition and text understanding, to the extent of competing with or even surpassing people. Despite inspiring and encouraging success of DNNs, thorough theoretical analyses still lack to unravel the mystery of their magics. The design of DNN structure is dominated by empirical results in terms of network depth, number of neurons and activations. A few of remarkable works published recently in an attempt to interpret DNNs have established the first glimpses of their internal mechanisms. Nevertheless, research on exploring how DNNs operate is still at the initial stage with plenty of room for refinement. In this paper, we extend precedent research on neural networks with piecewise linear activations (PLNN) concerning linear regions bounds. We present (i) the exact maximal number of linear regions for single layer PLNNs; (ii) a upper bound for multi-layer PLNNs; and (iii) a tighter upper bound for the maximal number of liner regions on rectifier networks. The derived bounds also indirectly explain why deep models are more powerful than shallow counterparts, and how non-linearity of activation functions impacts on expressiveness of networks.

</details>

<details>

<summary>2018-12-26 16:12:30 - Informative Object Annotations: Tell Me Something I Don't Know</summary>

- *Lior Bracha, Gal Chechik*

- `1812.10358v1` - [abs](http://arxiv.org/abs/1812.10358v1) - [pdf](http://arxiv.org/pdf/1812.10358v1)

> Capturing the interesting components of an image is a key aspect of image understanding. When a speaker annotates an image, selecting labels that are informative greatly depends on the prior knowledge of a prospective listener. Motivated by cognitive theories of categorization and communication, we present a new unsupervised approach to model this prior knowledge and quantify the informativeness of a description. Specifically, we compute how knowledge of a label reduces uncertainty over the space of labels and utilize this to rank candidate labels for describing an image. While the full estimation problem is intractable, we describe an efficient algorithm to approximate entropy reduction using a tree-structured graphical model. We evaluate our approach on the open-images dataset using a new evaluation set of 10K ground-truth ratings and find that it achieves ~65% agreement with human raters, largely outperforming other unsupervised baseline approaches.

</details>

<details>

<summary>2018-12-26 18:38:28 - Using an Ancillary Neural Network to Capture Weekends and Holidays in an Adjoint Neural Network Architecture for Intelligent Building Management</summary>

- *Zhicheng Ding, Mehmet Kerem Turkcan, Albert Boulanger*

- `1902.06778v1` - [abs](http://arxiv.org/abs/1902.06778v1) - [pdf](http://arxiv.org/pdf/1902.06778v1)

> The US EIA estimated in 2017 about 39\% of total U.S. energy consumption was by the residential and commercial sectors. Therefore, Intelligent Building Management (IBM) solutions that minimize consumption while maintaining tenant comfort are an important component in addressing climate change. A forecasting capability for accurate prediction of indoor temperatures in a planning horizon of 24 hours is essential to IBM. It should predict the indoor temperature in both short-term (e.g. 15 minutes) and long-term (e.g. 24 hours) periods accurately including weekends, major holidays, and minor holidays. Other requirements include the ability to predict the maximum and the minimum indoor temperatures precisely and provide the confidence for each prediction. To achieve these requirements, we propose a novel adjoint neural network architecture for time series prediction that uses an ancillary neural network to capture weekend and holiday information. We studied four long short-term memory (LSTM) based time series prediction networks within this architecture. We observed that the ancillary neural network helps to improve the prediction accuracy, the maximum and the minimum temperature prediction and model reliability for all networks tested.

</details>

<details>

<summary>2018-12-26 20:15:08 - On Evaluating and Comparing Open Domain Dialog Systems</summary>

- *Anu Venkatesh, Chandra Khatri, Ashwin Ram, Fenfei Guo, Raefer Gabriel, Ashish Nagar, Rohit Prasad, Ming Cheng, Behnam Hedayatnia, Angeliki Metallinou, Rahul Goel, Shaohua Yang, Anirudh Raju*

- `1801.03625v2` - [abs](http://arxiv.org/abs/1801.03625v2) - [pdf](http://arxiv.org/pdf/1801.03625v2)

> Conversational agents are exploding in popularity. However, much work remains in the area of non goal-oriented conversations, despite significant growth in research interest over recent years. To advance the state of the art in conversational AI, Amazon launched the Alexa Prize, a 2.5-million dollar university competition where sixteen selected university teams built conversational agents to deliver the best social conversational experience. Alexa Prize provided the academic community with the unique opportunity to perform research with a live system used by millions of users. The subjectivity associated with evaluating conversations is key element underlying the challenge of building non-goal oriented dialogue systems. In this paper, we propose a comprehensive evaluation strategy with multiple metrics designed to reduce subjectivity by selecting metrics which correlate well with human judgement. The proposed metrics provide granular analysis of the conversational agents, which is not captured in human ratings. We show that these metrics can be used as a reasonable proxy for human judgment. We provide a mechanism to unify the metrics for selecting the top performing agents, which has also been applied throughout the Alexa Prize competition. To our knowledge, to date it is the largest setting for evaluating agents with millions of conversations and hundreds of thousands of ratings from users. We believe that this work is a step towards an automatic evaluation process for conversational AIs.

</details>

<details>

<summary>2018-12-26 20:34:17 - Toward a self-learned Smart Contracts</summary>

- *Ahmed S. Almasoud, Maged M. Eljazzar, Farookh Hussain*

- `1812.10485v1` - [abs](http://arxiv.org/abs/1812.10485v1) - [pdf](http://arxiv.org/pdf/1812.10485v1)

> In recent years, Blockchain technology has been highly valued and disruptive. Several researches have presented a merge between blockchain and current application i.e. medical, supply chain, and e-commerce. Although Blockchain architecture does not have a standard yet, IBM, MS, AWS offer BaaS (Blockchain as a Service). In addition to the current public chains i.e. Ethereum, NEO, and Cardeno; there are some differences between several public ledgers in terms of development and architecture. This paper introduces the main factors that affect integration of Artificial Intelligence with Blockchain. As well as, how it could be integrated for forecasting and automating; building self-regulated chain.

</details>

<details>

<summary>2018-12-27 00:00:49 - Towards effective AI-powered agile project management</summary>

- *Hoa Khanh Dam, Truyen Tran, John Grundy, Aditya Ghose, Yasutaka Kamei*

- `1812.10578v1` - [abs](http://arxiv.org/abs/1812.10578v1) - [pdf](http://arxiv.org/pdf/1812.10578v1)

> The rise of Artificial intelligence (AI) has the potential to significantly transform the practice of project management. Project management has a large socio-technical element with many uncertainties arising from variability in human aspects e.g., customers' needs, developers' performance and team dynamics. AI can assist project managers and team members by automating repetitive, high-volume tasks to enable project analytics for estimation and risk prediction, providing actionable recommendations, and even making decisions. AI is potentially a game changer for project management in helping to accelerate productivity and increase project success rates. In this paper, we propose a framework where AI technologies can be leveraged to offer support for managing agile projects, which have become increasingly popular in the industry.

</details>

<details>

<summary>2018-12-27 01:34:08 - Learning Dynamic Generator Model by Alternating Back-Propagation Through Time</summary>

- *Jianwen Xie, Ruiqi Gao, Zilong Zheng, Song-Chun Zhu, Ying Nian Wu*

- `1812.10587v1` - [abs](http://arxiv.org/abs/1812.10587v1) - [pdf](http://arxiv.org/pdf/1812.10587v1)

> This paper studies the dynamic generator model for spatial-temporal processes such as dynamic textures and action sequences in video data. In this model, each time frame of the video sequence is generated by a generator model, which is a non-linear transformation of a latent state vector, where the non-linear transformation is parametrized by a top-down neural network. The sequence of latent state vectors follows a non-linear auto-regressive model, where the state vector of the next frame is a non-linear transformation of the state vector of the current frame as well as an independent noise vector that provides randomness in the transition. The non-linear transformation of this transition model can be parametrized by a feedforward neural network. We show that this model can be learned by an alternating back-propagation through time algorithm that iteratively samples the noise vectors and updates the parameters in the transition model and the generator model. We show that our training method can learn realistic models for dynamic textures and action patterns.

</details>

<details>

<summary>2018-12-27 03:31:33 - Double Neural Counterfactual Regret Minimization</summary>

- *Hui Li, Kailiang Hu, Zhibang Ge, Tao Jiang, Yuan Qi, Le Song*

- `1812.10607v1` - [abs](http://arxiv.org/abs/1812.10607v1) - [pdf](http://arxiv.org/pdf/1812.10607v1)

> Counterfactual Regret Minimization (CRF) is a fundamental and effective technique for solving Imperfect Information Games (IIG). However, the original CRF algorithm only works for discrete state and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games and continuing to improve from a poor strategy profile. In this paper, we propose a double neural representation for the imperfect information games, where one neural network represents the cumulative regret, and the other represents the average strategy. Furthermore, we adopt the counterfactual regret minimization algorithm to optimize this double neural representation. To make neural learning efficient, we also developed several novel techniques including a robust sampling method, mini-batch Monte Carlo Counterfactual Regret Minimization (MCCFR) and Monte Carlo Counterfactual Regret Minimization Plus (MCCFR+) which may be of independent interests. Experimentally, we demonstrate that the proposed double neural algorithm converges significantly better than the reinforcement learning counterpart.

</details>

<details>

<summary>2018-12-27 09:29:31 - TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game</summary>

- *Peng Sun, Xinghai Sun, Lei Han, Jiechao Xiong, Qing Wang, Bo Li, Yang Zheng, Ji Liu, Yongsheng Liu, Han Liu, Tong Zhang*

- `1809.07193v3` - [abs](http://arxiv.org/abs/1809.07193v3) - [pdf](http://arxiv.org/pdf/1809.07193v3)

> Starcraft II (SC2) is widely considered as the most challenging Real Time Strategy (RTS) game. The underlying challenges include a large observation space, a huge (continuous and infinite) action space, partial observations, simultaneous move for all players, and long horizon delayed rewards for local decisions. To push the frontier of AI research, Deepmind and Blizzard jointly developed the StarCraft II Learning Environment (SC2LE) as a testbench of complex decision making systems. SC2LE provides a few mini games such as MoveToBeacon, CollectMineralShards, and DefeatRoaches, where some AI agents have achieved the performance level of human professional players. However, for full games, the current AI agents are still far from achieving human professional level performance. To bridge this gap, we present two full game AI agents in this paper - the AI agent TStarBot1 is based on deep reinforcement learning over a flat action structure, and the AI agent TStarBot2 is based on hard-coded rules over a hierarchical action structure. Both TStarBot1 and TStarBot2 are able to defeat the built-in AI agents from level 1 to level 10 in a full game (1v1 Zerg-vs-Zerg game on the AbyssalReef map), noting that level 8, level 9, and level 10 are cheating agents with unfair advantages such as full vision on the whole map and resource harvest boosting. To the best of our knowledge, this is the first public work to investigate AI agents that can defeat the built-in AI in the StarCraft II full game.

</details>

<details>

<summary>2018-12-27 10:29:47 - KI, Philosophie, Logik</summary>

- *Karl Schlechta*

- `1901.00365v1` - [abs](http://arxiv.org/abs/1901.00365v1) - [pdf](http://arxiv.org/pdf/1901.00365v1)

> This is a short (and personal) introduction in German to the connections between artificial intelligence, philosophy, and logic, and to the author's work.   Dies ist eine kurze (und persoenliche) Einfuehrung in die Zusammenhaenge zwischen Kuenstlicher Intelligenz, Philosophie, und Logik, und in die Arbeiten des Autors.

</details>

<details>

<summary>2018-12-27 10:36:26 - Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty</summary>

- *Rowan McAllister, Gregory Kahn, Jeff Clune, Sergey Levine*

- `1812.10687v1` - [abs](http://arxiv.org/abs/1812.10687v1) - [pdf](http://arxiv.org/pdf/1812.10687v1)

> Deep learning provides a powerful tool for machine perception when the observations resemble the training data. However, real-world robotic systems must react intelligently to their observations even in unexpected circumstances. This requires a system to reason about its own uncertainty given unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but can struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density. However, the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty to cope with uncertainty stemming from out-of-distribution states. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit (generative) model of the observation distribution to handle out-of-distribution inputs. This is accomplished by probabilistically projecting observations onto the training distribution, such that out-of-distribution inputs map to uncertain in-distribution observations, which in turn produce uncertain task-related predictions, but only if task-relevant parts of the image change. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our method of projecting out-of-distribution observations improves the performance of four standard Bayesian and non-Bayesian neural network approaches, offering more favorable trade-offs between the proportion of time a robot can remain autonomous and the proportion of impending crashes successfully avoided.

</details>

<details>

<summary>2018-12-27 11:49:55 - Edge Intelligence: On-Demand Deep Learning Model Co-Inference with Device-Edge Synergy</summary>

- *En Li, Zhi Zhou, Xu Chen*

- `1806.07840v4` - [abs](http://arxiv.org/abs/1806.07840v4) - [pdf](http://arxiv.org/pdf/1806.07840v4)

> As the backbone technology of machine learning, deep neural networks (DNNs) have have quickly ascended to the spotlight. Running DNNs on resource-constrained mobile devices is, however, by no means trivial, since it incurs high performance and energy overhead. While offloading DNNs to the cloud for execution suffers unpredictable performance, due to the uncontrolled long wide-area network latency. To address these challenges, in this paper, we propose Edgent, a collaborative and on-demand DNN co-inference framework with device-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that adaptively partitions DNN computation between device and edge, in order to leverage hybrid computation resources in proximity for real-time DNN inference. (2) DNN right-sizing that accelerates DNN inference through early-exit at a proper intermediate DNN layer to further reduce the computation latency. The prototype implementation and extensive evaluations based on Raspberry Pi demonstrate Edgent's effectiveness in enabling on-demand low-latency edge intelligence.

</details>

<details>

<summary>2018-12-27 16:17:30 - Advancing the State of the Art in Open Domain Dialog Systems through the Alexa Prize</summary>

- *Chandra Khatri, Behnam Hedayatnia, Anu Venkatesh, Jeff Nunn, Yi Pan, Qing Liu, Han Song, Anna Gottardi, Sanjeev Kwatra, Sanju Pancholi, Ming Cheng, Qinglang Chen, Lauren Stubel, Karthik Gopalakrishnan, Kate Bland, Raefer Gabriel, Arindam Mandal, Dilek Hakkani-Tur, Gene Hwang, Nate Michel, Eric King, Rohit Prasad*

- `1812.10757v1` - [abs](http://arxiv.org/abs/1812.10757v1) - [pdf](http://arxiv.org/pdf/1812.10757v1)

> Building open domain conversational systems that allow users to have engaging conversations on topics of their choice is a challenging task. Alexa Prize was launched in 2016 to tackle the problem of achieving natural, sustained, coherent and engaging open-domain dialogs. In the second iteration of the competition in 2018, university teams advanced the state of the art by using context in dialog models, leveraging knowledge graphs for language understanding, handling complex utterances, building statistical and hierarchical dialog managers, and leveraging model-driven signals from user responses. The 2018 competition also included the provision of a suite of tools and models to the competitors including the CoBot (conversational bot) toolkit, topic and dialog act detection models, conversation evaluators, and a sensitive content detection model so that the competing teams could focus on building knowledge-rich, coherent and engaging multi-turn dialog systems. This paper outlines the advances developed by the university teams as well as the Alexa Prize team to achieve the common goal of advancing the science of Conversational AI. We address several key open-ended problems such as conversational speech recognition, open domain natural language understanding, commonsense reasoning, statistical dialog management, and dialog evaluation. These collaborative efforts have driven improved experiences by Alexa users to an average rating of 3.61, the median duration of 2 mins 18 seconds, and average turns to 14.6, increases of 14%, 92%, 54% respectively since the launch of the 2018 competition. For conversational speech recognition, we have improved our relative Word Error Rate by 55% and our relative Entity Error Rate by 34% since the launch of the Alexa Prize. Socialbots improved in quality significantly more rapidly in 2018, in part due to the release of the CoBot toolkit.

</details>

<details>

<summary>2018-12-27 18:57:43 - Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks</summary>

- *Difan Zou, Yuan Cao, Dongruo Zhou, Quanquan Gu*

- `1811.08888v3` - [abs](http://arxiv.org/abs/1811.08888v3) - [pdf](http://arxiv.org/pdf/1811.08888v3)

> We study the problem of training deep neural networks with Rectified Linear Unit (ReLU) activation function using gradient descent and stochastic gradient descent. In particular, we study the binary classification problem and show that for a broad family of loss functions, with proper random weight initialization, both gradient descent and stochastic gradient descent can find the global minima of the training loss for an over-parameterized deep ReLU network, under mild assumption on the training data. The key idea of our proof is that Gaussian random initialization followed by (stochastic) gradient descent produces a sequence of iterates that stay inside a small perturbation region centering around the initial weights, in which the empirical loss function of deep ReLU networks enjoys nice local curvature properties that ensure the global convergence of (stochastic) gradient descent. Our theoretical results shed light on understanding the optimization for deep learning, and pave the way for studying the optimization dynamics of training modern deep neural networks.

</details>

<details>

<summary>2018-12-27 19:25:22 - Variational Inference of Disentangled Latent Concepts from Unlabeled Observations</summary>

- *Abhishek Kumar, Prasanna Sattigeri, Avinash Balakrishnan*

- `1711.00848v3` - [abs](http://arxiv.org/abs/1711.00848v3) - [pdf](http://arxiv.org/pdf/1711.00848v3)

> Disentangled representations, where the higher level data generative factors are reflected in disjoint latent dimensions, offer several benefits such as ease of deriving invariant representations, transferability to other tasks, interpretability, etc. We consider the problem of unsupervised learning of disentangled representations from large pool of unlabeled observations, and propose a variational inference based approach to infer disentangled latent factors. We introduce a regularizer on the expectation of the approximate posterior over observed data that encourages the disentanglement. We also propose a new disentanglement metric which is better aligned with the qualitative disentanglement observed in the decoder's output. We empirically observe significant improvement over existing methods in terms of both disentanglement and data likelihood (reconstruction quality).

</details>

<details>

<summary>2018-12-28 00:36:29 - A Summary of Adaptation of Techniques from Search-based Optimal Multi-Agent Path Finding Solvers to Compilation-based Approach</summary>

- *Pavel Surynek*

- `1812.10851v1` - [abs](http://arxiv.org/abs/1812.10851v1) - [pdf](http://arxiv.org/pdf/1812.10851v1)

> In the multi-agent path finding problem (MAPF) we are given a set of agents each with respective start and goal positions. The task is to find paths for all agents while avoiding collisions aiming to minimize an objective function. Two such common objective functions is the sum-of-costs and the makespan. Many optimal solvers were introduced in the past decade - two prominent categories of solvers can be distinguished: search-based solvers and compilation-based solvers.   Search-based solvers were developed and tested for the sum-of-costs objective while the most prominent compilation-based solvers that are built around Boolean satisfiability (SAT) were designed for the makespan objective. Very little was known on the performance and relevance of the compilation-based approach on the sum-of-costs objective. In this paper we show how to close the gap between these cost functions in the compilation-based approach. Moreover we study applicability of various techniques developed for search-based solvers in the compilation-based approach.   A part of this paper introduces a SAT-solver that is directly aimed to solve the sum-of-costs objective function. Using both a lower bound on the sum-of-costs and an upper bound on the makespan, we are able to have a reasonable number of variables in our SAT encoding. We then further improve the encoding by borrowing ideas from ICTS, a search-based solver. Experimental evaluation on several domains show that there are many scenarios where our new SAT-based methods outperforms the best variants of previous sum-of-costs search solvers - the ICTS, CBS algorithms, and ICBS algorithms.

</details>

<details>

<summary>2018-12-28 02:05:11 - Hierarchical Block Sparse Neural Networks</summary>

- *Dharma Teja Vooturi, Dheevatsa Mudigere, Sasikanth Avancha*

- `1808.03420v2` - [abs](http://arxiv.org/abs/1808.03420v2) - [pdf](http://arxiv.org/pdf/1808.03420v2)

> Sparse deep neural networks(DNNs) are efficient in both memory and compute when compared to dense DNNs. But due to irregularity in computation of sparse DNNs, their efficiencies are much lower than that of dense DNNs on regular parallel hardware such as TPU. This inefficiency leads to poor/no performance benefits for sparse DNNs. Performance issue for sparse DNNs can be alleviated by bringing structure to the sparsity and leveraging it for improving runtime efficiency. But such structural constraints often lead to suboptimal accuracies. In this work, we jointly address both accuracy and performance of sparse DNNs using our proposed class of sparse neural networks called HBsNN (Hierarchical Block sparse Neural Networks). For a given sparsity, HBsNN models achieve better runtime performance than unstructured sparse models and better accuracy than highly structured sparse models.

</details>

<details>

<summary>2018-12-28 06:11:56 - Open-endedness in AI systems, cellular evolution and intellectual discussions</summary>

- *Kushal Shah*

- `1812.10900v1` - [abs](http://arxiv.org/abs/1812.10900v1) - [pdf](http://arxiv.org/pdf/1812.10900v1)

> One of the biggest challenges that artificial intelligence (AI) research is facing in recent times is to develop algorithms and systems that are not only good at performing a specific intelligent task but also good at learning a very diverse of skills somewhat like humans do. In other words, the goal is to be able to mimic biological evolution which has produced all the living species on this planet and which seems to have no end to its creativity. The process of intellectual discussions is also somewhat similar to biological evolution in this regard and is responsible for many of the innovative discoveries and inventions that scientists and engineers have made in the past. In this paper, we present an information theoretic analogy between the process of discussions and the molecular dynamics within a cell, showing that there is a common process of information exchange at the heart of these two seemingly different processes, which can perhaps help us in building AI systems capable of open-ended innovation. We also discuss the role of consciousness in this process and present a framework for the development of open-ended AI systems.

</details>

<details>

<summary>2018-12-28 08:51:17 - SupportNet: solving catastrophic forgetting in class incremental learning with support data</summary>

- *Yu Li, Zhongxiao Li, Lizhong Ding, Yijie Pan, Chao Huang, Yuhui Hu, Wei Chen, Xin Gao*

- `1806.02942v3` - [abs](http://arxiv.org/abs/1806.02942v3) - [pdf](http://arxiv.org/pdf/1806.02942v3)

> A plain well-trained deep learning model often does not have the ability to learn new knowledge without forgetting the previously learned knowledge, which is known as catastrophic forgetting. Here we propose a novel method, SupportNet, to efficiently and effectively solve the catastrophic forgetting problem in the class incremental learning scenario. SupportNet combines the strength of deep learning and support vector machine (SVM), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training so that the model can review the essential information of the old data when learning the new information. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. We validate our method with comprehensive experiments on various tasks, which show that SupportNet drastically outperforms the state-of-the-art incremental learning methods and even reaches similar performance as the deep learning model trained from scratch on both old and new data. Our program is accessible at: https://github.com/lykaust15/SupportNet

</details>

<details>

<summary>2018-12-28 09:22:44 - An Attention-Gated Convolutional Neural Network for Sentence Classification</summary>

- *Yang Liu, Lixin Ji, Ruiyang Huang, Tuosiyu Ming, Chao Gao, Jianpeng Zhang*

- `1808.07325v3` - [abs](http://arxiv.org/abs/1808.07325v3) - [pdf](http://arxiv.org/pdf/1808.07325v3)

> The classification of sentences is very challenging, since sentences contain the limited contextual information. In this paper, we proposed an Attention-Gated Convolutional Neural Network (AGCNN) for sentence classification, which generates attention weights from the feature's context windows of different sizes by using specialized convolution encoders. It makes full use of limited contextual information to extract and enhance the influence of important features in predicting the sentence's category. Experimental results demonstrated that our model can achieve up to 3.1% higher accuracy than standard CNN models, and gain competitive results over the baselines on four out of the six tasks. Besides, we designed an activation function, namely, Natural Logarithm rescaled Rectified Linear Unit (NLReLU). Experiments showed that NLReLU can outperform ReLU and is comparable to other well-known activation functions on AGCNN.

</details>

<details>

<summary>2018-12-28 11:51:14 - A Precedent Approach to Assigning Access Rights</summary>

- *S. V. Belim, N. F. Bogachenko, A. N. Kabanov*

- `1812.10961v1` - [abs](http://arxiv.org/abs/1812.10961v1) - [pdf](http://arxiv.org/pdf/1812.10961v1)

> To design a discretionary access control policy, a technique is proposed that uses the principle of analogies and is based on both the properties of objects and the properties of subjects. As attributes characterizing these properties, the values of the security attributes of subjects and objects are chosen. The concept of precedent is defined as an access rule explicitly specified by the security administrator. The problem of interpolation of the access matrix is formulated: the security administrator defines a sequence of precedents, it is required to automate the process of filling the remaining cells of the access matrix. On the family of sets of security attributes, a linear order is introduced. The principles of filling the access matrix on the basis of analogy with the dominant precedent in accordance with a given order relation are developed. The analysis of the proposed methodology is performed and its main advantages are revealed.

</details>

<details>

<summary>2018-12-28 15:12:58 - Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features</summary>

- *Matteo Pagliardini, Prakhar Gupta, Martin Jaggi*

- `1703.02507v3` - [abs](http://arxiv.org/abs/1703.02507v3) - [pdf](http://arxiv.org/pdf/1703.02507v3)

> The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.

</details>

<details>

<summary>2018-12-28 15:54:54 - Visualizing the Feature Importance for Black Box Models</summary>

- *Giuseppe Casalicchio, Christoph Molnar, Bernd Bischl*

- `1804.06620v3` - [abs](http://arxiv.org/abs/1804.06620v3) - [pdf](http://arxiv.org/pdf/1804.06620v3)

> In recent years, a large amount of model-agnostic methods to improve the transparency, trustability and interpretability of machine learning models have been developed. We introduce local feature importance as a local version of a recent model-agnostic global feature importance method. Based on local feature importance, we propose two visual tools: partial importance (PI) and individual conditional importance (ICI) plots which visualize how changes in a feature affect the model performance on average, as well as for individual observations. Our proposed methods are related to partial dependence (PD) and individual conditional expectation (ICE) plots, but visualize the expected (conditional) feature importance instead of the expected (conditional) prediction. Furthermore, we show that averaging ICI curves across observations yields a PI curve, and integrating the PI curve with respect to the distribution of the considered feature results in the global feature importance. Another contribution of our paper is the Shapley feature importance, which fairly distributes the overall performance of a model among the features according to the marginal contributions and which can be used to compare the feature importance across different models.

</details>

<details>

<summary>2018-12-28 18:11:12 - The Diagrammatic AI Language (DIAL): Version 0.1</summary>

- *Guy Marshall, André Freitas*

- `1812.11142v1` - [abs](http://arxiv.org/abs/1812.11142v1) - [pdf](http://arxiv.org/pdf/1812.11142v1)

> Currently, there is no consistent model for visually or formally representing the architecture of AI systems. This lack of representation brings interpretability, correctness and completeness challenges in the description of existing models and systems. DIAL (The Diagrammatic AI Language) has been created with the aspiration of being an "engineering schematic" for AI Systems. It is presented here as a starting point for a community dialogue towards a common diagrammatic language for AI Systems.

</details>

<details>

<summary>2018-12-28 18:44:49 - MEETING BOT: Reinforcement Learning for Dialogue Based Meeting Scheduling</summary>

- *Vishwanath D, Lovekesh Vig, Gautam Shroff, Puneet Agarwal*

- `1812.11158v1` - [abs](http://arxiv.org/abs/1812.11158v1) - [pdf](http://arxiv.org/pdf/1812.11158v1)

> In this paper we present Meeting Bot, a reinforcement learning based conversational system that interacts with multiple users to schedule meetings. The system is able to interpret user utterences and map them to preferred time slots, which are then fed to a reinforcement learning (RL) system with the goal of converging on an agreeable time slot. The RL system is able to adapt to user preferences and environmental changes in meeting arrival rate while still scheduling effectively. Learning is performed via policy gradient with exploration, by utilizing an MLP as an approximator of the policy function. Results demonstrate that the system outperforms standard scheduling algorithms in terms of overall scheduling efficiency. Additionally, the system is able to adapt its strategy to situations when users consistently reject or accept meetings in certain slots (such as Friday afternoon versus Thursday morning), or when the meeting is called by members who are at a more senior designation.

</details>

<details>

<summary>2018-12-28 18:52:50 - Learning to Reconstruct Shapes from Unseen Classes</summary>

- *Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Joshua B. Tenenbaum, William T. Freeman, Jiajun Wu*

- `1812.11166v1` - [abs](http://arxiv.org/abs/1812.11166v1) - [pdf](http://arxiv.org/pdf/1812.11166v1)

> From a single image, humans are able to perceive the full 3D shape of an object by exploiting learned shape priors from everyday life. Contemporary single-image 3D reconstruction algorithms aim to solve this task in a similar fashion, but often end up with priors that are highly biased by training classes. Here we present an algorithm, Generalizable Reconstruction (GenRe), designed to capture more generic, class-agnostic shape priors. We achieve this with an inference network and training procedure that combine 2.5D representations of visible surfaces (depth and silhouette), spherical shape representations of both visible and non-visible surfaces, and 3D voxel-based representations, in a principled manner that exploits the causal structure of how 3D shapes give rise to 2D images. Experiments demonstrate that GenRe performs well on single-view shape reconstruction, and generalizes to diverse novel objects from categories not seen during training.

</details>

<details>

<summary>2018-12-28 18:56:32 - Towards Neural Co-Processors for the Brain: Combining Decoding and Encoding in Brain-Computer Interfaces</summary>

- *Rajesh P. N. Rao*

- `1811.11876v2` - [abs](http://arxiv.org/abs/1811.11876v2) - [pdf](http://arxiv.org/pdf/1811.11876v2)

> The field of brain-computer interfaces is poised to advance from the traditional goal of controlling prosthetic devices using brain signals to combining neural decoding and encoding within a single neuroprosthetic device. Such a device acts as a "co-processor" for the brain, with applications ranging from inducing Hebbian plasticity for rehabilitation after brain injury to reanimating paralyzed limbs and enhancing memory. We review recent progress in simultaneous decoding and encoding for closed-loop control and plasticity induction. To address the challenge of multi-channel decoding and encoding, we introduce a unifying framework for developing brain co-processors based on artificial neural networks and deep learning. These "neural co-processors" can be used to jointly optimize cost functions with the nervous system to achieve desired behaviors ranging from targeted neuro-rehabilitation to augmentation of brain function.

</details>

<details>

<summary>2018-12-28 20:53:26 - GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization</summary>

- *Hung-I Harry Chen, Yu-Chiao Chiu, Tinghe Zhang, Songyao Zhang, Yufei Huang, Yidong Chen*

- `1805.07874v2` - [abs](http://arxiv.org/abs/1805.07874v2) - [pdf](http://arxiv.org/pdf/1805.07874v2)

> Bioinformatics tools have been developed to interpret gene expression data at the gene set level, and these gene set based analyses improve the biologists' capability to discover functional relevance of their experiment design. While elucidating gene set individually, inter gene sets association is rarely taken into consideration. Deep learning, an emerging machine learning technique in computational biology, can be used to generate an unbiased combination of gene set, and to determine the biological relevance and analysis consistency of these combining gene sets by leveraging large genomic data sets. In this study, we proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model with the incorporation of a priori defined gene sets that retain the crucial biological features in the latent layer. We introduced the concept of the gene superset, an unbiased combination of gene sets with weights trained by the autoencoder, where each node in the latent layer is a superset. Trained with genomic data from TCGA and evaluated with their accompanying clinical parameters, we showed gene supersets' ability of discriminating tumor subtypes and their prognostic capability. We further demonstrated the biological relevance of the top component gene sets in the significant supersets. Using autoencoder model and gene superset at its latent layer, we demonstrated that gene supersets retain sufficient biological information with respect to tumor subtypes and clinical prognostic significance. Superset also provides high reproducibility on survival analysis and accurate prediction for cancer subtypes.

</details>

<details>

<summary>2018-12-28 23:20:23 - On the Interaction Effects Between Prediction and Clustering</summary>

- *Matt Barnes, Artur Dubrawski*

- `1807.06713v2` - [abs](http://arxiv.org/abs/1807.06713v2) - [pdf](http://arxiv.org/pdf/1807.06713v2)

> Machine learning systems increasingly depend on pipelines of multiple algorithms to provide high quality and well structured predictions. This paper argues interaction effects between clustering and prediction (e.g. classification, regression) algorithms can cause subtle adverse behaviors during cross-validation that may not be initially apparent. In particular, we focus on the problem of estimating the out-of-cluster (OOC) prediction loss given an approximate clustering with probabilistic error rate $p_0$. Traditional cross-validation techniques exhibit significant empirical bias in this setting, and the few attempts to estimate and correct for these effects are intractable on larger datasets. Further, no previous work has been able to characterize the conditions under which these empirical effects occur, and if they do, what properties they have. We precisely answer these questions by providing theoretical properties which hold in various settings, and prove that expected out-of-cluster loss behavior rapidly decays with even minor clustering errors. Fortunately, we are able to leverage these same properties to construct hypothesis tests and scalable estimators necessary for correcting the problem. Empirical results on benchmark datasets validate our theoretical results and demonstrate how scaling techniques provide solutions to new classes of problems.

</details>

<details>

<summary>2018-12-29 03:04:26 - Weakly-Supervised Hierarchical Text Classification</summary>

- *Yu Meng, Jiaming Shen, Chao Zhang, Jiawei Han*

- `1812.11270v1` - [abs](http://arxiv.org/abs/1812.11270v1) - [pdf](http://arxiv.org/pdf/1812.11270v1)

> Hierarchical text classification, which aims to classify text documents into a given hierarchy, is an important task in many real-world applications. Recently, deep neural models are gaining increasing popularity for text classification due to their expressive power and minimum requirement for feature engineering. However, applying deep neural networks for hierarchical text classification remains challenging, because they heavily rely on a large amount of training data and meanwhile cannot easily determine appropriate levels of documents in the hierarchical setting. In this paper, we propose a weakly-supervised neural method for hierarchical text classification. Our method does not require a large amount of training data but requires only easy-to-provide weak supervision signals such as a few class-related documents or keywords. Our method effectively leverages such weak supervision signals to generate pseudo documents for model pre-training, and then performs self-training on real unlabeled data to iteratively refine the model. During the training process, our model features a hierarchical neural structure, which mimics the given hierarchy and is capable of determining the proper levels for documents with a blocking mechanism. Experiments on three datasets from different domains demonstrate the efficacy of our method compared with a comprehensive set of baselines.

</details>

<details>

<summary>2018-12-29 14:21:19 - StarAlgo: A Squad Movement Planning Library for StarCraft using Monte Carlo Tree Search and Negamax</summary>

- *Mykyta Viazovskyi, Michal Certicky*

- `1812.11371v1` - [abs](http://arxiv.org/abs/1812.11371v1) - [pdf](http://arxiv.org/pdf/1812.11371v1)

> Real-Time Strategy (RTS) games have recently become a popular testbed for artificial intelligence research. They represent a complex adversarial domain providing a number of interesting AI challenges. There exists a wide variety of research-supporting software tools, libraries and frameworks for one RTS game in particular -- StarCraft: Brood War. These tools are designed to address various specific sub-problems, such as resource allocation or opponent modelling so that researchers can focus exclusively on the tasks relevant to them. We present one such tool -- a library called StarAlgo that produces plans for the coordinated movement of squads (groups of combat units) within the game world. StarAlgo library can solve the squad movement planning problem using one of two algorithms: Monte Carlo Tree Search Considering Durations (MCTSCD) and a slightly modified version of Negamax. We evaluate both the algorithms, compare them, and demonstrate their usage. The library is implemented as a static C++ library that can be easily plugged into most StarCraft AI bots.

</details>

<details>

<summary>2018-12-29 16:11:01 - SLIM LSTMs</summary>

- *Fathi M. Salem*

- `1812.11391v1` - [abs](http://arxiv.org/abs/1812.11391v1) - [pdf](http://arxiv.org/pdf/1812.11391v1)

> Long Short-Term Memory (LSTM) Recurrent Neural networks (RNNs) rely on gating signals, each driven by a function of a weighted sum of at least 3 components: (i) one of an adaptive weight matrix multiplied by the incoming external input vector sequence, (ii) one adaptive weight matrix multiplied by the previous memory/state vector, and (iii) one adaptive bias vector. In effect, they augment the simple Recurrent Neural Networks (sRNNs) structure with the addition of a "memory cell" and the incorporation of at most 3 gating signals.   The standard LSTM structure and components encompass redundancy and overly increased parameterization. In this paper, we systemically introduce variants of the LSTM RNNs, referred to as SLIM LSTMs. These variants express aggressively reduced parameterizations to achieve computational saving and/or speedup in (training) performance---while necessarily retaining (validation accuracy) performance comparable to the standard LSTM RNN.

</details>

<details>

<summary>2018-12-30 05:37:19 - Toward the Engineering of Virtuous Machines</summary>

- *Naveen Sundar Govindarajulu, Selmer Bringsjord, Rikhiya Ghosh*

- `1812.03868v2` - [abs](http://arxiv.org/abs/1812.03868v2) - [pdf](http://arxiv.org/pdf/1812.03868v2)

> While various traditions under the 'virtue ethics' umbrella have been studied extensively and advocated by ethicists, it has not been clear that there exists a version of virtue ethics rigorous enough to be a target for machine ethics (which we take to include the engineering of an ethical sensibility in a machine or robot itself, not only the study of ethics in the humans who might create artificial agents). We begin to address this by presenting an embryonic formalization of a key part of any virtue-ethics theory: namely, the learning of virtue by a focus on exemplars of moral virtue. Our work is based in part on a computational formal logic previously used to formally model other ethical theories and principles therein, and to implement these models in artificial agents.

</details>

<details>

<summary>2018-12-30 06:56:06 - Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning</summary>

- *Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Luke Vilnis, Ishan Durugkar, Akshay Krishnamurthy, Alex Smola, Andrew McCallum*

- `1711.05851v2` - [abs](http://arxiv.org/abs/1711.05851v2) - [pdf](http://arxiv.org/pdf/1711.05851v2)

> Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. A popular approach to KB completion is to infer new relations by combinatory reasoning over the information found along other paths connecting a pair of entities. Given the enormous size of KBs and the exponential number of paths, previous path-based models have considered only the problem of predicting a missing relation given two entities or evaluating the truth of a proposed triple. Additionally, these methods have traditionally used random paths between fixed entity pairs or more recently learned to pick paths between them. We propose a new algorithm MINERVA, which addresses the much more difficult and practical task of answering questions where the relation is known, but only one entity. Since random walks are impractical in a setting with combinatorially many destinations from a start node, we present a neural reinforcement learning approach which learns how to navigate the graph conditioned on the input query to find predictive paths. Empirically, this approach obtains state-of-the-art results on several datasets, significantly outperforming prior methods.

</details>

<details>

<summary>2018-12-30 09:19:55 - Impact of Ground Truth Annotation Quality on Performance of Semantic Image Segmentation of Traffic Conditions</summary>

- *Vlad Taran, Yuri Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii Stirenko*

- `1901.00001v1` - [abs](http://arxiv.org/abs/1901.00001v1) - [pdf](http://arxiv.org/pdf/1901.00001v1)

> Preparation of high-quality datasets for the urban scene understanding is a labor-intensive task, especially, for datasets designed for the autonomous driving applications. The application of the coarse ground truth (GT) annotations of these datasets without detriment to the accuracy of semantic image segmentation (by the mean intersection over union - mIoU) could simplify and speedup the dataset preparation and model fine tuning before its practical application. Here the results of the comparative analysis for semantic segmentation accuracy obtained by PSPNet deep learning architecture are presented for fine and coarse annotated images from Cityscapes dataset. Two scenarios were investigated: scenario 1 - the fine GT images for training and prediction, and scenario 2 - the fine GT images for training and the coarse GT images for prediction. The obtained results demonstrated that for the most important classes the mean accuracy values of semantic image segmentation for coarse GT annotations are higher than for the fine GT ones, and the standard deviation values are vice versa. It means that for some applications some unimportant classes can be excluded and the model can be tuned further for some classes and specific regions on the coarse GT dataset without loss of the accuracy even. Moreover, this opens the perspectives to use deep neural networks for the preparation of such coarse GT datasets.

</details>

<details>

<summary>2018-12-30 18:42:08 - Leishmaniasis Parasite Segmentation and Classification using Deep Learning</summary>

- *Marc Górriz, Albert Aparicio, Berta Raventós, Verónica Vilaplana, Elisa Sayrol, Daniel López-Codina*

- `1812.11586v1` - [abs](http://arxiv.org/abs/1812.11586v1) - [pdf](http://arxiv.org/pdf/1812.11586v1)

> Leishmaniasis is considered a neglected disease that causes thousands of deaths annually in some tropical and subtropical countries. There are various techniques to diagnose leishmaniasis of which manual microscopy is considered to be the gold standard. There is a need for the development of automatic techniques that are able to detect parasites in a robust and unsupervised manner. In this paper we present a procedure for automatizing the detection process based on a deep learning approach. We train a U-net model that successfully segments leismania parasites and classifies them into promastigotes, amastigotes and adhered parasites.

</details>

<details>

<summary>2018-12-30 18:50:35 - Sentiment Classification of Customer Reviews about Automobiles in Roman Urdu</summary>

- *Moin Khan, Kamran Malik*

- `1812.11587v1` - [abs](http://arxiv.org/abs/1812.11587v1) - [pdf](http://arxiv.org/pdf/1812.11587v1)

> Text mining is a broad field having sentiment mining as its important constituent in which we try to deduce the behavior of people towards a specific item, merchandise, politics, sports, social media comments, review sites etc. Out of many issues in sentiment mining, analysis and classification, one major issue is that the reviews and comments can be in different languages like English, Arabic, Urdu etc. Handling each language according to its rules is a difficult task. A lot of research work has been done in English Language for sentiment analysis and classification but limited sentiment analysis work is being carried out on other regional languages like Arabic, Urdu and Hindi. In this paper, Waikato Environment for Knowledge Analysis (WEKA) is used as a platform to execute different classification models for text classification of Roman Urdu text. Reviews dataset has been scrapped from different automobiles sites. These extracted Roman Urdu reviews, containing 1000 positive and 1000 negative reviews, are then saved in WEKA attribute-relation file format (arff) as labeled examples. Training is done on 80% of this data and rest of it is used for testing purpose which is done using different models and results are analyzed in each case. The results show that Multinomial Naive Bayes outperformed Bagging, Deep Neural Network, Decision Tree, Random Forest, AdaBoost, k-NN and SVM Classifiers in terms of more accuracy, precision, recall and F-measure.

</details>

<details>

<summary>2018-12-30 18:51:37 - Cascaded V-Net using ROI masks for brain tumor segmentation</summary>

- *Adrià Casamitjana, Marcel Catà, Irina Sánchez, Marc Combalia, Verónica Vilaplana*

- `1812.11588v1` - [abs](http://arxiv.org/abs/1812.11588v1) - [pdf](http://arxiv.org/pdf/1812.11588v1)

> In this work we approach the brain tumor segmentation problem with a cascade of two CNNs inspired in the V-Net architecture \cite{VNet}, reformulating residual connections and making use of ROI masks to constrain the networks to train only on relevant voxels. This architecture allows dense training on problems with highly skewed class distributions, such as brain tumor segmentation, by focusing training only on the vecinity of the tumor area. We report results on BraTS2017 Training and Validation sets.

</details>

<details>

<summary>2018-12-31 02:26:48 - ADMM-NN: An Algorithm-Hardware Co-Design Framework of DNNs Using Alternating Direction Method of Multipliers</summary>

- *Ao Ren, Tianyun Zhang, Shaokai Ye, Jiayu Li, Wenyao Xu, Xuehai Qian, Xue Lin, Yanzhi Wang*

- `1812.11677v1` - [abs](http://arxiv.org/abs/1812.11677v1) - [pdf](http://arxiv.org/pdf/1812.11677v1)

> To facilitate efficient embedded and hardware implementations of deep neural networks (DNNs), two important categories of DNN model compression techniques: weight pruning and weight quantization are investigated. The former leverages the redundancy in the number of weights, whereas the latter leverages the redundancy in bit representation of weights. However, there lacks a systematic framework of joint weight pruning and quantization of DNNs, thereby limiting the available model compression ratio. Moreover, the computation reduction, energy efficiency improvement, and hardware performance overhead need to be accounted for besides simply model size reduction.   To address these limitations, we present ADMM-NN, the first algorithm-hardware co-optimization framework of DNNs using Alternating Direction Method of Multipliers (ADMM), a powerful technique to deal with non-convex optimization problems with possibly combinatorial constraints. The first part of ADMM-NN is a systematic, joint framework of DNN weight pruning and quantization using ADMM. It can be understood as a smart regularization technique with regularization target dynamically updated in each ADMM iteration, thereby resulting in higher performance in model compression than prior work. The second part is hardware-aware DNN optimizations to facilitate hardware-level implementations.   Without accuracy loss, we can achieve 85$\times$ and 24$\times$ pruning on LeNet-5 and AlexNet models, respectively, significantly higher than prior work. The improvement becomes more significant when focusing on computation reductions. Combining weight pruning and quantization, we achieve 1,910$\times$ and 231$\times$ reductions in overall model size on these two benchmarks, when focusing on data storage. Highly promising results are also observed on other representative DNNs such as VGGNet and ResNet-50.

</details>

<details>

<summary>2018-12-31 05:32:23 - T-GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction</summary>

- *Ling Zhao, Yujiao Song, Chao Zhang, Yu Liu, Pu Wang, Tao Lin, Min Deng, Haifeng Li*

- `1811.05320v3` - [abs](http://arxiv.org/abs/1811.05320v3) - [pdf](http://arxiv.org/pdf/1811.05320v3)

> Accurate and real-time traffic forecasting plays an important role in the Intelligent Traffic System and is of great significance for urban traffic planning, traffic management, and traffic control. However, traffic forecasting has always been considered an open scientific issue, owing to the constraints of urban road network topological structure and the law of dynamic change with time, namely, spatial dependence and temporal dependence. To capture the spatial and temporal dependence simultaneously, we propose a novel neural network-based traffic forecasting method, the temporal graph convolutional network (T-GCN) model, which is in combination with the graph convolutional network (GCN) and gated recurrent unit (GRU). Specifically, the GCN is used to learn complex topological structures to capture spatial dependence and the gated recurrent unit is used to learn dynamic changes of traffic data to capture temporal dependence. Then, the T-GCN model is employed to traffic forecasting based on the urban road network. Experiments demonstrate that our T-GCN model can obtain the spatio-temporal correlation from traffic data and the predictions outperform state-of-art baselines on real-world traffic datasets. Our tensorflow implementation of the T-GCN is available at https://github.com/lehaifeng/T-GCN.

</details>

<details>

<summary>2018-12-31 09:24:36 - Batch Size Influence on Performance of Graphic and Tensor Processing Units during Training and Inference Phases</summary>

- *Yuriy Kochura, Yuri Gordienko, Vlad Taran, Nikita Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii Stirenko*

- `1812.11731v1` - [abs](http://arxiv.org/abs/1812.11731v1) - [pdf](http://arxiv.org/pdf/1812.11731v1)

> The impact of the maximally possible batch size (for the better runtime) on performance of graphic processing units (GPU) and tensor processing units (TPU) during training and inference phases is investigated. The numerous runs of the selected deep neural network (DNN) were performed on the standard MNIST and Fashion-MNIST datasets. The significant speedup was obtained even for extremely low-scale usage of Google TPUv2 units (8 cores only) in comparison to the quite powerful GPU NVIDIA Tesla K80 card with the speedup up to 10x for training stage (without taking into account the overheads) and speedup up to 2x for prediction stage (with and without taking into account overheads). The precise speedup values depend on the utilization level of TPUv2 units and increase with the increase of the data volume under processing, but for the datasets used in this work (MNIST and Fashion-MNIST with images of sizes 28x28) the speedup was observed for batch sizes >512 images for training phase and >40 000 images for prediction phase. It should be noted that these results were obtained without detriment to the prediction accuracy and loss that were equal for both GPU and TPU runs up to the 3rd significant digit for MNIST dataset, and up to the 2nd significant digit for Fashion-MNIST dataset.

</details>

<details>

<summary>2018-12-31 15:16:18 - Backplay: "Man muss immer umkehren"</summary>

- *Cinjon Resnick, Roberta Raileanu, Sanyam Kapoor, Alexander Peysakhovich, Kyunghyun Cho, Joan Bruna*

- `1807.06919v4` - [abs](http://arxiv.org/abs/1807.06919v4) - [pdf](http://arxiv.org/pdf/1807.06919v4)

> Model-free reinforcement learning (RL) requires a large number of trials to learn a good policy, especially in environments with sparse rewards. We explore a method to improve the sample efficiency when we have access to demonstrations. Our approach, Backplay, uses a single demonstration to construct a curriculum for a given task. Rather than starting each training episode in the environment's fixed initial state, we start the agent near the end of the demonstration and move the starting point backwards during the course of training until we reach the initial state. Our contributions are that we analytically characterize the types of environments where Backplay can improve training speed, demonstrate the effectiveness of Backplay both in large grid worlds and a complex four player zero-sum game (Pommerman), and show that Backplay compares favorably to other competitive methods known to improve sample efficiency. This includes reward shaping, behavioral cloning, and reverse curriculum generation.

</details>

<details>

<summary>2018-12-31 15:50:53 - A shortest-path based clustering algorithm for joint human-machine analysis of complex datasets</summary>

- *Diego Ulisse Pizzagalli, Santiago Fernandez Gonzalez, Rolf Krause*

- `1812.11850v1` - [abs](http://arxiv.org/abs/1812.11850v1) - [pdf](http://arxiv.org/pdf/1812.11850v1)

> Clustering is a technique for the analysis of datasets obtained by empirical studies in several disciplines with a major application for biomedical research. Essentially, clustering algorithms are executed by machines aiming at finding groups of related points in a dataset. However, the result of grouping depends on both metrics for point-to-point similarity and rules for point-to-group association. Indeed, non-appropriate metrics and rules can lead to undesirable clustering artifacts. This is especially relevant for datasets, where groups with heterogeneous structures co-exist. In this work, we propose an algorithm that achieves clustering by exploring the paths between points. This allows both, to evaluate the properties of the path (such as gaps, density variations, etc.), and expressing the preference for certain paths. Moreover, our algorithm supports the integration of existing knowledge about admissible and non-admissible clusters by training a path classifier. We demonstrate the accuracy of the proposed method on challenging datasets including points from synthetic shapes in publicly available benchmarks and microscopy data.

</details>

<details>

<summary>2018-12-31 18:39:58 - Differentiable Satisfiability and Differentiable Answer Set Programming for Sampling-Based Multi-Model Optimization</summary>

- *Matthias Nickles*

- `1812.11948v1` - [abs](http://arxiv.org/abs/1812.11948v1) - [pdf](http://arxiv.org/pdf/1812.11948v1)

> We propose Differentiable Satisfiability and Differentiable Answer Set Programming (Differentiable SAT/ASP) for multi-model optimization. Models (answer sets or satisfying truth assignments) are sampled using a novel SAT/ASP solving approach which uses a gradient descent-based branching mechanism. Sampling proceeds until the value of a user-defined multi-model cost function reaches a given threshold. As major use cases for our approach we propose distribution-aware model sampling and expressive yet scalable probabilistic logic programming. As our main algorithmic approach to Differentiable SAT/ASP, we introduce an enhancement of the state-of-the-art CDNL/CDCL algorithm for SAT/ASP solving. Additionally, we present alternative algorithms which use an unmodified ASP solver (Clingo/clasp) and map the optimization task to conventional answer set optimization or use so-called propagators. We also report on the open source software DelSAT, a recent prototype implementation of our main algorithm, and on initial experimental results which indicate that DelSATs performance is, when applied to the use case of probabilistic logic inference, on par with Markov Logic Network (MLN) inference performance, despite having advantageous properties compared to MLNs, such as the ability to express inductive definitions and to work with probabilities as weights directly in all cases. Our experiments also indicate that our main algorithm is strongly superior in terms of performance compared to the presented alternative approaches which reduce a common instance of the general problem to regular SAT/ASP.

</details>

<details>

<summary>2018-12-31 20:25:14 - Connectionist Recommendation in the Wild: On the utility and scrutability of neural networks for personalized course guidance</summary>

- *Zachary A. Pardos, Zihao Fan, Weijie Jiang*

- `1803.09535v3` - [abs](http://arxiv.org/abs/1803.09535v3) - [pdf](http://arxiv.org/pdf/1803.09535v3)

> The aggregate behaviors of users can collectively encode deep semantic information about the objects with which they interact. In this paper, we demonstrate novel ways in which the synthesis of these data can illuminate the terrain of users' environment and support them in their decision making and wayfinding. A novel application of Recurrent Neural Networks and skip-gram models, approaches popularized by their application to modeling language, are brought to bear on student university enrollment sequences to create vector representations of courses and map out traversals across them. We present demonstrations of how scrutability from these neural networks can be gained and how the combination of these techniques can be seen as an evolution of content tagging and a means for a recommender to balance user preferences inferred from data with those explicitly specified. From validation of the models to the development of a UI, we discuss additional requisite functionality informed by the results of a usability study leading to the ultimate deployment of the system at a university.

</details>

<details>

<summary>2018-12-31 23:23:07 - Deep Learning to Improve Breast Cancer Early Detection on Screening Mammography</summary>

- *Li Shen, Laurie R. Margolies, Joseph H. Rothstein, Eugene Fluder, Russell B. McBride, Weiva Sieh*

- `1708.09427v5` - [abs](http://arxiv.org/abs/1708.09427v5) - [pdf](http://arxiv.org/pdf/1708.09427v5)

> The rapid development of deep learning, a family of machine learning techniques, has spurred much interest in its application to medical imaging problems. Here, we develop a deep learning algorithm that can accurately detect breast cancer on screening mammograms using an "end-to-end" training approach that efficiently leverages training datasets with either complete clinical annotation or only the cancer status (label) of the whole image. In this approach, lesion annotations are required only in the initial training stage, and subsequent stages require only image-level labels, eliminating the reliance on rarely available lesion annotations. Our all convolutional network method for classifying screening mammograms attained excellent performance in comparison with previous methods. On an independent test set of digitized film mammograms from Digital Database for Screening Mammography (DDSM), the best single model achieved a per-image AUC of 0.88, and four-model averaging improved the AUC to 0.91 (sensitivity: 86.1%, specificity: 80.1%). On a validation set of full-field digital mammography (FFDM) images from the INbreast database, the best single model achieved a per-image AUC of 0.95, and four-model averaging improved the AUC to 0.98 (sensitivity: 86.7%, specificity: 96.1%). We also demonstrate that a whole image classifier trained using our end-to-end approach on the DDSM digitized film mammograms can be transferred to INbreast FFDM images using only a subset of the INbreast data for fine-tuning and without further reliance on the availability of lesion annotations. These findings show that automatic deep learning methods can be readily trained to attain high accuracy on heterogeneous mammography platforms, and hold tremendous promise for improving clinical tools to reduce false positive and false negative screening mammography results.

</details>

